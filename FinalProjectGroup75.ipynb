{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalProjectGroup75.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "FedYxVZmQGkN"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "XnOLRrPRING4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **FinalProject** - Group 75"
      ]
    },
    {
      "metadata": {
        "id": "I9S38qB0I6t8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generic Utilities\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "gISuc2AxOJYg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn.init as init\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4IMz592RFFNy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH = '/gdrive/My Drive/COMP551/FinalProject-Group75'   # path to FinalProject folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dxWaYrTRDu-H",
        "colab_type": "code",
        "outputId": "6ca4ea88-baca-42a6-92dd-db13dbd41c51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "79qPQMHFVXyP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "n_epoches = 75\n",
        "batch_size = 64\n",
        "log_freq = 25\n",
        "learning_rate = 0.01\n",
        "momentum = 0.9\n",
        "\n",
        "cudnn.benchmark = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b-7xVlCAS9T3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t_wjXlqzisxk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_rs5XUDATxKm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
        "    lr = learning_rate * (0.1 ** (epoch // 30))\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QygTF3qsDcVR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Construct dataset"
      ]
    },
    {
      "metadata": {
        "id": "36DQj-ZybujV",
        "colab_type": "code",
        "outputId": "6694db49-91c3-462a-e559-d445a9c93de1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "val_image_path = os.path.join(PATH, 'tiny-imagenet-200', 'val', 'images')\n",
        "\n",
        "val_ids = []\n",
        "val_images = {}\n",
        "print(\"Loading validation images...\")\n",
        "for i in range(10000):\n",
        "  id = \"val_\" + str(i) + \".JPEG\"\n",
        "  val_ids.append(id)\n",
        "  img = Image.open(val_image_path+\"/\"+id)\n",
        "  val_images[id] = img.convert('RGB')\n",
        "  \n",
        "  if (i+1)%100==0:\n",
        "    print(str((i+1)/100) + '% ', end='')\n",
        "print(\"\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading validation images...\n",
            "1.0% 2.0% 3.0% 4.0% 5.0% 6.0% 7.0% 8.0% 9.0% 10.0% 11.0% 12.0% 13.0% 14.0% 15.0% 16.0% 17.0% 18.0% 19.0% 20.0% 21.0% 22.0% 23.0% 24.0% 25.0% 26.0% 27.0% 28.0% 29.0% 30.0% 31.0% 32.0% 33.0% 34.0% 35.0% 36.0% 37.0% 38.0% 39.0% 40.0% 41.0% 42.0% 43.0% 44.0% 45.0% 46.0% 47.0% 48.0% 49.0% 50.0% 51.0% 52.0% 53.0% 54.0% 55.0% 56.0% 57.0% 58.0% 59.0% 60.0% 61.0% 62.0% 63.0% 64.0% 65.0% 66.0% 67.0% 68.0% 69.0% 70.0% 71.0% 72.0% 73.0% 74.0% 75.0% 76.0% 77.0% 78.0% 79.0% 80.0% 81.0% 82.0% 83.0% 84.0% 85.0% 86.0% 87.0% 88.0% 89.0% 90.0% 91.0% 92.0% 93.0% 94.0% 95.0% 96.0% 97.0% 98.0% 99.0% 100.0% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v3t6_kSn3A0o",
        "colab_type": "code",
        "outputId": "26b3cccd-1828-4523-b7e0-133d974e676a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "val_annot_path = os.path.join(PATH, 'tiny-imagenet-200', 'val', 'val_annotations.txt')\n",
        "\n",
        "val_targets = {}\n",
        "labels = []\n",
        "print(\"Loading validation targets...\")\n",
        "with open(val_annot_path, 'r') as fo:\n",
        "  for line in fo: \n",
        "    line = line.split('\\t')\n",
        "    val_targets[line[0]] = line[1]\n",
        "    if not line[1] in labels:\n",
        "      labels.append(line[1])\n",
        "\n",
        "# encode labels\n",
        "labels.sort()\n",
        "for id, target in val_targets.items():\n",
        "  val_targets[id] = labels.index(target)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading validation targets...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "04Nwe99yrRXp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Dataset(data.Dataset):\n",
        "  def __init__(self, ids, inputs, targets, transform=None):\n",
        "    self.ids = ids\n",
        "    self.inputs = inputs\n",
        "    self.targets = targets\n",
        "    self.transform = transform\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.ids)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    id = self.ids[index]\n",
        "    \n",
        "    X = self.inputs[id]\n",
        "    y = self.targets[id]\n",
        "    \n",
        "    if self.transform:\n",
        "      X = self.transform(X)\n",
        "      \n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6tINPXe0wu_O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "\n",
        "train_set = Dataset(val_ids[:8000], val_images, val_targets, transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "]))\n",
        "train_loader = data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_set = Dataset(val_ids[8000:], val_images, val_targets, transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "]))\n",
        "val_loader = data.DataLoader(val_set, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YVXtdik1P4ma",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define train/validate functions"
      ]
    },
    {
      "metadata": {
        "id": "1Q5U0op3P_jm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(train_loader, model, criterion, optimizer, epoch):\n",
        "  batch_time = AverageMeter()\n",
        "  losses = AverageMeter()\n",
        "  top1 = AverageMeter()\n",
        "  top5 = AverageMeter()\n",
        "  \n",
        "  model.train()\n",
        "  \n",
        "  end = time.time()\n",
        "  for i, (input, target) in enumerate(train_loader):\n",
        "    target = target.cuda(async=True)\n",
        "    input_var = torch.autograd.Variable(input)\n",
        "    target_var = torch.autograd.Variable(target)\n",
        "    \n",
        "    # compute output\n",
        "    output = model(input_var)\n",
        "    loss = criterion(output, target_var)\n",
        "    losses.update(loss.data.item(), input.size()[0])\n",
        "    \n",
        "    # measure accuracy \n",
        "    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
        "    top1.update(prec1, input.size()[0])\n",
        "    top5.update(prec5, input.size()[0])\n",
        "    \n",
        "    # compute gradient and do backpropagation \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # measure time\n",
        "    batch_time.update(time.time() - end)\n",
        "    end = time.time()\n",
        "    \n",
        "    # print to screen\n",
        "    if (i+1)%log_freq == 0:\n",
        "      print('Epoch: {0}[{1}/{2}]\\t'\n",
        "            'Time used: {batch_time.val:.3f} (avg: {batch_time.avg:.3f})\\t'\n",
        "            'Loss: {loss.val:.4f} (avg: {loss.avg:.4f})\\t'\n",
        "            'Top1: {top1.val:.3f} (avg: {top1.avg:.3f})\\t'\n",
        "            'Top5: {top5.val:.3f} (avg: {top5.avg:.3f})\\t'.format(epoch, i+1, len(train_loader), batch_time=batch_time, loss=losses, top1=top1, top5=top5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w5ncMF2-0Xom",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def validate(valid_loader, model, criterion):\n",
        "  batch_time = AverageMeter()\n",
        "  losses = AverageMeter()\n",
        "  top1 = AverageMeter()\n",
        "  top5 = AverageMeter()\n",
        "  \n",
        "  model.eval()\n",
        "  \n",
        "  end = time.time()\n",
        "  for i, (input, target) in enumerate(valid_loader):\n",
        "    target = target.cuda(async=True)\n",
        "    input_var = torch.autograd.Variable(input)\n",
        "    target_var = torch.autograd.Variable(target)\n",
        "    \n",
        "    # compute output\n",
        "    output = model(input_var)\n",
        "    loss = criterion(output, target_var)\n",
        "    losses.update(loss.data.item(), input.size()[0])\n",
        "    \n",
        "    # measure accuracy \n",
        "    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
        "    top1.update(prec1, input.size()[0])\n",
        "    top5.update(prec5, input.size()[0])\n",
        "    \n",
        "    # measure time\n",
        "    batch_time.update(time.time() - end)\n",
        "    end = time.time()\n",
        "      \n",
        "  print(\"Loss: {loss.val:.4f}\\tTop 1 accuracy: {top1.avg:.3f}\\tTop 5 accuracy: {top5.avg:.3f}\".format(loss=losses, top1=top1, top5=top5))\n",
        "  \n",
        "  return batch_time.avg, top1.avg, top5.avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kGzyICnGIkUV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_model(model):\n",
        "  model_name = model.name()\n",
        "  model = torch.nn.DataParallel(model).cuda()\n",
        "  criterion = nn.CrossEntropyLoss().cuda()\n",
        "  optimizer = optim.SGD(model.parameters(), learning_rate, momentum=momentum)\n",
        "  \n",
        "  best_batch_time = 0\n",
        "  best_top1 = 0\n",
        "  best_top5 = 0\n",
        "  for epoch in range(n_epoches):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    \n",
        "    # train the model\n",
        "    print(\"Training...\")\n",
        "    train(train_loader, model, criterion, optimizer, epoch)\n",
        "    print(\"\")\n",
        "    \n",
        "    # validate\n",
        "    print(\"Validating...\")\n",
        "    batch_time, top1, top5 = validate(val_loader, model, criterion)\n",
        "    print(\"\")\n",
        "    \n",
        "    # save checkpoint \n",
        "    torch.save({'epoch': epoch, \n",
        "               'model_state_dict': model.state_dict(),\n",
        "               'optimizer_state_dict': model.state_dict(),\n",
        "               'top1_accuracy': top1,\n",
        "               'top5_accuracy': top5},\n",
        "              PATH+'/output/'+model_name+'_checkpoint.tar')\n",
        "    \n",
        "    # save the model with the best top5 accuracy\n",
        "    if top5 > best_top5:\n",
        "      best_batch_time = batch_time\n",
        "      best_top1 = top1\n",
        "      best_top5 = top5\n",
        "      torch.save({'epoch': epoch, \n",
        "               'model_state_dict': model.state_dict(),\n",
        "               'optimizer_state_dict': model.state_dict(),\n",
        "               'top1_accuracy': top1,\n",
        "               'top5_accuracy': top5},\n",
        "              PATH+'/output/'+model_name+'_best.tar')\n",
        "  \n",
        "  return best_batch_time, best_top1, best_top5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kxy729BufcKH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models"
      ]
    },
    {
      "metadata": {
        "id": "-VyUiFH9fiIT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### SqueezeNet"
      ]
    },
    {
      "metadata": {
        "id": "xozmQ80-ffEW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze(x))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1(x)),\n",
        "            self.expand3x3_activation(self.expand3x3(x))\n",
        "        ], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EZ7eHRzXgFri",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SqueezeNet(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=200):\n",
        "        super(SqueezeNet, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "      \n",
        "    def name(self):\n",
        "      return \"SqueezeNet\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5W6jwBdEaSbw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SqueezeNet_MetaParam(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=200, base=128, incr=128, pct=0.5, freq=2, sr=0.125):\n",
        "        super(SqueezeNet_MetaParam, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "            \n",
        "        self.num_classes = num_classes\n",
        "        self.base = base\n",
        "        self.incr = incr\n",
        "        self.pct = pct\n",
        "        self.freq = freq\n",
        "        self.sr = sr\n",
        "        \n",
        "        if version == 1.0:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, int(base*sr), int(base*(1-pct)), int(base*pct)),\n",
        "                Fire(int(base), int((base+1//freq*incr)*sr), int((base+1//freq*incr)*(1-pct)), int((base+1//freq*incr)*pct)),\n",
        "                Fire(int(base+1//freq*incr), int((base+2//freq*incr)*sr), int((base+2//freq*incr)*(1-pct)), int((base+2//freq*incr)*pct)),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(int(base+2//freq*incr), int((base+3//freq*incr)*sr), int((base+3//freq*incr)*(1-pct)), int((base+3//freq*incr)*pct)),\n",
        "                Fire(int(base+3//freq*incr), int((base+4//freq*incr)*sr), int((base+4//freq*incr)*(1-pct)), int((base+4//freq*incr)*pct)),\n",
        "                Fire(int(base+4//freq*incr), int((base+5//freq*incr)*sr), int((base+5//freq*incr)*(1-pct)), int((base+5//freq*incr)*pct)),\n",
        "                Fire(int(base+5//freq*incr), int((base+6//freq*incr)*sr), int((base+6//freq*incr)*(1-pct)), int((base+6//freq*incr)*pct)),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(int(base+6//freq*incr), int((base+7//freq*incr)*sr), int((base+7//freq*incr)*(1-pct)), int((base+7//freq*incr)*pct)),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(int(base+7//freq*incr), self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "      \n",
        "    def name(self):\n",
        "      return \"SqueezeNet_MetaParam\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GzAVFl5ZDGEX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Downsampling at different times "
      ]
    },
    {
      "metadata": {
        "id": "VrCAZI5cDLWX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SqueezeNet_Late_Pooling(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=200):\n",
        "        super(SqueezeNet_Late_Pooling, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 16, 64, 64),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "      \n",
        "    def name(self):\n",
        "      return \"SqueezeNet_Late_Pooling\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JVPr87bWDM0R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SqueezeNet_Very_Early_Pooling(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=200):\n",
        "        super(SqueezeNet_Very_Early_Pooling, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "      \n",
        "    def name(self):\n",
        "      return \"SqueezeNet_Very_Early_Pooling\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rNxaMQyVDQAs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SqueezeNet_Semi_Early_Pooling(nn.Module):\n",
        "\n",
        "    def __init__(self, version=1.0, num_classes=200):\n",
        "        super(SqueezeNet_Very_Early_Pooling, self).__init__()\n",
        "        if version not in [1.0, 1.1]:\n",
        "            raise ValueError(\"Unsupported SqueezeNet version {version}:\"\n",
        "                             \"1.0 or 1.1 expected\".format(version=version))\n",
        "        self.num_classes = num_classes\n",
        "        if version == 1.0:\n",
        "            self.features = nn.Sequential(\n",
        "                \n",
        "                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(96, 16, 64, 64),ker\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        else:\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(64, 16, 64, 64),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(128, 16, 64, 64),\n",
        "                Fire(128, 32, 128, 128),\n",
        "                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n",
        "                Fire(256, 32, 128, 128),\n",
        "                Fire(256, 48, 192, 192),\n",
        "                Fire(384, 48, 192, 192),\n",
        "                Fire(384, 64, 256, 256),\n",
        "                Fire(512, 64, 256, 256),\n",
        "            )\n",
        "        # Final convolution is initialized differently form the rest\n",
        "        final_conv = nn.Conv2d(512, self.num_classes, kernel_size=1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5),\n",
        "            final_conv,\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AvgPool2d(13, stride=1)\n",
        "        )\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                if m is final_conv:\n",
        "                    init.normal(m.weight.data, mean=0.0, std=0.01)\n",
        "                else:\n",
        "                    init.kaiming_uniform(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x.view(x.size(0), self.num_classes)\n",
        "      \n",
        "    def name(self):\n",
        "      return \"SqueezeNet_Very_Early_Pooling\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FaXgHbp0giau",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Experiments"
      ]
    },
    {
      "metadata": {
        "id": "FedYxVZmQGkN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Original Model"
      ]
    },
    {
      "metadata": {
        "id": "jOvARhcsglwC",
        "colab_type": "code",
        "outputId": "23e1e02b-531c-46d3-f121-beed34987f5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17071
        }
      },
      "cell_type": "code",
      "source": [
        "sq_model = SqueezeNet(version=1.0)\n",
        "batch_time, top1, top5 = test_model(sq_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.362 (avg: 0.496)\tLoss: 5.2963 (avg: 5.3106)\tTop1: 0.000 (avg: 0.125)\tTop5: 0.000 (avg: 1.938)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.363 (avg: 0.432)\tLoss: 5.2980 (avg: 5.3050)\tTop1: 0.000 (avg: 0.188)\tTop5: 3.125 (avg: 1.906)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.362 (avg: 0.411)\tLoss: 5.3023 (avg: 5.3028)\tTop1: 0.000 (avg: 0.354)\tTop5: 0.000 (avg: 2.146)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.360 (avg: 0.401)\tLoss: 5.2994 (avg: 5.3018)\tTop1: 0.000 (avg: 0.344)\tTop5: 3.125 (avg: 2.094)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.370 (avg: 0.395)\tLoss: 5.2984 (avg: 5.3011)\tTop1: 0.000 (avg: 0.375)\tTop5: 1.562 (avg: 2.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2947\tTop 1 accuracy: 0.400\tTop 5 accuracy: 2.200\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.365 (avg: 0.362)\tLoss: 5.2983 (avg: 5.2971)\tTop1: 0.000 (avg: 0.500)\tTop5: 4.688 (avg: 2.938)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.362 (avg: 0.366)\tLoss: 5.2948 (avg: 5.2973)\tTop1: 0.000 (avg: 0.406)\tTop5: 3.125 (avg: 2.688)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.359 (avg: 0.367)\tLoss: 5.2677 (avg: 5.2954)\tTop1: 3.125 (avg: 0.521)\tTop5: 4.688 (avg: 2.771)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.366 (avg: 0.367)\tLoss: 5.2686 (avg: 5.2902)\tTop1: 3.125 (avg: 0.516)\tTop5: 6.250 (avg: 2.859)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.366 (avg: 0.368)\tLoss: 5.2286 (avg: 5.2900)\tTop1: 1.562 (avg: 0.525)\tTop5: 4.688 (avg: 2.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2144\tTop 1 accuracy: 0.400\tTop 5 accuracy: 2.400\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.364 (avg: 0.362)\tLoss: 5.2897 (avg: 5.2691)\tTop1: 1.562 (avg: 0.938)\tTop5: 6.250 (avg: 2.312)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.364 (avg: 0.366)\tLoss: 5.2935 (avg: 5.2831)\tTop1: 0.000 (avg: 0.719)\tTop5: 1.562 (avg: 2.719)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.364 (avg: 0.368)\tLoss: 5.2812 (avg: 5.2863)\tTop1: 0.000 (avg: 0.646)\tTop5: 3.125 (avg: 2.625)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.367 (avg: 0.369)\tLoss: 5.2924 (avg: 5.2810)\tTop1: 0.000 (avg: 0.609)\tTop5: 4.688 (avg: 2.516)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.366 (avg: 0.369)\tLoss: 5.2830 (avg: 5.2784)\tTop1: 0.000 (avg: 0.600)\tTop5: 0.000 (avg: 2.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2214\tTop 1 accuracy: 0.550\tTop 5 accuracy: 3.300\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.362 (avg: 0.361)\tLoss: 5.1886 (avg: 5.2533)\tTop1: 3.125 (avg: 0.812)\tTop5: 6.250 (avg: 3.500)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.369 (avg: 0.366)\tLoss: 5.2390 (avg: 5.2486)\tTop1: 0.000 (avg: 0.781)\tTop5: 4.688 (avg: 3.594)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.368 (avg: 0.368)\tLoss: 5.2876 (avg: 5.2462)\tTop1: 0.000 (avg: 0.958)\tTop5: 1.562 (avg: 3.938)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.363 (avg: 0.369)\tLoss: 5.1663 (avg: 5.2465)\tTop1: 0.000 (avg: 0.922)\tTop5: 6.250 (avg: 4.031)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 5.2661 (avg: 5.2452)\tTop1: 1.562 (avg: 0.900)\tTop5: 1.562 (avg: 4.013)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2226\tTop 1 accuracy: 0.700\tTop 5 accuracy: 3.600\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.367 (avg: 0.362)\tLoss: 5.2068 (avg: 5.2479)\tTop1: 0.000 (avg: 0.750)\tTop5: 4.688 (avg: 4.125)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.366 (avg: 0.366)\tLoss: 5.2416 (avg: 5.2388)\tTop1: 1.562 (avg: 1.062)\tTop5: 3.125 (avg: 4.312)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.366 (avg: 0.367)\tLoss: 5.1296 (avg: 5.2273)\tTop1: 3.125 (avg: 1.083)\tTop5: 3.125 (avg: 4.792)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.359 (avg: 0.368)\tLoss: 5.3651 (avg: 5.2285)\tTop1: 1.562 (avg: 1.031)\tTop5: 1.562 (avg: 4.953)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.367 (avg: 0.369)\tLoss: 5.2462 (avg: 5.2257)\tTop1: 0.000 (avg: 1.163)\tTop5: 3.125 (avg: 4.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1926\tTop 1 accuracy: 0.750\tTop 5 accuracy: 4.200\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.368 (avg: 0.362)\tLoss: 5.2538 (avg: 5.1997)\tTop1: 0.000 (avg: 0.750)\tTop5: 1.562 (avg: 5.750)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.365 (avg: 0.365)\tLoss: 5.2156 (avg: 5.2099)\tTop1: 3.125 (avg: 0.844)\tTop5: 6.250 (avg: 5.844)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.363 (avg: 0.367)\tLoss: 5.2595 (avg: 5.2030)\tTop1: 0.000 (avg: 0.979)\tTop5: 6.250 (avg: 5.792)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.370 (avg: 0.368)\tLoss: 5.1120 (avg: 5.2081)\tTop1: 0.000 (avg: 0.969)\tTop5: 9.375 (avg: 5.531)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.361 (avg: 0.369)\tLoss: 5.1159 (avg: 5.2048)\tTop1: 0.000 (avg: 0.988)\tTop5: 3.125 (avg: 5.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0923\tTop 1 accuracy: 1.500\tTop 5 accuracy: 5.400\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.362 (avg: 0.362)\tLoss: 5.2173 (avg: 5.1891)\tTop1: 1.562 (avg: 1.125)\tTop5: 9.375 (avg: 4.812)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.362 (avg: 0.366)\tLoss: 5.2708 (avg: 5.1910)\tTop1: 0.000 (avg: 1.156)\tTop5: 1.562 (avg: 5.469)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.368 (avg: 0.368)\tLoss: 5.0541 (avg: 5.1837)\tTop1: 0.000 (avg: 1.104)\tTop5: 6.250 (avg: 5.500)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.359 (avg: 0.368)\tLoss: 5.2313 (avg: 5.1876)\tTop1: 0.000 (avg: 1.125)\tTop5: 4.688 (avg: 5.812)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.362 (avg: 0.369)\tLoss: 5.1778 (avg: 5.1887)\tTop1: 1.562 (avg: 1.125)\tTop5: 3.125 (avg: 5.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1663\tTop 1 accuracy: 1.000\tTop 5 accuracy: 5.050\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.357 (avg: 0.358)\tLoss: 5.2001 (avg: 5.1599)\tTop1: 0.000 (avg: 1.500)\tTop5: 4.688 (avg: 6.188)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.369 (avg: 0.364)\tLoss: 5.1472 (avg: 5.1654)\tTop1: 3.125 (avg: 1.562)\tTop5: 6.250 (avg: 6.344)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.359 (avg: 0.366)\tLoss: 5.1982 (avg: 5.1737)\tTop1: 0.000 (avg: 1.396)\tTop5: 1.562 (avg: 6.042)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.361 (avg: 0.367)\tLoss: 5.2343 (avg: 5.1741)\tTop1: 0.000 (avg: 1.422)\tTop5: 6.250 (avg: 5.938)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.362 (avg: 0.368)\tLoss: 5.1173 (avg: 5.1743)\tTop1: 1.562 (avg: 1.338)\tTop5: 12.500 (avg: 5.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0444\tTop 1 accuracy: 1.150\tTop 5 accuracy: 5.900\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.369 (avg: 0.361)\tLoss: 5.1461 (avg: 5.1713)\tTop1: 3.125 (avg: 0.938)\tTop5: 9.375 (avg: 6.750)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.363 (avg: 0.365)\tLoss: 5.1519 (avg: 5.1746)\tTop1: 1.562 (avg: 1.250)\tTop5: 3.125 (avg: 6.594)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.361 (avg: 0.367)\tLoss: 5.0448 (avg: 5.1697)\tTop1: 3.125 (avg: 1.375)\tTop5: 9.375 (avg: 6.500)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.364 (avg: 0.367)\tLoss: 5.0593 (avg: 5.1724)\tTop1: 0.000 (avg: 1.484)\tTop5: 7.812 (avg: 6.438)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.364 (avg: 0.368)\tLoss: 5.0886 (avg: 5.1669)\tTop1: 4.688 (avg: 1.413)\tTop5: 6.250 (avg: 6.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0778\tTop 1 accuracy: 1.450\tTop 5 accuracy: 6.400\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.360 (avg: 0.361)\tLoss: 5.1695 (avg: 5.1567)\tTop1: 1.562 (avg: 1.438)\tTop5: 3.125 (avg: 6.312)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.359 (avg: 0.366)\tLoss: 5.1842 (avg: 5.1493)\tTop1: 3.125 (avg: 1.469)\tTop5: 9.375 (avg: 6.719)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.360 (avg: 0.367)\tLoss: 5.2330 (avg: 5.1573)\tTop1: 1.562 (avg: 1.438)\tTop5: 4.688 (avg: 6.812)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.366 (avg: 0.368)\tLoss: 5.1149 (avg: 5.1620)\tTop1: 0.000 (avg: 1.375)\tTop5: 7.812 (avg: 6.547)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.364 (avg: 0.368)\tLoss: 5.0740 (avg: 5.1546)\tTop1: 1.562 (avg: 1.425)\tTop5: 9.375 (avg: 6.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0370\tTop 1 accuracy: 1.700\tTop 5 accuracy: 7.450\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.362 (avg: 0.361)\tLoss: 5.0899 (avg: 5.1421)\tTop1: 1.562 (avg: 2.250)\tTop5: 6.250 (avg: 7.688)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.362 (avg: 0.366)\tLoss: 5.1296 (avg: 5.1409)\tTop1: 1.562 (avg: 2.000)\tTop5: 4.688 (avg: 7.531)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.364 (avg: 0.368)\tLoss: 5.0507 (avg: 5.1443)\tTop1: 0.000 (avg: 1.938)\tTop5: 4.688 (avg: 7.333)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.365 (avg: 0.369)\tLoss: 5.1345 (avg: 5.1410)\tTop1: 1.562 (avg: 1.969)\tTop5: 7.812 (avg: 7.516)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.361 (avg: 0.369)\tLoss: 5.0225 (avg: 5.1413)\tTop1: 3.125 (avg: 1.950)\tTop5: 10.938 (avg: 7.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0492\tTop 1 accuracy: 1.800\tTop 5 accuracy: 7.550\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 5.2032 (avg: 5.1274)\tTop1: 0.000 (avg: 1.125)\tTop5: 4.688 (avg: 7.062)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.366 (avg: 0.366)\tLoss: 5.2109 (avg: 5.1152)\tTop1: 1.562 (avg: 1.594)\tTop5: 3.125 (avg: 7.500)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.362 (avg: 0.368)\tLoss: 5.0534 (avg: 5.1184)\tTop1: 4.688 (avg: 1.604)\tTop5: 14.062 (avg: 7.458)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.363 (avg: 0.368)\tLoss: 5.0881 (avg: 5.1282)\tTop1: 0.000 (avg: 1.609)\tTop5: 9.375 (avg: 7.297)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.363 (avg: 0.369)\tLoss: 5.1357 (avg: 5.1353)\tTop1: 1.562 (avg: 1.625)\tTop5: 9.375 (avg: 7.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0902\tTop 1 accuracy: 1.550\tTop 5 accuracy: 7.750\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.365 (avg: 0.362)\tLoss: 5.1318 (avg: 5.1229)\tTop1: 0.000 (avg: 1.812)\tTop5: 7.812 (avg: 7.812)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.363 (avg: 0.366)\tLoss: 5.0770 (avg: 5.1385)\tTop1: 1.562 (avg: 1.531)\tTop5: 9.375 (avg: 7.500)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.361 (avg: 0.368)\tLoss: 5.0365 (avg: 5.1229)\tTop1: 3.125 (avg: 1.562)\tTop5: 6.250 (avg: 7.604)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.359 (avg: 0.368)\tLoss: 5.1748 (avg: 5.1289)\tTop1: 0.000 (avg: 1.609)\tTop5: 1.562 (avg: 7.375)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.370 (avg: 0.368)\tLoss: 5.1118 (avg: 5.1197)\tTop1: 0.000 (avg: 1.725)\tTop5: 6.250 (avg: 7.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0065\tTop 1 accuracy: 1.500\tTop 5 accuracy: 6.750\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.362 (avg: 0.362)\tLoss: 5.1797 (avg: 5.0749)\tTop1: 1.562 (avg: 1.625)\tTop5: 9.375 (avg: 9.250)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.370 (avg: 0.366)\tLoss: 5.0281 (avg: 5.1008)\tTop1: 0.000 (avg: 1.594)\tTop5: 6.250 (avg: 8.219)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.362 (avg: 0.368)\tLoss: 5.0410 (avg: 5.1032)\tTop1: 0.000 (avg: 1.854)\tTop5: 7.812 (avg: 8.375)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.369 (avg: 0.368)\tLoss: 5.2755 (avg: 5.1052)\tTop1: 1.562 (avg: 1.906)\tTop5: 7.812 (avg: 8.094)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.362 (avg: 0.369)\tLoss: 5.1036 (avg: 5.1001)\tTop1: 3.125 (avg: 1.913)\tTop5: 9.375 (avg: 8.062)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8687\tTop 1 accuracy: 2.300\tTop 5 accuracy: 9.000\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.362 (avg: 0.362)\tLoss: 5.1891 (avg: 5.0841)\tTop1: 3.125 (avg: 2.500)\tTop5: 7.812 (avg: 9.375)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.361 (avg: 0.367)\tLoss: 5.1832 (avg: 5.0943)\tTop1: 0.000 (avg: 2.312)\tTop5: 4.688 (avg: 8.844)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.371 (avg: 0.368)\tLoss: 5.1295 (avg: 5.0956)\tTop1: 1.562 (avg: 2.292)\tTop5: 10.938 (avg: 8.750)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 5.0104 (avg: 5.0924)\tTop1: 0.000 (avg: 2.156)\tTop5: 4.688 (avg: 8.875)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.361 (avg: 0.369)\tLoss: 5.0456 (avg: 5.0925)\tTop1: 0.000 (avg: 2.175)\tTop5: 7.812 (avg: 8.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0929\tTop 1 accuracy: 2.400\tTop 5 accuracy: 9.350\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.361 (avg: 0.362)\tLoss: 5.1684 (avg: 5.0629)\tTop1: 1.562 (avg: 2.000)\tTop5: 3.125 (avg: 9.750)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.372 (avg: 0.367)\tLoss: 4.9739 (avg: 5.0754)\tTop1: 1.562 (avg: 1.844)\tTop5: 10.938 (avg: 8.875)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.361 (avg: 0.368)\tLoss: 5.2562 (avg: 5.0850)\tTop1: 0.000 (avg: 1.938)\tTop5: 3.125 (avg: 8.583)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.363 (avg: 0.369)\tLoss: 5.0521 (avg: 5.0744)\tTop1: 1.562 (avg: 2.281)\tTop5: 7.812 (avg: 8.922)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.362 (avg: 0.369)\tLoss: 5.1349 (avg: 5.0657)\tTop1: 3.125 (avg: 2.325)\tTop5: 4.688 (avg: 8.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0086\tTop 1 accuracy: 2.650\tTop 5 accuracy: 8.800\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.372 (avg: 0.362)\tLoss: 5.0057 (avg: 5.0055)\tTop1: 4.688 (avg: 2.562)\tTop5: 10.938 (avg: 11.062)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.363 (avg: 0.365)\tLoss: 5.0712 (avg: 5.0247)\tTop1: 3.125 (avg: 2.406)\tTop5: 10.938 (avg: 10.469)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 5.0718 (avg: 5.0243)\tTop1: 0.000 (avg: 2.458)\tTop5: 0.000 (avg: 9.938)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.361 (avg: 0.368)\tLoss: 5.1118 (avg: 5.0276)\tTop1: 0.000 (avg: 2.531)\tTop5: 4.688 (avg: 9.781)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.364 (avg: 0.368)\tLoss: 5.0503 (avg: 5.0373)\tTop1: 6.250 (avg: 2.538)\tTop5: 7.812 (avg: 9.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7957\tTop 1 accuracy: 2.000\tTop 5 accuracy: 7.150\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.362 (avg: 0.362)\tLoss: 4.9115 (avg: 5.0379)\tTop1: 1.562 (avg: 2.312)\tTop5: 12.500 (avg: 8.938)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.363 (avg: 0.366)\tLoss: 5.1624 (avg: 5.0375)\tTop1: 1.562 (avg: 2.219)\tTop5: 4.688 (avg: 8.625)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.361 (avg: 0.368)\tLoss: 4.7763 (avg: 5.0347)\tTop1: 6.250 (avg: 2.312)\tTop5: 14.062 (avg: 8.812)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.366 (avg: 0.369)\tLoss: 5.0498 (avg: 5.0330)\tTop1: 3.125 (avg: 2.422)\tTop5: 7.812 (avg: 8.969)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.365 (avg: 0.369)\tLoss: 4.9773 (avg: 5.0277)\tTop1: 3.125 (avg: 2.475)\tTop5: 9.375 (avg: 9.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0377\tTop 1 accuracy: 2.350\tTop 5 accuracy: 11.000\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 5.1341 (avg: 5.0047)\tTop1: 1.562 (avg: 2.125)\tTop5: 7.812 (avg: 10.750)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.362 (avg: 0.364)\tLoss: 4.9947 (avg: 5.0017)\tTop1: 4.688 (avg: 2.312)\tTop5: 10.938 (avg: 11.000)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.359 (avg: 0.366)\tLoss: 4.9859 (avg: 4.9937)\tTop1: 1.562 (avg: 2.646)\tTop5: 14.062 (avg: 10.875)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 5.1289 (avg: 4.9965)\tTop1: 1.562 (avg: 2.469)\tTop5: 6.250 (avg: 10.516)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.359 (avg: 0.368)\tLoss: 4.9355 (avg: 4.9913)\tTop1: 4.688 (avg: 2.525)\tTop5: 12.500 (avg: 10.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0338\tTop 1 accuracy: 3.000\tTop 5 accuracy: 10.600\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.362 (avg: 0.362)\tLoss: 4.7495 (avg: 4.9335)\tTop1: 4.688 (avg: 3.188)\tTop5: 20.312 (avg: 12.062)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.364 (avg: 0.366)\tLoss: 5.0155 (avg: 4.9727)\tTop1: 1.562 (avg: 3.156)\tTop5: 4.688 (avg: 11.094)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.367 (avg: 0.368)\tLoss: 4.9538 (avg: 4.9646)\tTop1: 6.250 (avg: 3.104)\tTop5: 12.500 (avg: 11.000)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.366 (avg: 0.369)\tLoss: 5.0561 (avg: 4.9662)\tTop1: 1.562 (avg: 2.906)\tTop5: 10.938 (avg: 10.828)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.359 (avg: 0.369)\tLoss: 4.9415 (avg: 4.9750)\tTop1: 1.562 (avg: 2.750)\tTop5: 7.812 (avg: 10.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8772\tTop 1 accuracy: 2.750\tTop 5 accuracy: 11.200\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.367 (avg: 0.362)\tLoss: 4.7153 (avg: 4.9071)\tTop1: 3.125 (avg: 2.562)\tTop5: 12.500 (avg: 11.125)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.365 (avg: 0.367)\tLoss: 4.9874 (avg: 4.9189)\tTop1: 1.562 (avg: 2.406)\tTop5: 4.688 (avg: 10.562)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.364 (avg: 0.368)\tLoss: 4.8892 (avg: 4.9126)\tTop1: 6.250 (avg: 2.708)\tTop5: 14.062 (avg: 10.979)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.362 (avg: 0.369)\tLoss: 4.8904 (avg: 4.9062)\tTop1: 3.125 (avg: 2.812)\tTop5: 9.375 (avg: 11.281)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.368 (avg: 0.370)\tLoss: 4.8398 (avg: 4.9093)\tTop1: 9.375 (avg: 2.863)\tTop5: 17.188 (avg: 11.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9687\tTop 1 accuracy: 2.100\tTop 5 accuracy: 10.000\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.364 (avg: 0.362)\tLoss: 4.7332 (avg: 4.8235)\tTop1: 3.125 (avg: 4.375)\tTop5: 20.312 (avg: 14.688)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.362 (avg: 0.366)\tLoss: 4.7464 (avg: 4.8486)\tTop1: 4.688 (avg: 3.875)\tTop5: 10.938 (avg: 12.969)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.361 (avg: 0.368)\tLoss: 4.7413 (avg: 4.8607)\tTop1: 4.688 (avg: 3.812)\tTop5: 12.500 (avg: 12.792)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.370 (avg: 0.368)\tLoss: 5.0235 (avg: 4.8582)\tTop1: 3.125 (avg: 3.766)\tTop5: 9.375 (avg: 12.828)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.365 (avg: 0.369)\tLoss: 4.7729 (avg: 4.8584)\tTop1: 4.688 (avg: 3.663)\tTop5: 15.625 (avg: 12.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9124\tTop 1 accuracy: 3.700\tTop 5 accuracy: 11.650\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.362 (avg: 0.362)\tLoss: 4.8095 (avg: 4.8470)\tTop1: 4.688 (avg: 3.625)\tTop5: 12.500 (avg: 12.375)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.360 (avg: 0.367)\tLoss: 4.8467 (avg: 4.8310)\tTop1: 1.562 (avg: 3.750)\tTop5: 12.500 (avg: 12.906)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.369 (avg: 0.369)\tLoss: 4.8990 (avg: 4.8500)\tTop1: 0.000 (avg: 3.583)\tTop5: 7.812 (avg: 12.917)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.356 (avg: 0.369)\tLoss: 4.8248 (avg: 4.8518)\tTop1: 4.688 (avg: 3.766)\tTop5: 14.062 (avg: 13.078)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.362 (avg: 0.370)\tLoss: 4.8580 (avg: 4.8454)\tTop1: 3.125 (avg: 3.763)\tTop5: 7.812 (avg: 13.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8762\tTop 1 accuracy: 3.450\tTop 5 accuracy: 11.350\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.364 (avg: 0.363)\tLoss: 4.7241 (avg: 4.8186)\tTop1: 1.562 (avg: 4.000)\tTop5: 15.625 (avg: 14.250)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.374 (avg: 0.368)\tLoss: 5.0785 (avg: 4.7966)\tTop1: 1.562 (avg: 4.188)\tTop5: 7.812 (avg: 14.406)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 4.7300 (avg: 4.7835)\tTop1: 1.562 (avg: 4.229)\tTop5: 14.062 (avg: 14.583)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.362 (avg: 0.369)\tLoss: 4.6411 (avg: 4.7829)\tTop1: 3.125 (avg: 4.203)\tTop5: 17.188 (avg: 14.406)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.360 (avg: 0.369)\tLoss: 4.7890 (avg: 4.7778)\tTop1: 4.688 (avg: 4.200)\tTop5: 12.500 (avg: 14.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6882\tTop 1 accuracy: 4.950\tTop 5 accuracy: 15.900\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.370 (avg: 0.363)\tLoss: 4.8201 (avg: 4.6986)\tTop1: 1.562 (avg: 4.875)\tTop5: 10.938 (avg: 16.625)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 4.6290 (avg: 4.6839)\tTop1: 3.125 (avg: 4.906)\tTop5: 17.188 (avg: 16.594)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 4.8180 (avg: 4.7097)\tTop1: 0.000 (avg: 4.479)\tTop5: 12.500 (avg: 16.354)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.363 (avg: 0.369)\tLoss: 4.7119 (avg: 4.7192)\tTop1: 1.562 (avg: 4.438)\tTop5: 15.625 (avg: 16.094)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.366 (avg: 0.370)\tLoss: 4.5181 (avg: 4.7199)\tTop1: 1.562 (avg: 4.438)\tTop5: 20.312 (avg: 16.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6817\tTop 1 accuracy: 4.200\tTop 5 accuracy: 15.600\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.363 (avg: 0.363)\tLoss: 4.6553 (avg: 4.6314)\tTop1: 3.125 (avg: 4.875)\tTop5: 14.062 (avg: 17.688)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.364 (avg: 0.367)\tLoss: 4.4867 (avg: 4.6767)\tTop1: 7.812 (avg: 4.844)\tTop5: 25.000 (avg: 16.594)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.362 (avg: 0.369)\tLoss: 4.7007 (avg: 4.6682)\tTop1: 7.812 (avg: 5.125)\tTop5: 14.062 (avg: 16.917)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.366 (avg: 0.369)\tLoss: 4.8170 (avg: 4.6693)\tTop1: 3.125 (avg: 5.094)\tTop5: 12.500 (avg: 16.891)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.366 (avg: 0.370)\tLoss: 4.6039 (avg: 4.6603)\tTop1: 4.688 (avg: 5.250)\tTop5: 20.312 (avg: 17.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9025\tTop 1 accuracy: 4.700\tTop 5 accuracy: 17.600\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.361 (avg: 0.363)\tLoss: 4.3924 (avg: 4.5646)\tTop1: 6.250 (avg: 6.125)\tTop5: 26.562 (avg: 19.562)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.365 (avg: 0.368)\tLoss: 4.7074 (avg: 4.5967)\tTop1: 12.500 (avg: 6.250)\tTop5: 20.312 (avg: 19.031)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.368 (avg: 0.369)\tLoss: 4.5182 (avg: 4.6094)\tTop1: 10.938 (avg: 5.938)\tTop5: 17.188 (avg: 18.667)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 4.5610 (avg: 4.6053)\tTop1: 9.375 (avg: 5.641)\tTop5: 20.312 (avg: 18.656)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 4.7145 (avg: 4.6119)\tTop1: 7.812 (avg: 5.638)\tTop5: 17.188 (avg: 18.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3896\tTop 1 accuracy: 5.200\tTop 5 accuracy: 16.950\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 4.6808 (avg: 4.5570)\tTop1: 4.688 (avg: 6.562)\tTop5: 18.750 (avg: 20.312)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.366 (avg: 0.366)\tLoss: 4.6304 (avg: 4.5741)\tTop1: 9.375 (avg: 6.719)\tTop5: 17.188 (avg: 19.469)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.366 (avg: 0.368)\tLoss: 4.4710 (avg: 4.5776)\tTop1: 9.375 (avg: 6.417)\tTop5: 26.562 (avg: 19.312)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.369 (avg: 0.369)\tLoss: 4.6482 (avg: 4.5794)\tTop1: 1.562 (avg: 6.391)\tTop5: 14.062 (avg: 19.188)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.361 (avg: 0.369)\tLoss: 4.3549 (avg: 4.5806)\tTop1: 4.688 (avg: 6.250)\tTop5: 20.312 (avg: 19.325)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5788\tTop 1 accuracy: 5.500\tTop 5 accuracy: 18.100\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.363 (avg: 0.363)\tLoss: 4.7839 (avg: 4.4753)\tTop1: 3.125 (avg: 6.875)\tTop5: 18.750 (avg: 22.000)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.364 (avg: 0.367)\tLoss: 4.9559 (avg: 4.5172)\tTop1: 1.562 (avg: 6.594)\tTop5: 10.938 (avg: 21.031)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.367 (avg: 0.369)\tLoss: 4.2929 (avg: 4.5118)\tTop1: 7.812 (avg: 6.750)\tTop5: 28.125 (avg: 21.167)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.362 (avg: 0.370)\tLoss: 4.5311 (avg: 4.5122)\tTop1: 6.250 (avg: 6.516)\tTop5: 23.438 (avg: 21.109)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.371 (avg: 0.370)\tLoss: 4.4160 (avg: 4.5067)\tTop1: 4.688 (avg: 6.325)\tTop5: 18.750 (avg: 21.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8619\tTop 1 accuracy: 5.800\tTop 5 accuracy: 19.150\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.367 (avg: 0.363)\tLoss: 4.3804 (avg: 4.4426)\tTop1: 6.250 (avg: 6.375)\tTop5: 25.000 (avg: 21.812)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.362 (avg: 0.366)\tLoss: 4.1488 (avg: 4.4524)\tTop1: 17.188 (avg: 7.219)\tTop5: 37.500 (avg: 21.812)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.363 (avg: 0.367)\tLoss: 4.3230 (avg: 4.4467)\tTop1: 7.812 (avg: 7.062)\tTop5: 26.562 (avg: 22.229)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.370 (avg: 0.368)\tLoss: 4.7421 (avg: 4.4442)\tTop1: 6.250 (avg: 7.266)\tTop5: 17.188 (avg: 22.266)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.365 (avg: 0.369)\tLoss: 4.7241 (avg: 4.4536)\tTop1: 4.688 (avg: 7.200)\tTop5: 9.375 (avg: 21.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3639\tTop 1 accuracy: 6.350\tTop 5 accuracy: 20.900\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.363 (avg: 0.363)\tLoss: 4.2634 (avg: 4.2886)\tTop1: 12.500 (avg: 9.188)\tTop5: 29.688 (avg: 25.938)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.366 (avg: 0.367)\tLoss: 4.2127 (avg: 4.2236)\tTop1: 14.062 (avg: 10.031)\tTop5: 28.125 (avg: 27.375)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.370 (avg: 0.369)\tLoss: 4.3089 (avg: 4.2054)\tTop1: 10.938 (avg: 10.021)\tTop5: 21.875 (avg: 27.896)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.369 (avg: 0.370)\tLoss: 4.3229 (avg: 4.2025)\tTop1: 4.688 (avg: 10.250)\tTop5: 20.312 (avg: 27.922)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.360 (avg: 0.370)\tLoss: 4.1353 (avg: 4.2014)\tTop1: 10.938 (avg: 10.400)\tTop5: 29.688 (avg: 27.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2437\tTop 1 accuracy: 8.600\tTop 5 accuracy: 25.000\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 4.2870 (avg: 4.1415)\tTop1: 9.375 (avg: 12.688)\tTop5: 25.000 (avg: 30.375)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.370 (avg: 0.366)\tLoss: 4.0995 (avg: 4.1234)\tTop1: 10.938 (avg: 11.312)\tTop5: 31.250 (avg: 30.219)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.365 (avg: 0.368)\tLoss: 4.0091 (avg: 4.1298)\tTop1: 14.062 (avg: 11.583)\tTop5: 35.938 (avg: 30.292)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.361 (avg: 0.369)\tLoss: 4.2868 (avg: 4.1311)\tTop1: 15.625 (avg: 11.469)\tTop5: 28.125 (avg: 30.109)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.362 (avg: 0.369)\tLoss: 4.2205 (avg: 4.1381)\tTop1: 12.500 (avg: 11.225)\tTop5: 23.438 (avg: 29.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3775\tTop 1 accuracy: 8.150\tTop 5 accuracy: 24.650\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.370 (avg: 0.363)\tLoss: 4.1354 (avg: 4.0631)\tTop1: 9.375 (avg: 12.688)\tTop5: 25.000 (avg: 33.188)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.366 (avg: 0.367)\tLoss: 4.0713 (avg: 4.1024)\tTop1: 12.500 (avg: 11.750)\tTop5: 34.375 (avg: 31.875)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.363 (avg: 0.369)\tLoss: 4.0189 (avg: 4.1042)\tTop1: 6.250 (avg: 11.875)\tTop5: 28.125 (avg: 31.104)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.360 (avg: 0.369)\tLoss: 4.0779 (avg: 4.1066)\tTop1: 14.062 (avg: 11.812)\tTop5: 25.000 (avg: 31.422)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.366 (avg: 0.369)\tLoss: 4.1129 (avg: 4.1152)\tTop1: 4.688 (avg: 11.550)\tTop5: 37.500 (avg: 30.950)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3354\tTop 1 accuracy: 8.850\tTop 5 accuracy: 25.050\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 3.9433 (avg: 4.0447)\tTop1: 15.625 (avg: 13.062)\tTop5: 35.938 (avg: 32.938)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.360 (avg: 0.365)\tLoss: 4.2415 (avg: 4.0932)\tTop1: 7.812 (avg: 12.344)\tTop5: 32.812 (avg: 31.594)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 4.0333 (avg: 4.1013)\tTop1: 7.812 (avg: 11.958)\tTop5: 40.625 (avg: 31.479)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.363 (avg: 0.368)\tLoss: 4.1709 (avg: 4.0916)\tTop1: 10.938 (avg: 11.828)\tTop5: 26.562 (avg: 31.531)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.365 (avg: 0.369)\tLoss: 4.1536 (avg: 4.0891)\tTop1: 15.625 (avg: 12.013)\tTop5: 31.250 (avg: 31.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3144\tTop 1 accuracy: 8.350\tTop 5 accuracy: 24.850\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.363 (avg: 0.363)\tLoss: 4.0195 (avg: 4.0551)\tTop1: 12.500 (avg: 12.188)\tTop5: 40.625 (avg: 32.250)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.363 (avg: 0.367)\tLoss: 3.9580 (avg: 4.0776)\tTop1: 7.812 (avg: 11.781)\tTop5: 28.125 (avg: 31.625)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.368 (avg: 0.369)\tLoss: 4.4432 (avg: 4.0826)\tTop1: 7.812 (avg: 11.625)\tTop5: 28.125 (avg: 32.062)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 4.0816 (avg: 4.0803)\tTop1: 17.188 (avg: 11.688)\tTop5: 37.500 (avg: 32.000)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.366 (avg: 0.370)\tLoss: 3.9241 (avg: 4.0817)\tTop1: 15.625 (avg: 11.625)\tTop5: 32.812 (avg: 31.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2496\tTop 1 accuracy: 8.900\tTop 5 accuracy: 25.950\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 4.4007 (avg: 4.1082)\tTop1: 7.812 (avg: 10.938)\tTop5: 28.125 (avg: 31.812)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.366 (avg: 0.367)\tLoss: 4.0630 (avg: 4.0676)\tTop1: 7.812 (avg: 11.438)\tTop5: 31.250 (avg: 32.188)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.367 (avg: 0.368)\tLoss: 3.9612 (avg: 4.0855)\tTop1: 10.938 (avg: 11.708)\tTop5: 35.938 (avg: 31.583)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.362 (avg: 0.369)\tLoss: 3.8525 (avg: 4.0665)\tTop1: 15.625 (avg: 11.844)\tTop5: 37.500 (avg: 31.938)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 3.9790 (avg: 4.0726)\tTop1: 14.062 (avg: 12.013)\tTop5: 35.938 (avg: 31.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2202\tTop 1 accuracy: 9.350\tTop 5 accuracy: 26.250\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.367 (avg: 0.362)\tLoss: 4.1447 (avg: 4.1013)\tTop1: 12.500 (avg: 12.750)\tTop5: 28.125 (avg: 31.188)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.364 (avg: 0.367)\tLoss: 3.8280 (avg: 4.0409)\tTop1: 18.750 (avg: 12.438)\tTop5: 40.625 (avg: 32.906)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.365 (avg: 0.369)\tLoss: 4.2724 (avg: 4.0361)\tTop1: 7.812 (avg: 12.792)\tTop5: 32.812 (avg: 32.812)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 4.2124 (avg: 4.0515)\tTop1: 9.375 (avg: 12.703)\tTop5: 32.812 (avg: 32.203)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.372 (avg: 0.370)\tLoss: 4.2454 (avg: 4.0618)\tTop1: 10.938 (avg: 12.575)\tTop5: 26.562 (avg: 32.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1564\tTop 1 accuracy: 9.600\tTop 5 accuracy: 25.800\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.368 (avg: 0.363)\tLoss: 4.1167 (avg: 4.0048)\tTop1: 7.812 (avg: 12.312)\tTop5: 28.125 (avg: 34.438)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.362 (avg: 0.368)\tLoss: 4.2004 (avg: 4.0222)\tTop1: 15.625 (avg: 12.875)\tTop5: 23.438 (avg: 33.594)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.363 (avg: 0.369)\tLoss: 3.9201 (avg: 4.0322)\tTop1: 14.062 (avg: 12.562)\tTop5: 35.938 (avg: 33.375)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.372 (avg: 0.370)\tLoss: 3.9957 (avg: 4.0333)\tTop1: 18.750 (avg: 12.469)\tTop5: 37.500 (avg: 33.172)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.362 (avg: 0.370)\tLoss: 4.1544 (avg: 4.0402)\tTop1: 6.250 (avg: 12.425)\tTop5: 28.125 (avg: 33.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4413\tTop 1 accuracy: 9.100\tTop 5 accuracy: 26.250\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.362 (avg: 0.362)\tLoss: 3.8758 (avg: 3.9955)\tTop1: 14.062 (avg: 13.312)\tTop5: 42.188 (avg: 34.375)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.363 (avg: 0.366)\tLoss: 3.9015 (avg: 4.0317)\tTop1: 4.688 (avg: 11.625)\tTop5: 43.750 (avg: 32.625)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.370 (avg: 0.368)\tLoss: 4.1806 (avg: 4.0433)\tTop1: 14.062 (avg: 11.958)\tTop5: 26.562 (avg: 32.333)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.369 (avg: 0.369)\tLoss: 3.9186 (avg: 4.0293)\tTop1: 14.062 (avg: 12.172)\tTop5: 39.062 (avg: 32.781)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.363 (avg: 0.369)\tLoss: 4.1152 (avg: 4.0313)\tTop1: 9.375 (avg: 12.400)\tTop5: 21.875 (avg: 32.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3461\tTop 1 accuracy: 9.450\tTop 5 accuracy: 26.500\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.366 (avg: 0.363)\tLoss: 3.8372 (avg: 3.9692)\tTop1: 20.312 (avg: 14.062)\tTop5: 39.062 (avg: 34.750)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.374 (avg: 0.367)\tLoss: 3.8801 (avg: 3.9686)\tTop1: 17.188 (avg: 13.344)\tTop5: 35.938 (avg: 35.156)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 4.0856 (avg: 4.0104)\tTop1: 14.062 (avg: 12.812)\tTop5: 28.125 (avg: 33.854)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.362 (avg: 0.370)\tLoss: 3.9916 (avg: 4.0078)\tTop1: 10.938 (avg: 13.312)\tTop5: 39.062 (avg: 34.234)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.361 (avg: 0.370)\tLoss: 3.8153 (avg: 4.0158)\tTop1: 12.500 (avg: 12.850)\tTop5: 43.750 (avg: 33.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3180\tTop 1 accuracy: 9.650\tTop 5 accuracy: 26.350\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.369 (avg: 0.363)\tLoss: 4.2581 (avg: 3.9177)\tTop1: 15.625 (avg: 14.375)\tTop5: 29.688 (avg: 37.312)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.363 (avg: 0.367)\tLoss: 3.8124 (avg: 3.9489)\tTop1: 10.938 (avg: 13.344)\tTop5: 39.062 (avg: 35.531)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.361 (avg: 0.368)\tLoss: 3.7757 (avg: 3.9713)\tTop1: 9.375 (avg: 12.812)\tTop5: 39.062 (avg: 34.771)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.364 (avg: 0.368)\tLoss: 4.1462 (avg: 3.9777)\tTop1: 12.500 (avg: 12.750)\tTop5: 32.812 (avg: 34.984)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 3.9164 (avg: 3.9913)\tTop1: 15.625 (avg: 12.600)\tTop5: 32.812 (avg: 34.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3195\tTop 1 accuracy: 9.000\tTop 5 accuracy: 26.250\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.364 (avg: 0.363)\tLoss: 3.8137 (avg: 3.9398)\tTop1: 17.188 (avg: 13.500)\tTop5: 40.625 (avg: 34.188)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.364 (avg: 0.367)\tLoss: 4.0356 (avg: 3.9683)\tTop1: 17.188 (avg: 13.062)\tTop5: 45.312 (avg: 34.312)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.362 (avg: 0.369)\tLoss: 4.0409 (avg: 3.9682)\tTop1: 18.750 (avg: 13.042)\tTop5: 34.375 (avg: 34.292)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 4.3690 (avg: 3.9928)\tTop1: 4.688 (avg: 12.625)\tTop5: 23.438 (avg: 33.594)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.365 (avg: 0.370)\tLoss: 3.8363 (avg: 3.9884)\tTop1: 21.875 (avg: 13.000)\tTop5: 34.375 (avg: 33.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2204\tTop 1 accuracy: 9.950\tTop 5 accuracy: 27.450\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.365 (avg: 0.363)\tLoss: 4.1948 (avg: 3.9737)\tTop1: 7.812 (avg: 14.938)\tTop5: 32.812 (avg: 35.250)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.366 (avg: 0.368)\tLoss: 4.0609 (avg: 3.9733)\tTop1: 10.938 (avg: 13.969)\tTop5: 34.375 (avg: 34.938)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 4.1063 (avg: 3.9598)\tTop1: 6.250 (avg: 13.979)\tTop5: 32.812 (avg: 35.167)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 3.9864 (avg: 3.9637)\tTop1: 17.188 (avg: 13.875)\tTop5: 29.688 (avg: 34.938)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 3.8726 (avg: 3.9739)\tTop1: 10.938 (avg: 13.675)\tTop5: 39.062 (avg: 34.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1647\tTop 1 accuracy: 9.200\tTop 5 accuracy: 28.300\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.363 (avg: 0.363)\tLoss: 4.1912 (avg: 3.9746)\tTop1: 10.938 (avg: 14.750)\tTop5: 35.938 (avg: 35.250)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.364 (avg: 0.368)\tLoss: 3.9591 (avg: 3.9758)\tTop1: 12.500 (avg: 14.656)\tTop5: 26.562 (avg: 35.031)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.365 (avg: 0.369)\tLoss: 4.0606 (avg: 3.9515)\tTop1: 10.938 (avg: 14.604)\tTop5: 34.375 (avg: 35.562)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.360 (avg: 0.369)\tLoss: 4.1257 (avg: 3.9620)\tTop1: 6.250 (avg: 14.000)\tTop5: 37.500 (avg: 34.844)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 4.2863 (avg: 3.9692)\tTop1: 14.062 (avg: 13.813)\tTop5: 32.812 (avg: 34.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3510\tTop 1 accuracy: 9.650\tTop 5 accuracy: 28.700\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.367 (avg: 0.363)\tLoss: 4.1601 (avg: 3.8910)\tTop1: 14.062 (avg: 14.375)\tTop5: 25.000 (avg: 35.688)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.369 (avg: 0.367)\tLoss: 3.6790 (avg: 3.9147)\tTop1: 14.062 (avg: 13.688)\tTop5: 42.188 (avg: 36.156)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 4.0128 (avg: 3.9283)\tTop1: 15.625 (avg: 13.792)\tTop5: 31.250 (avg: 36.021)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.361 (avg: 0.370)\tLoss: 3.8403 (avg: 3.9361)\tTop1: 14.062 (avg: 14.312)\tTop5: 35.938 (avg: 35.984)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.374 (avg: 0.370)\tLoss: 4.2812 (avg: 3.9463)\tTop1: 12.500 (avg: 14.150)\tTop5: 34.375 (avg: 35.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2507\tTop 1 accuracy: 10.300\tTop 5 accuracy: 29.800\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.368 (avg: 0.363)\tLoss: 4.1531 (avg: 3.9171)\tTop1: 10.938 (avg: 13.875)\tTop5: 35.938 (avg: 35.688)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.367 (avg: 0.368)\tLoss: 3.9302 (avg: 3.9265)\tTop1: 9.375 (avg: 13.656)\tTop5: 35.938 (avg: 35.781)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.361 (avg: 0.369)\tLoss: 3.6477 (avg: 3.9087)\tTop1: 17.188 (avg: 13.833)\tTop5: 34.375 (avg: 35.771)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.370 (avg: 0.370)\tLoss: 3.8320 (avg: 3.9201)\tTop1: 12.500 (avg: 13.562)\tTop5: 43.750 (avg: 35.531)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.365 (avg: 0.370)\tLoss: 4.0918 (avg: 3.9271)\tTop1: 14.062 (avg: 13.413)\tTop5: 35.938 (avg: 35.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3142\tTop 1 accuracy: 9.400\tTop 5 accuracy: 27.200\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.366 (avg: 0.359)\tLoss: 3.7261 (avg: 3.8583)\tTop1: 12.500 (avg: 15.125)\tTop5: 35.938 (avg: 39.125)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.362 (avg: 0.365)\tLoss: 3.9838 (avg: 3.9037)\tTop1: 7.812 (avg: 14.438)\tTop5: 32.812 (avg: 37.031)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.370 (avg: 0.367)\tLoss: 3.9540 (avg: 3.9089)\tTop1: 17.188 (avg: 13.896)\tTop5: 39.062 (avg: 36.312)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.363 (avg: 0.368)\tLoss: 3.4667 (avg: 3.9158)\tTop1: 21.875 (avg: 13.969)\tTop5: 50.000 (avg: 36.078)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.356 (avg: 0.369)\tLoss: 4.0357 (avg: 3.9220)\tTop1: 12.500 (avg: 13.875)\tTop5: 28.125 (avg: 35.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5628\tTop 1 accuracy: 9.550\tTop 5 accuracy: 26.850\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.364 (avg: 0.363)\tLoss: 3.8282 (avg: 3.9142)\tTop1: 14.062 (avg: 14.375)\tTop5: 43.750 (avg: 37.375)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.371 (avg: 0.367)\tLoss: 3.7312 (avg: 3.8838)\tTop1: 10.938 (avg: 14.562)\tTop5: 39.062 (avg: 37.625)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.362 (avg: 0.369)\tLoss: 3.7726 (avg: 3.9027)\tTop1: 17.188 (avg: 14.125)\tTop5: 39.062 (avg: 37.417)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.363 (avg: 0.370)\tLoss: 3.9714 (avg: 3.8940)\tTop1: 18.750 (avg: 14.391)\tTop5: 34.375 (avg: 37.375)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.363 (avg: 0.370)\tLoss: 3.9153 (avg: 3.9067)\tTop1: 15.625 (avg: 14.413)\tTop5: 39.062 (avg: 36.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3577\tTop 1 accuracy: 9.800\tTop 5 accuracy: 28.850\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.370 (avg: 0.364)\tLoss: 3.6281 (avg: 3.8788)\tTop1: 17.188 (avg: 15.250)\tTop5: 42.188 (avg: 36.188)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.362 (avg: 0.368)\tLoss: 3.6071 (avg: 3.8619)\tTop1: 21.875 (avg: 15.531)\tTop5: 45.312 (avg: 37.062)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 3.5632 (avg: 3.8809)\tTop1: 15.625 (avg: 14.646)\tTop5: 37.500 (avg: 36.646)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.365 (avg: 0.370)\tLoss: 3.9782 (avg: 3.8821)\tTop1: 9.375 (avg: 14.547)\tTop5: 28.125 (avg: 36.656)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.366 (avg: 0.370)\tLoss: 3.9813 (avg: 3.8948)\tTop1: 12.500 (avg: 14.313)\tTop5: 32.812 (avg: 36.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2166\tTop 1 accuracy: 10.550\tTop 5 accuracy: 29.100\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.366 (avg: 0.360)\tLoss: 3.7424 (avg: 3.8399)\tTop1: 18.750 (avg: 16.750)\tTop5: 37.500 (avg: 38.375)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.363 (avg: 0.366)\tLoss: 3.9176 (avg: 3.8494)\tTop1: 14.062 (avg: 16.219)\tTop5: 31.250 (avg: 37.750)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.363 (avg: 0.368)\tLoss: 4.0574 (avg: 3.8718)\tTop1: 12.500 (avg: 15.250)\tTop5: 28.125 (avg: 37.104)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.359 (avg: 0.369)\tLoss: 3.8352 (avg: 3.8807)\tTop1: 17.188 (avg: 15.078)\tTop5: 40.625 (avg: 36.500)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.365 (avg: 0.369)\tLoss: 4.0801 (avg: 3.8811)\tTop1: 14.062 (avg: 14.925)\tTop5: 31.250 (avg: 36.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3254\tTop 1 accuracy: 10.700\tTop 5 accuracy: 28.600\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.365 (avg: 0.363)\tLoss: 4.0161 (avg: 3.8340)\tTop1: 20.312 (avg: 15.375)\tTop5: 34.375 (avg: 37.938)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.364 (avg: 0.368)\tLoss: 3.8678 (avg: 3.8559)\tTop1: 20.312 (avg: 15.406)\tTop5: 37.500 (avg: 37.625)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.367 (avg: 0.369)\tLoss: 3.8274 (avg: 3.8742)\tTop1: 12.500 (avg: 15.062)\tTop5: 34.375 (avg: 37.271)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.367 (avg: 0.370)\tLoss: 3.9300 (avg: 3.8679)\tTop1: 10.938 (avg: 15.094)\tTop5: 31.250 (avg: 37.422)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.362 (avg: 0.370)\tLoss: 4.0325 (avg: 3.8720)\tTop1: 6.250 (avg: 14.825)\tTop5: 26.562 (avg: 37.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1094\tTop 1 accuracy: 10.850\tTop 5 accuracy: 29.750\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.362 (avg: 0.364)\tLoss: 3.8480 (avg: 3.8803)\tTop1: 15.625 (avg: 14.125)\tTop5: 40.625 (avg: 37.312)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.367 (avg: 0.368)\tLoss: 3.6651 (avg: 3.8648)\tTop1: 14.062 (avg: 15.031)\tTop5: 45.312 (avg: 37.750)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.366 (avg: 0.370)\tLoss: 3.7751 (avg: 3.8611)\tTop1: 20.312 (avg: 14.812)\tTop5: 40.625 (avg: 37.438)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.358 (avg: 0.369)\tLoss: 3.9676 (avg: 3.8484)\tTop1: 12.500 (avg: 15.203)\tTop5: 39.062 (avg: 37.891)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.362 (avg: 0.369)\tLoss: 3.7920 (avg: 3.8520)\tTop1: 23.438 (avg: 15.113)\tTop5: 50.000 (avg: 37.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4257\tTop 1 accuracy: 10.700\tTop 5 accuracy: 29.150\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.367 (avg: 0.362)\tLoss: 3.6569 (avg: 3.7978)\tTop1: 17.188 (avg: 16.562)\tTop5: 40.625 (avg: 37.188)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.366 (avg: 0.367)\tLoss: 3.8031 (avg: 3.8007)\tTop1: 7.812 (avg: 16.188)\tTop5: 35.938 (avg: 37.750)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.366 (avg: 0.369)\tLoss: 4.0261 (avg: 3.8189)\tTop1: 17.188 (avg: 15.542)\tTop5: 35.938 (avg: 37.396)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.363 (avg: 0.369)\tLoss: 3.8253 (avg: 3.8159)\tTop1: 17.188 (avg: 15.875)\tTop5: 35.938 (avg: 37.672)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.374 (avg: 0.370)\tLoss: 3.8065 (avg: 3.8310)\tTop1: 15.625 (avg: 15.500)\tTop5: 32.812 (avg: 37.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1269\tTop 1 accuracy: 11.100\tTop 5 accuracy: 29.250\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.366 (avg: 0.363)\tLoss: 3.7441 (avg: 3.7543)\tTop1: 14.062 (avg: 16.625)\tTop5: 42.188 (avg: 39.688)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.362 (avg: 0.368)\tLoss: 3.7467 (avg: 3.7685)\tTop1: 17.188 (avg: 16.844)\tTop5: 39.062 (avg: 39.500)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 4.0666 (avg: 3.7843)\tTop1: 10.938 (avg: 16.771)\tTop5: 29.688 (avg: 39.333)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.373 (avg: 0.370)\tLoss: 3.7591 (avg: 3.8021)\tTop1: 12.500 (avg: 16.312)\tTop5: 45.312 (avg: 39.000)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.360 (avg: 0.370)\tLoss: 3.9077 (avg: 3.8086)\tTop1: 7.812 (avg: 15.950)\tTop5: 45.312 (avg: 38.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2506\tTop 1 accuracy: 11.250\tTop 5 accuracy: 30.000\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.365 (avg: 0.364)\tLoss: 4.1391 (avg: 3.7600)\tTop1: 12.500 (avg: 16.875)\tTop5: 26.562 (avg: 40.000)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.366 (avg: 0.368)\tLoss: 4.1765 (avg: 3.7829)\tTop1: 14.062 (avg: 16.938)\tTop5: 29.688 (avg: 38.688)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.370 (avg: 0.369)\tLoss: 3.7599 (avg: 3.8024)\tTop1: 17.188 (avg: 16.646)\tTop5: 42.188 (avg: 38.250)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.363 (avg: 0.369)\tLoss: 3.9082 (avg: 3.8133)\tTop1: 12.500 (avg: 15.797)\tTop5: 35.938 (avg: 38.031)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.365 (avg: 0.370)\tLoss: 3.7503 (avg: 3.8140)\tTop1: 21.875 (avg: 15.800)\tTop5: 37.500 (avg: 38.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2139\tTop 1 accuracy: 10.700\tTop 5 accuracy: 29.300\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.364 (avg: 0.363)\tLoss: 3.7190 (avg: 3.6987)\tTop1: 21.875 (avg: 16.562)\tTop5: 42.188 (avg: 41.312)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.370 (avg: 0.367)\tLoss: 4.2491 (avg: 3.7594)\tTop1: 7.812 (avg: 16.188)\tTop5: 29.688 (avg: 39.562)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.365 (avg: 0.369)\tLoss: 4.0281 (avg: 3.7519)\tTop1: 23.438 (avg: 16.604)\tTop5: 43.750 (avg: 39.938)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.362 (avg: 0.370)\tLoss: 3.8569 (avg: 3.7676)\tTop1: 12.500 (avg: 16.594)\tTop5: 34.375 (avg: 39.438)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.363 (avg: 0.370)\tLoss: 4.1344 (avg: 3.7834)\tTop1: 14.062 (avg: 16.075)\tTop5: 32.812 (avg: 39.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0449\tTop 1 accuracy: 11.750\tTop 5 accuracy: 30.400\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.368 (avg: 0.363)\tLoss: 3.4773 (avg: 3.7095)\tTop1: 15.625 (avg: 18.438)\tTop5: 43.750 (avg: 39.750)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 3.9113 (avg: 3.7024)\tTop1: 9.375 (avg: 17.875)\tTop5: 34.375 (avg: 40.656)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.367 (avg: 0.369)\tLoss: 4.0609 (avg: 3.7497)\tTop1: 10.938 (avg: 17.104)\tTop5: 35.938 (avg: 39.875)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 3.8093 (avg: 3.7638)\tTop1: 12.500 (avg: 16.859)\tTop5: 34.375 (avg: 39.703)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.368 (avg: 0.370)\tLoss: 3.8851 (avg: 3.7742)\tTop1: 18.750 (avg: 16.625)\tTop5: 37.500 (avg: 39.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4350\tTop 1 accuracy: 11.900\tTop 5 accuracy: 29.750\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.361 (avg: 0.359)\tLoss: 3.9420 (avg: 3.7652)\tTop1: 17.188 (avg: 15.812)\tTop5: 42.188 (avg: 39.812)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.361 (avg: 0.363)\tLoss: 3.8836 (avg: 3.7716)\tTop1: 15.625 (avg: 15.938)\tTop5: 32.812 (avg: 39.812)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.360 (avg: 0.366)\tLoss: 3.7553 (avg: 3.7701)\tTop1: 14.062 (avg: 16.188)\tTop5: 40.625 (avg: 39.812)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.363 (avg: 0.367)\tLoss: 3.7512 (avg: 3.7739)\tTop1: 15.625 (avg: 16.016)\tTop5: 34.375 (avg: 39.734)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.366 (avg: 0.368)\tLoss: 3.8410 (avg: 3.7752)\tTop1: 9.375 (avg: 16.163)\tTop5: 28.125 (avg: 39.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3080\tTop 1 accuracy: 11.550\tTop 5 accuracy: 29.500\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.362 (avg: 0.362)\tLoss: 3.8428 (avg: 3.7058)\tTop1: 17.188 (avg: 17.000)\tTop5: 34.375 (avg: 40.750)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.365 (avg: 0.367)\tLoss: 3.4718 (avg: 3.7290)\tTop1: 17.188 (avg: 16.438)\tTop5: 48.438 (avg: 40.281)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.362 (avg: 0.368)\tLoss: 3.7008 (avg: 3.7162)\tTop1: 14.062 (avg: 17.250)\tTop5: 40.625 (avg: 40.479)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.368 (avg: 0.369)\tLoss: 3.6873 (avg: 3.7284)\tTop1: 14.062 (avg: 16.891)\tTop5: 32.812 (avg: 39.812)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 3.5329 (avg: 3.7443)\tTop1: 26.562 (avg: 16.725)\tTop5: 57.812 (avg: 39.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2373\tTop 1 accuracy: 12.200\tTop 5 accuracy: 30.400\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.365 (avg: 0.363)\tLoss: 3.9274 (avg: 3.7650)\tTop1: 14.062 (avg: 17.188)\tTop5: 32.812 (avg: 40.250)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.364 (avg: 0.367)\tLoss: 3.4601 (avg: 3.7345)\tTop1: 21.875 (avg: 17.188)\tTop5: 42.188 (avg: 40.719)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 3.7472 (avg: 3.7189)\tTop1: 15.625 (avg: 17.062)\tTop5: 43.750 (avg: 41.000)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.368 (avg: 0.370)\tLoss: 3.9139 (avg: 3.7227)\tTop1: 14.062 (avg: 17.172)\tTop5: 32.812 (avg: 40.938)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 3.8592 (avg: 3.7308)\tTop1: 17.188 (avg: 16.888)\tTop5: 39.062 (avg: 40.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2232\tTop 1 accuracy: 11.300\tTop 5 accuracy: 30.500\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.365 (avg: 0.360)\tLoss: 3.8601 (avg: 3.6111)\tTop1: 18.750 (avg: 18.500)\tTop5: 45.312 (avg: 43.500)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.365 (avg: 0.366)\tLoss: 3.6222 (avg: 3.5861)\tTop1: 23.438 (avg: 19.156)\tTop5: 42.188 (avg: 43.844)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.365 (avg: 0.368)\tLoss: 3.7045 (avg: 3.6074)\tTop1: 9.375 (avg: 18.625)\tTop5: 45.312 (avg: 43.104)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.363 (avg: 0.369)\tLoss: 3.4217 (avg: 3.6163)\tTop1: 21.875 (avg: 19.125)\tTop5: 48.438 (avg: 42.547)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.372 (avg: 0.369)\tLoss: 3.9103 (avg: 3.6126)\tTop1: 14.062 (avg: 19.350)\tTop5: 34.375 (avg: 42.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1733\tTop 1 accuracy: 12.550\tTop 5 accuracy: 31.250\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.368 (avg: 0.363)\tLoss: 3.7275 (avg: 3.5910)\tTop1: 14.062 (avg: 18.938)\tTop5: 37.500 (avg: 43.438)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.364 (avg: 0.367)\tLoss: 3.7256 (avg: 3.5673)\tTop1: 10.938 (avg: 19.500)\tTop5: 31.250 (avg: 43.719)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.361 (avg: 0.369)\tLoss: 3.4394 (avg: 3.5656)\tTop1: 20.312 (avg: 19.750)\tTop5: 45.312 (avg: 43.708)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.372 (avg: 0.369)\tLoss: 3.7377 (avg: 3.5783)\tTop1: 17.188 (avg: 19.625)\tTop5: 42.188 (avg: 43.859)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.365 (avg: 0.370)\tLoss: 3.4002 (avg: 3.5849)\tTop1: 21.875 (avg: 19.400)\tTop5: 50.000 (avg: 43.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2014\tTop 1 accuracy: 12.350\tTop 5 accuracy: 31.400\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 3.5102 (avg: 3.5303)\tTop1: 21.875 (avg: 20.438)\tTop5: 43.750 (avg: 44.688)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.364 (avg: 0.367)\tLoss: 3.7558 (avg: 3.5574)\tTop1: 10.938 (avg: 20.125)\tTop5: 39.062 (avg: 44.781)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.371 (avg: 0.369)\tLoss: 3.3797 (avg: 3.5808)\tTop1: 20.312 (avg: 20.021)\tTop5: 53.125 (avg: 44.312)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.360 (avg: 0.369)\tLoss: 3.6517 (avg: 3.5684)\tTop1: 12.500 (avg: 20.078)\tTop5: 29.688 (avg: 44.719)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.359 (avg: 0.369)\tLoss: 3.6199 (avg: 3.5760)\tTop1: 12.500 (avg: 19.738)\tTop5: 45.312 (avg: 44.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1470\tTop 1 accuracy: 12.000\tTop 5 accuracy: 31.850\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.362 (avg: 0.363)\tLoss: 3.6359 (avg: 3.5294)\tTop1: 10.938 (avg: 20.938)\tTop5: 35.938 (avg: 44.625)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.373 (avg: 0.367)\tLoss: 3.3457 (avg: 3.5285)\tTop1: 26.562 (avg: 20.219)\tTop5: 50.000 (avg: 45.312)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.361 (avg: 0.369)\tLoss: 3.3261 (avg: 3.5510)\tTop1: 20.312 (avg: 20.000)\tTop5: 46.875 (avg: 45.062)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 3.5808 (avg: 3.5648)\tTop1: 20.312 (avg: 20.250)\tTop5: 40.625 (avg: 44.453)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.362 (avg: 0.370)\tLoss: 3.8760 (avg: 3.5727)\tTop1: 17.188 (avg: 20.013)\tTop5: 39.062 (avg: 44.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1312\tTop 1 accuracy: 12.550\tTop 5 accuracy: 31.650\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.371 (avg: 0.363)\tLoss: 3.6227 (avg: 3.5797)\tTop1: 14.062 (avg: 19.312)\tTop5: 43.750 (avg: 43.562)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.363 (avg: 0.367)\tLoss: 4.2371 (avg: 3.5693)\tTop1: 4.688 (avg: 19.656)\tTop5: 32.812 (avg: 43.562)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 3.7617 (avg: 3.5616)\tTop1: 15.625 (avg: 19.917)\tTop5: 37.500 (avg: 44.250)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.362 (avg: 0.370)\tLoss: 3.6270 (avg: 3.5729)\tTop1: 21.875 (avg: 19.672)\tTop5: 34.375 (avg: 44.156)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.369 (avg: 0.370)\tLoss: 3.3927 (avg: 3.5698)\tTop1: 26.562 (avg: 19.525)\tTop5: 48.438 (avg: 44.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2516\tTop 1 accuracy: 12.400\tTop 5 accuracy: 30.950\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.363 (avg: 0.363)\tLoss: 3.5808 (avg: 3.5912)\tTop1: 20.312 (avg: 19.375)\tTop5: 46.875 (avg: 43.938)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.363 (avg: 0.367)\tLoss: 3.2964 (avg: 3.5531)\tTop1: 25.000 (avg: 20.438)\tTop5: 48.438 (avg: 45.000)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.361 (avg: 0.369)\tLoss: 3.5032 (avg: 3.5459)\tTop1: 23.438 (avg: 20.188)\tTop5: 54.688 (avg: 44.917)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.366 (avg: 0.369)\tLoss: 3.6629 (avg: 3.5607)\tTop1: 18.750 (avg: 19.859)\tTop5: 43.750 (avg: 44.453)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.366 (avg: 0.370)\tLoss: 3.4008 (avg: 3.5603)\tTop1: 25.000 (avg: 20.075)\tTop5: 42.188 (avg: 44.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2225\tTop 1 accuracy: 12.150\tTop 5 accuracy: 31.550\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.363 (avg: 0.363)\tLoss: 3.4863 (avg: 3.5363)\tTop1: 21.875 (avg: 20.688)\tTop5: 50.000 (avg: 45.375)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.363 (avg: 0.367)\tLoss: 3.6841 (avg: 3.5673)\tTop1: 10.938 (avg: 20.000)\tTop5: 37.500 (avg: 45.094)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.367 (avg: 0.369)\tLoss: 3.5818 (avg: 3.5776)\tTop1: 21.875 (avg: 19.688)\tTop5: 51.562 (avg: 44.188)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 3.0860 (avg: 3.5667)\tTop1: 21.875 (avg: 19.656)\tTop5: 59.375 (avg: 44.484)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.363 (avg: 0.370)\tLoss: 3.4623 (avg: 3.5662)\tTop1: 21.875 (avg: 19.713)\tTop5: 43.750 (avg: 44.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2406\tTop 1 accuracy: 12.600\tTop 5 accuracy: 31.700\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.364 (avg: 0.364)\tLoss: 3.3097 (avg: 3.5330)\tTop1: 23.438 (avg: 21.188)\tTop5: 53.125 (avg: 45.938)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.366 (avg: 0.368)\tLoss: 3.6921 (avg: 3.5509)\tTop1: 20.312 (avg: 20.844)\tTop5: 45.312 (avg: 45.125)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 3.2479 (avg: 3.5504)\tTop1: 18.750 (avg: 20.021)\tTop5: 48.438 (avg: 45.000)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.366 (avg: 0.370)\tLoss: 3.6387 (avg: 3.5479)\tTop1: 25.000 (avg: 19.828)\tTop5: 42.188 (avg: 44.625)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.371 (avg: 0.371)\tLoss: 3.4120 (avg: 3.5558)\tTop1: 20.312 (avg: 19.863)\tTop5: 53.125 (avg: 44.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2641\tTop 1 accuracy: 12.800\tTop 5 accuracy: 31.250\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.367 (avg: 0.363)\tLoss: 3.2191 (avg: 3.5415)\tTop1: 28.125 (avg: 21.375)\tTop5: 46.875 (avg: 44.625)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.361 (avg: 0.366)\tLoss: 3.3577 (avg: 3.5456)\tTop1: 28.125 (avg: 20.969)\tTop5: 50.000 (avg: 44.812)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.367 (avg: 0.367)\tLoss: 3.2988 (avg: 3.5540)\tTop1: 26.562 (avg: 20.062)\tTop5: 48.438 (avg: 44.604)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.364 (avg: 0.368)\tLoss: 3.5637 (avg: 3.5601)\tTop1: 23.438 (avg: 20.359)\tTop5: 35.938 (avg: 44.641)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.374 (avg: 0.369)\tLoss: 3.3720 (avg: 3.5487)\tTop1: 32.812 (avg: 20.300)\tTop5: 48.438 (avg: 44.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2392\tTop 1 accuracy: 12.250\tTop 5 accuracy: 31.500\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.364 (avg: 0.363)\tLoss: 3.6351 (avg: 3.5560)\tTop1: 20.312 (avg: 20.375)\tTop5: 42.188 (avg: 43.625)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.359 (avg: 0.367)\tLoss: 3.7370 (avg: 3.5280)\tTop1: 15.625 (avg: 20.344)\tTop5: 39.062 (avg: 44.469)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.363 (avg: 0.369)\tLoss: 3.6927 (avg: 3.5423)\tTop1: 20.312 (avg: 20.833)\tTop5: 45.312 (avg: 44.438)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.372 (avg: 0.369)\tLoss: 3.5644 (avg: 3.5521)\tTop1: 25.000 (avg: 20.469)\tTop5: 46.875 (avg: 44.562)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.362 (avg: 0.370)\tLoss: 3.9538 (avg: 3.5477)\tTop1: 21.875 (avg: 20.213)\tTop5: 37.500 (avg: 44.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2121\tTop 1 accuracy: 12.450\tTop 5 accuracy: 31.700\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.364 (avg: 0.363)\tLoss: 3.3424 (avg: 3.5276)\tTop1: 23.438 (avg: 21.000)\tTop5: 46.875 (avg: 44.812)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.364 (avg: 0.367)\tLoss: 3.4766 (avg: 3.5236)\tTop1: 20.312 (avg: 20.719)\tTop5: 45.312 (avg: 45.250)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.371 (avg: 0.369)\tLoss: 3.0407 (avg: 3.5277)\tTop1: 32.812 (avg: 21.021)\tTop5: 62.500 (avg: 45.208)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.362 (avg: 0.370)\tLoss: 3.4843 (avg: 3.5357)\tTop1: 29.688 (avg: 20.859)\tTop5: 46.875 (avg: 44.859)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.363 (avg: 0.370)\tLoss: 3.4139 (avg: 3.5472)\tTop1: 21.875 (avg: 20.388)\tTop5: 45.312 (avg: 44.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2683\tTop 1 accuracy: 12.200\tTop 5 accuracy: 31.200\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.365 (avg: 0.362)\tLoss: 3.7941 (avg: 3.4903)\tTop1: 21.875 (avg: 22.062)\tTop5: 40.625 (avg: 45.875)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.374 (avg: 0.367)\tLoss: 3.6043 (avg: 3.5180)\tTop1: 20.312 (avg: 20.750)\tTop5: 46.875 (avg: 45.594)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.362 (avg: 0.369)\tLoss: 3.5928 (avg: 3.5208)\tTop1: 17.188 (avg: 20.750)\tTop5: 39.062 (avg: 45.771)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.366 (avg: 0.370)\tLoss: 3.3637 (avg: 3.5126)\tTop1: 20.312 (avg: 21.062)\tTop5: 50.000 (avg: 46.000)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 3.4918 (avg: 3.5372)\tTop1: 18.750 (avg: 20.625)\tTop5: 46.875 (avg: 45.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1945\tTop 1 accuracy: 12.650\tTop 5 accuracy: 32.000\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.369 (avg: 0.363)\tLoss: 3.5402 (avg: 3.5484)\tTop1: 20.312 (avg: 21.500)\tTop5: 42.188 (avg: 45.188)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 3.5628 (avg: 3.5421)\tTop1: 15.625 (avg: 20.969)\tTop5: 46.875 (avg: 44.531)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 3.5695 (avg: 3.5400)\tTop1: 23.438 (avg: 20.708)\tTop5: 37.500 (avg: 44.812)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.362 (avg: 0.370)\tLoss: 3.3499 (avg: 3.5209)\tTop1: 25.000 (avg: 20.859)\tTop5: 43.750 (avg: 45.094)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.367 (avg: 0.370)\tLoss: 3.6639 (avg: 3.5390)\tTop1: 18.750 (avg: 20.500)\tTop5: 45.312 (avg: 44.325)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1701\tTop 1 accuracy: 12.650\tTop 5 accuracy: 31.300\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.361 (avg: 0.363)\tLoss: 3.3243 (avg: 3.4851)\tTop1: 14.062 (avg: 20.562)\tTop5: 50.000 (avg: 46.750)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.363 (avg: 0.367)\tLoss: 3.3632 (avg: 3.5219)\tTop1: 15.625 (avg: 20.312)\tTop5: 54.688 (avg: 45.219)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.362 (avg: 0.369)\tLoss: 3.6012 (avg: 3.5344)\tTop1: 12.500 (avg: 20.354)\tTop5: 46.875 (avg: 44.729)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.366 (avg: 0.370)\tLoss: 4.2403 (avg: 3.5389)\tTop1: 12.500 (avg: 20.438)\tTop5: 35.938 (avg: 44.484)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.362 (avg: 0.370)\tLoss: 3.3794 (avg: 3.5356)\tTop1: 20.312 (avg: 20.425)\tTop5: 56.250 (avg: 44.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2395\tTop 1 accuracy: 12.600\tTop 5 accuracy: 31.400\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.362 (avg: 0.363)\tLoss: 3.4523 (avg: 3.5414)\tTop1: 21.875 (avg: 20.562)\tTop5: 50.000 (avg: 44.750)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.360 (avg: 0.367)\tLoss: 3.4112 (avg: 3.5446)\tTop1: 26.562 (avg: 20.656)\tTop5: 46.875 (avg: 45.156)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.366 (avg: 0.369)\tLoss: 3.1306 (avg: 3.5381)\tTop1: 28.125 (avg: 20.625)\tTop5: 53.125 (avg: 45.229)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.366 (avg: 0.369)\tLoss: 3.3666 (avg: 3.5338)\tTop1: 20.312 (avg: 20.688)\tTop5: 43.750 (avg: 45.203)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.366 (avg: 0.370)\tLoss: 3.6544 (avg: 3.5318)\tTop1: 12.500 (avg: 20.450)\tTop5: 37.500 (avg: 45.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2435\tTop 1 accuracy: 12.650\tTop 5 accuracy: 31.300\n",
            "\n",
            "Training...\n",
            "Epoch: 75[25/125]\tTime used: 0.364 (avg: 0.363)\tLoss: 3.8689 (avg: 3.5060)\tTop1: 14.062 (avg: 21.125)\tTop5: 35.938 (avg: 47.188)\t\n",
            "Epoch: 75[50/125]\tTime used: 0.367 (avg: 0.367)\tLoss: 3.7418 (avg: 3.5359)\tTop1: 10.938 (avg: 20.312)\tTop5: 37.500 (avg: 45.344)\t\n",
            "Epoch: 75[75/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 3.4062 (avg: 3.5235)\tTop1: 25.000 (avg: 20.792)\tTop5: 45.312 (avg: 45.771)\t\n",
            "Epoch: 75[100/125]\tTime used: 0.363 (avg: 0.370)\tLoss: 3.7888 (avg: 3.5336)\tTop1: 20.312 (avg: 20.562)\tTop5: 35.938 (avg: 45.359)\t\n",
            "Epoch: 75[125/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 3.6520 (avg: 3.5299)\tTop1: 14.062 (avg: 20.663)\tTop5: 43.750 (avg: 45.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2411\tTop 1 accuracy: 12.750\tTop 5 accuracy: 31.750\n",
            "\n",
            "Training...\n",
            "Epoch: 76[25/125]\tTime used: 0.366 (avg: 0.364)\tLoss: 3.6113 (avg: 3.4968)\tTop1: 23.438 (avg: 20.562)\tTop5: 39.062 (avg: 45.438)\t\n",
            "Epoch: 76[50/125]\tTime used: 0.367 (avg: 0.368)\tLoss: 3.3961 (avg: 3.5224)\tTop1: 15.625 (avg: 20.188)\tTop5: 48.438 (avg: 44.969)\t\n",
            "Epoch: 76[75/125]\tTime used: 0.362 (avg: 0.369)\tLoss: 3.3487 (avg: 3.5329)\tTop1: 18.750 (avg: 20.021)\tTop5: 46.875 (avg: 44.854)\t\n",
            "Epoch: 76[100/125]\tTime used: 0.365 (avg: 0.369)\tLoss: 3.7322 (avg: 3.5289)\tTop1: 18.750 (avg: 20.234)\tTop5: 34.375 (avg: 45.156)\t\n",
            "Epoch: 76[125/125]\tTime used: 0.372 (avg: 0.370)\tLoss: 3.7511 (avg: 3.5249)\tTop1: 10.938 (avg: 20.563)\tTop5: 39.062 (avg: 45.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2647\tTop 1 accuracy: 12.600\tTop 5 accuracy: 31.600\n",
            "\n",
            "Training...\n",
            "Epoch: 77[25/125]\tTime used: 0.365 (avg: 0.363)\tLoss: 3.4759 (avg: 3.5297)\tTop1: 20.312 (avg: 20.250)\tTop5: 53.125 (avg: 45.438)\t\n",
            "Epoch: 77[50/125]\tTime used: 0.363 (avg: 0.367)\tLoss: 3.2065 (avg: 3.5015)\tTop1: 28.125 (avg: 21.031)\tTop5: 48.438 (avg: 45.969)\t\n",
            "Epoch: 77[75/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 3.4466 (avg: 3.4946)\tTop1: 20.312 (avg: 21.188)\tTop5: 48.438 (avg: 45.583)\t\n",
            "Epoch: 77[100/125]\tTime used: 0.369 (avg: 0.370)\tLoss: 4.0580 (avg: 3.5282)\tTop1: 18.750 (avg: 20.828)\tTop5: 34.375 (avg: 44.703)\t\n",
            "Epoch: 77[125/125]\tTime used: 0.360 (avg: 0.370)\tLoss: 3.1797 (avg: 3.5265)\tTop1: 26.562 (avg: 20.625)\tTop5: 53.125 (avg: 44.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1945\tTop 1 accuracy: 12.750\tTop 5 accuracy: 31.750\n",
            "\n",
            "Training...\n",
            "Epoch: 78[25/125]\tTime used: 0.364 (avg: 0.363)\tLoss: 2.8953 (avg: 3.5353)\tTop1: 32.812 (avg: 20.875)\tTop5: 54.688 (avg: 44.750)\t\n",
            "Epoch: 78[50/125]\tTime used: 0.364 (avg: 0.367)\tLoss: 3.5675 (avg: 3.5304)\tTop1: 17.188 (avg: 20.969)\tTop5: 46.875 (avg: 44.812)\t\n",
            "Epoch: 78[75/125]\tTime used: 0.372 (avg: 0.369)\tLoss: 3.6040 (avg: 3.5101)\tTop1: 23.438 (avg: 21.583)\tTop5: 43.750 (avg: 45.062)\t\n",
            "Epoch: 78[100/125]\tTime used: 0.363 (avg: 0.370)\tLoss: 3.0951 (avg: 3.5203)\tTop1: 26.562 (avg: 21.000)\tTop5: 56.250 (avg: 45.000)\t\n",
            "Epoch: 78[125/125]\tTime used: 0.365 (avg: 0.370)\tLoss: 3.1620 (avg: 3.5216)\tTop1: 23.438 (avg: 20.663)\tTop5: 57.812 (avg: 45.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1792\tTop 1 accuracy: 13.050\tTop 5 accuracy: 31.750\n",
            "\n",
            "Training...\n",
            "Epoch: 79[25/125]\tTime used: 0.365 (avg: 0.363)\tLoss: 3.4604 (avg: 3.4806)\tTop1: 17.188 (avg: 21.375)\tTop5: 50.000 (avg: 46.812)\t\n",
            "Epoch: 79[50/125]\tTime used: 0.373 (avg: 0.368)\tLoss: 3.8990 (avg: 3.4832)\tTop1: 20.312 (avg: 20.875)\tTop5: 42.188 (avg: 46.281)\t\n",
            "Epoch: 79[75/125]\tTime used: 0.359 (avg: 0.368)\tLoss: 3.4309 (avg: 3.4836)\tTop1: 23.438 (avg: 21.438)\tTop5: 48.438 (avg: 46.396)\t\n",
            "Epoch: 79[100/125]\tTime used: 0.365 (avg: 0.369)\tLoss: 4.0076 (avg: 3.4892)\tTop1: 17.188 (avg: 21.281)\tTop5: 29.688 (avg: 46.234)\t\n",
            "Epoch: 79[125/125]\tTime used: 0.362 (avg: 0.369)\tLoss: 3.7852 (avg: 3.5174)\tTop1: 18.750 (avg: 20.688)\tTop5: 37.500 (avg: 45.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1989\tTop 1 accuracy: 12.600\tTop 5 accuracy: 31.400\n",
            "\n",
            "Training...\n",
            "Epoch: 80[25/125]\tTime used: 0.371 (avg: 0.363)\tLoss: 3.9628 (avg: 3.5167)\tTop1: 15.625 (avg: 21.250)\tTop5: 40.625 (avg: 44.562)\t\n",
            "Epoch: 80[50/125]\tTime used: 0.363 (avg: 0.367)\tLoss: 3.3759 (avg: 3.5000)\tTop1: 17.188 (avg: 21.125)\tTop5: 48.438 (avg: 45.844)\t\n",
            "Epoch: 80[75/125]\tTime used: 0.369 (avg: 0.369)\tLoss: 3.8157 (avg: 3.5352)\tTop1: 18.750 (avg: 20.875)\tTop5: 35.938 (avg: 44.812)\t\n",
            "Epoch: 80[100/125]\tTime used: 0.366 (avg: 0.369)\tLoss: 3.6026 (avg: 3.5312)\tTop1: 17.188 (avg: 20.781)\tTop5: 42.188 (avg: 44.969)\t\n",
            "Epoch: 80[125/125]\tTime used: 0.365 (avg: 0.370)\tLoss: 3.3032 (avg: 3.5206)\tTop1: 21.875 (avg: 20.938)\tTop5: 48.438 (avg: 45.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1645\tTop 1 accuracy: 12.850\tTop 5 accuracy: 31.000\n",
            "\n",
            "Training...\n",
            "Epoch: 81[25/125]\tTime used: 0.362 (avg: 0.362)\tLoss: 3.3344 (avg: 3.5226)\tTop1: 21.875 (avg: 23.062)\tTop5: 45.312 (avg: 45.250)\t\n",
            "Epoch: 81[50/125]\tTime used: 0.361 (avg: 0.365)\tLoss: 2.9763 (avg: 3.5203)\tTop1: 29.688 (avg: 21.844)\tTop5: 56.250 (avg: 45.719)\t\n",
            "Epoch: 81[75/125]\tTime used: 0.360 (avg: 0.367)\tLoss: 3.4879 (avg: 3.5065)\tTop1: 17.188 (avg: 21.604)\tTop5: 45.312 (avg: 46.125)\t\n",
            "Epoch: 81[100/125]\tTime used: 0.365 (avg: 0.368)\tLoss: 3.2766 (avg: 3.5123)\tTop1: 21.875 (avg: 21.312)\tTop5: 48.438 (avg: 45.891)\t\n",
            "Epoch: 81[125/125]\tTime used: 0.362 (avg: 0.368)\tLoss: 3.2690 (avg: 3.5109)\tTop1: 20.312 (avg: 21.050)\tTop5: 51.562 (avg: 45.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3164\tTop 1 accuracy: 12.900\tTop 5 accuracy: 31.800\n",
            "\n",
            "Training...\n",
            "Epoch: 82[25/125]\tTime used: 0.365 (avg: 0.362)\tLoss: 3.3526 (avg: 3.5358)\tTop1: 28.125 (avg: 21.688)\tTop5: 48.438 (avg: 44.375)\t\n",
            "Epoch: 82[50/125]\tTime used: 0.364 (avg: 0.367)\tLoss: 3.5208 (avg: 3.5119)\tTop1: 17.188 (avg: 21.125)\tTop5: 42.188 (avg: 45.000)\t\n",
            "Epoch: 82[75/125]\tTime used: 0.367 (avg: 0.368)\tLoss: 3.2473 (avg: 3.5146)\tTop1: 20.312 (avg: 21.208)\tTop5: 46.875 (avg: 44.750)\t\n",
            "Epoch: 82[100/125]\tTime used: 0.368 (avg: 0.369)\tLoss: 3.5036 (avg: 3.5120)\tTop1: 20.312 (avg: 21.312)\tTop5: 48.438 (avg: 44.906)\t\n",
            "Epoch: 82[125/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 3.4551 (avg: 3.5038)\tTop1: 17.188 (avg: 21.550)\tTop5: 43.750 (avg: 45.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2259\tTop 1 accuracy: 12.600\tTop 5 accuracy: 31.600\n",
            "\n",
            "Training...\n",
            "Epoch: 83[25/125]\tTime used: 0.364 (avg: 0.363)\tLoss: 3.7991 (avg: 3.5152)\tTop1: 14.062 (avg: 21.188)\tTop5: 37.500 (avg: 45.562)\t\n",
            "Epoch: 83[50/125]\tTime used: 0.365 (avg: 0.367)\tLoss: 3.4669 (avg: 3.4624)\tTop1: 14.062 (avg: 21.625)\tTop5: 45.312 (avg: 46.656)\t\n",
            "Epoch: 83[75/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 3.5519 (avg: 3.4859)\tTop1: 20.312 (avg: 21.396)\tTop5: 42.188 (avg: 46.000)\t\n",
            "Epoch: 83[100/125]\tTime used: 0.365 (avg: 0.369)\tLoss: 3.6860 (avg: 3.4864)\tTop1: 17.188 (avg: 21.797)\tTop5: 42.188 (avg: 46.078)\t\n",
            "Epoch: 83[125/125]\tTime used: 0.365 (avg: 0.370)\tLoss: 3.7131 (avg: 3.5014)\tTop1: 15.625 (avg: 21.700)\tTop5: 45.312 (avg: 45.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2463\tTop 1 accuracy: 13.000\tTop 5 accuracy: 31.850\n",
            "\n",
            "Training...\n",
            "Epoch: 84[25/125]\tTime used: 0.366 (avg: 0.363)\tLoss: 3.5778 (avg: 3.5516)\tTop1: 18.750 (avg: 20.812)\tTop5: 40.625 (avg: 45.938)\t\n",
            "Epoch: 84[50/125]\tTime used: 0.365 (avg: 0.368)\tLoss: 3.8869 (avg: 3.5154)\tTop1: 15.625 (avg: 20.594)\tTop5: 32.812 (avg: 46.312)\t\n",
            "Epoch: 84[75/125]\tTime used: 0.366 (avg: 0.369)\tLoss: 3.2154 (avg: 3.5207)\tTop1: 23.438 (avg: 20.458)\tTop5: 56.250 (avg: 45.979)\t\n",
            "Epoch: 84[100/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 3.4942 (avg: 3.4901)\tTop1: 14.062 (avg: 21.016)\tTop5: 45.312 (avg: 46.547)\t\n",
            "Epoch: 84[125/125]\tTime used: 0.370 (avg: 0.370)\tLoss: 4.1374 (avg: 3.5013)\tTop1: 15.625 (avg: 20.875)\tTop5: 34.375 (avg: 46.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3564\tTop 1 accuracy: 13.000\tTop 5 accuracy: 31.100\n",
            "\n",
            "Training...\n",
            "Epoch: 85[25/125]\tTime used: 0.370 (avg: 0.361)\tLoss: 3.4663 (avg: 3.4896)\tTop1: 20.312 (avg: 21.250)\tTop5: 51.562 (avg: 46.812)\t\n",
            "Epoch: 85[50/125]\tTime used: 0.365 (avg: 0.366)\tLoss: 3.4611 (avg: 3.4574)\tTop1: 26.562 (avg: 21.750)\tTop5: 43.750 (avg: 47.375)\t\n",
            "Epoch: 85[75/125]\tTime used: 0.365 (avg: 0.368)\tLoss: 3.4769 (avg: 3.4808)\tTop1: 17.188 (avg: 21.375)\tTop5: 43.750 (avg: 46.250)\t\n",
            "Epoch: 85[100/125]\tTime used: 0.372 (avg: 0.369)\tLoss: 3.5659 (avg: 3.4735)\tTop1: 21.875 (avg: 21.344)\tTop5: 34.375 (avg: 46.703)\t\n",
            "Epoch: 85[125/125]\tTime used: 0.363 (avg: 0.370)\tLoss: 3.6671 (avg: 3.4942)\tTop1: 15.625 (avg: 20.788)\tTop5: 37.500 (avg: 45.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2197\tTop 1 accuracy: 13.050\tTop 5 accuracy: 31.600\n",
            "\n",
            "Training...\n",
            "Epoch: 86[25/125]\tTime used: 0.362 (avg: 0.363)\tLoss: 3.5916 (avg: 3.5001)\tTop1: 18.750 (avg: 21.625)\tTop5: 43.750 (avg: 45.688)\t\n",
            "Epoch: 86[50/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 3.1484 (avg: 3.5228)\tTop1: 18.750 (avg: 21.000)\tTop5: 48.438 (avg: 45.375)\t\n",
            "Epoch: 86[75/125]\tTime used: 0.370 (avg: 0.369)\tLoss: 3.5391 (avg: 3.5219)\tTop1: 21.875 (avg: 21.229)\tTop5: 43.750 (avg: 45.354)\t\n",
            "Epoch: 86[100/125]\tTime used: 0.363 (avg: 0.369)\tLoss: 3.3245 (avg: 3.4968)\tTop1: 23.438 (avg: 21.094)\tTop5: 50.000 (avg: 45.828)\t\n",
            "Epoch: 86[125/125]\tTime used: 0.360 (avg: 0.371)\tLoss: 3.6338 (avg: 3.4931)\tTop1: 18.750 (avg: 21.238)\tTop5: 40.625 (avg: 45.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3433\tTop 1 accuracy: 13.050\tTop 5 accuracy: 31.600\n",
            "\n",
            "Training...\n",
            "Epoch: 87[25/125]\tTime used: 0.361 (avg: 0.363)\tLoss: 3.5856 (avg: 3.4670)\tTop1: 14.062 (avg: 20.812)\tTop5: 43.750 (avg: 45.062)\t\n",
            "Epoch: 87[50/125]\tTime used: 0.372 (avg: 0.368)\tLoss: 3.3711 (avg: 3.4823)\tTop1: 23.438 (avg: 21.062)\tTop5: 53.125 (avg: 45.750)\t\n",
            "Epoch: 87[75/125]\tTime used: 0.358 (avg: 0.368)\tLoss: 3.2973 (avg: 3.4857)\tTop1: 29.688 (avg: 21.146)\tTop5: 46.875 (avg: 45.917)\t\n",
            "Epoch: 87[100/125]\tTime used: 0.366 (avg: 0.369)\tLoss: 3.7130 (avg: 3.4787)\tTop1: 18.750 (avg: 21.344)\tTop5: 42.188 (avg: 45.969)\t\n",
            "Epoch: 87[125/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 3.7198 (avg: 3.4896)\tTop1: 14.062 (avg: 21.150)\tTop5: 40.625 (avg: 45.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2975\tTop 1 accuracy: 12.600\tTop 5 accuracy: 31.500\n",
            "\n",
            "Training...\n",
            "Epoch: 88[25/125]\tTime used: 0.372 (avg: 0.363)\tLoss: 3.5212 (avg: 3.4269)\tTop1: 28.125 (avg: 22.000)\tTop5: 45.312 (avg: 48.188)\t\n",
            "Epoch: 88[50/125]\tTime used: 0.363 (avg: 0.368)\tLoss: 3.8383 (avg: 3.4487)\tTop1: 17.188 (avg: 22.344)\tTop5: 40.625 (avg: 47.125)\t\n",
            "Epoch: 88[75/125]\tTime used: 0.362 (avg: 0.369)\tLoss: 3.3596 (avg: 3.4592)\tTop1: 21.875 (avg: 21.646)\tTop5: 45.312 (avg: 46.542)\t\n",
            "Epoch: 88[100/125]\tTime used: 0.362 (avg: 0.370)\tLoss: 3.6194 (avg: 3.4604)\tTop1: 18.750 (avg: 21.609)\tTop5: 50.000 (avg: 46.578)\t\n",
            "Epoch: 88[125/125]\tTime used: 0.365 (avg: 0.370)\tLoss: 3.7730 (avg: 3.4884)\tTop1: 15.625 (avg: 20.925)\tTop5: 42.188 (avg: 46.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2877\tTop 1 accuracy: 12.750\tTop 5 accuracy: 32.050\n",
            "\n",
            "Training...\n",
            "Epoch: 89[25/125]\tTime used: 0.363 (avg: 0.363)\tLoss: 3.1515 (avg: 3.4588)\tTop1: 21.875 (avg: 21.812)\tTop5: 50.000 (avg: 46.062)\t\n",
            "Epoch: 89[50/125]\tTime used: 0.365 (avg: 0.367)\tLoss: 3.1520 (avg: 3.4702)\tTop1: 31.250 (avg: 21.469)\tTop5: 46.875 (avg: 45.594)\t\n",
            "Epoch: 89[75/125]\tTime used: 0.360 (avg: 0.368)\tLoss: 4.0642 (avg: 3.4724)\tTop1: 20.312 (avg: 21.875)\tTop5: 37.500 (avg: 45.958)\t\n",
            "Epoch: 89[100/125]\tTime used: 0.368 (avg: 0.369)\tLoss: 3.8788 (avg: 3.4788)\tTop1: 14.062 (avg: 21.547)\tTop5: 40.625 (avg: 45.859)\t\n",
            "Epoch: 89[125/125]\tTime used: 0.366 (avg: 0.370)\tLoss: 3.6428 (avg: 3.4868)\tTop1: 14.062 (avg: 21.338)\tTop5: 43.750 (avg: 45.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2505\tTop 1 accuracy: 13.000\tTop 5 accuracy: 31.750\n",
            "\n",
            "Training...\n",
            "Epoch: 90[25/125]\tTime used: 0.364 (avg: 0.363)\tLoss: 3.3023 (avg: 3.4380)\tTop1: 23.438 (avg: 22.812)\tTop5: 51.562 (avg: 47.000)\t\n",
            "Epoch: 90[50/125]\tTime used: 0.361 (avg: 0.367)\tLoss: 3.4646 (avg: 3.4582)\tTop1: 26.562 (avg: 22.031)\tTop5: 48.438 (avg: 45.969)\t\n",
            "Epoch: 90[75/125]\tTime used: 0.360 (avg: 0.369)\tLoss: 3.3768 (avg: 3.4747)\tTop1: 26.562 (avg: 21.562)\tTop5: 51.562 (avg: 46.083)\t\n",
            "Epoch: 90[100/125]\tTime used: 0.364 (avg: 0.368)\tLoss: 3.2881 (avg: 3.4697)\tTop1: 25.000 (avg: 21.969)\tTop5: 48.438 (avg: 46.031)\t\n",
            "Epoch: 90[125/125]\tTime used: 0.363 (avg: 0.369)\tLoss: 3.8327 (avg: 3.4627)\tTop1: 14.062 (avg: 22.213)\tTop5: 39.062 (avg: 46.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2584\tTop 1 accuracy: 13.350\tTop 5 accuracy: 31.750\n",
            "\n",
            "Training...\n",
            "Epoch: 91[25/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 3.5412 (avg: 3.4408)\tTop1: 21.875 (avg: 23.188)\tTop5: 53.125 (avg: 47.562)\t\n",
            "Epoch: 91[50/125]\tTime used: 0.368 (avg: 0.367)\tLoss: 3.3642 (avg: 3.4579)\tTop1: 20.312 (avg: 22.812)\tTop5: 51.562 (avg: 46.969)\t\n",
            "Epoch: 91[75/125]\tTime used: 0.365 (avg: 0.369)\tLoss: 3.6380 (avg: 3.4457)\tTop1: 18.750 (avg: 22.708)\tTop5: 37.500 (avg: 46.833)\t\n",
            "Epoch: 91[100/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 3.3435 (avg: 3.4481)\tTop1: 21.875 (avg: 22.406)\tTop5: 46.875 (avg: 46.641)\t\n",
            "Epoch: 91[125/125]\tTime used: 0.365 (avg: 0.370)\tLoss: 3.3915 (avg: 3.4540)\tTop1: 20.312 (avg: 22.350)\tTop5: 45.312 (avg: 46.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2703\tTop 1 accuracy: 13.300\tTop 5 accuracy: 31.650\n",
            "\n",
            "Training...\n",
            "Epoch: 92[25/125]\tTime used: 0.362 (avg: 0.362)\tLoss: 3.7755 (avg: 3.4634)\tTop1: 17.188 (avg: 23.125)\tTop5: 45.312 (avg: 47.438)\t\n",
            "Epoch: 92[50/125]\tTime used: 0.366 (avg: 0.367)\tLoss: 3.0847 (avg: 3.4668)\tTop1: 25.000 (avg: 22.562)\tTop5: 50.000 (avg: 47.219)\t\n",
            "Epoch: 92[75/125]\tTime used: 0.365 (avg: 0.369)\tLoss: 3.2542 (avg: 3.4543)\tTop1: 28.125 (avg: 22.417)\tTop5: 50.000 (avg: 46.854)\t\n",
            "Epoch: 92[100/125]\tTime used: 0.363 (avg: 0.370)\tLoss: 3.5108 (avg: 3.4624)\tTop1: 17.188 (avg: 21.891)\tTop5: 48.438 (avg: 46.484)\t\n",
            "Epoch: 92[125/125]\tTime used: 0.373 (avg: 0.370)\tLoss: 3.6363 (avg: 3.4602)\tTop1: 17.188 (avg: 21.725)\tTop5: 43.750 (avg: 46.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2727\tTop 1 accuracy: 13.450\tTop 5 accuracy: 31.700\n",
            "\n",
            "Training...\n",
            "Epoch: 93[25/125]\tTime used: 0.367 (avg: 0.363)\tLoss: 3.6617 (avg: 3.5047)\tTop1: 14.062 (avg: 21.312)\tTop5: 45.312 (avg: 46.938)\t\n",
            "Epoch: 93[50/125]\tTime used: 0.371 (avg: 0.368)\tLoss: 3.2110 (avg: 3.4609)\tTop1: 28.125 (avg: 22.000)\tTop5: 51.562 (avg: 47.031)\t\n",
            "Epoch: 93[75/125]\tTime used: 0.368 (avg: 0.369)\tLoss: 3.3763 (avg: 3.4739)\tTop1: 23.438 (avg: 21.917)\tTop5: 46.875 (avg: 46.417)\t\n",
            "Epoch: 93[100/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 3.5701 (avg: 3.4526)\tTop1: 25.000 (avg: 22.328)\tTop5: 45.312 (avg: 46.594)\t\n",
            "Epoch: 93[125/125]\tTime used: 0.366 (avg: 0.372)\tLoss: 3.7666 (avg: 3.4583)\tTop1: 17.188 (avg: 22.313)\tTop5: 39.062 (avg: 46.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2549\tTop 1 accuracy: 13.250\tTop 5 accuracy: 31.750\n",
            "\n",
            "Training...\n",
            "Epoch: 94[25/125]\tTime used: 0.361 (avg: 0.363)\tLoss: 3.7417 (avg: 3.4556)\tTop1: 21.875 (avg: 22.125)\tTop5: 40.625 (avg: 47.250)\t\n",
            "Epoch: 94[50/125]\tTime used: 0.363 (avg: 0.368)\tLoss: 3.7538 (avg: 3.4770)\tTop1: 17.188 (avg: 21.688)\tTop5: 39.062 (avg: 46.562)\t\n",
            "Epoch: 94[75/125]\tTime used: 0.371 (avg: 0.369)\tLoss: 3.6072 (avg: 3.4475)\tTop1: 15.625 (avg: 21.896)\tTop5: 40.625 (avg: 46.792)\t\n",
            "Epoch: 94[100/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 3.3836 (avg: 3.4381)\tTop1: 20.312 (avg: 21.859)\tTop5: 50.000 (avg: 46.906)\t\n",
            "Epoch: 94[125/125]\tTime used: 0.363 (avg: 0.370)\tLoss: 3.4800 (avg: 3.4526)\tTop1: 14.062 (avg: 21.638)\tTop5: 43.750 (avg: 46.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2621\tTop 1 accuracy: 13.350\tTop 5 accuracy: 31.800\n",
            "\n",
            "Training...\n",
            "Epoch: 95[25/125]\tTime used: 0.365 (avg: 0.363)\tLoss: 4.0153 (avg: 3.5348)\tTop1: 17.188 (avg: 20.438)\tTop5: 31.250 (avg: 44.688)\t\n",
            "Epoch: 95[50/125]\tTime used: 0.373 (avg: 0.368)\tLoss: 3.4797 (avg: 3.4823)\tTop1: 31.250 (avg: 20.969)\tTop5: 51.562 (avg: 45.000)\t\n",
            "Epoch: 95[75/125]\tTime used: 0.364 (avg: 0.369)\tLoss: 3.8217 (avg: 3.4961)\tTop1: 21.875 (avg: 21.333)\tTop5: 34.375 (avg: 45.500)\t\n",
            "Epoch: 95[100/125]\tTime used: 0.364 (avg: 0.370)\tLoss: 3.3314 (avg: 3.4638)\tTop1: 20.312 (avg: 21.922)\tTop5: 46.875 (avg: 46.250)\t\n",
            "Epoch: 95[125/125]\tTime used: 0.365 (avg: 0.370)\tLoss: 3.6666 (avg: 3.4565)\tTop1: 21.875 (avg: 22.213)\tTop5: 40.625 (avg: 46.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2566\tTop 1 accuracy: 13.400\tTop 5 accuracy: 31.700\n",
            "\n",
            "Training...\n",
            "Epoch: 96[25/125]\tTime used: 0.367 (avg: 0.360)\tLoss: 3.8148 (avg: 3.4100)\tTop1: 18.750 (avg: 22.562)\tTop5: 35.938 (avg: 47.500)\t\n",
            "Epoch: 96[50/125]\tTime used: 0.365 (avg: 0.365)\tLoss: 3.5213 (avg: 3.4356)\tTop1: 18.750 (avg: 22.188)\tTop5: 40.625 (avg: 46.594)\t\n",
            "Epoch: 96[75/125]\tTime used: 0.362 (avg: 0.368)\tLoss: 3.6261 (avg: 3.4492)\tTop1: 17.188 (avg: 21.729)\tTop5: 48.438 (avg: 47.021)\t\n",
            "Epoch: 96[100/125]\tTime used: 0.363 (avg: 0.369)\tLoss: 3.4991 (avg: 3.4495)\tTop1: 18.750 (avg: 21.719)\tTop5: 50.000 (avg: 47.125)\t\n",
            "Epoch: 96[125/125]\tTime used: 0.367 (avg: 0.369)\tLoss: 3.5845 (avg: 3.4534)\tTop1: 15.625 (avg: 21.800)\tTop5: 48.438 (avg: 46.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2891\tTop 1 accuracy: 13.050\tTop 5 accuracy: 31.650\n",
            "\n",
            "Training...\n",
            "Epoch: 97[25/125]\tTime used: 0.363 (avg: 0.363)\tLoss: 3.6148 (avg: 3.4443)\tTop1: 15.625 (avg: 22.438)\tTop5: 40.625 (avg: 45.188)\t\n",
            "Epoch: 97[50/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 3.5115 (avg: 3.4340)\tTop1: 20.312 (avg: 22.062)\tTop5: 43.750 (avg: 46.000)\t\n",
            "Epoch: 97[75/125]\tTime used: 0.363 (avg: 0.369)\tLoss: 3.4731 (avg: 3.4561)\tTop1: 28.125 (avg: 22.083)\tTop5: 46.875 (avg: 45.979)\t\n",
            "Epoch: 97[100/125]\tTime used: 0.367 (avg: 0.370)\tLoss: 3.7124 (avg: 3.4450)\tTop1: 17.188 (avg: 22.328)\tTop5: 37.500 (avg: 46.250)\t\n",
            "Epoch: 97[125/125]\tTime used: 0.366 (avg: 0.370)\tLoss: 3.2808 (avg: 3.4522)\tTop1: 26.562 (avg: 21.975)\tTop5: 45.312 (avg: 46.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2892\tTop 1 accuracy: 13.050\tTop 5 accuracy: 31.750\n",
            "\n",
            "Training...\n",
            "Epoch: 98[25/125]\tTime used: 0.363 (avg: 0.363)\tLoss: 3.5364 (avg: 3.3976)\tTop1: 20.312 (avg: 20.562)\tTop5: 45.312 (avg: 48.125)\t\n",
            "Epoch: 98[50/125]\tTime used: 0.364 (avg: 0.368)\tLoss: 3.6206 (avg: 3.4524)\tTop1: 18.750 (avg: 20.906)\tTop5: 34.375 (avg: 46.125)\t\n",
            "Epoch: 98[75/125]\tTime used: 0.365 (avg: 0.368)\tLoss: 3.5238 (avg: 3.4416)\tTop1: 20.312 (avg: 21.708)\tTop5: 43.750 (avg: 46.438)\t\n",
            "Epoch: 98[100/125]\tTime used: 0.366 (avg: 0.369)\tLoss: 3.0742 (avg: 3.4343)\tTop1: 21.875 (avg: 22.344)\tTop5: 59.375 (avg: 47.141)\t\n",
            "Epoch: 98[125/125]\tTime used: 0.361 (avg: 0.370)\tLoss: 3.3860 (avg: 3.4551)\tTop1: 21.875 (avg: 21.950)\tTop5: 50.000 (avg: 46.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2787\tTop 1 accuracy: 13.100\tTop 5 accuracy: 31.950\n",
            "\n",
            "Training...\n",
            "Epoch: 99[25/125]\tTime used: 0.363 (avg: 0.363)\tLoss: 3.2816 (avg: 3.4249)\tTop1: 25.000 (avg: 21.938)\tTop5: 54.688 (avg: 47.438)\t\n",
            "Epoch: 99[50/125]\tTime used: 0.365 (avg: 0.367)\tLoss: 3.4333 (avg: 3.4370)\tTop1: 26.562 (avg: 22.125)\tTop5: 46.875 (avg: 47.281)\t\n",
            "Epoch: 99[75/125]\tTime used: 0.363 (avg: 0.369)\tLoss: 3.7582 (avg: 3.4481)\tTop1: 10.938 (avg: 21.833)\tTop5: 43.750 (avg: 46.646)\t\n",
            "Epoch: 99[100/125]\tTime used: 0.365 (avg: 0.370)\tLoss: 3.6043 (avg: 3.4586)\tTop1: 18.750 (avg: 21.594)\tTop5: 42.188 (avg: 46.156)\t\n",
            "Epoch: 99[125/125]\tTime used: 0.366 (avg: 0.370)\tLoss: 3.5835 (avg: 3.4535)\tTop1: 25.000 (avg: 22.000)\tTop5: 43.750 (avg: 46.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2563\tTop 1 accuracy: 13.250\tTop 5 accuracy: 31.650\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xBIT0ZfbCm6H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Metaparameters"
      ]
    },
    {
      "metadata": {
        "id": "oWp-fxCYCuFR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64008
        },
        "outputId": "799df13d-5da7-455c-ea2a-c73f5203d658"
      },
      "cell_type": "code",
      "source": [
        "# Squeeze ratio\n",
        "sr_list = [0.125, 0.25, 0.5, 0.75, 1.0]\n",
        "sr_top1s = []\n",
        "sr_top5s = []\n",
        "sr_batch_times = []\n",
        "for sr in sr_list:\n",
        "  model = SqueezeNet_MetaParam(version=1.0, sr=sr)\n",
        "  batch_time, top1, top5 = test_model(model)\n",
        "  sr_top1s.append(top1)\n",
        "  sr_top5s.append(top5)\n",
        "  sr_batch_times.append(batch_time)\n",
        "  print(\"SR = {0}: top1 = {1} \\t top5 = {2} \\t batch time = {3}\\n\".format(sr, top1, top5, batch_time))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.352 (avg: 0.356)\tLoss: 5.3022 (avg: 5.3025)\tTop1: 0.000 (avg: 0.562)\tTop5: 1.562 (avg: 2.500)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.363 (avg: 0.359)\tLoss: 5.2944 (avg: 5.3000)\tTop1: 1.562 (avg: 0.531)\tTop5: 1.562 (avg: 2.469)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.350 (avg: 0.359)\tLoss: 5.2947 (avg: 5.2975)\tTop1: 0.000 (avg: 0.521)\tTop5: 0.000 (avg: 2.458)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.352 (avg: 0.360)\tLoss: 5.2583 (avg: 5.2950)\tTop1: 0.000 (avg: 0.500)\tTop5: 3.125 (avg: 2.391)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.351 (avg: 0.360)\tLoss: 5.2488 (avg: 5.2903)\tTop1: 0.000 (avg: 0.500)\tTop5: 3.125 (avg: 2.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2625\tTop 1 accuracy: 1.050\tTop 5 accuracy: 2.800\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.353 (avg: 0.352)\tLoss: 5.2764 (avg: 5.2706)\tTop1: 0.000 (avg: 0.562)\tTop5: 1.562 (avg: 2.938)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.361 (avg: 0.356)\tLoss: 5.2853 (avg: 5.2683)\tTop1: 1.562 (avg: 0.562)\tTop5: 3.125 (avg: 3.031)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 5.3581 (avg: 5.2654)\tTop1: 0.000 (avg: 0.729)\tTop5: 1.562 (avg: 3.250)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.349 (avg: 0.359)\tLoss: 5.2350 (avg: 5.2614)\tTop1: 1.562 (avg: 0.734)\tTop5: 4.688 (avg: 3.250)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 5.2555 (avg: 5.2568)\tTop1: 1.562 (avg: 0.775)\tTop5: 3.125 (avg: 3.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2509\tTop 1 accuracy: 0.800\tTop 5 accuracy: 3.650\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.352 (avg: 0.351)\tLoss: 5.2100 (avg: 5.2527)\tTop1: 3.125 (avg: 0.938)\tTop5: 10.938 (avg: 4.625)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.358 (avg: 0.355)\tLoss: 5.2154 (avg: 5.2506)\tTop1: 1.562 (avg: 1.094)\tTop5: 3.125 (avg: 4.625)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.348 (avg: 0.356)\tLoss: 5.2248 (avg: 5.2452)\tTop1: 0.000 (avg: 1.062)\tTop5: 4.688 (avg: 4.500)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.348 (avg: 0.356)\tLoss: 5.1600 (avg: 5.2401)\tTop1: 1.562 (avg: 1.031)\tTop5: 4.688 (avg: 4.453)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.348 (avg: 0.357)\tLoss: 5.2227 (avg: 5.2385)\tTop1: 3.125 (avg: 1.013)\tTop5: 4.688 (avg: 4.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2680\tTop 1 accuracy: 0.750\tTop 5 accuracy: 4.250\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.351 (avg: 0.351)\tLoss: 5.2315 (avg: 5.2440)\tTop1: 0.000 (avg: 1.250)\tTop5: 3.125 (avg: 4.688)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.360 (avg: 0.356)\tLoss: 5.1620 (avg: 5.2369)\tTop1: 0.000 (avg: 1.188)\tTop5: 7.812 (avg: 4.562)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.352 (avg: 0.357)\tLoss: 5.2282 (avg: 5.2398)\tTop1: 1.562 (avg: 1.042)\tTop5: 7.812 (avg: 4.292)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.349 (avg: 0.358)\tLoss: 5.2806 (avg: 5.2438)\tTop1: 0.000 (avg: 1.047)\tTop5: 4.688 (avg: 4.422)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 5.1969 (avg: 5.2400)\tTop1: 3.125 (avg: 0.975)\tTop5: 6.250 (avg: 4.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2616\tTop 1 accuracy: 0.900\tTop 5 accuracy: 4.250\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.356 (avg: 0.351)\tLoss: 5.2969 (avg: 5.2128)\tTop1: 1.562 (avg: 1.188)\tTop5: 3.125 (avg: 5.250)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.357 (avg: 0.355)\tLoss: 5.2319 (avg: 5.2291)\tTop1: 3.125 (avg: 1.094)\tTop5: 6.250 (avg: 4.969)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.350 (avg: 0.357)\tLoss: 5.1994 (avg: 5.2297)\tTop1: 0.000 (avg: 0.979)\tTop5: 3.125 (avg: 4.750)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 5.2231 (avg: 5.2300)\tTop1: 0.000 (avg: 0.984)\tTop5: 3.125 (avg: 4.734)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 5.2480 (avg: 5.2307)\tTop1: 1.562 (avg: 0.975)\tTop5: 6.250 (avg: 4.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2610\tTop 1 accuracy: 1.000\tTop 5 accuracy: 4.800\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.350 (avg: 0.351)\tLoss: 5.1948 (avg: 5.2213)\tTop1: 0.000 (avg: 0.938)\tTop5: 3.125 (avg: 4.812)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.362 (avg: 0.356)\tLoss: 5.2334 (avg: 5.2136)\tTop1: 0.000 (avg: 1.219)\tTop5: 3.125 (avg: 5.156)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 5.1509 (avg: 5.2138)\tTop1: 1.562 (avg: 1.271)\tTop5: 9.375 (avg: 5.271)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.349 (avg: 0.358)\tLoss: 5.3206 (avg: 5.2191)\tTop1: 0.000 (avg: 1.141)\tTop5: 3.125 (avg: 5.109)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 5.1102 (avg: 5.2205)\tTop1: 1.562 (avg: 1.113)\tTop5: 14.062 (avg: 5.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2181\tTop 1 accuracy: 1.600\tTop 5 accuracy: 5.300\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.353 (avg: 0.352)\tLoss: 5.2335 (avg: 5.2032)\tTop1: 0.000 (avg: 1.500)\tTop5: 1.562 (avg: 5.438)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.359 (avg: 0.357)\tLoss: 5.1833 (avg: 5.2068)\tTop1: 0.000 (avg: 1.469)\tTop5: 4.688 (avg: 5.750)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 5.1661 (avg: 5.2055)\tTop1: 4.688 (avg: 1.458)\tTop5: 10.938 (avg: 5.938)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 5.2041 (avg: 5.2093)\tTop1: 0.000 (avg: 1.312)\tTop5: 6.250 (avg: 5.766)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.350 (avg: 0.359)\tLoss: 5.2243 (avg: 5.2054)\tTop1: 0.000 (avg: 1.338)\tTop5: 7.812 (avg: 5.813)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2705\tTop 1 accuracy: 1.400\tTop 5 accuracy: 4.800\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.349 (avg: 0.352)\tLoss: 5.2431 (avg: 5.1651)\tTop1: 1.562 (avg: 1.250)\tTop5: 6.250 (avg: 7.250)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.358 (avg: 0.356)\tLoss: 5.2983 (avg: 5.1842)\tTop1: 1.562 (avg: 1.281)\tTop5: 4.688 (avg: 6.812)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 5.1403 (avg: 5.1823)\tTop1: 1.562 (avg: 1.312)\tTop5: 6.250 (avg: 6.604)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 5.2221 (avg: 5.1856)\tTop1: 1.562 (avg: 1.188)\tTop5: 4.688 (avg: 6.531)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 5.2397 (avg: 5.1873)\tTop1: 0.000 (avg: 1.200)\tTop5: 6.250 (avg: 6.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2136\tTop 1 accuracy: 1.500\tTop 5 accuracy: 5.950\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.348 (avg: 0.349)\tLoss: 5.1325 (avg: 5.1648)\tTop1: 3.125 (avg: 1.938)\tTop5: 10.938 (avg: 6.438)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.355 (avg: 0.354)\tLoss: 5.0897 (avg: 5.1605)\tTop1: 3.125 (avg: 1.688)\tTop5: 10.938 (avg: 6.344)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.352 (avg: 0.355)\tLoss: 5.0501 (avg: 5.1597)\tTop1: 6.250 (avg: 1.542)\tTop5: 15.625 (avg: 6.375)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.351 (avg: 0.357)\tLoss: 5.2170 (avg: 5.1678)\tTop1: 1.562 (avg: 1.453)\tTop5: 4.688 (avg: 6.031)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.352 (avg: 0.357)\tLoss: 5.0626 (avg: 5.1604)\tTop1: 1.562 (avg: 1.438)\tTop5: 6.250 (avg: 6.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2594\tTop 1 accuracy: 1.500\tTop 5 accuracy: 7.400\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.353 (avg: 0.352)\tLoss: 5.1760 (avg: 5.1175)\tTop1: 1.562 (avg: 1.688)\tTop5: 3.125 (avg: 7.188)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.361 (avg: 0.356)\tLoss: 5.0417 (avg: 5.1120)\tTop1: 1.562 (avg: 1.625)\tTop5: 7.812 (avg: 7.094)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 5.0480 (avg: 5.1241)\tTop1: 1.562 (avg: 1.646)\tTop5: 7.812 (avg: 6.854)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.352 (avg: 0.359)\tLoss: 5.1414 (avg: 5.1251)\tTop1: 0.000 (avg: 1.656)\tTop5: 6.250 (avg: 7.047)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 5.2151 (avg: 5.1256)\tTop1: 0.000 (avg: 1.663)\tTop5: 4.688 (avg: 7.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1004\tTop 1 accuracy: 1.600\tTop 5 accuracy: 7.600\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.350 (avg: 0.351)\tLoss: 5.2272 (avg: 5.0871)\tTop1: 1.562 (avg: 1.375)\tTop5: 6.250 (avg: 7.562)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.362 (avg: 0.356)\tLoss: 5.0865 (avg: 5.0840)\tTop1: 1.562 (avg: 1.719)\tTop5: 9.375 (avg: 8.000)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.353 (avg: 0.358)\tLoss: 5.0413 (avg: 5.0919)\tTop1: 1.562 (avg: 1.771)\tTop5: 10.938 (avg: 7.812)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 5.2298 (avg: 5.0889)\tTop1: 1.562 (avg: 1.766)\tTop5: 7.812 (avg: 8.000)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.350 (avg: 0.359)\tLoss: 5.1312 (avg: 5.0889)\tTop1: 1.562 (avg: 1.913)\tTop5: 6.250 (avg: 8.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2235\tTop 1 accuracy: 1.800\tTop 5 accuracy: 8.400\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.352 (avg: 0.352)\tLoss: 5.0135 (avg: 5.0443)\tTop1: 1.562 (avg: 2.000)\tTop5: 12.500 (avg: 8.625)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.360 (avg: 0.356)\tLoss: 5.0481 (avg: 5.0430)\tTop1: 3.125 (avg: 1.938)\tTop5: 10.938 (avg: 8.406)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.352 (avg: 0.357)\tLoss: 4.9674 (avg: 5.0374)\tTop1: 4.688 (avg: 2.000)\tTop5: 7.812 (avg: 8.292)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 4.9038 (avg: 5.0368)\tTop1: 1.562 (avg: 2.000)\tTop5: 10.938 (avg: 8.406)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.350 (avg: 0.359)\tLoss: 5.0640 (avg: 5.0338)\tTop1: 3.125 (avg: 2.075)\tTop5: 4.688 (avg: 8.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1734\tTop 1 accuracy: 2.050\tTop 5 accuracy: 7.500\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.353 (avg: 0.352)\tLoss: 4.9209 (avg: 5.0487)\tTop1: 0.000 (avg: 1.688)\tTop5: 15.625 (avg: 8.188)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.363 (avg: 0.357)\tLoss: 5.0404 (avg: 5.0466)\tTop1: 1.562 (avg: 2.031)\tTop5: 4.688 (avg: 8.094)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.353 (avg: 0.358)\tLoss: 5.0639 (avg: 5.0314)\tTop1: 3.125 (avg: 2.062)\tTop5: 7.812 (avg: 8.708)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 5.0491 (avg: 5.0284)\tTop1: 1.562 (avg: 2.094)\tTop5: 10.938 (avg: 8.672)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.350 (avg: 0.359)\tLoss: 4.9159 (avg: 5.0274)\tTop1: 3.125 (avg: 2.150)\tTop5: 9.375 (avg: 8.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9766\tTop 1 accuracy: 1.850\tTop 5 accuracy: 8.350\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.352 (avg: 0.352)\tLoss: 5.0082 (avg: 4.9897)\tTop1: 3.125 (avg: 2.312)\tTop5: 10.938 (avg: 9.750)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.362 (avg: 0.356)\tLoss: 4.8794 (avg: 4.9740)\tTop1: 6.250 (avg: 2.312)\tTop5: 14.062 (avg: 9.844)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.355 (avg: 0.358)\tLoss: 4.8960 (avg: 4.9782)\tTop1: 4.688 (avg: 2.333)\tTop5: 9.375 (avg: 9.792)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.350 (avg: 0.358)\tLoss: 4.9520 (avg: 4.9739)\tTop1: 1.562 (avg: 2.359)\tTop5: 6.250 (avg: 9.828)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.350 (avg: 0.358)\tLoss: 4.8115 (avg: 4.9693)\tTop1: 3.125 (avg: 2.350)\tTop5: 7.812 (avg: 9.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1755\tTop 1 accuracy: 1.850\tTop 5 accuracy: 9.500\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.347 (avg: 0.348)\tLoss: 4.8846 (avg: 4.9217)\tTop1: 1.562 (avg: 3.188)\tTop5: 3.125 (avg: 11.812)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.361 (avg: 0.354)\tLoss: 4.7671 (avg: 4.9289)\tTop1: 3.125 (avg: 2.812)\tTop5: 15.625 (avg: 11.438)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.352 (avg: 0.356)\tLoss: 4.9856 (avg: 4.9193)\tTop1: 0.000 (avg: 2.896)\tTop5: 3.125 (avg: 11.104)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.350 (avg: 0.358)\tLoss: 4.8720 (avg: 4.9288)\tTop1: 3.125 (avg: 2.875)\tTop5: 17.188 (avg: 11.000)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.350 (avg: 0.358)\tLoss: 4.8607 (avg: 4.9295)\tTop1: 4.688 (avg: 2.888)\tTop5: 14.062 (avg: 11.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9324\tTop 1 accuracy: 2.700\tTop 5 accuracy: 10.250\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.351 (avg: 0.353)\tLoss: 4.5465 (avg: 4.8463)\tTop1: 6.250 (avg: 3.688)\tTop5: 20.312 (avg: 13.062)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.363 (avg: 0.357)\tLoss: 4.8764 (avg: 4.8828)\tTop1: 1.562 (avg: 3.312)\tTop5: 10.938 (avg: 12.406)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.355 (avg: 0.358)\tLoss: 4.9718 (avg: 4.8803)\tTop1: 3.125 (avg: 3.062)\tTop5: 9.375 (avg: 12.042)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.352 (avg: 0.359)\tLoss: 4.7499 (avg: 4.8795)\tTop1: 6.250 (avg: 3.062)\tTop5: 15.625 (avg: 12.016)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.351 (avg: 0.360)\tLoss: 4.8908 (avg: 4.8819)\tTop1: 1.562 (avg: 3.113)\tTop5: 10.938 (avg: 11.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7458\tTop 1 accuracy: 3.550\tTop 5 accuracy: 12.000\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.353 (avg: 0.352)\tLoss: 4.9788 (avg: 4.7775)\tTop1: 1.562 (avg: 2.688)\tTop5: 10.938 (avg: 14.375)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.364 (avg: 0.357)\tLoss: 4.7881 (avg: 4.7887)\tTop1: 3.125 (avg: 3.031)\tTop5: 14.062 (avg: 14.094)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 4.9054 (avg: 4.7980)\tTop1: 4.688 (avg: 3.167)\tTop5: 4.688 (avg: 13.625)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 4.9122 (avg: 4.8059)\tTop1: 1.562 (avg: 3.156)\tTop5: 14.062 (avg: 13.219)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.351 (avg: 0.360)\tLoss: 4.8822 (avg: 4.8131)\tTop1: 4.688 (avg: 3.100)\tTop5: 10.938 (avg: 13.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9563\tTop 1 accuracy: 2.900\tTop 5 accuracy: 12.200\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.352 (avg: 0.352)\tLoss: 4.6225 (avg: 4.7325)\tTop1: 3.125 (avg: 4.438)\tTop5: 26.562 (avg: 15.188)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.354 (avg: 0.356)\tLoss: 4.8767 (avg: 4.7548)\tTop1: 6.250 (avg: 3.938)\tTop5: 18.750 (avg: 14.969)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 4.5776 (avg: 4.7535)\tTop1: 4.688 (avg: 3.750)\tTop5: 17.188 (avg: 14.708)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.350 (avg: 0.359)\tLoss: 4.6589 (avg: 4.7574)\tTop1: 7.812 (avg: 3.766)\tTop5: 26.562 (avg: 14.391)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 4.6619 (avg: 4.7620)\tTop1: 10.938 (avg: 3.788)\tTop5: 23.438 (avg: 14.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4873\tTop 1 accuracy: 3.400\tTop 5 accuracy: 13.600\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.352 (avg: 0.353)\tLoss: 4.7527 (avg: 4.7263)\tTop1: 1.562 (avg: 3.438)\tTop5: 12.500 (avg: 14.625)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.360 (avg: 0.357)\tLoss: 4.7430 (avg: 4.7177)\tTop1: 4.688 (avg: 4.000)\tTop5: 18.750 (avg: 15.438)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 4.8941 (avg: 4.7127)\tTop1: 3.125 (avg: 4.292)\tTop5: 7.812 (avg: 15.896)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.349 (avg: 0.359)\tLoss: 4.9127 (avg: 4.7173)\tTop1: 0.000 (avg: 4.344)\tTop5: 7.812 (avg: 15.844)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 5.1363 (avg: 4.7176)\tTop1: 1.562 (avg: 4.425)\tTop5: 12.500 (avg: 15.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8139\tTop 1 accuracy: 4.150\tTop 5 accuracy: 14.550\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.353 (avg: 0.353)\tLoss: 4.8059 (avg: 4.6784)\tTop1: 4.688 (avg: 4.688)\tTop5: 21.875 (avg: 15.688)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.354 (avg: 0.357)\tLoss: 4.6089 (avg: 4.6818)\tTop1: 4.688 (avg: 4.750)\tTop5: 23.438 (avg: 15.969)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.353 (avg: 0.358)\tLoss: 4.5416 (avg: 4.6942)\tTop1: 9.375 (avg: 4.250)\tTop5: 21.875 (avg: 15.500)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.350 (avg: 0.358)\tLoss: 4.4002 (avg: 4.6728)\tTop1: 9.375 (avg: 4.359)\tTop5: 25.000 (avg: 16.125)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.354 (avg: 0.358)\tLoss: 4.6897 (avg: 4.6671)\tTop1: 3.125 (avg: 4.475)\tTop5: 15.625 (avg: 16.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7677\tTop 1 accuracy: 4.650\tTop 5 accuracy: 14.400\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.353 (avg: 0.353)\tLoss: 4.4854 (avg: 4.6045)\tTop1: 7.812 (avg: 5.438)\tTop5: 20.312 (avg: 17.375)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.359 (avg: 0.357)\tLoss: 4.8402 (avg: 4.6040)\tTop1: 4.688 (avg: 4.938)\tTop5: 9.375 (avg: 17.438)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 4.6442 (avg: 4.6032)\tTop1: 7.812 (avg: 5.000)\tTop5: 20.312 (avg: 17.354)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 4.3337 (avg: 4.6103)\tTop1: 9.375 (avg: 5.094)\tTop5: 26.562 (avg: 17.516)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.350 (avg: 0.360)\tLoss: 4.5267 (avg: 4.6094)\tTop1: 9.375 (avg: 5.250)\tTop5: 23.438 (avg: 17.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7635\tTop 1 accuracy: 5.800\tTop 5 accuracy: 17.450\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.353 (avg: 0.353)\tLoss: 4.5542 (avg: 4.5312)\tTop1: 3.125 (avg: 5.250)\tTop5: 20.312 (avg: 19.625)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.368 (avg: 0.358)\tLoss: 4.5016 (avg: 4.5550)\tTop1: 3.125 (avg: 5.062)\tTop5: 15.625 (avg: 18.562)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.352 (avg: 0.359)\tLoss: 4.6306 (avg: 4.5609)\tTop1: 4.688 (avg: 4.854)\tTop5: 28.125 (avg: 18.667)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 4.5729 (avg: 4.5641)\tTop1: 4.688 (avg: 5.000)\tTop5: 14.062 (avg: 18.500)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.352 (avg: 0.360)\tLoss: 4.4948 (avg: 4.5581)\tTop1: 9.375 (avg: 5.050)\tTop5: 21.875 (avg: 18.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9819\tTop 1 accuracy: 4.800\tTop 5 accuracy: 14.850\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.351 (avg: 0.353)\tLoss: 4.5142 (avg: 4.5128)\tTop1: 6.250 (avg: 6.375)\tTop5: 21.875 (avg: 21.312)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.359 (avg: 0.357)\tLoss: 4.6425 (avg: 4.5175)\tTop1: 6.250 (avg: 5.875)\tTop5: 18.750 (avg: 20.656)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 4.8043 (avg: 4.5328)\tTop1: 1.562 (avg: 5.792)\tTop5: 14.062 (avg: 20.292)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.350 (avg: 0.359)\tLoss: 4.5992 (avg: 4.5388)\tTop1: 7.812 (avg: 5.719)\tTop5: 20.312 (avg: 20.203)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.350 (avg: 0.359)\tLoss: 4.5931 (avg: 4.5335)\tTop1: 6.250 (avg: 5.938)\tTop5: 15.625 (avg: 20.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5919\tTop 1 accuracy: 5.350\tTop 5 accuracy: 18.100\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.352 (avg: 0.352)\tLoss: 4.6605 (avg: 4.5220)\tTop1: 1.562 (avg: 5.875)\tTop5: 28.125 (avg: 20.500)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.360 (avg: 0.357)\tLoss: 4.1690 (avg: 4.5050)\tTop1: 9.375 (avg: 6.000)\tTop5: 26.562 (avg: 20.562)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 4.4854 (avg: 4.5007)\tTop1: 9.375 (avg: 6.167)\tTop5: 20.312 (avg: 20.646)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 4.8395 (avg: 4.4883)\tTop1: 3.125 (avg: 6.297)\tTop5: 10.938 (avg: 20.844)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.352 (avg: 0.359)\tLoss: 4.2898 (avg: 4.4877)\tTop1: 9.375 (avg: 6.213)\tTop5: 26.562 (avg: 21.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6233\tTop 1 accuracy: 6.650\tTop 5 accuracy: 19.550\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.352 (avg: 0.352)\tLoss: 4.5434 (avg: 4.4073)\tTop1: 10.938 (avg: 6.812)\tTop5: 20.312 (avg: 21.750)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.358 (avg: 0.357)\tLoss: 4.4164 (avg: 4.4117)\tTop1: 10.938 (avg: 6.812)\tTop5: 26.562 (avg: 21.969)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.354 (avg: 0.358)\tLoss: 4.3901 (avg: 4.4385)\tTop1: 10.938 (avg: 6.667)\tTop5: 28.125 (avg: 21.896)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 4.3979 (avg: 4.4415)\tTop1: 6.250 (avg: 6.734)\tTop5: 25.000 (avg: 22.172)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 4.4471 (avg: 4.4341)\tTop1: 6.250 (avg: 6.663)\tTop5: 23.438 (avg: 22.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2865\tTop 1 accuracy: 6.350\tTop 5 accuracy: 21.950\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.352 (avg: 0.352)\tLoss: 4.4110 (avg: 4.3737)\tTop1: 10.938 (avg: 7.375)\tTop5: 25.000 (avg: 23.062)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.361 (avg: 0.357)\tLoss: 4.3063 (avg: 4.3887)\tTop1: 10.938 (avg: 7.344)\tTop5: 35.938 (avg: 23.562)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.349 (avg: 0.358)\tLoss: 4.5725 (avg: 4.3849)\tTop1: 9.375 (avg: 7.333)\tTop5: 26.562 (avg: 23.417)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 4.4231 (avg: 4.3752)\tTop1: 7.812 (avg: 7.688)\tTop5: 17.188 (avg: 23.828)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.354 (avg: 0.358)\tLoss: 4.4150 (avg: 4.3809)\tTop1: 3.125 (avg: 7.563)\tTop5: 20.312 (avg: 23.563)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3725\tTop 1 accuracy: 6.900\tTop 5 accuracy: 21.400\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.353 (avg: 0.353)\tLoss: 4.8044 (avg: 4.3569)\tTop1: 1.562 (avg: 8.188)\tTop5: 12.500 (avg: 23.688)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.364 (avg: 0.357)\tLoss: 4.5185 (avg: 4.3633)\tTop1: 3.125 (avg: 7.906)\tTop5: 20.312 (avg: 23.000)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 4.2342 (avg: 4.3474)\tTop1: 9.375 (avg: 8.042)\tTop5: 28.125 (avg: 23.854)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 4.4229 (avg: 4.3445)\tTop1: 10.938 (avg: 8.016)\tTop5: 28.125 (avg: 23.984)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.351 (avg: 0.360)\tLoss: 4.4870 (avg: 4.3613)\tTop1: 6.250 (avg: 7.925)\tTop5: 23.438 (avg: 23.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5167\tTop 1 accuracy: 5.700\tTop 5 accuracy: 19.850\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.354 (avg: 0.353)\tLoss: 4.3369 (avg: 4.2431)\tTop1: 6.250 (avg: 8.500)\tTop5: 26.562 (avg: 27.188)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.366 (avg: 0.357)\tLoss: 4.2238 (avg: 4.2749)\tTop1: 7.812 (avg: 8.812)\tTop5: 28.125 (avg: 26.031)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 4.3701 (avg: 4.2995)\tTop1: 10.938 (avg: 8.417)\tTop5: 23.438 (avg: 25.333)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 4.3122 (avg: 4.3387)\tTop1: 15.625 (avg: 8.328)\tTop5: 28.125 (avg: 24.859)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.348 (avg: 0.359)\tLoss: 4.3959 (avg: 4.3439)\tTop1: 10.938 (avg: 8.238)\tTop5: 25.000 (avg: 25.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9478\tTop 1 accuracy: 7.000\tTop 5 accuracy: 21.450\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.354 (avg: 0.353)\tLoss: 4.0470 (avg: 4.2618)\tTop1: 10.938 (avg: 8.812)\tTop5: 34.375 (avg: 26.750)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.362 (avg: 0.357)\tLoss: 4.4409 (avg: 4.2826)\tTop1: 6.250 (avg: 8.031)\tTop5: 25.000 (avg: 25.500)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 4.4677 (avg: 4.2879)\tTop1: 3.125 (avg: 7.896)\tTop5: 23.438 (avg: 25.958)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.352 (avg: 0.359)\tLoss: 4.2174 (avg: 4.2908)\tTop1: 6.250 (avg: 8.016)\tTop5: 20.312 (avg: 25.797)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.352 (avg: 0.359)\tLoss: 4.1027 (avg: 4.2790)\tTop1: 9.375 (avg: 8.300)\tTop5: 23.438 (avg: 25.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1282\tTop 1 accuracy: 7.650\tTop 5 accuracy: 22.350\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.352 (avg: 0.352)\tLoss: 4.2888 (avg: 4.1664)\tTop1: 4.688 (avg: 9.250)\tTop5: 26.562 (avg: 30.250)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.357 (avg: 0.356)\tLoss: 4.3138 (avg: 4.2402)\tTop1: 9.375 (avg: 8.531)\tTop5: 28.125 (avg: 27.969)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.348 (avg: 0.357)\tLoss: 4.1475 (avg: 4.2330)\tTop1: 7.812 (avg: 8.625)\tTop5: 21.875 (avg: 27.708)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.349 (avg: 0.357)\tLoss: 4.2328 (avg: 4.2329)\tTop1: 10.938 (avg: 8.531)\tTop5: 21.875 (avg: 27.406)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.349 (avg: 0.358)\tLoss: 4.1135 (avg: 4.2405)\tTop1: 10.938 (avg: 8.488)\tTop5: 28.125 (avg: 27.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0291\tTop 1 accuracy: 8.150\tTop 5 accuracy: 24.500\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.351 (avg: 0.351)\tLoss: 3.9262 (avg: 4.0582)\tTop1: 7.812 (avg: 11.438)\tTop5: 31.250 (avg: 31.375)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.359 (avg: 0.356)\tLoss: 3.8561 (avg: 4.0312)\tTop1: 14.062 (avg: 11.281)\tTop5: 43.750 (avg: 32.188)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.350 (avg: 0.356)\tLoss: 3.8205 (avg: 4.0295)\tTop1: 3.125 (avg: 11.729)\tTop5: 34.375 (avg: 32.104)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.350 (avg: 0.357)\tLoss: 3.9143 (avg: 4.0209)\tTop1: 14.062 (avg: 11.984)\tTop5: 32.812 (avg: 32.562)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.349 (avg: 0.357)\tLoss: 3.8224 (avg: 4.0009)\tTop1: 9.375 (avg: 12.713)\tTop5: 37.500 (avg: 33.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8147\tTop 1 accuracy: 10.650\tTop 5 accuracy: 27.900\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.348 (avg: 0.349)\tLoss: 4.1672 (avg: 3.9932)\tTop1: 14.062 (avg: 13.562)\tTop5: 29.688 (avg: 33.000)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.354 (avg: 0.352)\tLoss: 3.7611 (avg: 3.9494)\tTop1: 9.375 (avg: 13.750)\tTop5: 37.500 (avg: 34.500)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.349 (avg: 0.354)\tLoss: 4.0098 (avg: 3.9129)\tTop1: 17.188 (avg: 14.333)\tTop5: 29.688 (avg: 35.625)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.348 (avg: 0.355)\tLoss: 3.8209 (avg: 3.9148)\tTop1: 14.062 (avg: 14.375)\tTop5: 37.500 (avg: 35.672)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.352 (avg: 0.356)\tLoss: 3.9984 (avg: 3.9127)\tTop1: 12.500 (avg: 14.113)\tTop5: 35.938 (avg: 36.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7356\tTop 1 accuracy: 10.550\tTop 5 accuracy: 28.050\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.351 (avg: 0.350)\tLoss: 4.0885 (avg: 3.8428)\tTop1: 14.062 (avg: 15.938)\tTop5: 35.938 (avg: 38.438)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.360 (avg: 0.356)\tLoss: 3.9530 (avg: 3.8852)\tTop1: 25.000 (avg: 15.344)\tTop5: 42.188 (avg: 37.281)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.351 (avg: 0.357)\tLoss: 3.8227 (avg: 3.8871)\tTop1: 21.875 (avg: 15.104)\tTop5: 37.500 (avg: 37.062)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.349 (avg: 0.358)\tLoss: 3.9256 (avg: 3.8929)\tTop1: 14.062 (avg: 14.750)\tTop5: 45.312 (avg: 36.984)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 3.7713 (avg: 3.8919)\tTop1: 10.938 (avg: 14.675)\tTop5: 34.375 (avg: 36.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6875\tTop 1 accuracy: 10.750\tTop 5 accuracy: 29.400\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.352 (avg: 0.352)\tLoss: 3.5414 (avg: 3.8507)\tTop1: 15.625 (avg: 14.500)\tTop5: 42.188 (avg: 36.812)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.358 (avg: 0.356)\tLoss: 3.9432 (avg: 3.8831)\tTop1: 15.625 (avg: 14.500)\tTop5: 37.500 (avg: 36.531)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.350 (avg: 0.358)\tLoss: 4.2593 (avg: 3.8985)\tTop1: 14.062 (avg: 14.167)\tTop5: 29.688 (avg: 36.250)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.350 (avg: 0.358)\tLoss: 3.5672 (avg: 3.8857)\tTop1: 17.188 (avg: 14.344)\tTop5: 43.750 (avg: 36.734)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 3.5023 (avg: 3.8766)\tTop1: 15.625 (avg: 14.688)\tTop5: 42.188 (avg: 37.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7260\tTop 1 accuracy: 11.450\tTop 5 accuracy: 28.650\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.353 (avg: 0.353)\tLoss: 4.0492 (avg: 3.8545)\tTop1: 14.062 (avg: 15.875)\tTop5: 32.812 (avg: 38.125)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.365 (avg: 0.357)\tLoss: 3.7489 (avg: 3.8654)\tTop1: 21.875 (avg: 15.375)\tTop5: 37.500 (avg: 37.094)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.353 (avg: 0.358)\tLoss: 3.8587 (avg: 3.8490)\tTop1: 17.188 (avg: 15.333)\tTop5: 39.062 (avg: 37.438)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 3.7959 (avg: 3.8449)\tTop1: 23.438 (avg: 15.547)\tTop5: 35.938 (avg: 37.484)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 3.5378 (avg: 3.8574)\tTop1: 12.500 (avg: 15.163)\tTop5: 48.438 (avg: 36.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7579\tTop 1 accuracy: 10.700\tTop 5 accuracy: 28.450\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.356 (avg: 0.352)\tLoss: 3.5091 (avg: 3.8370)\tTop1: 20.312 (avg: 14.938)\tTop5: 45.312 (avg: 36.438)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.354 (avg: 0.357)\tLoss: 3.6725 (avg: 3.8514)\tTop1: 15.625 (avg: 15.312)\tTop5: 43.750 (avg: 36.656)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.350 (avg: 0.358)\tLoss: 3.7609 (avg: 3.8568)\tTop1: 20.312 (avg: 15.354)\tTop5: 32.812 (avg: 36.583)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 3.8667 (avg: 3.8484)\tTop1: 9.375 (avg: 15.297)\tTop5: 32.812 (avg: 37.047)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 3.7444 (avg: 3.8399)\tTop1: 15.625 (avg: 15.563)\tTop5: 37.500 (avg: 37.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8891\tTop 1 accuracy: 11.450\tTop 5 accuracy: 28.400\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.351 (avg: 0.352)\tLoss: 3.8113 (avg: 3.8170)\tTop1: 17.188 (avg: 15.500)\tTop5: 35.938 (avg: 37.812)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.362 (avg: 0.355)\tLoss: 3.8571 (avg: 3.8094)\tTop1: 17.188 (avg: 15.531)\tTop5: 39.062 (avg: 37.469)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.355 (avg: 0.357)\tLoss: 4.1115 (avg: 3.8157)\tTop1: 4.688 (avg: 15.729)\tTop5: 35.938 (avg: 38.229)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 3.8926 (avg: 3.8364)\tTop1: 14.062 (avg: 15.453)\tTop5: 34.375 (avg: 37.969)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.352 (avg: 0.359)\tLoss: 3.7844 (avg: 3.8286)\tTop1: 18.750 (avg: 15.650)\tTop5: 39.062 (avg: 38.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7920\tTop 1 accuracy: 11.600\tTop 5 accuracy: 29.750\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.351 (avg: 0.351)\tLoss: 3.4690 (avg: 3.7736)\tTop1: 17.188 (avg: 16.500)\tTop5: 48.438 (avg: 39.375)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.363 (avg: 0.356)\tLoss: 3.9955 (avg: 3.8168)\tTop1: 7.812 (avg: 15.688)\tTop5: 29.688 (avg: 38.938)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.353 (avg: 0.358)\tLoss: 3.6047 (avg: 3.7987)\tTop1: 17.188 (avg: 15.750)\tTop5: 39.062 (avg: 38.729)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.350 (avg: 0.359)\tLoss: 3.8960 (avg: 3.8159)\tTop1: 15.625 (avg: 15.578)\tTop5: 39.062 (avg: 38.266)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 3.6712 (avg: 3.8160)\tTop1: 12.500 (avg: 15.763)\tTop5: 37.500 (avg: 38.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7790\tTop 1 accuracy: 11.350\tTop 5 accuracy: 29.400\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.353 (avg: 0.353)\tLoss: 3.8427 (avg: 3.8277)\tTop1: 14.062 (avg: 15.312)\tTop5: 39.062 (avg: 38.938)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.362 (avg: 0.357)\tLoss: 3.9576 (avg: 3.7999)\tTop1: 15.625 (avg: 15.719)\tTop5: 35.938 (avg: 39.219)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.354 (avg: 0.359)\tLoss: 3.9818 (avg: 3.7920)\tTop1: 12.500 (avg: 16.042)\tTop5: 32.812 (avg: 39.521)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.352 (avg: 0.359)\tLoss: 3.9885 (avg: 3.7947)\tTop1: 10.938 (avg: 16.031)\tTop5: 29.688 (avg: 39.219)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 3.8832 (avg: 3.8005)\tTop1: 17.188 (avg: 15.963)\tTop5: 35.938 (avg: 38.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7396\tTop 1 accuracy: 11.600\tTop 5 accuracy: 29.150\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.353 (avg: 0.353)\tLoss: 3.3324 (avg: 3.6841)\tTop1: 21.875 (avg: 19.375)\tTop5: 54.688 (avg: 41.250)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.363 (avg: 0.358)\tLoss: 3.5795 (avg: 3.7585)\tTop1: 20.312 (avg: 16.875)\tTop5: 39.062 (avg: 39.000)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 3.7002 (avg: 3.7852)\tTop1: 23.438 (avg: 16.375)\tTop5: 40.625 (avg: 38.625)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.352 (avg: 0.360)\tLoss: 3.5851 (avg: 3.7796)\tTop1: 17.188 (avg: 16.562)\tTop5: 48.438 (avg: 38.781)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.351 (avg: 0.360)\tLoss: 3.5624 (avg: 3.7877)\tTop1: 15.625 (avg: 16.513)\tTop5: 40.625 (avg: 38.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6346\tTop 1 accuracy: 11.050\tTop 5 accuracy: 29.000\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.350 (avg: 0.353)\tLoss: 3.7070 (avg: 3.7711)\tTop1: 20.312 (avg: 16.438)\tTop5: 45.312 (avg: 37.750)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.359 (avg: 0.357)\tLoss: 3.4732 (avg: 3.7683)\tTop1: 25.000 (avg: 16.688)\tTop5: 46.875 (avg: 38.500)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 3.5123 (avg: 3.7803)\tTop1: 18.750 (avg: 16.021)\tTop5: 51.562 (avg: 38.896)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.350 (avg: 0.359)\tLoss: 4.0202 (avg: 3.7938)\tTop1: 10.938 (avg: 15.969)\tTop5: 35.938 (avg: 38.938)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.353 (avg: 0.360)\tLoss: 3.3385 (avg: 3.7784)\tTop1: 25.000 (avg: 16.188)\tTop5: 53.125 (avg: 39.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6934\tTop 1 accuracy: 11.850\tTop 5 accuracy: 29.900\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.352 (avg: 0.352)\tLoss: 3.4278 (avg: 3.6971)\tTop1: 25.000 (avg: 17.062)\tTop5: 54.688 (avg: 40.312)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.362 (avg: 0.357)\tLoss: 3.4985 (avg: 3.7155)\tTop1: 15.625 (avg: 17.094)\tTop5: 46.875 (avg: 40.281)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.360 (avg: 0.358)\tLoss: 4.0136 (avg: 3.7331)\tTop1: 10.938 (avg: 17.062)\tTop5: 26.562 (avg: 39.979)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 3.7954 (avg: 3.7486)\tTop1: 14.062 (avg: 16.797)\tTop5: 43.750 (avg: 39.781)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.347 (avg: 0.359)\tLoss: 4.0304 (avg: 3.7667)\tTop1: 10.938 (avg: 16.475)\tTop5: 26.562 (avg: 39.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6223\tTop 1 accuracy: 11.400\tTop 5 accuracy: 29.900\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.352 (avg: 0.352)\tLoss: 4.2338 (avg: 3.6816)\tTop1: 7.812 (avg: 18.250)\tTop5: 23.438 (avg: 41.312)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.361 (avg: 0.357)\tLoss: 3.9981 (avg: 3.7301)\tTop1: 10.938 (avg: 17.469)\tTop5: 31.250 (avg: 40.281)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.354 (avg: 0.358)\tLoss: 3.6689 (avg: 3.7499)\tTop1: 17.188 (avg: 17.229)\tTop5: 40.625 (avg: 40.521)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.349 (avg: 0.358)\tLoss: 3.7418 (avg: 3.7633)\tTop1: 18.750 (avg: 16.984)\tTop5: 40.625 (avg: 40.453)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 3.6835 (avg: 3.7483)\tTop1: 23.438 (avg: 17.100)\tTop5: 46.875 (avg: 40.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7327\tTop 1 accuracy: 12.000\tTop 5 accuracy: 29.300\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.353 (avg: 0.352)\tLoss: 4.0524 (avg: 3.6987)\tTop1: 12.500 (avg: 17.188)\tTop5: 35.938 (avg: 41.312)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.363 (avg: 0.357)\tLoss: 3.4637 (avg: 3.7220)\tTop1: 23.438 (avg: 17.656)\tTop5: 48.438 (avg: 40.594)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 3.6801 (avg: 3.7402)\tTop1: 12.500 (avg: 16.958)\tTop5: 37.500 (avg: 39.875)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 3.8422 (avg: 3.7430)\tTop1: 17.188 (avg: 16.812)\tTop5: 43.750 (avg: 39.516)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.344 (avg: 0.359)\tLoss: 3.7602 (avg: 3.7447)\tTop1: 18.750 (avg: 16.750)\tTop5: 48.438 (avg: 39.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7071\tTop 1 accuracy: 11.400\tTop 5 accuracy: 29.550\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.353 (avg: 0.352)\tLoss: 3.8157 (avg: 3.6274)\tTop1: 17.188 (avg: 17.250)\tTop5: 37.500 (avg: 41.875)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.365 (avg: 0.356)\tLoss: 3.5693 (avg: 3.7015)\tTop1: 23.438 (avg: 17.094)\tTop5: 51.562 (avg: 40.375)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.354 (avg: 0.358)\tLoss: 4.0990 (avg: 3.6795)\tTop1: 15.625 (avg: 18.292)\tTop5: 35.938 (avg: 41.292)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.352 (avg: 0.359)\tLoss: 3.4614 (avg: 3.7082)\tTop1: 25.000 (avg: 17.750)\tTop5: 46.875 (avg: 40.625)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 3.5993 (avg: 3.7223)\tTop1: 20.312 (avg: 17.413)\tTop5: 40.625 (avg: 40.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8790\tTop 1 accuracy: 11.800\tTop 5 accuracy: 29.650\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.352 (avg: 0.352)\tLoss: 3.7170 (avg: 3.7097)\tTop1: 18.750 (avg: 16.688)\tTop5: 45.312 (avg: 41.125)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.360 (avg: 0.356)\tLoss: 3.9430 (avg: 3.6931)\tTop1: 12.500 (avg: 16.656)\tTop5: 29.688 (avg: 41.031)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 3.5735 (avg: 3.7011)\tTop1: 31.250 (avg: 17.042)\tTop5: 45.312 (avg: 41.458)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.347 (avg: 0.359)\tLoss: 3.5143 (avg: 3.7185)\tTop1: 29.688 (avg: 16.641)\tTop5: 46.875 (avg: 40.922)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 3.9442 (avg: 3.7145)\tTop1: 14.062 (avg: 17.025)\tTop5: 39.062 (avg: 40.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6100\tTop 1 accuracy: 11.100\tTop 5 accuracy: 29.750\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.354 (avg: 0.354)\tLoss: 3.5668 (avg: 3.6639)\tTop1: 17.188 (avg: 19.500)\tTop5: 46.875 (avg: 43.875)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.366 (avg: 0.358)\tLoss: 3.5183 (avg: 3.6704)\tTop1: 18.750 (avg: 18.156)\tTop5: 43.750 (avg: 42.406)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 3.9207 (avg: 3.6958)\tTop1: 14.062 (avg: 17.521)\tTop5: 34.375 (avg: 41.625)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.349 (avg: 0.360)\tLoss: 3.5714 (avg: 3.6917)\tTop1: 21.875 (avg: 17.312)\tTop5: 45.312 (avg: 41.562)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.352 (avg: 0.360)\tLoss: 3.8008 (avg: 3.7007)\tTop1: 14.062 (avg: 17.288)\tTop5: 35.938 (avg: 41.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6168\tTop 1 accuracy: 12.150\tTop 5 accuracy: 31.350\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.355 (avg: 0.353)\tLoss: 3.5333 (avg: 3.6079)\tTop1: 17.188 (avg: 18.562)\tTop5: 48.438 (avg: 44.000)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.365 (avg: 0.357)\tLoss: 3.8344 (avg: 3.6556)\tTop1: 12.500 (avg: 17.250)\tTop5: 32.812 (avg: 42.469)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.348 (avg: 0.358)\tLoss: 3.8686 (avg: 3.6658)\tTop1: 14.062 (avg: 17.688)\tTop5: 39.062 (avg: 42.333)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.350 (avg: 0.358)\tLoss: 3.4374 (avg: 3.6728)\tTop1: 17.188 (avg: 17.547)\tTop5: 48.438 (avg: 41.906)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 3.7194 (avg: 3.6892)\tTop1: 17.188 (avg: 17.600)\tTop5: 46.875 (avg: 41.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5262\tTop 1 accuracy: 12.800\tTop 5 accuracy: 30.700\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.351 (avg: 0.353)\tLoss: 3.7797 (avg: 3.6332)\tTop1: 12.500 (avg: 18.750)\tTop5: 45.312 (avg: 43.312)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.356 (avg: 0.357)\tLoss: 3.5594 (avg: 3.6086)\tTop1: 18.750 (avg: 18.875)\tTop5: 46.875 (avg: 43.719)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.352 (avg: 0.357)\tLoss: 3.5621 (avg: 3.6404)\tTop1: 18.750 (avg: 18.500)\tTop5: 46.875 (avg: 42.625)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 3.8707 (avg: 3.6676)\tTop1: 12.500 (avg: 17.719)\tTop5: 34.375 (avg: 41.891)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 3.8064 (avg: 3.6748)\tTop1: 12.500 (avg: 17.562)\tTop5: 42.188 (avg: 41.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6841\tTop 1 accuracy: 12.500\tTop 5 accuracy: 30.200\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.343 (avg: 0.351)\tLoss: 3.7545 (avg: 3.5703)\tTop1: 23.438 (avg: 19.188)\tTop5: 42.188 (avg: 43.438)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.361 (avg: 0.357)\tLoss: 3.7971 (avg: 3.5853)\tTop1: 20.312 (avg: 19.000)\tTop5: 35.938 (avg: 42.562)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 3.7611 (avg: 3.6360)\tTop1: 14.062 (avg: 18.333)\tTop5: 37.500 (avg: 41.667)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.349 (avg: 0.358)\tLoss: 3.4652 (avg: 3.6365)\tTop1: 20.312 (avg: 18.469)\tTop5: 51.562 (avg: 41.875)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.350 (avg: 0.358)\tLoss: 3.9774 (avg: 3.6663)\tTop1: 10.938 (avg: 18.013)\tTop5: 31.250 (avg: 41.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6403\tTop 1 accuracy: 12.100\tTop 5 accuracy: 31.150\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.349 (avg: 0.351)\tLoss: 3.8417 (avg: 3.5467)\tTop1: 9.375 (avg: 20.062)\tTop5: 34.375 (avg: 43.438)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.361 (avg: 0.355)\tLoss: 3.9223 (avg: 3.6040)\tTop1: 12.500 (avg: 19.062)\tTop5: 32.812 (avg: 42.094)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.351 (avg: 0.357)\tLoss: 3.6868 (avg: 3.6232)\tTop1: 21.875 (avg: 18.500)\tTop5: 43.750 (avg: 42.208)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.350 (avg: 0.357)\tLoss: 3.4936 (avg: 3.6334)\tTop1: 25.000 (avg: 18.531)\tTop5: 45.312 (avg: 42.312)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.350 (avg: 0.358)\tLoss: 3.7739 (avg: 3.6561)\tTop1: 18.750 (avg: 18.175)\tTop5: 45.312 (avg: 41.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8067\tTop 1 accuracy: 11.800\tTop 5 accuracy: 30.800\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.352 (avg: 0.351)\tLoss: 3.5034 (avg: 3.5849)\tTop1: 23.438 (avg: 20.062)\tTop5: 39.062 (avg: 43.188)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.358 (avg: 0.355)\tLoss: 3.7548 (avg: 3.5893)\tTop1: 17.188 (avg: 20.000)\tTop5: 37.500 (avg: 42.938)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.351 (avg: 0.357)\tLoss: 3.8922 (avg: 3.6046)\tTop1: 20.312 (avg: 19.729)\tTop5: 40.625 (avg: 43.312)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.352 (avg: 0.357)\tLoss: 3.6011 (avg: 3.6277)\tTop1: 14.062 (avg: 19.328)\tTop5: 43.750 (avg: 42.766)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 3.7835 (avg: 3.6287)\tTop1: 10.938 (avg: 19.363)\tTop5: 28.125 (avg: 42.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7143\tTop 1 accuracy: 11.350\tTop 5 accuracy: 29.750\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.350 (avg: 0.352)\tLoss: 3.8075 (avg: 3.5834)\tTop1: 18.750 (avg: 19.562)\tTop5: 40.625 (avg: 44.062)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.359 (avg: 0.356)\tLoss: 3.9367 (avg: 3.5851)\tTop1: 15.625 (avg: 18.969)\tTop5: 32.812 (avg: 43.938)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.352 (avg: 0.357)\tLoss: 3.4587 (avg: 3.6155)\tTop1: 17.188 (avg: 18.354)\tTop5: 43.750 (avg: 42.938)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.355 (avg: 0.358)\tLoss: 3.6723 (avg: 3.6282)\tTop1: 20.312 (avg: 18.391)\tTop5: 50.000 (avg: 42.344)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.354 (avg: 0.358)\tLoss: 3.7430 (avg: 3.6235)\tTop1: 18.750 (avg: 18.788)\tTop5: 43.750 (avg: 42.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8170\tTop 1 accuracy: 11.650\tTop 5 accuracy: 31.000\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.349 (avg: 0.349)\tLoss: 3.5424 (avg: 3.6170)\tTop1: 17.188 (avg: 20.438)\tTop5: 45.312 (avg: 41.188)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.359 (avg: 0.354)\tLoss: 3.5520 (avg: 3.6079)\tTop1: 20.312 (avg: 19.438)\tTop5: 40.625 (avg: 42.594)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.352 (avg: 0.356)\tLoss: 4.0517 (avg: 3.6012)\tTop1: 15.625 (avg: 19.229)\tTop5: 32.812 (avg: 43.062)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.351 (avg: 0.357)\tLoss: 3.7746 (avg: 3.6228)\tTop1: 14.062 (avg: 18.703)\tTop5: 35.938 (avg: 42.250)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.349 (avg: 0.357)\tLoss: 3.6071 (avg: 3.6125)\tTop1: 21.875 (avg: 18.838)\tTop5: 45.312 (avg: 42.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7997\tTop 1 accuracy: 11.950\tTop 5 accuracy: 30.650\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.347 (avg: 0.348)\tLoss: 3.4309 (avg: 3.5394)\tTop1: 18.750 (avg: 19.562)\tTop5: 42.188 (avg: 44.750)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.357 (avg: 0.353)\tLoss: 3.6315 (avg: 3.5628)\tTop1: 20.312 (avg: 19.312)\tTop5: 45.312 (avg: 43.531)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.348 (avg: 0.355)\tLoss: 3.4867 (avg: 3.5711)\tTop1: 17.188 (avg: 19.396)\tTop5: 53.125 (avg: 43.417)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.349 (avg: 0.356)\tLoss: 3.5264 (avg: 3.5817)\tTop1: 21.875 (avg: 19.234)\tTop5: 42.188 (avg: 43.531)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.354 (avg: 0.357)\tLoss: 3.7217 (avg: 3.5898)\tTop1: 18.750 (avg: 19.213)\tTop5: 45.312 (avg: 43.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4951\tTop 1 accuracy: 12.650\tTop 5 accuracy: 31.700\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.351 (avg: 0.351)\tLoss: 3.5500 (avg: 3.5041)\tTop1: 21.875 (avg: 20.562)\tTop5: 42.188 (avg: 46.875)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.358 (avg: 0.355)\tLoss: 3.4520 (avg: 3.5480)\tTop1: 25.000 (avg: 19.906)\tTop5: 50.000 (avg: 45.000)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.351 (avg: 0.356)\tLoss: 3.0359 (avg: 3.5426)\tTop1: 23.438 (avg: 19.688)\tTop5: 53.125 (avg: 44.521)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.348 (avg: 0.357)\tLoss: 3.5705 (avg: 3.5819)\tTop1: 20.312 (avg: 19.516)\tTop5: 39.062 (avg: 43.484)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 3.1947 (avg: 3.5848)\tTop1: 26.562 (avg: 19.575)\tTop5: 54.688 (avg: 43.625)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6631\tTop 1 accuracy: 12.400\tTop 5 accuracy: 31.250\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.345 (avg: 0.352)\tLoss: 3.7233 (avg: 3.5166)\tTop1: 14.062 (avg: 20.812)\tTop5: 39.062 (avg: 46.188)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.359 (avg: 0.356)\tLoss: 3.4105 (avg: 3.5225)\tTop1: 20.312 (avg: 20.031)\tTop5: 50.000 (avg: 44.688)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.351 (avg: 0.357)\tLoss: 3.4299 (avg: 3.5590)\tTop1: 26.562 (avg: 19.625)\tTop5: 45.312 (avg: 43.583)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.350 (avg: 0.357)\tLoss: 3.4654 (avg: 3.5646)\tTop1: 20.312 (avg: 19.578)\tTop5: 45.312 (avg: 43.656)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.350 (avg: 0.358)\tLoss: 3.7394 (avg: 3.5565)\tTop1: 15.625 (avg: 19.913)\tTop5: 35.938 (avg: 43.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7950\tTop 1 accuracy: 11.700\tTop 5 accuracy: 31.250\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.352 (avg: 0.351)\tLoss: 3.7024 (avg: 3.4691)\tTop1: 18.750 (avg: 21.875)\tTop5: 43.750 (avg: 45.875)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.360 (avg: 0.355)\tLoss: 3.6667 (avg: 3.5330)\tTop1: 18.750 (avg: 20.688)\tTop5: 43.750 (avg: 45.438)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.351 (avg: 0.357)\tLoss: 3.5313 (avg: 3.5531)\tTop1: 23.438 (avg: 20.312)\tTop5: 46.875 (avg: 45.125)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.358 (avg: 0.357)\tLoss: 3.3805 (avg: 3.5321)\tTop1: 26.562 (avg: 20.375)\tTop5: 48.438 (avg: 45.547)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 3.9506 (avg: 3.5491)\tTop1: 17.188 (avg: 20.062)\tTop5: 43.750 (avg: 45.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8325\tTop 1 accuracy: 12.750\tTop 5 accuracy: 30.650\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.352 (avg: 0.351)\tLoss: 3.3140 (avg: 3.4445)\tTop1: 18.750 (avg: 21.250)\tTop5: 45.312 (avg: 46.938)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.358 (avg: 0.356)\tLoss: 3.4040 (avg: 3.5241)\tTop1: 20.312 (avg: 19.812)\tTop5: 51.562 (avg: 45.188)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.352 (avg: 0.357)\tLoss: 3.7101 (avg: 3.5250)\tTop1: 17.188 (avg: 19.833)\tTop5: 39.062 (avg: 45.042)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.350 (avg: 0.357)\tLoss: 3.2888 (avg: 3.5275)\tTop1: 23.438 (avg: 20.062)\tTop5: 56.250 (avg: 45.125)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.350 (avg: 0.357)\tLoss: 3.6005 (avg: 3.5240)\tTop1: 20.312 (avg: 20.288)\tTop5: 43.750 (avg: 44.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7648\tTop 1 accuracy: 12.700\tTop 5 accuracy: 31.200\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.350 (avg: 0.350)\tLoss: 3.4294 (avg: 3.4856)\tTop1: 17.188 (avg: 20.875)\tTop5: 46.875 (avg: 46.875)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.359 (avg: 0.355)\tLoss: 3.2257 (avg: 3.5024)\tTop1: 25.000 (avg: 20.250)\tTop5: 50.000 (avg: 46.625)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.350 (avg: 0.356)\tLoss: 3.8252 (avg: 3.5128)\tTop1: 15.625 (avg: 20.458)\tTop5: 35.938 (avg: 45.896)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.349 (avg: 0.357)\tLoss: 3.4620 (avg: 3.5101)\tTop1: 23.438 (avg: 20.609)\tTop5: 51.562 (avg: 45.812)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.348 (avg: 0.357)\tLoss: 3.7521 (avg: 3.5197)\tTop1: 15.625 (avg: 20.450)\tTop5: 37.500 (avg: 45.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5804\tTop 1 accuracy: 13.000\tTop 5 accuracy: 31.100\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.350 (avg: 0.351)\tLoss: 3.3137 (avg: 3.4217)\tTop1: 18.750 (avg: 21.875)\tTop5: 48.438 (avg: 47.812)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.359 (avg: 0.355)\tLoss: 3.1107 (avg: 3.4152)\tTop1: 25.000 (avg: 22.500)\tTop5: 64.062 (avg: 47.594)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.350 (avg: 0.356)\tLoss: 3.3002 (avg: 3.4100)\tTop1: 26.562 (avg: 22.583)\tTop5: 46.875 (avg: 48.000)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.357 (avg: 0.357)\tLoss: 3.1824 (avg: 3.4163)\tTop1: 20.312 (avg: 22.641)\tTop5: 59.375 (avg: 48.156)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.349 (avg: 0.357)\tLoss: 3.3957 (avg: 3.4001)\tTop1: 18.750 (avg: 22.813)\tTop5: 45.312 (avg: 48.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6674\tTop 1 accuracy: 13.850\tTop 5 accuracy: 33.400\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.350 (avg: 0.350)\tLoss: 3.7710 (avg: 3.4325)\tTop1: 10.938 (avg: 20.562)\tTop5: 40.625 (avg: 47.250)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.357 (avg: 0.355)\tLoss: 3.4767 (avg: 3.3571)\tTop1: 21.875 (avg: 23.062)\tTop5: 45.312 (avg: 49.375)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.350 (avg: 0.356)\tLoss: 3.5869 (avg: 3.3515)\tTop1: 21.875 (avg: 23.500)\tTop5: 45.312 (avg: 49.521)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.349 (avg: 0.356)\tLoss: 3.4361 (avg: 3.3649)\tTop1: 28.125 (avg: 23.281)\tTop5: 50.000 (avg: 48.969)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.349 (avg: 0.357)\tLoss: 3.5567 (avg: 3.3741)\tTop1: 25.000 (avg: 23.275)\tTop5: 45.312 (avg: 48.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6780\tTop 1 accuracy: 13.850\tTop 5 accuracy: 33.800\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.356 (avg: 0.350)\tLoss: 3.6220 (avg: 3.3596)\tTop1: 20.312 (avg: 23.062)\tTop5: 48.438 (avg: 49.250)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.359 (avg: 0.354)\tLoss: 3.1504 (avg: 3.3657)\tTop1: 29.688 (avg: 22.875)\tTop5: 50.000 (avg: 48.781)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.350 (avg: 0.356)\tLoss: 3.0121 (avg: 3.3667)\tTop1: 32.812 (avg: 23.146)\tTop5: 57.812 (avg: 48.750)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.350 (avg: 0.357)\tLoss: 3.3557 (avg: 3.3668)\tTop1: 25.000 (avg: 23.484)\tTop5: 50.000 (avg: 48.875)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.350 (avg: 0.357)\tLoss: 3.6090 (avg: 3.3648)\tTop1: 29.688 (avg: 23.488)\tTop5: 43.750 (avg: 48.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7064\tTop 1 accuracy: 13.600\tTop 5 accuracy: 33.450\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.350 (avg: 0.350)\tLoss: 3.4588 (avg: 3.3948)\tTop1: 18.750 (avg: 23.812)\tTop5: 42.188 (avg: 48.062)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.357 (avg: 0.354)\tLoss: 3.0333 (avg: 3.3370)\tTop1: 29.688 (avg: 24.062)\tTop5: 51.562 (avg: 49.344)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.358 (avg: 0.356)\tLoss: 3.3162 (avg: 3.3368)\tTop1: 17.188 (avg: 23.958)\tTop5: 53.125 (avg: 49.542)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.349 (avg: 0.357)\tLoss: 3.6619 (avg: 3.3589)\tTop1: 26.562 (avg: 23.297)\tTop5: 42.188 (avg: 48.984)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.352 (avg: 0.357)\tLoss: 3.5879 (avg: 3.3605)\tTop1: 15.625 (avg: 23.288)\tTop5: 42.188 (avg: 49.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7057\tTop 1 accuracy: 13.950\tTop 5 accuracy: 33.150\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.351 (avg: 0.351)\tLoss: 3.6329 (avg: 3.3508)\tTop1: 18.750 (avg: 23.750)\tTop5: 40.625 (avg: 48.938)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.358 (avg: 0.355)\tLoss: 3.1800 (avg: 3.3820)\tTop1: 20.312 (avg: 23.406)\tTop5: 43.750 (avg: 48.219)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.351 (avg: 0.356)\tLoss: 3.1856 (avg: 3.3630)\tTop1: 29.688 (avg: 23.458)\tTop5: 53.125 (avg: 48.958)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.350 (avg: 0.357)\tLoss: 3.3840 (avg: 3.3535)\tTop1: 21.875 (avg: 23.516)\tTop5: 37.500 (avg: 49.547)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.350 (avg: 0.357)\tLoss: 3.1290 (avg: 3.3541)\tTop1: 35.938 (avg: 23.913)\tTop5: 51.562 (avg: 49.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8088\tTop 1 accuracy: 13.750\tTop 5 accuracy: 33.050\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.351 (avg: 0.350)\tLoss: 3.3135 (avg: 3.3736)\tTop1: 26.562 (avg: 24.000)\tTop5: 51.562 (avg: 48.375)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.359 (avg: 0.355)\tLoss: 3.6584 (avg: 3.3482)\tTop1: 21.875 (avg: 23.625)\tTop5: 35.938 (avg: 49.469)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.352 (avg: 0.356)\tLoss: 3.6117 (avg: 3.3504)\tTop1: 14.062 (avg: 23.688)\tTop5: 50.000 (avg: 49.771)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.348 (avg: 0.356)\tLoss: 3.4806 (avg: 3.3521)\tTop1: 23.438 (avg: 23.781)\tTop5: 48.438 (avg: 49.625)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.350 (avg: 0.357)\tLoss: 3.4272 (avg: 3.3513)\tTop1: 25.000 (avg: 23.550)\tTop5: 43.750 (avg: 49.625)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7217\tTop 1 accuracy: 13.750\tTop 5 accuracy: 33.600\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.351 (avg: 0.351)\tLoss: 3.2940 (avg: 3.4142)\tTop1: 23.438 (avg: 22.875)\tTop5: 50.000 (avg: 47.688)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.359 (avg: 0.355)\tLoss: 3.2204 (avg: 3.3732)\tTop1: 29.688 (avg: 23.375)\tTop5: 56.250 (avg: 49.312)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.351 (avg: 0.357)\tLoss: 3.0906 (avg: 3.3598)\tTop1: 25.000 (avg: 24.021)\tTop5: 51.562 (avg: 48.979)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.349 (avg: 0.357)\tLoss: 3.5732 (avg: 3.3646)\tTop1: 15.625 (avg: 23.547)\tTop5: 43.750 (avg: 48.938)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.350 (avg: 0.358)\tLoss: 3.6051 (avg: 3.3502)\tTop1: 20.312 (avg: 23.788)\tTop5: 48.438 (avg: 49.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7738\tTop 1 accuracy: 13.600\tTop 5 accuracy: 33.150\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.352 (avg: 0.351)\tLoss: 2.8433 (avg: 3.3115)\tTop1: 35.938 (avg: 23.312)\tTop5: 60.938 (avg: 50.688)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.359 (avg: 0.355)\tLoss: 3.2492 (avg: 3.3274)\tTop1: 29.688 (avg: 23.062)\tTop5: 51.562 (avg: 49.469)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.351 (avg: 0.357)\tLoss: 2.7325 (avg: 3.3515)\tTop1: 42.188 (avg: 22.958)\tTop5: 67.188 (avg: 48.979)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.350 (avg: 0.357)\tLoss: 3.1949 (avg: 3.3317)\tTop1: 21.875 (avg: 23.766)\tTop5: 53.125 (avg: 49.547)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 3.1437 (avg: 3.3505)\tTop1: 31.250 (avg: 23.700)\tTop5: 60.938 (avg: 49.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8201\tTop 1 accuracy: 13.400\tTop 5 accuracy: 33.550\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.350 (avg: 0.351)\tLoss: 3.4602 (avg: 3.3669)\tTop1: 23.438 (avg: 24.375)\tTop5: 40.625 (avg: 48.062)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.359 (avg: 0.355)\tLoss: 3.2586 (avg: 3.3397)\tTop1: 29.688 (avg: 24.344)\tTop5: 46.875 (avg: 49.562)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.355 (avg: 0.357)\tLoss: 3.2574 (avg: 3.3449)\tTop1: 31.250 (avg: 24.396)\tTop5: 50.000 (avg: 49.375)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.350 (avg: 0.357)\tLoss: 3.7393 (avg: 3.3504)\tTop1: 21.875 (avg: 23.922)\tTop5: 43.750 (avg: 49.062)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 3.0161 (avg: 3.3402)\tTop1: 31.250 (avg: 24.000)\tTop5: 54.688 (avg: 49.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7920\tTop 1 accuracy: 13.550\tTop 5 accuracy: 33.000\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.351 (avg: 0.351)\tLoss: 3.0564 (avg: 3.3314)\tTop1: 31.250 (avg: 24.688)\tTop5: 48.438 (avg: 49.938)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.359 (avg: 0.355)\tLoss: 3.5365 (avg: 3.3056)\tTop1: 25.000 (avg: 24.125)\tTop5: 50.000 (avg: 50.312)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.352 (avg: 0.357)\tLoss: 3.4345 (avg: 3.2981)\tTop1: 17.188 (avg: 24.125)\tTop5: 54.688 (avg: 50.604)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.349 (avg: 0.357)\tLoss: 3.3103 (avg: 3.3265)\tTop1: 25.000 (avg: 23.844)\tTop5: 54.688 (avg: 49.703)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 2.9805 (avg: 3.3381)\tTop1: 31.250 (avg: 23.950)\tTop5: 60.938 (avg: 49.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7758\tTop 1 accuracy: 13.700\tTop 5 accuracy: 33.200\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.352 (avg: 0.348)\tLoss: 3.4345 (avg: 3.3157)\tTop1: 29.688 (avg: 24.562)\tTop5: 46.875 (avg: 50.000)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.359 (avg: 0.354)\tLoss: 3.2072 (avg: 3.3199)\tTop1: 31.250 (avg: 23.875)\tTop5: 57.812 (avg: 49.875)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.350 (avg: 0.356)\tLoss: 3.3485 (avg: 3.3206)\tTop1: 20.312 (avg: 23.708)\tTop5: 43.750 (avg: 49.688)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.355 (avg: 0.357)\tLoss: 3.3312 (avg: 3.3254)\tTop1: 26.562 (avg: 24.016)\tTop5: 50.000 (avg: 49.453)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.349 (avg: 0.357)\tLoss: 3.0201 (avg: 3.3354)\tTop1: 28.125 (avg: 23.863)\tTop5: 57.812 (avg: 49.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7757\tTop 1 accuracy: 13.800\tTop 5 accuracy: 34.200\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.351 (avg: 0.351)\tLoss: 3.0998 (avg: 3.3213)\tTop1: 25.000 (avg: 23.938)\tTop5: 54.688 (avg: 49.812)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.353 (avg: 0.354)\tLoss: 3.1955 (avg: 3.3364)\tTop1: 23.438 (avg: 23.938)\tTop5: 59.375 (avg: 50.031)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.352 (avg: 0.355)\tLoss: 3.5735 (avg: 3.3324)\tTop1: 21.875 (avg: 23.979)\tTop5: 42.188 (avg: 49.938)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.351 (avg: 0.356)\tLoss: 3.3276 (avg: 3.3316)\tTop1: 23.438 (avg: 23.922)\tTop5: 48.438 (avg: 49.672)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.347 (avg: 0.357)\tLoss: 3.3372 (avg: 3.3316)\tTop1: 21.875 (avg: 24.188)\tTop5: 42.188 (avg: 49.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7651\tTop 1 accuracy: 14.050\tTop 5 accuracy: 34.100\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.350 (avg: 0.351)\tLoss: 3.8585 (avg: 3.2888)\tTop1: 20.312 (avg: 24.500)\tTop5: 37.500 (avg: 51.062)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.359 (avg: 0.355)\tLoss: 3.1319 (avg: 3.3228)\tTop1: 25.000 (avg: 23.750)\tTop5: 62.500 (avg: 50.188)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.351 (avg: 0.357)\tLoss: 2.9497 (avg: 3.3160)\tTop1: 28.125 (avg: 24.000)\tTop5: 53.125 (avg: 50.000)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.350 (avg: 0.357)\tLoss: 3.2036 (avg: 3.3314)\tTop1: 20.312 (avg: 23.578)\tTop5: 56.250 (avg: 49.969)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.354 (avg: 0.358)\tLoss: 3.0172 (avg: 3.3347)\tTop1: 28.125 (avg: 23.688)\tTop5: 54.688 (avg: 49.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7292\tTop 1 accuracy: 13.450\tTop 5 accuracy: 33.600\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.350 (avg: 0.351)\tLoss: 3.3395 (avg: 3.2944)\tTop1: 35.938 (avg: 24.438)\tTop5: 51.562 (avg: 51.562)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.360 (avg: 0.355)\tLoss: 2.9822 (avg: 3.2859)\tTop1: 29.688 (avg: 25.625)\tTop5: 56.250 (avg: 50.688)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.352 (avg: 0.357)\tLoss: 2.8411 (avg: 3.2946)\tTop1: 32.812 (avg: 25.312)\tTop5: 62.500 (avg: 50.542)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.348 (avg: 0.357)\tLoss: 2.9342 (avg: 3.3104)\tTop1: 23.438 (avg: 24.891)\tTop5: 54.688 (avg: 50.312)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 3.2498 (avg: 3.3242)\tTop1: 21.875 (avg: 24.525)\tTop5: 51.562 (avg: 49.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7810\tTop 1 accuracy: 13.500\tTop 5 accuracy: 33.500\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.353 (avg: 0.350)\tLoss: 3.3423 (avg: 3.3012)\tTop1: 23.438 (avg: 24.500)\tTop5: 54.688 (avg: 50.375)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.359 (avg: 0.355)\tLoss: 3.5299 (avg: 3.3594)\tTop1: 21.875 (avg: 23.281)\tTop5: 45.312 (avg: 48.344)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.351 (avg: 0.357)\tLoss: 3.6390 (avg: 3.3562)\tTop1: 20.312 (avg: 23.917)\tTop5: 39.062 (avg: 48.500)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.350 (avg: 0.357)\tLoss: 3.4026 (avg: 3.3441)\tTop1: 26.562 (avg: 24.266)\tTop5: 46.875 (avg: 48.672)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 3.1319 (avg: 3.3224)\tTop1: 20.312 (avg: 24.450)\tTop5: 46.875 (avg: 49.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7714\tTop 1 accuracy: 13.450\tTop 5 accuracy: 33.500\n",
            "\n",
            "SR = 0.125: top1 = 13.800000190734863\ttop5 = 34.20000076293945\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.417 (avg: 0.556)\tLoss: 5.3087 (avg: 5.3060)\tTop1: 0.000 (avg: 0.312)\tTop5: 4.688 (avg: 2.938)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.407 (avg: 0.485)\tLoss: 5.2935 (avg: 5.3031)\tTop1: 1.562 (avg: 0.500)\tTop5: 4.688 (avg: 2.594)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.403 (avg: 0.462)\tLoss: 5.3007 (avg: 5.3017)\tTop1: 0.000 (avg: 0.521)\tTop5: 1.562 (avg: 2.458)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.408 (avg: 0.449)\tLoss: 5.2841 (avg: 5.3006)\tTop1: 1.562 (avg: 0.484)\tTop5: 9.375 (avg: 2.438)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.411 (avg: 0.442)\tLoss: 5.3053 (avg: 5.2995)\tTop1: 0.000 (avg: 0.475)\tTop5: 3.125 (avg: 2.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2951\tTop 1 accuracy: 1.300\tTop 5 accuracy: 3.250\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.404 (avg: 0.404)\tLoss: 5.2842 (avg: 5.2844)\tTop1: 1.562 (avg: 0.562)\tTop5: 3.125 (avg: 3.562)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.406 (avg: 0.409)\tLoss: 5.2557 (avg: 5.2746)\tTop1: 3.125 (avg: 0.656)\tTop5: 6.250 (avg: 3.656)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.407 (avg: 0.411)\tLoss: 5.2402 (avg: 5.2711)\tTop1: 1.562 (avg: 0.708)\tTop5: 3.125 (avg: 3.875)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.411 (avg: 0.412)\tLoss: 5.2863 (avg: 5.2675)\tTop1: 1.562 (avg: 0.719)\tTop5: 3.125 (avg: 3.906)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.400 (avg: 0.411)\tLoss: 5.2709 (avg: 5.2639)\tTop1: 1.562 (avg: 0.775)\tTop5: 3.125 (avg: 4.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2794\tTop 1 accuracy: 0.550\tTop 5 accuracy: 4.550\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.403 (avg: 0.405)\tLoss: 5.2795 (avg: 5.2270)\tTop1: 4.688 (avg: 1.188)\tTop5: 4.688 (avg: 5.125)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 5.2097 (avg: 5.2226)\tTop1: 1.562 (avg: 1.312)\tTop5: 6.250 (avg: 5.344)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.411 (avg: 0.411)\tLoss: 5.1088 (avg: 5.2235)\tTop1: 3.125 (avg: 1.312)\tTop5: 7.812 (avg: 5.208)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.402 (avg: 0.412)\tLoss: 5.2176 (avg: 5.2239)\tTop1: 0.000 (avg: 1.297)\tTop5: 6.250 (avg: 5.266)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.402 (avg: 0.412)\tLoss: 5.2499 (avg: 5.2178)\tTop1: 0.000 (avg: 1.288)\tTop5: 1.562 (avg: 5.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1039\tTop 1 accuracy: 1.300\tTop 5 accuracy: 6.250\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.411 (avg: 0.404)\tLoss: 5.1804 (avg: 5.1803)\tTop1: 1.562 (avg: 1.562)\tTop5: 9.375 (avg: 6.438)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.413 (avg: 0.410)\tLoss: 5.1488 (avg: 5.1784)\tTop1: 0.000 (avg: 1.438)\tTop5: 7.812 (avg: 6.750)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.405 (avg: 0.411)\tLoss: 5.1922 (avg: 5.1720)\tTop1: 0.000 (avg: 1.396)\tTop5: 4.688 (avg: 6.729)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.408 (avg: 0.412)\tLoss: 5.1153 (avg: 5.1665)\tTop1: 0.000 (avg: 1.422)\tTop5: 3.125 (avg: 7.031)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 5.2908 (avg: 5.1637)\tTop1: 0.000 (avg: 1.450)\tTop5: 4.688 (avg: 6.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9474\tTop 1 accuracy: 1.650\tTop 5 accuracy: 7.950\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.412 (avg: 0.404)\tLoss: 5.2085 (avg: 5.1048)\tTop1: 0.000 (avg: 1.812)\tTop5: 6.250 (avg: 7.625)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.406 (avg: 0.409)\tLoss: 5.1310 (avg: 5.1139)\tTop1: 1.562 (avg: 1.531)\tTop5: 6.250 (avg: 7.625)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 5.2263 (avg: 5.1089)\tTop1: 1.562 (avg: 1.792)\tTop5: 4.688 (avg: 7.792)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.407 (avg: 0.411)\tLoss: 5.1196 (avg: 5.1048)\tTop1: 0.000 (avg: 1.703)\tTop5: 3.125 (avg: 7.922)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.410 (avg: 0.412)\tLoss: 5.1558 (avg: 5.1062)\tTop1: 1.562 (avg: 1.750)\tTop5: 6.250 (avg: 8.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8733\tTop 1 accuracy: 1.650\tTop 5 accuracy: 8.050\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.405 (avg: 0.405)\tLoss: 4.8363 (avg: 5.0162)\tTop1: 1.562 (avg: 2.000)\tTop5: 18.750 (avg: 10.062)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 5.1699 (avg: 5.0532)\tTop1: 1.562 (avg: 2.281)\tTop5: 3.125 (avg: 8.938)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.404 (avg: 0.411)\tLoss: 4.9969 (avg: 5.0604)\tTop1: 3.125 (avg: 2.250)\tTop5: 7.812 (avg: 8.625)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.417 (avg: 0.411)\tLoss: 5.1525 (avg: 5.0551)\tTop1: 1.562 (avg: 2.203)\tTop5: 6.250 (avg: 8.812)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.404 (avg: 0.412)\tLoss: 4.9817 (avg: 5.0533)\tTop1: 1.562 (avg: 2.213)\tTop5: 10.938 (avg: 9.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8860\tTop 1 accuracy: 3.050\tTop 5 accuracy: 11.800\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.406 (avg: 0.404)\tLoss: 5.0335 (avg: 4.9812)\tTop1: 0.000 (avg: 2.438)\tTop5: 7.812 (avg: 9.812)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.409 (avg: 0.409)\tLoss: 5.1386 (avg: 5.0091)\tTop1: 1.562 (avg: 2.406)\tTop5: 7.812 (avg: 9.312)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.413 (avg: 0.411)\tLoss: 4.9523 (avg: 5.0123)\tTop1: 1.562 (avg: 2.542)\tTop5: 7.812 (avg: 9.688)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.403 (avg: 0.412)\tLoss: 5.0106 (avg: 5.0126)\tTop1: 4.688 (avg: 2.312)\tTop5: 14.062 (avg: 9.641)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.405 (avg: 0.412)\tLoss: 4.8610 (avg: 4.9966)\tTop1: 1.562 (avg: 2.450)\tTop5: 6.250 (avg: 9.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9666\tTop 1 accuracy: 2.850\tTop 5 accuracy: 10.850\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.408 (avg: 0.405)\tLoss: 4.8994 (avg: 4.9095)\tTop1: 1.562 (avg: 3.188)\tTop5: 9.375 (avg: 11.625)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.413 (avg: 0.410)\tLoss: 5.0472 (avg: 4.9228)\tTop1: 1.562 (avg: 3.000)\tTop5: 6.250 (avg: 10.969)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.405 (avg: 0.412)\tLoss: 4.8839 (avg: 4.9251)\tTop1: 4.688 (avg: 3.250)\tTop5: 12.500 (avg: 11.188)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 5.0081 (avg: 4.9354)\tTop1: 1.562 (avg: 3.062)\tTop5: 10.938 (avg: 10.969)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 5.0024 (avg: 4.9405)\tTop1: 4.688 (avg: 3.000)\tTop5: 14.062 (avg: 11.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7081\tTop 1 accuracy: 4.050\tTop 5 accuracy: 12.900\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.414 (avg: 0.405)\tLoss: 4.8466 (avg: 4.8775)\tTop1: 1.562 (avg: 2.875)\tTop5: 12.500 (avg: 11.750)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.406 (avg: 0.409)\tLoss: 4.8296 (avg: 4.8943)\tTop1: 6.250 (avg: 3.219)\tTop5: 12.500 (avg: 11.750)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.404 (avg: 0.411)\tLoss: 4.8460 (avg: 4.9002)\tTop1: 3.125 (avg: 3.208)\tTop5: 9.375 (avg: 11.729)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.408 (avg: 0.412)\tLoss: 4.8869 (avg: 4.8815)\tTop1: 1.562 (avg: 3.281)\tTop5: 15.625 (avg: 11.969)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.411 (avg: 0.413)\tLoss: 4.8384 (avg: 4.8859)\tTop1: 4.688 (avg: 3.288)\tTop5: 14.062 (avg: 11.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8759\tTop 1 accuracy: 3.600\tTop 5 accuracy: 12.100\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.407 (avg: 0.405)\tLoss: 4.7970 (avg: 4.8250)\tTop1: 1.562 (avg: 3.250)\tTop5: 10.938 (avg: 13.188)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.405 (avg: 0.410)\tLoss: 4.9410 (avg: 4.8237)\tTop1: 0.000 (avg: 3.094)\tTop5: 15.625 (avg: 12.781)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.411 (avg: 0.412)\tLoss: 4.6208 (avg: 4.8260)\tTop1: 6.250 (avg: 3.208)\tTop5: 18.750 (avg: 12.875)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.413 (avg: 0.413)\tLoss: 4.9377 (avg: 4.8252)\tTop1: 0.000 (avg: 3.234)\tTop5: 10.938 (avg: 13.062)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.407 (avg: 0.413)\tLoss: 4.7537 (avg: 4.8348)\tTop1: 1.562 (avg: 3.200)\tTop5: 9.375 (avg: 12.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7316\tTop 1 accuracy: 3.300\tTop 5 accuracy: 14.200\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.408 (avg: 0.405)\tLoss: 4.7244 (avg: 4.7538)\tTop1: 4.688 (avg: 4.250)\tTop5: 12.500 (avg: 15.062)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.409 (avg: 0.410)\tLoss: 4.7483 (avg: 4.7696)\tTop1: 1.562 (avg: 3.656)\tTop5: 10.938 (avg: 13.844)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.407 (avg: 0.411)\tLoss: 4.7067 (avg: 4.7734)\tTop1: 3.125 (avg: 3.500)\tTop5: 9.375 (avg: 13.667)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 4.9991 (avg: 4.7797)\tTop1: 1.562 (avg: 3.656)\tTop5: 6.250 (avg: 13.688)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.405 (avg: 0.413)\tLoss: 4.7893 (avg: 4.7851)\tTop1: 3.125 (avg: 3.688)\tTop5: 20.312 (avg: 13.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8940\tTop 1 accuracy: 3.550\tTop 5 accuracy: 14.400\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.405 (avg: 0.405)\tLoss: 4.7187 (avg: 4.7173)\tTop1: 3.125 (avg: 4.500)\tTop5: 17.188 (avg: 15.750)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.413 (avg: 0.410)\tLoss: 4.8876 (avg: 4.7245)\tTop1: 3.125 (avg: 4.594)\tTop5: 6.250 (avg: 15.750)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 4.6930 (avg: 4.7215)\tTop1: 4.688 (avg: 4.333)\tTop5: 15.625 (avg: 15.333)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 4.9583 (avg: 4.7295)\tTop1: 0.000 (avg: 4.234)\tTop5: 10.938 (avg: 15.172)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.404 (avg: 0.412)\tLoss: 4.9554 (avg: 4.7302)\tTop1: 4.688 (avg: 4.100)\tTop5: 14.062 (avg: 15.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7485\tTop 1 accuracy: 3.900\tTop 5 accuracy: 14.550\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.412 (avg: 0.405)\tLoss: 4.7610 (avg: 4.7141)\tTop1: 3.125 (avg: 4.875)\tTop5: 14.062 (avg: 17.000)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.406 (avg: 0.410)\tLoss: 4.5638 (avg: 4.7139)\tTop1: 6.250 (avg: 4.469)\tTop5: 20.312 (avg: 16.656)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 4.4561 (avg: 4.6882)\tTop1: 7.812 (avg: 4.521)\tTop5: 20.312 (avg: 16.792)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 4.6478 (avg: 4.6833)\tTop1: 3.125 (avg: 4.438)\tTop5: 20.312 (avg: 16.969)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.413 (avg: 0.413)\tLoss: 4.7276 (avg: 4.6621)\tTop1: 3.125 (avg: 4.650)\tTop5: 17.188 (avg: 17.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7750\tTop 1 accuracy: 5.450\tTop 5 accuracy: 18.050\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.406 (avg: 0.405)\tLoss: 4.5066 (avg: 4.5566)\tTop1: 1.562 (avg: 4.812)\tTop5: 20.312 (avg: 19.562)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.406 (avg: 0.410)\tLoss: 4.7276 (avg: 4.5547)\tTop1: 4.688 (avg: 5.469)\tTop5: 18.750 (avg: 19.500)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.409 (avg: 0.412)\tLoss: 4.4100 (avg: 4.5716)\tTop1: 4.688 (avg: 5.208)\tTop5: 21.875 (avg: 19.083)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.413 (avg: 0.413)\tLoss: 4.3962 (avg: 4.5685)\tTop1: 4.688 (avg: 5.156)\tTop5: 14.062 (avg: 18.938)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.410 (avg: 0.413)\tLoss: 4.5839 (avg: 4.5598)\tTop1: 6.250 (avg: 5.375)\tTop5: 17.188 (avg: 19.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6683\tTop 1 accuracy: 5.900\tTop 5 accuracy: 18.200\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.407 (avg: 0.406)\tLoss: 4.7952 (avg: 4.5022)\tTop1: 1.562 (avg: 6.688)\tTop5: 7.812 (avg: 21.812)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.403 (avg: 0.410)\tLoss: 4.5815 (avg: 4.5356)\tTop1: 6.250 (avg: 6.062)\tTop5: 20.312 (avg: 20.938)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.415 (avg: 0.412)\tLoss: 4.9030 (avg: 4.5489)\tTop1: 3.125 (avg: 6.042)\tTop5: 14.062 (avg: 20.229)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.406 (avg: 0.413)\tLoss: 4.7645 (avg: 4.5416)\tTop1: 7.812 (avg: 6.047)\tTop5: 17.188 (avg: 20.188)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.410 (avg: 0.413)\tLoss: 4.6644 (avg: 4.5316)\tTop1: 10.938 (avg: 6.150)\tTop5: 20.312 (avg: 20.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5942\tTop 1 accuracy: 6.700\tTop 5 accuracy: 21.850\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.409 (avg: 0.406)\tLoss: 4.5199 (avg: 4.4851)\tTop1: 3.125 (avg: 6.750)\tTop5: 23.438 (avg: 22.125)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.412 (avg: 0.411)\tLoss: 4.5632 (avg: 4.4921)\tTop1: 12.500 (avg: 6.719)\tTop5: 23.438 (avg: 21.281)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.406 (avg: 0.411)\tLoss: 4.3440 (avg: 4.4866)\tTop1: 10.938 (avg: 6.771)\tTop5: 25.000 (avg: 21.562)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.409 (avg: 0.412)\tLoss: 4.5244 (avg: 4.4778)\tTop1: 3.125 (avg: 6.594)\tTop5: 15.625 (avg: 21.562)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.405 (avg: 0.413)\tLoss: 4.6130 (avg: 4.4808)\tTop1: 4.688 (avg: 6.650)\tTop5: 23.438 (avg: 21.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4954\tTop 1 accuracy: 5.250\tTop 5 accuracy: 18.250\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.411 (avg: 0.405)\tLoss: 4.2088 (avg: 4.3780)\tTop1: 10.938 (avg: 8.125)\tTop5: 29.688 (avg: 23.875)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.406 (avg: 0.410)\tLoss: 4.0756 (avg: 4.3980)\tTop1: 14.062 (avg: 7.781)\tTop5: 31.250 (avg: 23.625)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 4.6832 (avg: 4.4096)\tTop1: 3.125 (avg: 7.312)\tTop5: 9.375 (avg: 23.104)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.408 (avg: 0.412)\tLoss: 4.4069 (avg: 4.4166)\tTop1: 6.250 (avg: 7.281)\tTop5: 23.438 (avg: 23.125)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.409 (avg: 0.413)\tLoss: 4.2647 (avg: 4.4150)\tTop1: 9.375 (avg: 7.375)\tTop5: 29.688 (avg: 22.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4223\tTop 1 accuracy: 5.800\tTop 5 accuracy: 20.300\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.405 (avg: 0.405)\tLoss: 4.4404 (avg: 4.3613)\tTop1: 6.250 (avg: 6.812)\tTop5: 18.750 (avg: 22.938)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.410 (avg: 0.410)\tLoss: 4.3241 (avg: 4.3640)\tTop1: 10.938 (avg: 7.594)\tTop5: 29.688 (avg: 23.812)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.410 (avg: 0.411)\tLoss: 4.5685 (avg: 4.3652)\tTop1: 4.688 (avg: 7.604)\tTop5: 21.875 (avg: 23.917)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.415 (avg: 0.412)\tLoss: 4.6369 (avg: 4.3691)\tTop1: 3.125 (avg: 7.438)\tTop5: 18.750 (avg: 24.188)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.403 (avg: 0.413)\tLoss: 4.3374 (avg: 4.3664)\tTop1: 7.812 (avg: 7.450)\tTop5: 31.250 (avg: 24.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4241\tTop 1 accuracy: 6.950\tTop 5 accuracy: 21.900\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.408 (avg: 0.405)\tLoss: 4.3856 (avg: 4.3526)\tTop1: 4.688 (avg: 7.312)\tTop5: 18.750 (avg: 23.750)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 4.7399 (avg: 4.3538)\tTop1: 3.125 (avg: 7.719)\tTop5: 17.188 (avg: 24.438)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.410 (avg: 0.412)\tLoss: 4.0893 (avg: 4.3343)\tTop1: 10.938 (avg: 7.958)\tTop5: 40.625 (avg: 25.167)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 4.1161 (avg: 4.3268)\tTop1: 12.500 (avg: 7.875)\tTop5: 34.375 (avg: 25.484)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.406 (avg: 0.413)\tLoss: 4.2114 (avg: 4.3336)\tTop1: 1.562 (avg: 7.750)\tTop5: 26.562 (avg: 25.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4468\tTop 1 accuracy: 7.650\tTop 5 accuracy: 22.500\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.408 (avg: 0.404)\tLoss: 4.0978 (avg: 4.2298)\tTop1: 4.688 (avg: 9.125)\tTop5: 28.125 (avg: 28.000)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.414 (avg: 0.410)\tLoss: 4.1613 (avg: 4.2588)\tTop1: 4.688 (avg: 8.750)\tTop5: 28.125 (avg: 27.938)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.404 (avg: 0.411)\tLoss: 4.1143 (avg: 4.2693)\tTop1: 7.812 (avg: 8.667)\tTop5: 29.688 (avg: 27.188)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 4.2546 (avg: 4.2692)\tTop1: 10.938 (avg: 8.625)\tTop5: 26.562 (avg: 26.688)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.407 (avg: 0.413)\tLoss: 4.5036 (avg: 4.2808)\tTop1: 9.375 (avg: 8.588)\tTop5: 26.562 (avg: 26.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5517\tTop 1 accuracy: 6.450\tTop 5 accuracy: 20.850\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.410 (avg: 0.405)\tLoss: 4.2347 (avg: 4.1998)\tTop1: 6.250 (avg: 8.812)\tTop5: 23.438 (avg: 27.938)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.406 (avg: 0.409)\tLoss: 4.1419 (avg: 4.1917)\tTop1: 6.250 (avg: 9.500)\tTop5: 25.000 (avg: 28.562)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.405 (avg: 0.410)\tLoss: 4.1417 (avg: 4.2173)\tTop1: 6.250 (avg: 9.188)\tTop5: 34.375 (avg: 27.521)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.407 (avg: 0.411)\tLoss: 4.3951 (avg: 4.2258)\tTop1: 4.688 (avg: 9.000)\tTop5: 20.312 (avg: 27.234)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.411 (avg: 0.412)\tLoss: 4.1319 (avg: 4.2334)\tTop1: 9.375 (avg: 8.875)\tTop5: 23.438 (avg: 27.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2439\tTop 1 accuracy: 7.350\tTop 5 accuracy: 24.400\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.404 (avg: 0.404)\tLoss: 4.3289 (avg: 4.1483)\tTop1: 7.812 (avg: 9.875)\tTop5: 28.125 (avg: 29.750)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.409 (avg: 0.409)\tLoss: 4.4262 (avg: 4.2317)\tTop1: 9.375 (avg: 9.062)\tTop5: 23.438 (avg: 27.594)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.408 (avg: 0.411)\tLoss: 4.2232 (avg: 4.2508)\tTop1: 6.250 (avg: 8.812)\tTop5: 17.188 (avg: 27.167)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.415 (avg: 0.412)\tLoss: 3.9021 (avg: 4.2343)\tTop1: 12.500 (avg: 8.953)\tTop5: 31.250 (avg: 27.734)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.404 (avg: 0.412)\tLoss: 4.3815 (avg: 4.2229)\tTop1: 4.688 (avg: 8.938)\tTop5: 18.750 (avg: 27.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8326\tTop 1 accuracy: 8.950\tTop 5 accuracy: 27.500\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.411 (avg: 0.405)\tLoss: 4.3016 (avg: 4.1106)\tTop1: 9.375 (avg: 11.312)\tTop5: 17.188 (avg: 32.250)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.410 (avg: 0.410)\tLoss: 3.9291 (avg: 4.1547)\tTop1: 10.938 (avg: 10.500)\tTop5: 35.938 (avg: 30.188)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.410 (avg: 0.412)\tLoss: 3.9865 (avg: 4.1477)\tTop1: 12.500 (avg: 10.354)\tTop5: 28.125 (avg: 29.792)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.404 (avg: 0.412)\tLoss: 3.9278 (avg: 4.1622)\tTop1: 10.938 (avg: 10.266)\tTop5: 37.500 (avg: 29.328)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 4.1205 (avg: 4.1613)\tTop1: 4.688 (avg: 10.238)\tTop5: 29.688 (avg: 29.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2302\tTop 1 accuracy: 7.850\tTop 5 accuracy: 24.650\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.406 (avg: 0.405)\tLoss: 3.9177 (avg: 4.0358)\tTop1: 7.812 (avg: 11.688)\tTop5: 34.375 (avg: 31.812)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.415 (avg: 0.409)\tLoss: 4.0878 (avg: 4.0604)\tTop1: 10.938 (avg: 11.125)\tTop5: 29.688 (avg: 31.781)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.407 (avg: 0.411)\tLoss: 4.0604 (avg: 4.0688)\tTop1: 9.375 (avg: 10.812)\tTop5: 35.938 (avg: 31.750)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.408 (avg: 0.412)\tLoss: 4.1849 (avg: 4.0876)\tTop1: 12.500 (avg: 10.812)\tTop5: 29.688 (avg: 31.094)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.410 (avg: 0.412)\tLoss: 4.0297 (avg: 4.0958)\tTop1: 14.062 (avg: 10.775)\tTop5: 32.812 (avg: 30.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2890\tTop 1 accuracy: 7.400\tTop 5 accuracy: 24.150\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.415 (avg: 0.405)\tLoss: 4.0479 (avg: 3.9957)\tTop1: 10.938 (avg: 12.500)\tTop5: 31.250 (avg: 33.000)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.406 (avg: 0.410)\tLoss: 4.1712 (avg: 4.0111)\tTop1: 10.938 (avg: 11.562)\tTop5: 25.000 (avg: 32.344)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 4.0017 (avg: 4.0105)\tTop1: 12.500 (avg: 11.646)\tTop5: 32.812 (avg: 32.542)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.412 (avg: 0.412)\tLoss: 4.1220 (avg: 4.0329)\tTop1: 4.688 (avg: 11.516)\tTop5: 21.875 (avg: 32.109)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.418 (avg: 0.413)\tLoss: 3.9813 (avg: 4.0513)\tTop1: 9.375 (avg: 11.525)\tTop5: 34.375 (avg: 31.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0089\tTop 1 accuracy: 10.000\tTop 5 accuracy: 27.850\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.410 (avg: 0.405)\tLoss: 4.4671 (avg: 3.9297)\tTop1: 9.375 (avg: 13.062)\tTop5: 25.000 (avg: 35.188)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.403 (avg: 0.410)\tLoss: 3.8977 (avg: 3.9570)\tTop1: 4.688 (avg: 12.656)\tTop5: 42.188 (avg: 34.312)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.409 (avg: 0.411)\tLoss: 4.1138 (avg: 4.0058)\tTop1: 9.375 (avg: 12.271)\tTop5: 31.250 (avg: 33.167)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.411 (avg: 0.412)\tLoss: 4.1373 (avg: 4.0203)\tTop1: 6.250 (avg: 12.031)\tTop5: 26.562 (avg: 32.922)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.404 (avg: 0.412)\tLoss: 4.0310 (avg: 4.0151)\tTop1: 9.375 (avg: 12.038)\tTop5: 35.938 (avg: 33.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9928\tTop 1 accuracy: 9.100\tTop 5 accuracy: 27.150\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.406 (avg: 0.406)\tLoss: 3.9126 (avg: 3.8014)\tTop1: 9.375 (avg: 15.812)\tTop5: 32.812 (avg: 38.062)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 3.9800 (avg: 3.9110)\tTop1: 15.625 (avg: 13.812)\tTop5: 29.688 (avg: 35.219)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.413 (avg: 0.412)\tLoss: 4.4912 (avg: 3.9309)\tTop1: 6.250 (avg: 13.292)\tTop5: 17.188 (avg: 34.688)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.404 (avg: 0.413)\tLoss: 3.8693 (avg: 3.9511)\tTop1: 12.500 (avg: 12.812)\tTop5: 43.750 (avg: 34.109)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.409 (avg: 0.413)\tLoss: 4.3621 (avg: 3.9764)\tTop1: 7.812 (avg: 12.475)\tTop5: 21.875 (avg: 33.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9885\tTop 1 accuracy: 8.850\tTop 5 accuracy: 26.000\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.409 (avg: 0.404)\tLoss: 3.8827 (avg: 3.8593)\tTop1: 15.625 (avg: 14.000)\tTop5: 29.688 (avg: 34.938)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.412 (avg: 0.410)\tLoss: 3.7422 (avg: 3.8854)\tTop1: 23.438 (avg: 13.781)\tTop5: 42.188 (avg: 35.969)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.408 (avg: 0.411)\tLoss: 4.0829 (avg: 3.9347)\tTop1: 6.250 (avg: 12.750)\tTop5: 28.125 (avg: 34.729)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 4.0262 (avg: 3.9629)\tTop1: 12.500 (avg: 12.516)\tTop5: 39.062 (avg: 34.062)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.409 (avg: 0.413)\tLoss: 3.7997 (avg: 3.9537)\tTop1: 12.500 (avg: 12.700)\tTop5: 34.375 (avg: 34.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6872\tTop 1 accuracy: 10.600\tTop 5 accuracy: 30.250\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.409 (avg: 0.405)\tLoss: 3.6860 (avg: 3.7611)\tTop1: 15.625 (avg: 14.500)\tTop5: 46.875 (avg: 39.250)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.406 (avg: 0.410)\tLoss: 3.9221 (avg: 3.8498)\tTop1: 15.625 (avg: 13.969)\tTop5: 37.500 (avg: 36.719)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 3.5805 (avg: 3.8453)\tTop1: 18.750 (avg: 14.271)\tTop5: 45.312 (avg: 36.938)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.396 (avg: 0.413)\tLoss: 3.7339 (avg: 3.8501)\tTop1: 17.188 (avg: 14.219)\tTop5: 35.938 (avg: 36.875)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.415 (avg: 0.413)\tLoss: 4.1638 (avg: 3.8550)\tTop1: 10.938 (avg: 13.900)\tTop5: 32.812 (avg: 36.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0538\tTop 1 accuracy: 10.750\tTop 5 accuracy: 29.600\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.397 (avg: 0.405)\tLoss: 3.6901 (avg: 3.7921)\tTop1: 23.438 (avg: 15.188)\tTop5: 39.062 (avg: 38.500)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 3.7267 (avg: 3.8025)\tTop1: 15.625 (avg: 15.281)\tTop5: 39.062 (avg: 38.188)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.410 (avg: 0.412)\tLoss: 3.8256 (avg: 3.8430)\tTop1: 10.938 (avg: 14.542)\tTop5: 34.375 (avg: 37.229)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.414 (avg: 0.413)\tLoss: 4.0327 (avg: 3.8269)\tTop1: 18.750 (avg: 14.859)\tTop5: 31.250 (avg: 37.516)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.405 (avg: 0.413)\tLoss: 3.6853 (avg: 3.8386)\tTop1: 15.625 (avg: 14.625)\tTop5: 39.062 (avg: 37.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9957\tTop 1 accuracy: 10.000\tTop 5 accuracy: 28.250\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.407 (avg: 0.406)\tLoss: 3.6951 (avg: 3.5607)\tTop1: 17.188 (avg: 18.812)\tTop5: 43.750 (avg: 43.938)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 3.4554 (avg: 3.5180)\tTop1: 14.062 (avg: 19.531)\tTop5: 45.312 (avg: 44.656)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.414 (avg: 0.411)\tLoss: 3.4742 (avg: 3.4808)\tTop1: 17.188 (avg: 20.229)\tTop5: 37.500 (avg: 45.812)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.404 (avg: 0.412)\tLoss: 3.7376 (avg: 3.4531)\tTop1: 15.625 (avg: 21.125)\tTop5: 48.438 (avg: 46.688)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.407 (avg: 0.413)\tLoss: 3.1604 (avg: 3.4423)\tTop1: 25.000 (avg: 21.188)\tTop5: 54.688 (avg: 46.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3703\tTop 1 accuracy: 14.150\tTop 5 accuracy: 35.050\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.409 (avg: 0.406)\tLoss: 3.3550 (avg: 3.3442)\tTop1: 26.562 (avg: 22.375)\tTop5: 42.188 (avg: 48.750)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.413 (avg: 0.411)\tLoss: 3.4953 (avg: 3.3303)\tTop1: 15.625 (avg: 22.969)\tTop5: 42.188 (avg: 48.812)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.410 (avg: 0.412)\tLoss: 3.3017 (avg: 3.3268)\tTop1: 18.750 (avg: 23.521)\tTop5: 46.875 (avg: 48.938)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 3.4798 (avg: 3.3123)\tTop1: 18.750 (avg: 23.672)\tTop5: 39.062 (avg: 49.688)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.409 (avg: 0.413)\tLoss: 3.2553 (avg: 3.3189)\tTop1: 32.812 (avg: 23.675)\tTop5: 53.125 (avg: 49.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5199\tTop 1 accuracy: 13.850\tTop 5 accuracy: 34.600\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.414 (avg: 0.403)\tLoss: 3.4385 (avg: 3.2810)\tTop1: 25.000 (avg: 24.688)\tTop5: 53.125 (avg: 50.000)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.406 (avg: 0.409)\tLoss: 2.8519 (avg: 3.2767)\tTop1: 32.812 (avg: 24.906)\tTop5: 65.625 (avg: 50.219)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.409 (avg: 0.411)\tLoss: 3.1184 (avg: 3.2914)\tTop1: 29.688 (avg: 24.750)\tTop5: 48.438 (avg: 49.833)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.409 (avg: 0.412)\tLoss: 3.3371 (avg: 3.2950)\tTop1: 20.312 (avg: 24.547)\tTop5: 53.125 (avg: 50.094)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.413 (avg: 0.413)\tLoss: 3.0967 (avg: 3.2829)\tTop1: 23.438 (avg: 24.575)\tTop5: 53.125 (avg: 50.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3737\tTop 1 accuracy: 14.150\tTop 5 accuracy: 35.400\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.405 (avg: 0.405)\tLoss: 3.3536 (avg: 3.2232)\tTop1: 28.125 (avg: 23.125)\tTop5: 50.000 (avg: 50.750)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 3.0964 (avg: 3.2044)\tTop1: 31.250 (avg: 24.656)\tTop5: 51.562 (avg: 51.406)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 3.1655 (avg: 3.2559)\tTop1: 32.812 (avg: 24.792)\tTop5: 51.562 (avg: 50.583)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.411 (avg: 0.413)\tLoss: 2.7986 (avg: 3.2429)\tTop1: 35.938 (avg: 24.938)\tTop5: 56.250 (avg: 50.797)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.403 (avg: 0.413)\tLoss: 3.5052 (avg: 3.2504)\tTop1: 17.188 (avg: 24.875)\tTop5: 43.750 (avg: 50.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5170\tTop 1 accuracy: 14.050\tTop 5 accuracy: 35.250\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.408 (avg: 0.405)\tLoss: 2.8462 (avg: 3.1710)\tTop1: 32.812 (avg: 28.125)\tTop5: 60.938 (avg: 53.062)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.411 (avg: 0.411)\tLoss: 3.0217 (avg: 3.1952)\tTop1: 25.000 (avg: 26.219)\tTop5: 54.688 (avg: 52.781)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.415 (avg: 0.412)\tLoss: 2.9922 (avg: 3.2123)\tTop1: 25.000 (avg: 25.521)\tTop5: 54.688 (avg: 51.833)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.406 (avg: 0.413)\tLoss: 3.1100 (avg: 3.2199)\tTop1: 28.125 (avg: 25.406)\tTop5: 59.375 (avg: 51.766)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.407 (avg: 0.414)\tLoss: 3.1712 (avg: 3.2172)\tTop1: 23.438 (avg: 25.288)\tTop5: 53.125 (avg: 51.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4541\tTop 1 accuracy: 14.750\tTop 5 accuracy: 35.950\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.407 (avg: 0.405)\tLoss: 3.7130 (avg: 3.1770)\tTop1: 21.875 (avg: 26.312)\tTop5: 39.062 (avg: 53.375)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.414 (avg: 0.409)\tLoss: 3.1715 (avg: 3.1877)\tTop1: 26.562 (avg: 25.750)\tTop5: 53.125 (avg: 52.688)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.406 (avg: 0.411)\tLoss: 3.3042 (avg: 3.1694)\tTop1: 23.438 (avg: 26.062)\tTop5: 50.000 (avg: 53.250)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.409 (avg: 0.412)\tLoss: 3.1504 (avg: 3.1779)\tTop1: 28.125 (avg: 26.016)\tTop5: 46.875 (avg: 52.922)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.407 (avg: 0.413)\tLoss: 2.9136 (avg: 3.1895)\tTop1: 29.688 (avg: 26.038)\tTop5: 57.812 (avg: 52.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4390\tTop 1 accuracy: 14.700\tTop 5 accuracy: 35.550\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.411 (avg: 0.405)\tLoss: 3.2471 (avg: 3.1378)\tTop1: 21.875 (avg: 26.875)\tTop5: 45.312 (avg: 54.000)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 2.8710 (avg: 3.1212)\tTop1: 26.562 (avg: 27.312)\tTop5: 57.812 (avg: 54.406)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.405 (avg: 0.412)\tLoss: 2.9931 (avg: 3.1601)\tTop1: 32.812 (avg: 26.688)\tTop5: 62.500 (avg: 53.458)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 3.1722 (avg: 3.1580)\tTop1: 32.812 (avg: 26.562)\tTop5: 51.562 (avg: 53.516)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.413 (avg: 0.413)\tLoss: 3.7367 (avg: 3.1685)\tTop1: 14.062 (avg: 26.350)\tTop5: 40.625 (avg: 53.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5522\tTop 1 accuracy: 15.400\tTop 5 accuracy: 35.850\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.402 (avg: 0.403)\tLoss: 3.4351 (avg: 3.0447)\tTop1: 15.625 (avg: 27.688)\tTop5: 53.125 (avg: 54.188)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.407 (avg: 0.409)\tLoss: 3.1799 (avg: 3.0866)\tTop1: 29.688 (avg: 27.781)\tTop5: 53.125 (avg: 54.000)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.407 (avg: 0.411)\tLoss: 2.9563 (avg: 3.1230)\tTop1: 29.688 (avg: 27.292)\tTop5: 60.938 (avg: 53.500)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.412 (avg: 0.412)\tLoss: 2.7376 (avg: 3.1232)\tTop1: 39.062 (avg: 27.109)\tTop5: 67.188 (avg: 53.672)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.405 (avg: 0.413)\tLoss: 3.1270 (avg: 3.1342)\tTop1: 18.750 (avg: 26.838)\tTop5: 59.375 (avg: 53.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5451\tTop 1 accuracy: 14.850\tTop 5 accuracy: 36.000\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.407 (avg: 0.405)\tLoss: 3.0223 (avg: 3.0794)\tTop1: 31.250 (avg: 27.125)\tTop5: 60.938 (avg: 54.625)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 3.2218 (avg: 3.1080)\tTop1: 20.312 (avg: 26.781)\tTop5: 60.938 (avg: 54.844)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.415 (avg: 0.412)\tLoss: 3.3143 (avg: 3.0815)\tTop1: 25.000 (avg: 27.312)\tTop5: 54.688 (avg: 55.354)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.405 (avg: 0.413)\tLoss: 2.7192 (avg: 3.1023)\tTop1: 31.250 (avg: 27.172)\tTop5: 65.625 (avg: 54.719)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 2.9367 (avg: 3.1182)\tTop1: 32.812 (avg: 27.025)\tTop5: 56.250 (avg: 54.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5308\tTop 1 accuracy: 14.800\tTop 5 accuracy: 35.700\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.409 (avg: 0.405)\tLoss: 3.3740 (avg: 3.0470)\tTop1: 21.875 (avg: 28.500)\tTop5: 48.438 (avg: 56.062)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.413 (avg: 0.410)\tLoss: 3.2291 (avg: 3.0604)\tTop1: 21.875 (avg: 27.938)\tTop5: 56.250 (avg: 55.562)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 2.8355 (avg: 3.0552)\tTop1: 32.812 (avg: 27.875)\tTop5: 53.125 (avg: 55.417)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.404 (avg: 0.413)\tLoss: 3.2919 (avg: 3.0691)\tTop1: 23.438 (avg: 27.703)\tTop5: 51.562 (avg: 55.328)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 3.2699 (avg: 3.0832)\tTop1: 28.125 (avg: 27.538)\tTop5: 48.438 (avg: 55.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6036\tTop 1 accuracy: 14.600\tTop 5 accuracy: 35.800\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.408 (avg: 0.405)\tLoss: 3.1984 (avg: 3.0617)\tTop1: 23.438 (avg: 28.750)\tTop5: 50.000 (avg: 56.062)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.402 (avg: 0.409)\tLoss: 3.1002 (avg: 3.0161)\tTop1: 32.812 (avg: 29.219)\tTop5: 57.812 (avg: 56.938)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.406 (avg: 0.411)\tLoss: 3.2760 (avg: 3.0295)\tTop1: 25.000 (avg: 28.167)\tTop5: 50.000 (avg: 56.188)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.410 (avg: 0.412)\tLoss: 2.7413 (avg: 3.0513)\tTop1: 31.250 (avg: 27.969)\tTop5: 59.375 (avg: 55.719)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.411 (avg: 0.413)\tLoss: 2.8807 (avg: 3.0727)\tTop1: 28.125 (avg: 27.600)\tTop5: 65.625 (avg: 55.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6251\tTop 1 accuracy: 15.100\tTop 5 accuracy: 36.400\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.405 (avg: 0.405)\tLoss: 2.8322 (avg: 2.9982)\tTop1: 29.688 (avg: 28.750)\tTop5: 60.938 (avg: 56.812)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.406 (avg: 0.410)\tLoss: 2.8578 (avg: 2.9862)\tTop1: 26.562 (avg: 28.469)\tTop5: 70.312 (avg: 56.875)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.408 (avg: 0.412)\tLoss: 3.2584 (avg: 3.0162)\tTop1: 21.875 (avg: 28.208)\tTop5: 53.125 (avg: 56.667)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.412 (avg: 0.413)\tLoss: 2.6520 (avg: 3.0172)\tTop1: 32.812 (avg: 28.078)\tTop5: 60.938 (avg: 56.375)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.409 (avg: 0.413)\tLoss: 3.4279 (avg: 3.0462)\tTop1: 31.250 (avg: 27.900)\tTop5: 48.438 (avg: 55.813)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5287\tTop 1 accuracy: 14.800\tTop 5 accuracy: 34.800\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.407 (avg: 0.404)\tLoss: 3.3325 (avg: 2.9627)\tTop1: 29.688 (avg: 30.500)\tTop5: 48.438 (avg: 57.688)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.410 (avg: 0.409)\tLoss: 2.9554 (avg: 2.9705)\tTop1: 32.812 (avg: 29.906)\tTop5: 54.688 (avg: 57.438)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.412 (avg: 0.411)\tLoss: 3.3435 (avg: 2.9986)\tTop1: 23.438 (avg: 28.979)\tTop5: 50.000 (avg: 56.896)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 3.4234 (avg: 3.0169)\tTop1: 21.875 (avg: 28.328)\tTop5: 39.062 (avg: 56.562)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.405 (avg: 0.413)\tLoss: 2.9874 (avg: 3.0206)\tTop1: 37.500 (avg: 28.513)\tTop5: 64.062 (avg: 56.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4874\tTop 1 accuracy: 15.450\tTop 5 accuracy: 36.300\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.409 (avg: 0.406)\tLoss: 3.1569 (avg: 2.9422)\tTop1: 26.562 (avg: 29.375)\tTop5: 50.000 (avg: 58.000)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.414 (avg: 0.411)\tLoss: 2.9000 (avg: 3.0057)\tTop1: 31.250 (avg: 29.469)\tTop5: 53.125 (avg: 57.094)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.408 (avg: 0.412)\tLoss: 3.0514 (avg: 2.9931)\tTop1: 25.000 (avg: 29.188)\tTop5: 51.562 (avg: 57.521)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.406 (avg: 0.413)\tLoss: 3.2122 (avg: 2.9850)\tTop1: 23.438 (avg: 29.281)\tTop5: 51.562 (avg: 57.312)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.411 (avg: 0.414)\tLoss: 2.8468 (avg: 2.9976)\tTop1: 35.938 (avg: 29.013)\tTop5: 59.375 (avg: 56.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6818\tTop 1 accuracy: 15.100\tTop 5 accuracy: 36.200\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.409 (avg: 0.406)\tLoss: 3.2896 (avg: 2.9600)\tTop1: 25.000 (avg: 29.750)\tTop5: 51.562 (avg: 58.062)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.405 (avg: 0.410)\tLoss: 3.1674 (avg: 2.9906)\tTop1: 31.250 (avg: 29.719)\tTop5: 56.250 (avg: 57.031)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 2.7793 (avg: 2.9799)\tTop1: 28.125 (avg: 29.521)\tTop5: 59.375 (avg: 56.979)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.410 (avg: 0.413)\tLoss: 2.9044 (avg: 2.9701)\tTop1: 31.250 (avg: 29.812)\tTop5: 59.375 (avg: 57.359)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.405 (avg: 0.414)\tLoss: 2.7639 (avg: 2.9725)\tTop1: 31.250 (avg: 29.375)\tTop5: 59.375 (avg: 57.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7867\tTop 1 accuracy: 14.650\tTop 5 accuracy: 36.800\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.402 (avg: 0.404)\tLoss: 2.6123 (avg: 2.9514)\tTop1: 37.500 (avg: 29.625)\tTop5: 62.500 (avg: 58.438)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.405 (avg: 0.409)\tLoss: 2.9034 (avg: 2.9208)\tTop1: 28.125 (avg: 30.000)\tTop5: 56.250 (avg: 58.719)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.398 (avg: 0.411)\tLoss: 3.0897 (avg: 2.9379)\tTop1: 28.125 (avg: 29.896)\tTop5: 48.438 (avg: 58.271)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.412 (avg: 0.412)\tLoss: 2.5656 (avg: 2.9299)\tTop1: 34.375 (avg: 30.000)\tTop5: 64.062 (avg: 58.641)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 3.1896 (avg: 2.9455)\tTop1: 25.000 (avg: 29.588)\tTop5: 54.688 (avg: 58.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7573\tTop 1 accuracy: 15.450\tTop 5 accuracy: 36.150\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.408 (avg: 0.406)\tLoss: 2.6640 (avg: 2.8689)\tTop1: 28.125 (avg: 30.000)\tTop5: 64.062 (avg: 58.688)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.409 (avg: 0.410)\tLoss: 2.9848 (avg: 2.9136)\tTop1: 25.000 (avg: 29.781)\tTop5: 57.812 (avg: 57.969)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.411 (avg: 0.412)\tLoss: 3.0003 (avg: 2.9257)\tTop1: 25.000 (avg: 29.896)\tTop5: 59.375 (avg: 58.521)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 2.8171 (avg: 2.9127)\tTop1: 31.250 (avg: 30.203)\tTop5: 60.938 (avg: 58.859)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.405 (avg: 0.414)\tLoss: 2.7933 (avg: 2.9074)\tTop1: 26.562 (avg: 30.250)\tTop5: 62.500 (avg: 58.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8638\tTop 1 accuracy: 15.400\tTop 5 accuracy: 36.950\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.406 (avg: 0.402)\tLoss: 2.9224 (avg: 2.8457)\tTop1: 28.125 (avg: 32.375)\tTop5: 59.375 (avg: 59.938)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.412 (avg: 0.408)\tLoss: 2.8081 (avg: 2.8702)\tTop1: 28.125 (avg: 32.188)\tTop5: 64.062 (avg: 59.375)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.405 (avg: 0.411)\tLoss: 2.9863 (avg: 2.8890)\tTop1: 32.812 (avg: 31.708)\tTop5: 53.125 (avg: 58.812)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 2.8706 (avg: 2.9093)\tTop1: 29.688 (avg: 30.969)\tTop5: 57.812 (avg: 58.422)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.407 (avg: 0.413)\tLoss: 3.1637 (avg: 2.9093)\tTop1: 23.438 (avg: 30.925)\tTop5: 60.938 (avg: 58.625)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8800\tTop 1 accuracy: 15.700\tTop 5 accuracy: 36.350\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.415 (avg: 0.405)\tLoss: 2.9957 (avg: 2.8255)\tTop1: 28.125 (avg: 31.875)\tTop5: 64.062 (avg: 60.750)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.405 (avg: 0.410)\tLoss: 2.6721 (avg: 2.8560)\tTop1: 35.938 (avg: 31.469)\tTop5: 65.625 (avg: 60.188)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.404 (avg: 0.412)\tLoss: 2.9896 (avg: 2.8432)\tTop1: 28.125 (avg: 31.146)\tTop5: 56.250 (avg: 60.104)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.411 (avg: 0.413)\tLoss: 3.0394 (avg: 2.8523)\tTop1: 23.438 (avg: 31.078)\tTop5: 56.250 (avg: 60.062)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.412 (avg: 0.413)\tLoss: 3.3680 (avg: 2.8767)\tTop1: 26.562 (avg: 30.900)\tTop5: 51.562 (avg: 59.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6218\tTop 1 accuracy: 14.650\tTop 5 accuracy: 37.600\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.405 (avg: 0.406)\tLoss: 2.5714 (avg: 2.8434)\tTop1: 37.500 (avg: 31.312)\tTop5: 65.625 (avg: 59.375)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.410 (avg: 0.410)\tLoss: 2.5613 (avg: 2.8055)\tTop1: 29.688 (avg: 31.625)\tTop5: 65.625 (avg: 60.938)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.408 (avg: 0.412)\tLoss: 3.2276 (avg: 2.8355)\tTop1: 26.562 (avg: 31.000)\tTop5: 51.562 (avg: 60.208)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.417 (avg: 0.413)\tLoss: 2.7811 (avg: 2.8468)\tTop1: 39.062 (avg: 31.094)\tTop5: 62.500 (avg: 60.125)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.405 (avg: 0.413)\tLoss: 2.6562 (avg: 2.8354)\tTop1: 39.062 (avg: 31.713)\tTop5: 67.188 (avg: 60.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8130\tTop 1 accuracy: 15.500\tTop 5 accuracy: 37.050\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.402 (avg: 0.403)\tLoss: 3.0078 (avg: 2.8048)\tTop1: 25.000 (avg: 33.000)\tTop5: 53.125 (avg: 59.125)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.407 (avg: 0.409)\tLoss: 2.6198 (avg: 2.8140)\tTop1: 40.625 (avg: 33.000)\tTop5: 68.750 (avg: 60.062)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.412 (avg: 0.411)\tLoss: 2.6925 (avg: 2.8115)\tTop1: 34.375 (avg: 32.562)\tTop5: 62.500 (avg: 60.438)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.405 (avg: 0.412)\tLoss: 2.7696 (avg: 2.7818)\tTop1: 34.375 (avg: 33.125)\tTop5: 65.625 (avg: 61.406)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 2.9575 (avg: 2.7930)\tTop1: 26.562 (avg: 32.738)\tTop5: 51.562 (avg: 60.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8061\tTop 1 accuracy: 15.550\tTop 5 accuracy: 36.600\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.408 (avg: 0.405)\tLoss: 3.0444 (avg: 2.7223)\tTop1: 35.938 (avg: 35.500)\tTop5: 51.562 (avg: 62.375)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.413 (avg: 0.410)\tLoss: 2.9914 (avg: 2.7495)\tTop1: 26.562 (avg: 34.000)\tTop5: 59.375 (avg: 61.719)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.403 (avg: 0.411)\tLoss: 2.4281 (avg: 2.7366)\tTop1: 39.062 (avg: 33.812)\tTop5: 67.188 (avg: 62.396)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 2.7907 (avg: 2.7487)\tTop1: 31.250 (avg: 33.609)\tTop5: 57.812 (avg: 62.109)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.411 (avg: 0.413)\tLoss: 2.9818 (avg: 2.7771)\tTop1: 26.562 (avg: 33.150)\tTop5: 53.125 (avg: 61.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0520\tTop 1 accuracy: 15.450\tTop 5 accuracy: 36.600\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.409 (avg: 0.403)\tLoss: 2.5992 (avg: 2.7177)\tTop1: 37.500 (avg: 34.000)\tTop5: 67.188 (avg: 62.750)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.406 (avg: 0.409)\tLoss: 2.7397 (avg: 2.7021)\tTop1: 31.250 (avg: 34.688)\tTop5: 62.500 (avg: 62.844)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.410 (avg: 0.411)\tLoss: 2.8929 (avg: 2.7371)\tTop1: 29.688 (avg: 33.917)\tTop5: 59.375 (avg: 62.479)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.412 (avg: 0.412)\tLoss: 3.0211 (avg: 2.7217)\tTop1: 37.500 (avg: 34.141)\tTop5: 60.938 (avg: 62.938)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.415 (avg: 0.413)\tLoss: 2.8173 (avg: 2.7447)\tTop1: 26.562 (avg: 33.675)\tTop5: 57.812 (avg: 62.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8501\tTop 1 accuracy: 14.800\tTop 5 accuracy: 35.800\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.405 (avg: 0.405)\tLoss: 2.8706 (avg: 2.6332)\tTop1: 35.938 (avg: 36.438)\tTop5: 62.500 (avg: 64.188)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 2.5839 (avg: 2.6906)\tTop1: 39.062 (avg: 35.406)\tTop5: 62.500 (avg: 63.500)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.412 (avg: 0.412)\tLoss: 2.6248 (avg: 2.7038)\tTop1: 34.375 (avg: 34.833)\tTop5: 60.938 (avg: 63.229)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.411 (avg: 0.413)\tLoss: 2.4171 (avg: 2.7007)\tTop1: 43.750 (avg: 35.047)\tTop5: 70.312 (avg: 63.031)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.407 (avg: 0.414)\tLoss: 2.8354 (avg: 2.7060)\tTop1: 29.688 (avg: 34.888)\tTop5: 54.688 (avg: 62.950)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9684\tTop 1 accuracy: 14.950\tTop 5 accuracy: 35.500\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.406 (avg: 0.406)\tLoss: 2.8451 (avg: 2.5676)\tTop1: 35.938 (avg: 38.312)\tTop5: 64.062 (avg: 65.562)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.409 (avg: 0.411)\tLoss: 2.9563 (avg: 2.6268)\tTop1: 26.562 (avg: 36.312)\tTop5: 56.250 (avg: 64.562)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.412 (avg: 0.412)\tLoss: 2.6833 (avg: 2.6700)\tTop1: 37.500 (avg: 35.417)\tTop5: 62.500 (avg: 64.083)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 2.4693 (avg: 2.6658)\tTop1: 32.812 (avg: 35.375)\tTop5: 70.312 (avg: 64.344)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.408 (avg: 0.414)\tLoss: 2.9900 (avg: 2.6737)\tTop1: 35.938 (avg: 35.325)\tTop5: 50.000 (avg: 64.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1262\tTop 1 accuracy: 14.650\tTop 5 accuracy: 35.650\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.408 (avg: 0.404)\tLoss: 2.5132 (avg: 2.4868)\tTop1: 45.312 (avg: 38.688)\tTop5: 67.188 (avg: 67.875)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.411 (avg: 0.410)\tLoss: 2.6725 (avg: 2.5773)\tTop1: 31.250 (avg: 36.875)\tTop5: 64.062 (avg: 66.375)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 2.5052 (avg: 2.5904)\tTop1: 39.062 (avg: 36.583)\tTop5: 62.500 (avg: 65.917)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.402 (avg: 0.413)\tLoss: 2.7815 (avg: 2.6299)\tTop1: 29.688 (avg: 35.688)\tTop5: 60.938 (avg: 64.828)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 2.6164 (avg: 2.6755)\tTop1: 28.125 (avg: 34.875)\tTop5: 62.500 (avg: 63.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6622\tTop 1 accuracy: 15.250\tTop 5 accuracy: 36.900\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.413 (avg: 0.406)\tLoss: 2.9733 (avg: 2.5933)\tTop1: 32.812 (avg: 35.812)\tTop5: 59.375 (avg: 65.125)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.408 (avg: 0.411)\tLoss: 2.6380 (avg: 2.6084)\tTop1: 34.375 (avg: 36.188)\tTop5: 65.625 (avg: 64.781)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.402 (avg: 0.412)\tLoss: 2.6006 (avg: 2.6099)\tTop1: 31.250 (avg: 36.438)\tTop5: 70.312 (avg: 65.000)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 2.5132 (avg: 2.6177)\tTop1: 32.812 (avg: 36.188)\tTop5: 60.938 (avg: 64.797)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.412 (avg: 0.413)\tLoss: 2.9651 (avg: 2.6283)\tTop1: 26.562 (avg: 35.538)\tTop5: 57.812 (avg: 64.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8735\tTop 1 accuracy: 15.000\tTop 5 accuracy: 36.650\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.403 (avg: 0.403)\tLoss: 2.3499 (avg: 2.4353)\tTop1: 40.625 (avg: 40.000)\tTop5: 62.500 (avg: 69.375)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.405 (avg: 0.408)\tLoss: 2.8749 (avg: 2.4942)\tTop1: 31.250 (avg: 37.625)\tTop5: 60.938 (avg: 68.625)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 2.7263 (avg: 2.5401)\tTop1: 34.375 (avg: 37.146)\tTop5: 67.188 (avg: 67.417)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.414 (avg: 0.412)\tLoss: 2.4713 (avg: 2.5510)\tTop1: 40.625 (avg: 37.312)\tTop5: 73.438 (avg: 66.781)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 2.4505 (avg: 2.5710)\tTop1: 37.500 (avg: 36.688)\tTop5: 70.312 (avg: 66.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0098\tTop 1 accuracy: 15.650\tTop 5 accuracy: 36.200\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.408 (avg: 0.405)\tLoss: 2.2559 (avg: 2.5518)\tTop1: 43.750 (avg: 37.312)\tTop5: 75.000 (avg: 66.312)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.415 (avg: 0.410)\tLoss: 2.5419 (avg: 2.5438)\tTop1: 29.688 (avg: 36.125)\tTop5: 60.938 (avg: 66.281)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.411 (avg: 0.411)\tLoss: 2.4508 (avg: 2.5278)\tTop1: 42.188 (avg: 36.479)\tTop5: 65.625 (avg: 66.771)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 2.3796 (avg: 2.5303)\tTop1: 42.188 (avg: 36.891)\tTop5: 67.188 (avg: 66.719)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.409 (avg: 0.412)\tLoss: 2.6979 (avg: 2.5383)\tTop1: 40.625 (avg: 36.950)\tTop5: 62.500 (avg: 66.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7034\tTop 1 accuracy: 14.800\tTop 5 accuracy: 35.900\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.407 (avg: 0.404)\tLoss: 2.6459 (avg: 2.4963)\tTop1: 28.125 (avg: 38.938)\tTop5: 68.750 (avg: 67.562)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.412 (avg: 0.410)\tLoss: 2.3327 (avg: 2.4781)\tTop1: 39.062 (avg: 39.125)\tTop5: 73.438 (avg: 67.938)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.405 (avg: 0.411)\tLoss: 2.6665 (avg: 2.4916)\tTop1: 34.375 (avg: 38.500)\tTop5: 67.188 (avg: 67.875)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.405 (avg: 0.412)\tLoss: 2.2294 (avg: 2.5160)\tTop1: 46.875 (avg: 37.750)\tTop5: 65.625 (avg: 67.172)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.413 (avg: 0.413)\tLoss: 3.0394 (avg: 2.5421)\tTop1: 31.250 (avg: 37.525)\tTop5: 54.688 (avg: 66.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9214\tTop 1 accuracy: 15.800\tTop 5 accuracy: 37.150\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.412 (avg: 0.404)\tLoss: 2.0593 (avg: 2.3542)\tTop1: 50.000 (avg: 41.500)\tTop5: 75.000 (avg: 69.938)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.407 (avg: 0.409)\tLoss: 2.3284 (avg: 2.3268)\tTop1: 45.312 (avg: 42.062)\tTop5: 67.188 (avg: 70.688)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.407 (avg: 0.411)\tLoss: 2.0700 (avg: 2.2853)\tTop1: 46.875 (avg: 43.000)\tTop5: 73.438 (avg: 71.500)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 2.4145 (avg: 2.2717)\tTop1: 34.375 (avg: 43.672)\tTop5: 67.188 (avg: 71.703)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.410 (avg: 0.413)\tLoss: 2.1742 (avg: 2.2625)\tTop1: 45.312 (avg: 43.975)\tTop5: 71.875 (avg: 71.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7569\tTop 1 accuracy: 16.150\tTop 5 accuracy: 38.650\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.405 (avg: 0.406)\tLoss: 2.0960 (avg: 2.1841)\tTop1: 50.000 (avg: 45.375)\tTop5: 79.688 (avg: 74.062)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 2.1351 (avg: 2.1963)\tTop1: 39.062 (avg: 45.500)\tTop5: 79.688 (avg: 73.250)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 2.1442 (avg: 2.1789)\tTop1: 46.875 (avg: 45.854)\tTop5: 78.125 (avg: 73.667)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.413 (avg: 0.413)\tLoss: 2.4736 (avg: 2.1823)\tTop1: 39.062 (avg: 45.641)\tTop5: 71.875 (avg: 73.438)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.406 (avg: 0.414)\tLoss: 2.0193 (avg: 2.1864)\tTop1: 48.438 (avg: 45.500)\tTop5: 79.688 (avg: 73.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9253\tTop 1 accuracy: 16.050\tTop 5 accuracy: 38.650\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.401 (avg: 0.403)\tLoss: 1.9744 (avg: 2.1271)\tTop1: 53.125 (avg: 47.750)\tTop5: 78.125 (avg: 74.375)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.414 (avg: 0.408)\tLoss: 2.2965 (avg: 2.1499)\tTop1: 50.000 (avg: 47.219)\tTop5: 75.000 (avg: 73.938)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.416 (avg: 0.410)\tLoss: 2.1164 (avg: 2.1390)\tTop1: 46.875 (avg: 47.250)\tTop5: 67.188 (avg: 73.708)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.406 (avg: 0.411)\tLoss: 2.1297 (avg: 2.1560)\tTop1: 43.750 (avg: 46.656)\tTop5: 73.438 (avg: 73.297)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 1.9487 (avg: 2.1716)\tTop1: 48.438 (avg: 46.275)\tTop5: 79.688 (avg: 73.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8719\tTop 1 accuracy: 16.550\tTop 5 accuracy: 38.350\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.408 (avg: 0.405)\tLoss: 2.3603 (avg: 2.1359)\tTop1: 46.875 (avg: 46.625)\tTop5: 67.188 (avg: 74.500)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.411 (avg: 0.410)\tLoss: 2.1752 (avg: 2.1353)\tTop1: 43.750 (avg: 46.375)\tTop5: 70.312 (avg: 74.219)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.408 (avg: 0.412)\tLoss: 1.9479 (avg: 2.1413)\tTop1: 57.812 (avg: 46.479)\tTop5: 76.562 (avg: 74.250)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.409 (avg: 0.413)\tLoss: 1.9043 (avg: 2.1481)\tTop1: 48.438 (avg: 46.625)\tTop5: 79.688 (avg: 73.984)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 2.3267 (avg: 2.1569)\tTop1: 48.438 (avg: 46.313)\tTop5: 67.188 (avg: 73.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9974\tTop 1 accuracy: 16.250\tTop 5 accuracy: 38.050\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.412 (avg: 0.406)\tLoss: 1.7280 (avg: 2.1306)\tTop1: 48.438 (avg: 46.500)\tTop5: 79.688 (avg: 74.000)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 2.2171 (avg: 2.1766)\tTop1: 45.312 (avg: 46.312)\tTop5: 70.312 (avg: 73.312)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.410 (avg: 0.412)\tLoss: 1.9464 (avg: 2.1519)\tTop1: 54.688 (avg: 46.583)\tTop5: 76.562 (avg: 73.854)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.406 (avg: 0.413)\tLoss: 2.5397 (avg: 2.1644)\tTop1: 31.250 (avg: 46.500)\tTop5: 68.750 (avg: 73.609)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.412 (avg: 0.414)\tLoss: 2.2212 (avg: 2.1542)\tTop1: 40.625 (avg: 46.850)\tTop5: 71.875 (avg: 73.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1085\tTop 1 accuracy: 16.200\tTop 5 accuracy: 38.150\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.406 (avg: 0.405)\tLoss: 2.2801 (avg: 2.1040)\tTop1: 45.312 (avg: 47.500)\tTop5: 71.875 (avg: 74.375)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 2.2415 (avg: 2.1318)\tTop1: 48.438 (avg: 47.125)\tTop5: 75.000 (avg: 73.969)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.411 (avg: 0.412)\tLoss: 2.0360 (avg: 2.1228)\tTop1: 50.000 (avg: 47.438)\tTop5: 73.438 (avg: 74.125)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.412 (avg: 0.413)\tLoss: 1.9471 (avg: 2.1260)\tTop1: 50.000 (avg: 47.109)\tTop5: 75.000 (avg: 74.062)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.406 (avg: 0.413)\tLoss: 1.9354 (avg: 2.1319)\tTop1: 46.875 (avg: 46.950)\tTop5: 76.562 (avg: 73.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1964\tTop 1 accuracy: 15.500\tTop 5 accuracy: 38.300\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.407 (avg: 0.405)\tLoss: 1.9717 (avg: 2.0997)\tTop1: 53.125 (avg: 46.875)\tTop5: 76.562 (avg: 75.500)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 1.9212 (avg: 2.1331)\tTop1: 64.062 (avg: 46.406)\tTop5: 76.562 (avg: 74.000)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.412 (avg: 0.412)\tLoss: 2.1658 (avg: 2.1167)\tTop1: 48.438 (avg: 47.021)\tTop5: 73.438 (avg: 74.042)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.403 (avg: 0.412)\tLoss: 2.3441 (avg: 2.1246)\tTop1: 46.875 (avg: 47.094)\tTop5: 68.750 (avg: 74.109)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.409 (avg: 0.413)\tLoss: 2.0626 (avg: 2.1219)\tTop1: 46.875 (avg: 47.263)\tTop5: 75.000 (avg: 74.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0708\tTop 1 accuracy: 16.400\tTop 5 accuracy: 38.550\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.403 (avg: 0.404)\tLoss: 1.9896 (avg: 2.0721)\tTop1: 48.438 (avg: 48.000)\tTop5: 73.438 (avg: 76.062)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.414 (avg: 0.408)\tLoss: 2.1431 (avg: 2.0808)\tTop1: 45.312 (avg: 47.844)\tTop5: 76.562 (avg: 75.156)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.405 (avg: 0.411)\tLoss: 2.0605 (avg: 2.0848)\tTop1: 51.562 (avg: 48.000)\tTop5: 76.562 (avg: 75.292)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.405 (avg: 0.412)\tLoss: 2.2641 (avg: 2.0944)\tTop1: 45.312 (avg: 47.781)\tTop5: 75.000 (avg: 74.984)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.406 (avg: 0.413)\tLoss: 2.1088 (avg: 2.1088)\tTop1: 42.188 (avg: 47.375)\tTop5: 70.312 (avg: 74.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1341\tTop 1 accuracy: 15.650\tTop 5 accuracy: 37.750\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.414 (avg: 0.406)\tLoss: 2.0614 (avg: 2.0605)\tTop1: 50.000 (avg: 47.375)\tTop5: 75.000 (avg: 74.250)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 2.2424 (avg: 2.0710)\tTop1: 43.750 (avg: 47.719)\tTop5: 68.750 (avg: 74.969)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.406 (avg: 0.413)\tLoss: 2.4217 (avg: 2.0734)\tTop1: 46.875 (avg: 48.500)\tTop5: 76.562 (avg: 75.146)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 2.0444 (avg: 2.0865)\tTop1: 43.750 (avg: 47.906)\tTop5: 78.125 (avg: 74.859)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.412 (avg: 0.414)\tLoss: 1.9830 (avg: 2.1022)\tTop1: 46.875 (avg: 47.513)\tTop5: 81.250 (avg: 74.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2093\tTop 1 accuracy: 16.150\tTop 5 accuracy: 37.250\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.402 (avg: 0.405)\tLoss: 2.0566 (avg: 2.0834)\tTop1: 53.125 (avg: 48.375)\tTop5: 78.125 (avg: 74.688)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 1.6993 (avg: 2.0492)\tTop1: 57.812 (avg: 49.125)\tTop5: 78.125 (avg: 75.281)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 2.1417 (avg: 2.0758)\tTop1: 46.875 (avg: 48.000)\tTop5: 75.000 (avg: 74.917)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.413 (avg: 0.412)\tLoss: 1.8332 (avg: 2.0711)\tTop1: 57.812 (avg: 48.203)\tTop5: 75.000 (avg: 75.016)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.404 (avg: 0.413)\tLoss: 1.7221 (avg: 2.0845)\tTop1: 60.938 (avg: 47.888)\tTop5: 76.562 (avg: 74.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2197\tTop 1 accuracy: 16.100\tTop 5 accuracy: 38.000\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.407 (avg: 0.405)\tLoss: 2.0483 (avg: 2.0271)\tTop1: 51.562 (avg: 49.438)\tTop5: 70.312 (avg: 74.875)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 1.8003 (avg: 2.0340)\tTop1: 60.938 (avg: 49.969)\tTop5: 82.812 (avg: 75.594)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.414 (avg: 0.412)\tLoss: 2.3226 (avg: 2.0632)\tTop1: 46.875 (avg: 48.438)\tTop5: 70.312 (avg: 75.271)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.404 (avg: 0.413)\tLoss: 2.6795 (avg: 2.0665)\tTop1: 43.750 (avg: 48.469)\tTop5: 59.375 (avg: 75.297)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.406 (avg: 0.413)\tLoss: 2.3812 (avg: 2.0814)\tTop1: 48.438 (avg: 48.425)\tTop5: 68.750 (avg: 75.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2176\tTop 1 accuracy: 15.950\tTop 5 accuracy: 37.950\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.410 (avg: 0.404)\tLoss: 2.3421 (avg: 2.0787)\tTop1: 39.062 (avg: 48.625)\tTop5: 68.750 (avg: 75.562)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.412 (avg: 0.409)\tLoss: 2.4469 (avg: 2.0949)\tTop1: 39.062 (avg: 47.688)\tTop5: 70.312 (avg: 75.625)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.404 (avg: 0.411)\tLoss: 2.2597 (avg: 2.0786)\tTop1: 48.438 (avg: 47.750)\tTop5: 76.562 (avg: 75.438)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 2.2370 (avg: 2.0862)\tTop1: 46.875 (avg: 47.625)\tTop5: 70.312 (avg: 75.266)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 1.9900 (avg: 2.0806)\tTop1: 51.562 (avg: 47.625)\tTop5: 78.125 (avg: 75.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2242\tTop 1 accuracy: 16.150\tTop 5 accuracy: 37.600\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.411 (avg: 0.405)\tLoss: 1.8635 (avg: 2.0868)\tTop1: 54.688 (avg: 48.188)\tTop5: 71.875 (avg: 74.438)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.407 (avg: 0.408)\tLoss: 2.2544 (avg: 2.0416)\tTop1: 40.625 (avg: 49.062)\tTop5: 73.438 (avg: 75.562)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.407 (avg: 0.411)\tLoss: 2.1230 (avg: 2.0401)\tTop1: 42.188 (avg: 49.375)\tTop5: 75.000 (avg: 75.792)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.409 (avg: 0.412)\tLoss: 1.9374 (avg: 2.0565)\tTop1: 50.000 (avg: 48.984)\tTop5: 79.688 (avg: 75.562)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.413 (avg: 0.413)\tLoss: 2.2011 (avg: 2.0620)\tTop1: 51.562 (avg: 49.050)\tTop5: 75.000 (avg: 75.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2057\tTop 1 accuracy: 16.700\tTop 5 accuracy: 37.750\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.406 (avg: 0.406)\tLoss: 2.4380 (avg: 2.0844)\tTop1: 42.188 (avg: 47.688)\tTop5: 67.188 (avg: 74.375)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 2.0783 (avg: 2.0339)\tTop1: 48.438 (avg: 48.844)\tTop5: 79.688 (avg: 75.531)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.409 (avg: 0.412)\tLoss: 1.6246 (avg: 2.0463)\tTop1: 57.812 (avg: 48.500)\tTop5: 76.562 (avg: 75.833)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.410 (avg: 0.413)\tLoss: 2.1642 (avg: 2.0594)\tTop1: 37.500 (avg: 48.406)\tTop5: 71.875 (avg: 75.500)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.407 (avg: 0.413)\tLoss: 2.0768 (avg: 2.0674)\tTop1: 46.875 (avg: 48.250)\tTop5: 78.125 (avg: 75.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3001\tTop 1 accuracy: 16.450\tTop 5 accuracy: 38.050\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.408 (avg: 0.405)\tLoss: 2.0147 (avg: 2.0277)\tTop1: 53.125 (avg: 51.000)\tTop5: 76.562 (avg: 75.688)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.406 (avg: 0.410)\tLoss: 1.7375 (avg: 2.0322)\tTop1: 57.812 (avg: 49.969)\tTop5: 81.250 (avg: 76.281)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.413 (avg: 0.411)\tLoss: 2.2013 (avg: 2.0439)\tTop1: 51.562 (avg: 49.208)\tTop5: 70.312 (avg: 75.583)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 2.1574 (avg: 2.0377)\tTop1: 40.625 (avg: 49.016)\tTop5: 71.875 (avg: 75.797)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 2.5265 (avg: 2.0464)\tTop1: 34.375 (avg: 48.675)\tTop5: 71.875 (avg: 75.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3384\tTop 1 accuracy: 16.200\tTop 5 accuracy: 38.000\n",
            "\n",
            "SR = 0.25: top1 = 16.150001525878906\ttop5 = 38.650001525878906\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.545 (avg: 0.764)\tLoss: 5.2915 (avg: 5.3099)\tTop1: 0.000 (avg: 0.188)\tTop5: 3.125 (avg: 2.000)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.546 (avg: 0.658)\tLoss: 5.3049 (avg: 5.3051)\tTop1: 0.000 (avg: 0.250)\tTop5: 0.000 (avg: 2.188)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.548 (avg: 0.622)\tLoss: 5.2972 (avg: 5.3032)\tTop1: 0.000 (avg: 0.396)\tTop5: 3.125 (avg: 2.062)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.546 (avg: 0.605)\tLoss: 5.2999 (avg: 5.3021)\tTop1: 0.000 (avg: 0.469)\tTop5: 3.125 (avg: 2.141)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.548 (avg: 0.594)\tLoss: 5.2986 (avg: 5.3014)\tTop1: 0.000 (avg: 0.463)\tTop5: 0.000 (avg: 2.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2883\tTop 1 accuracy: 0.600\tTop 5 accuracy: 2.150\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.549 (avg: 0.541)\tLoss: 5.3071 (avg: 5.2941)\tTop1: 0.000 (avg: 1.062)\tTop5: 4.688 (avg: 3.312)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.550 (avg: 0.547)\tLoss: 5.2934 (avg: 5.2917)\tTop1: 0.000 (avg: 1.000)\tTop5: 4.688 (avg: 3.250)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.548 (avg: 0.550)\tLoss: 5.3137 (avg: 5.2870)\tTop1: 0.000 (avg: 1.021)\tTop5: 0.000 (avg: 3.354)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.548 (avg: 0.550)\tLoss: 5.2578 (avg: 5.2810)\tTop1: 1.562 (avg: 1.125)\tTop5: 9.375 (avg: 3.688)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.543 (avg: 0.551)\tLoss: 5.2893 (avg: 5.2776)\tTop1: 1.562 (avg: 1.025)\tTop5: 3.125 (avg: 3.813)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2801\tTop 1 accuracy: 0.750\tTop 5 accuracy: 3.750\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.539 (avg: 0.538)\tLoss: 5.2626 (avg: 5.2363)\tTop1: 1.562 (avg: 1.312)\tTop5: 7.812 (avg: 6.688)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.545 (avg: 0.545)\tLoss: 5.3219 (avg: 5.2255)\tTop1: 0.000 (avg: 1.375)\tTop5: 1.562 (avg: 6.500)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.547 (avg: 0.547)\tLoss: 5.2711 (avg: 5.2245)\tTop1: 1.562 (avg: 1.438)\tTop5: 3.125 (avg: 6.604)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.544 (avg: 0.548)\tLoss: 5.0549 (avg: 5.2186)\tTop1: 0.000 (avg: 1.344)\tTop5: 9.375 (avg: 6.562)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.546 (avg: 0.549)\tLoss: 5.1401 (avg: 5.2139)\tTop1: 0.000 (avg: 1.238)\tTop5: 7.812 (avg: 6.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2652\tTop 1 accuracy: 1.850\tTop 5 accuracy: 6.600\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.546 (avg: 0.540)\tLoss: 5.1591 (avg: 5.1479)\tTop1: 1.562 (avg: 1.750)\tTop5: 9.375 (avg: 8.312)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.549 (avg: 0.546)\tLoss: 5.0951 (avg: 5.1594)\tTop1: 1.562 (avg: 1.531)\tTop5: 9.375 (avg: 7.188)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.547 (avg: 0.549)\tLoss: 5.1757 (avg: 5.1522)\tTop1: 4.688 (avg: 1.583)\tTop5: 7.812 (avg: 7.271)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.551 (avg: 0.550)\tLoss: 5.1179 (avg: 5.1570)\tTop1: 6.250 (avg: 1.562)\tTop5: 10.938 (avg: 7.156)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.542 (avg: 0.550)\tLoss: 5.1930 (avg: 5.1480)\tTop1: 0.000 (avg: 1.525)\tTop5: 3.125 (avg: 7.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1773\tTop 1 accuracy: 2.300\tTop 5 accuracy: 9.600\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.548 (avg: 0.542)\tLoss: 5.1017 (avg: 5.0872)\tTop1: 0.000 (avg: 1.812)\tTop5: 9.375 (avg: 8.500)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.546 (avg: 0.548)\tLoss: 5.1811 (avg: 5.1054)\tTop1: 3.125 (avg: 1.688)\tTop5: 9.375 (avg: 8.312)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.550 (avg: 0.551)\tLoss: 5.1239 (avg: 5.1037)\tTop1: 3.125 (avg: 1.750)\tTop5: 7.812 (avg: 8.333)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.549 (avg: 0.552)\tLoss: 5.0991 (avg: 5.1082)\tTop1: 6.250 (avg: 1.844)\tTop5: 14.062 (avg: 8.078)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.552 (avg: 0.553)\tLoss: 4.9329 (avg: 5.1024)\tTop1: 3.125 (avg: 1.900)\tTop5: 9.375 (avg: 8.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0280\tTop 1 accuracy: 1.850\tTop 5 accuracy: 9.150\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.545 (avg: 0.540)\tLoss: 4.9334 (avg: 5.0257)\tTop1: 4.688 (avg: 2.375)\tTop5: 10.938 (avg: 8.875)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.542 (avg: 0.546)\tLoss: 5.0746 (avg: 5.0533)\tTop1: 4.688 (avg: 2.219)\tTop5: 7.812 (avg: 8.562)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.539 (avg: 0.548)\tLoss: 5.0877 (avg: 5.0442)\tTop1: 4.688 (avg: 2.458)\tTop5: 10.938 (avg: 9.000)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.551 (avg: 0.549)\tLoss: 5.0903 (avg: 5.0422)\tTop1: 1.562 (avg: 2.484)\tTop5: 7.812 (avg: 9.250)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.555 (avg: 0.549)\tLoss: 4.8673 (avg: 5.0392)\tTop1: 3.125 (avg: 2.525)\tTop5: 12.500 (avg: 9.562)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7033\tTop 1 accuracy: 3.450\tTop 5 accuracy: 11.400\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.546 (avg: 0.542)\tLoss: 5.2686 (avg: 4.9817)\tTop1: 0.000 (avg: 2.500)\tTop5: 4.688 (avg: 10.812)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.553 (avg: 0.548)\tLoss: 5.0383 (avg: 5.0046)\tTop1: 0.000 (avg: 2.312)\tTop5: 7.812 (avg: 9.938)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.546 (avg: 0.550)\tLoss: 4.9431 (avg: 4.9963)\tTop1: 3.125 (avg: 2.250)\tTop5: 10.938 (avg: 9.917)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.546 (avg: 0.551)\tLoss: 5.0971 (avg: 4.9955)\tTop1: 4.688 (avg: 2.438)\tTop5: 14.062 (avg: 10.016)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.550 (avg: 0.552)\tLoss: 4.8108 (avg: 4.9895)\tTop1: 4.688 (avg: 2.650)\tTop5: 14.062 (avg: 10.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5455\tTop 1 accuracy: 3.550\tTop 5 accuracy: 13.150\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.553 (avg: 0.543)\tLoss: 5.1868 (avg: 4.8879)\tTop1: 3.125 (avg: 2.625)\tTop5: 7.812 (avg: 11.562)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.545 (avg: 0.550)\tLoss: 4.9711 (avg: 4.9219)\tTop1: 0.000 (avg: 3.062)\tTop5: 6.250 (avg: 11.406)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.548 (avg: 0.551)\tLoss: 4.8861 (avg: 4.9178)\tTop1: 6.250 (avg: 3.208)\tTop5: 17.188 (avg: 11.688)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.552 (avg: 0.553)\tLoss: 4.8417 (avg: 4.9237)\tTop1: 0.000 (avg: 3.047)\tTop5: 14.062 (avg: 11.578)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.548 (avg: 0.554)\tLoss: 4.8893 (avg: 4.9194)\tTop1: 1.562 (avg: 2.838)\tTop5: 12.500 (avg: 11.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8646\tTop 1 accuracy: 2.400\tTop 5 accuracy: 11.550\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.542 (avg: 0.540)\tLoss: 4.8782 (avg: 4.8483)\tTop1: 4.688 (avg: 4.125)\tTop5: 12.500 (avg: 13.812)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.544 (avg: 0.547)\tLoss: 4.8506 (avg: 4.8474)\tTop1: 3.125 (avg: 3.594)\tTop5: 12.500 (avg: 13.312)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.542 (avg: 0.549)\tLoss: 4.8524 (avg: 4.8685)\tTop1: 3.125 (avg: 3.438)\tTop5: 10.938 (avg: 12.771)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.544 (avg: 0.550)\tLoss: 4.7486 (avg: 4.8743)\tTop1: 3.125 (avg: 3.250)\tTop5: 6.250 (avg: 12.734)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.546 (avg: 0.551)\tLoss: 4.5732 (avg: 4.8640)\tTop1: 6.250 (avg: 3.350)\tTop5: 23.438 (avg: 13.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5850\tTop 1 accuracy: 3.650\tTop 5 accuracy: 13.900\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.549 (avg: 0.542)\tLoss: 4.7220 (avg: 4.7830)\tTop1: 3.125 (avg: 3.562)\tTop5: 12.500 (avg: 14.562)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.542 (avg: 0.548)\tLoss: 4.8404 (avg: 4.8044)\tTop1: 1.562 (avg: 3.375)\tTop5: 7.812 (avg: 13.969)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.547 (avg: 0.549)\tLoss: 4.6561 (avg: 4.7996)\tTop1: 4.688 (avg: 3.750)\tTop5: 17.188 (avg: 14.438)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.548 (avg: 0.551)\tLoss: 4.8548 (avg: 4.7937)\tTop1: 4.688 (avg: 3.844)\tTop5: 12.500 (avg: 14.688)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.549 (avg: 0.552)\tLoss: 4.8303 (avg: 4.7960)\tTop1: 0.000 (avg: 3.863)\tTop5: 9.375 (avg: 14.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5066\tTop 1 accuracy: 3.950\tTop 5 accuracy: 15.800\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.545 (avg: 0.539)\tLoss: 4.7673 (avg: 4.7387)\tTop1: 4.688 (avg: 3.688)\tTop5: 14.062 (avg: 15.500)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.538 (avg: 0.546)\tLoss: 4.8179 (avg: 4.7566)\tTop1: 1.562 (avg: 3.750)\tTop5: 10.938 (avg: 15.562)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.549 (avg: 0.548)\tLoss: 4.7816 (avg: 4.7454)\tTop1: 1.562 (avg: 4.271)\tTop5: 14.062 (avg: 15.854)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.546 (avg: 0.549)\tLoss: 4.8228 (avg: 4.7455)\tTop1: 3.125 (avg: 4.297)\tTop5: 14.062 (avg: 15.484)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.544 (avg: 0.550)\tLoss: 4.9274 (avg: 4.7373)\tTop1: 4.688 (avg: 4.363)\tTop5: 10.938 (avg: 15.563)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4922\tTop 1 accuracy: 4.500\tTop 5 accuracy: 16.700\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.544 (avg: 0.541)\tLoss: 4.5298 (avg: 4.6420)\tTop1: 6.250 (avg: 5.062)\tTop5: 20.312 (avg: 18.000)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.547 (avg: 0.546)\tLoss: 4.8601 (avg: 4.6548)\tTop1: 3.125 (avg: 5.375)\tTop5: 14.062 (avg: 17.469)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.550 (avg: 0.549)\tLoss: 4.5883 (avg: 4.6673)\tTop1: 4.688 (avg: 5.125)\tTop5: 20.312 (avg: 17.042)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.546 (avg: 0.550)\tLoss: 4.6769 (avg: 4.6631)\tTop1: 3.125 (avg: 5.203)\tTop5: 15.625 (avg: 17.312)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.548 (avg: 0.551)\tLoss: 4.5953 (avg: 4.6724)\tTop1: 7.812 (avg: 5.138)\tTop5: 21.875 (avg: 16.950)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3631\tTop 1 accuracy: 4.350\tTop 5 accuracy: 18.100\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.548 (avg: 0.543)\tLoss: 4.5061 (avg: 4.6853)\tTop1: 3.125 (avg: 4.125)\tTop5: 21.875 (avg: 16.938)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.550 (avg: 0.549)\tLoss: 4.6284 (avg: 4.6670)\tTop1: 4.688 (avg: 4.375)\tTop5: 15.625 (avg: 16.750)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.549 (avg: 0.552)\tLoss: 4.5874 (avg: 4.6483)\tTop1: 6.250 (avg: 4.896)\tTop5: 17.188 (avg: 17.542)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.552 (avg: 0.553)\tLoss: 4.6948 (avg: 4.6553)\tTop1: 3.125 (avg: 4.859)\tTop5: 14.062 (avg: 17.453)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.551 (avg: 0.554)\tLoss: 4.8305 (avg: 4.6551)\tTop1: 3.125 (avg: 4.900)\tTop5: 7.812 (avg: 17.312)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2125\tTop 1 accuracy: 5.150\tTop 5 accuracy: 18.550\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.540 (avg: 0.538)\tLoss: 4.7902 (avg: 4.5037)\tTop1: 0.000 (avg: 5.688)\tTop5: 10.938 (avg: 20.500)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.545 (avg: 0.544)\tLoss: 4.8342 (avg: 4.5302)\tTop1: 1.562 (avg: 6.062)\tTop5: 9.375 (avg: 19.875)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.545 (avg: 0.547)\tLoss: 4.5115 (avg: 4.5558)\tTop1: 6.250 (avg: 6.062)\tTop5: 28.125 (avg: 19.604)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.544 (avg: 0.548)\tLoss: 4.6384 (avg: 4.5575)\tTop1: 6.250 (avg: 5.984)\tTop5: 15.625 (avg: 19.500)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.552 (avg: 0.549)\tLoss: 4.6899 (avg: 4.5606)\tTop1: 3.125 (avg: 5.925)\tTop5: 18.750 (avg: 19.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5285\tTop 1 accuracy: 5.000\tTop 5 accuracy: 16.900\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.549 (avg: 0.542)\tLoss: 4.6259 (avg: 4.5904)\tTop1: 4.688 (avg: 5.875)\tTop5: 18.750 (avg: 18.938)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.550 (avg: 0.548)\tLoss: 4.5596 (avg: 4.5263)\tTop1: 6.250 (avg: 6.438)\tTop5: 17.188 (avg: 20.281)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.547 (avg: 0.551)\tLoss: 4.5105 (avg: 4.5110)\tTop1: 4.688 (avg: 6.479)\tTop5: 23.438 (avg: 21.062)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.551 (avg: 0.552)\tLoss: 4.5922 (avg: 4.5147)\tTop1: 9.375 (avg: 6.547)\tTop5: 23.438 (avg: 21.266)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.549 (avg: 0.552)\tLoss: 4.4003 (avg: 4.5152)\tTop1: 6.250 (avg: 6.438)\tTop5: 21.875 (avg: 21.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1192\tTop 1 accuracy: 5.950\tTop 5 accuracy: 19.300\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.552 (avg: 0.542)\tLoss: 4.4405 (avg: 4.4599)\tTop1: 7.812 (avg: 7.250)\tTop5: 21.875 (avg: 24.125)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.548 (avg: 0.549)\tLoss: 4.5744 (avg: 4.4540)\tTop1: 7.812 (avg: 6.812)\tTop5: 21.875 (avg: 23.438)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.547 (avg: 0.551)\tLoss: 4.4442 (avg: 4.4564)\tTop1: 10.938 (avg: 7.125)\tTop5: 20.312 (avg: 22.625)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.552 (avg: 0.553)\tLoss: 4.6296 (avg: 4.4491)\tTop1: 6.250 (avg: 6.906)\tTop5: 17.188 (avg: 22.672)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.552 (avg: 0.554)\tLoss: 4.2530 (avg: 4.4475)\tTop1: 10.938 (avg: 6.738)\tTop5: 29.688 (avg: 22.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1960\tTop 1 accuracy: 5.850\tTop 5 accuracy: 21.200\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.546 (avg: 0.540)\tLoss: 4.4604 (avg: 4.3395)\tTop1: 7.812 (avg: 8.938)\tTop5: 18.750 (avg: 24.812)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.546 (avg: 0.547)\tLoss: 4.3306 (avg: 4.3708)\tTop1: 9.375 (avg: 8.469)\tTop5: 23.438 (avg: 25.000)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.549 (avg: 0.549)\tLoss: 4.4383 (avg: 4.3830)\tTop1: 7.812 (avg: 7.750)\tTop5: 18.750 (avg: 24.396)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.547 (avg: 0.550)\tLoss: 4.3859 (avg: 4.3993)\tTop1: 7.812 (avg: 7.594)\tTop5: 21.875 (avg: 24.094)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.551 (avg: 0.551)\tLoss: 4.7339 (avg: 4.3953)\tTop1: 7.812 (avg: 7.475)\tTop5: 23.438 (avg: 24.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0483\tTop 1 accuracy: 6.900\tTop 5 accuracy: 22.050\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.548 (avg: 0.539)\tLoss: 4.4174 (avg: 4.3790)\tTop1: 7.812 (avg: 7.562)\tTop5: 20.312 (avg: 23.625)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.547 (avg: 0.546)\tLoss: 4.0708 (avg: 4.3586)\tTop1: 9.375 (avg: 7.531)\tTop5: 26.562 (avg: 23.812)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.548 (avg: 0.549)\tLoss: 4.3908 (avg: 4.3484)\tTop1: 6.250 (avg: 7.604)\tTop5: 23.438 (avg: 24.458)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.550 (avg: 0.550)\tLoss: 4.5500 (avg: 4.3531)\tTop1: 1.562 (avg: 7.719)\tTop5: 18.750 (avg: 24.375)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.547 (avg: 0.551)\tLoss: 4.3657 (avg: 4.3444)\tTop1: 12.500 (avg: 7.650)\tTop5: 26.562 (avg: 24.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7824\tTop 1 accuracy: 7.250\tTop 5 accuracy: 23.550\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.548 (avg: 0.539)\tLoss: 4.3131 (avg: 4.1885)\tTop1: 18.750 (avg: 9.250)\tTop5: 23.438 (avg: 28.875)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.543 (avg: 0.545)\tLoss: 4.2005 (avg: 4.2453)\tTop1: 10.938 (avg: 8.594)\tTop5: 29.688 (avg: 26.906)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.546 (avg: 0.547)\tLoss: 4.0642 (avg: 4.2362)\tTop1: 7.812 (avg: 8.833)\tTop5: 28.125 (avg: 27.208)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.546 (avg: 0.548)\tLoss: 4.1904 (avg: 4.2647)\tTop1: 3.125 (avg: 8.547)\tTop5: 15.625 (avg: 26.516)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.546 (avg: 0.549)\tLoss: 4.4243 (avg: 4.2616)\tTop1: 9.375 (avg: 8.562)\tTop5: 29.688 (avg: 26.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9208\tTop 1 accuracy: 8.550\tTop 5 accuracy: 24.350\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.547 (avg: 0.540)\tLoss: 3.9881 (avg: 4.1861)\tTop1: 17.188 (avg: 9.438)\tTop5: 28.125 (avg: 29.312)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.545 (avg: 0.546)\tLoss: 4.1758 (avg: 4.1794)\tTop1: 10.938 (avg: 9.875)\tTop5: 23.438 (avg: 28.938)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.550 (avg: 0.549)\tLoss: 4.3903 (avg: 4.2203)\tTop1: 10.938 (avg: 9.354)\tTop5: 29.688 (avg: 28.208)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.547 (avg: 0.550)\tLoss: 4.1393 (avg: 4.1990)\tTop1: 10.938 (avg: 9.500)\tTop5: 28.125 (avg: 28.578)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.549 (avg: 0.550)\tLoss: 3.7840 (avg: 4.2072)\tTop1: 17.188 (avg: 9.575)\tTop5: 46.875 (avg: 28.563)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7596\tTop 1 accuracy: 7.000\tTop 5 accuracy: 23.750\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.553 (avg: 0.542)\tLoss: 4.1984 (avg: 4.1423)\tTop1: 9.375 (avg: 10.188)\tTop5: 34.375 (avg: 28.438)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.548 (avg: 0.549)\tLoss: 4.1457 (avg: 4.1706)\tTop1: 6.250 (avg: 9.625)\tTop5: 29.688 (avg: 28.438)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.550 (avg: 0.551)\tLoss: 4.2941 (avg: 4.1449)\tTop1: 7.812 (avg: 10.104)\tTop5: 18.750 (avg: 29.188)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.547 (avg: 0.552)\tLoss: 4.2697 (avg: 4.1666)\tTop1: 9.375 (avg: 10.141)\tTop5: 28.125 (avg: 28.750)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.542 (avg: 0.553)\tLoss: 3.8955 (avg: 4.1756)\tTop1: 15.625 (avg: 9.888)\tTop5: 32.812 (avg: 28.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9422\tTop 1 accuracy: 8.350\tTop 5 accuracy: 25.600\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.546 (avg: 0.538)\tLoss: 4.1210 (avg: 4.0739)\tTop1: 4.688 (avg: 12.000)\tTop5: 29.688 (avg: 31.562)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.543 (avg: 0.545)\tLoss: 4.0734 (avg: 4.1071)\tTop1: 12.500 (avg: 10.656)\tTop5: 34.375 (avg: 30.344)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.547 (avg: 0.547)\tLoss: 3.9432 (avg: 4.1188)\tTop1: 12.500 (avg: 10.688)\tTop5: 32.812 (avg: 30.188)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.549 (avg: 0.549)\tLoss: 3.8513 (avg: 4.1197)\tTop1: 17.188 (avg: 10.859)\tTop5: 40.625 (avg: 30.203)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.547 (avg: 0.550)\tLoss: 4.1899 (avg: 4.1167)\tTop1: 6.250 (avg: 11.125)\tTop5: 23.438 (avg: 30.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8005\tTop 1 accuracy: 9.400\tTop 5 accuracy: 26.850\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.546 (avg: 0.541)\tLoss: 4.2663 (avg: 4.0202)\tTop1: 6.250 (avg: 12.312)\tTop5: 20.312 (avg: 33.250)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.540 (avg: 0.548)\tLoss: 3.8305 (avg: 4.0155)\tTop1: 15.625 (avg: 12.562)\tTop5: 42.188 (avg: 33.094)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.549 (avg: 0.551)\tLoss: 3.8984 (avg: 4.0223)\tTop1: 14.062 (avg: 12.125)\tTop5: 32.812 (avg: 33.438)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.549 (avg: 0.551)\tLoss: 4.1513 (avg: 4.0492)\tTop1: 9.375 (avg: 12.000)\tTop5: 29.688 (avg: 32.922)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.549 (avg: 0.552)\tLoss: 4.2263 (avg: 4.0647)\tTop1: 12.500 (avg: 11.688)\tTop5: 26.562 (avg: 32.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7257\tTop 1 accuracy: 10.200\tTop 5 accuracy: 27.100\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.550 (avg: 0.543)\tLoss: 3.9507 (avg: 3.8410)\tTop1: 6.250 (avg: 13.438)\tTop5: 37.500 (avg: 37.062)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.552 (avg: 0.550)\tLoss: 4.2823 (avg: 3.9262)\tTop1: 10.938 (avg: 12.781)\tTop5: 29.688 (avg: 35.438)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.553 (avg: 0.552)\tLoss: 3.8201 (avg: 3.9717)\tTop1: 17.188 (avg: 12.333)\tTop5: 32.812 (avg: 33.604)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.550 (avg: 0.553)\tLoss: 4.4409 (avg: 3.9903)\tTop1: 10.938 (avg: 12.328)\tTop5: 23.438 (avg: 33.328)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.553 (avg: 0.554)\tLoss: 4.0129 (avg: 4.0032)\tTop1: 9.375 (avg: 12.338)\tTop5: 34.375 (avg: 33.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3967\tTop 1 accuracy: 9.900\tTop 5 accuracy: 28.950\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.549 (avg: 0.540)\tLoss: 3.7815 (avg: 3.9551)\tTop1: 14.062 (avg: 12.500)\tTop5: 35.938 (avg: 34.562)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.549 (avg: 0.546)\tLoss: 3.7995 (avg: 3.9176)\tTop1: 14.062 (avg: 13.062)\tTop5: 43.750 (avg: 35.812)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.542 (avg: 0.549)\tLoss: 3.5939 (avg: 3.9492)\tTop1: 15.625 (avg: 12.896)\tTop5: 43.750 (avg: 34.833)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.546 (avg: 0.550)\tLoss: 3.7262 (avg: 3.9478)\tTop1: 15.625 (avg: 13.078)\tTop5: 39.062 (avg: 34.984)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.545 (avg: 0.550)\tLoss: 3.9424 (avg: 3.9513)\tTop1: 14.062 (avg: 13.013)\tTop5: 35.938 (avg: 34.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7501\tTop 1 accuracy: 9.100\tTop 5 accuracy: 26.500\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.546 (avg: 0.541)\tLoss: 3.6394 (avg: 3.8667)\tTop1: 20.312 (avg: 14.312)\tTop5: 43.750 (avg: 37.250)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.549 (avg: 0.548)\tLoss: 3.8146 (avg: 3.8602)\tTop1: 14.062 (avg: 14.531)\tTop5: 39.062 (avg: 37.156)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.548 (avg: 0.550)\tLoss: 3.7177 (avg: 3.8643)\tTop1: 18.750 (avg: 14.750)\tTop5: 43.750 (avg: 37.167)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.548 (avg: 0.552)\tLoss: 3.8473 (avg: 3.8700)\tTop1: 10.938 (avg: 14.484)\tTop5: 34.375 (avg: 37.094)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.545 (avg: 0.552)\tLoss: 3.8804 (avg: 3.8832)\tTop1: 14.062 (avg: 14.138)\tTop5: 37.500 (avg: 36.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8548\tTop 1 accuracy: 10.350\tTop 5 accuracy: 29.650\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.543 (avg: 0.539)\tLoss: 3.4640 (avg: 3.7594)\tTop1: 20.312 (avg: 16.250)\tTop5: 50.000 (avg: 40.500)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.547 (avg: 0.545)\tLoss: 3.6586 (avg: 3.8039)\tTop1: 17.188 (avg: 15.625)\tTop5: 43.750 (avg: 39.500)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.547 (avg: 0.547)\tLoss: 3.9772 (avg: 3.8262)\tTop1: 18.750 (avg: 14.833)\tTop5: 37.500 (avg: 38.604)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.546 (avg: 0.548)\tLoss: 3.8469 (avg: 3.8567)\tTop1: 18.750 (avg: 14.594)\tTop5: 31.250 (avg: 37.688)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.540 (avg: 0.549)\tLoss: 4.0864 (avg: 3.8561)\tTop1: 10.938 (avg: 14.838)\tTop5: 25.000 (avg: 37.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9801\tTop 1 accuracy: 11.500\tTop 5 accuracy: 29.800\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.547 (avg: 0.540)\tLoss: 3.4168 (avg: 3.7271)\tTop1: 15.625 (avg: 15.438)\tTop5: 53.125 (avg: 39.812)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.546 (avg: 0.547)\tLoss: 3.7334 (avg: 3.7735)\tTop1: 12.500 (avg: 14.312)\tTop5: 35.938 (avg: 38.344)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.550 (avg: 0.549)\tLoss: 3.5817 (avg: 3.7685)\tTop1: 21.875 (avg: 14.646)\tTop5: 48.438 (avg: 38.771)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.546 (avg: 0.550)\tLoss: 3.4936 (avg: 3.7589)\tTop1: 23.438 (avg: 14.797)\tTop5: 42.188 (avg: 39.297)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.539 (avg: 0.551)\tLoss: 3.5805 (avg: 3.7730)\tTop1: 21.875 (avg: 15.038)\tTop5: 45.312 (avg: 38.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6753\tTop 1 accuracy: 11.050\tTop 5 accuracy: 30.400\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.548 (avg: 0.543)\tLoss: 3.9865 (avg: 3.6760)\tTop1: 10.938 (avg: 17.312)\tTop5: 35.938 (avg: 42.625)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.547 (avg: 0.550)\tLoss: 3.7803 (avg: 3.7156)\tTop1: 17.188 (avg: 16.531)\tTop5: 40.625 (avg: 41.500)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.549 (avg: 0.552)\tLoss: 4.0966 (avg: 3.7451)\tTop1: 9.375 (avg: 16.083)\tTop5: 26.562 (avg: 40.104)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.546 (avg: 0.553)\tLoss: 3.6980 (avg: 3.7461)\tTop1: 17.188 (avg: 16.047)\tTop5: 40.625 (avg: 39.750)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.554 (avg: 0.553)\tLoss: 3.9633 (avg: 3.7336)\tTop1: 10.938 (avg: 16.138)\tTop5: 32.812 (avg: 40.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6108\tTop 1 accuracy: 10.150\tTop 5 accuracy: 27.600\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.546 (avg: 0.539)\tLoss: 3.4935 (avg: 3.5055)\tTop1: 23.438 (avg: 19.562)\tTop5: 42.188 (avg: 43.938)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.546 (avg: 0.546)\tLoss: 3.6106 (avg: 3.5943)\tTop1: 20.312 (avg: 18.344)\tTop5: 46.875 (avg: 43.000)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.544 (avg: 0.548)\tLoss: 3.7175 (avg: 3.6328)\tTop1: 12.500 (avg: 17.688)\tTop5: 34.375 (avg: 42.188)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.544 (avg: 0.549)\tLoss: 3.5741 (avg: 3.6636)\tTop1: 21.875 (avg: 17.328)\tTop5: 39.062 (avg: 41.547)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.543 (avg: 0.550)\tLoss: 3.8659 (avg: 3.6618)\tTop1: 14.062 (avg: 17.312)\tTop5: 35.938 (avg: 41.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1614\tTop 1 accuracy: 11.800\tTop 5 accuracy: 30.950\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.544 (avg: 0.542)\tLoss: 3.1199 (avg: 3.3941)\tTop1: 28.125 (avg: 22.188)\tTop5: 62.500 (avg: 49.062)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.549 (avg: 0.548)\tLoss: 3.3556 (avg: 3.3263)\tTop1: 23.438 (avg: 23.719)\tTop5: 40.625 (avg: 49.531)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.548 (avg: 0.550)\tLoss: 3.2140 (avg: 3.2667)\tTop1: 25.000 (avg: 24.333)\tTop5: 45.312 (avg: 50.896)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.552 (avg: 0.551)\tLoss: 2.8306 (avg: 3.2257)\tTop1: 26.562 (avg: 25.281)\tTop5: 59.375 (avg: 52.109)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.549 (avg: 0.552)\tLoss: 3.1175 (avg: 3.1970)\tTop1: 25.000 (avg: 25.513)\tTop5: 56.250 (avg: 52.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3531\tTop 1 accuracy: 15.600\tTop 5 accuracy: 36.250\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.549 (avg: 0.543)\tLoss: 3.0814 (avg: 2.9980)\tTop1: 18.750 (avg: 27.875)\tTop5: 50.000 (avg: 56.938)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.552 (avg: 0.550)\tLoss: 2.9400 (avg: 3.0289)\tTop1: 31.250 (avg: 28.312)\tTop5: 57.812 (avg: 57.094)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.551 (avg: 0.552)\tLoss: 3.4723 (avg: 3.0485)\tTop1: 20.312 (avg: 28.562)\tTop5: 39.062 (avg: 56.354)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.552 (avg: 0.554)\tLoss: 3.1657 (avg: 3.0552)\tTop1: 26.562 (avg: 28.797)\tTop5: 48.438 (avg: 56.281)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.553 (avg: 0.555)\tLoss: 3.1611 (avg: 3.0497)\tTop1: 28.125 (avg: 28.750)\tTop5: 50.000 (avg: 56.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3597\tTop 1 accuracy: 15.650\tTop 5 accuracy: 36.100\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.545 (avg: 0.541)\tLoss: 2.9700 (avg: 2.9259)\tTop1: 28.125 (avg: 31.125)\tTop5: 54.688 (avg: 59.812)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.551 (avg: 0.549)\tLoss: 2.8122 (avg: 2.9481)\tTop1: 25.000 (avg: 30.719)\tTop5: 60.938 (avg: 58.625)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.555 (avg: 0.550)\tLoss: 2.6637 (avg: 2.9578)\tTop1: 39.062 (avg: 30.396)\tTop5: 70.312 (avg: 58.479)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.548 (avg: 0.551)\tLoss: 2.6340 (avg: 2.9776)\tTop1: 34.375 (avg: 29.953)\tTop5: 64.062 (avg: 57.938)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.551 (avg: 0.552)\tLoss: 3.0798 (avg: 2.9937)\tTop1: 29.688 (avg: 29.688)\tTop5: 48.438 (avg: 57.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3510\tTop 1 accuracy: 15.000\tTop 5 accuracy: 36.350\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.550 (avg: 0.544)\tLoss: 2.8026 (avg: 2.9408)\tTop1: 34.375 (avg: 30.562)\tTop5: 65.625 (avg: 59.312)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.550 (avg: 0.550)\tLoss: 2.8450 (avg: 2.9418)\tTop1: 31.250 (avg: 30.875)\tTop5: 60.938 (avg: 59.219)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.556 (avg: 0.552)\tLoss: 2.6974 (avg: 2.9270)\tTop1: 29.688 (avg: 30.792)\tTop5: 67.188 (avg: 59.479)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.547 (avg: 0.553)\tLoss: 3.0482 (avg: 2.9321)\tTop1: 26.562 (avg: 30.781)\tTop5: 50.000 (avg: 58.922)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.549 (avg: 0.553)\tLoss: 2.8345 (avg: 2.9332)\tTop1: 35.938 (avg: 30.900)\tTop5: 59.375 (avg: 58.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3149\tTop 1 accuracy: 16.400\tTop 5 accuracy: 37.000\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.545 (avg: 0.538)\tLoss: 2.9016 (avg: 2.8517)\tTop1: 35.938 (avg: 32.312)\tTop5: 62.500 (avg: 60.812)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.543 (avg: 0.545)\tLoss: 2.9593 (avg: 2.8972)\tTop1: 28.125 (avg: 32.031)\tTop5: 57.812 (avg: 60.000)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.550 (avg: 0.547)\tLoss: 3.4043 (avg: 2.8718)\tTop1: 26.562 (avg: 32.708)\tTop5: 51.562 (avg: 59.958)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.547 (avg: 0.549)\tLoss: 2.9487 (avg: 2.8858)\tTop1: 28.125 (avg: 32.281)\tTop5: 53.125 (avg: 59.547)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.544 (avg: 0.549)\tLoss: 2.9215 (avg: 2.9014)\tTop1: 29.688 (avg: 31.888)\tTop5: 59.375 (avg: 58.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4162\tTop 1 accuracy: 16.000\tTop 5 accuracy: 37.400\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.544 (avg: 0.540)\tLoss: 2.9128 (avg: 2.7239)\tTop1: 39.062 (avg: 36.250)\tTop5: 57.812 (avg: 62.625)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.549 (avg: 0.547)\tLoss: 2.7637 (avg: 2.7739)\tTop1: 32.812 (avg: 33.781)\tTop5: 56.250 (avg: 61.281)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.549 (avg: 0.550)\tLoss: 3.0950 (avg: 2.8158)\tTop1: 28.125 (avg: 32.979)\tTop5: 56.250 (avg: 60.771)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.551 (avg: 0.551)\tLoss: 3.1890 (avg: 2.8370)\tTop1: 26.562 (avg: 32.406)\tTop5: 53.125 (avg: 60.516)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.545 (avg: 0.551)\tLoss: 2.5970 (avg: 2.8522)\tTop1: 34.375 (avg: 32.113)\tTop5: 67.188 (avg: 59.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5859\tTop 1 accuracy: 15.700\tTop 5 accuracy: 36.550\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.546 (avg: 0.542)\tLoss: 2.9059 (avg: 2.8030)\tTop1: 29.688 (avg: 32.812)\tTop5: 54.688 (avg: 60.750)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.550 (avg: 0.549)\tLoss: 3.0186 (avg: 2.7705)\tTop1: 32.812 (avg: 33.594)\tTop5: 59.375 (avg: 61.812)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.550 (avg: 0.551)\tLoss: 2.4915 (avg: 2.8003)\tTop1: 35.938 (avg: 32.875)\tTop5: 65.625 (avg: 61.146)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.554 (avg: 0.552)\tLoss: 2.4644 (avg: 2.8029)\tTop1: 35.938 (avg: 32.812)\tTop5: 71.875 (avg: 61.344)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.546 (avg: 0.553)\tLoss: 2.3824 (avg: 2.8206)\tTop1: 37.500 (avg: 32.463)\tTop5: 62.500 (avg: 60.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3969\tTop 1 accuracy: 16.600\tTop 5 accuracy: 37.700\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.544 (avg: 0.539)\tLoss: 2.6867 (avg: 2.7509)\tTop1: 34.375 (avg: 35.125)\tTop5: 68.750 (avg: 62.688)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.542 (avg: 0.545)\tLoss: 2.7766 (avg: 2.7637)\tTop1: 28.125 (avg: 34.688)\tTop5: 56.250 (avg: 61.812)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.551 (avg: 0.548)\tLoss: 2.8687 (avg: 2.7751)\tTop1: 29.688 (avg: 33.896)\tTop5: 60.938 (avg: 61.562)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.547 (avg: 0.549)\tLoss: 2.7322 (avg: 2.7781)\tTop1: 42.188 (avg: 33.578)\tTop5: 60.938 (avg: 61.656)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.544 (avg: 0.549)\tLoss: 3.0110 (avg: 2.7908)\tTop1: 32.812 (avg: 33.388)\tTop5: 59.375 (avg: 61.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7116\tTop 1 accuracy: 15.650\tTop 5 accuracy: 36.800\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.547 (avg: 0.542)\tLoss: 2.7233 (avg: 2.6652)\tTop1: 39.062 (avg: 37.000)\tTop5: 65.625 (avg: 64.500)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.547 (avg: 0.548)\tLoss: 3.0641 (avg: 2.6634)\tTop1: 25.000 (avg: 36.406)\tTop5: 59.375 (avg: 64.281)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.549 (avg: 0.551)\tLoss: 2.4507 (avg: 2.6933)\tTop1: 39.062 (avg: 35.938)\tTop5: 73.438 (avg: 63.188)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.543 (avg: 0.552)\tLoss: 2.7828 (avg: 2.7122)\tTop1: 34.375 (avg: 35.578)\tTop5: 60.938 (avg: 63.031)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.550 (avg: 0.553)\tLoss: 3.3711 (avg: 2.7424)\tTop1: 25.000 (avg: 34.812)\tTop5: 54.688 (avg: 62.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5828\tTop 1 accuracy: 15.600\tTop 5 accuracy: 38.200\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.550 (avg: 0.544)\tLoss: 2.3060 (avg: 2.6410)\tTop1: 39.062 (avg: 35.500)\tTop5: 73.438 (avg: 65.562)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.558 (avg: 0.551)\tLoss: 2.3859 (avg: 2.6653)\tTop1: 40.625 (avg: 36.000)\tTop5: 68.750 (avg: 64.562)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.552 (avg: 0.553)\tLoss: 3.3743 (avg: 2.6726)\tTop1: 25.000 (avg: 35.583)\tTop5: 48.438 (avg: 64.312)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.554 (avg: 0.554)\tLoss: 3.0759 (avg: 2.6962)\tTop1: 28.125 (avg: 34.844)\tTop5: 59.375 (avg: 64.109)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.551 (avg: 0.555)\tLoss: 2.7928 (avg: 2.7076)\tTop1: 35.938 (avg: 34.325)\tTop5: 60.938 (avg: 63.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6703\tTop 1 accuracy: 16.250\tTop 5 accuracy: 37.150\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.540 (avg: 0.540)\tLoss: 2.4383 (avg: 2.6181)\tTop1: 45.312 (avg: 37.688)\tTop5: 73.438 (avg: 65.062)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.551 (avg: 0.546)\tLoss: 2.5205 (avg: 2.5915)\tTop1: 34.375 (avg: 38.281)\tTop5: 65.625 (avg: 65.625)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.552 (avg: 0.549)\tLoss: 2.2484 (avg: 2.6494)\tTop1: 46.875 (avg: 36.875)\tTop5: 71.875 (avg: 64.354)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.551 (avg: 0.550)\tLoss: 2.3694 (avg: 2.6469)\tTop1: 42.188 (avg: 36.922)\tTop5: 71.875 (avg: 64.297)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.548 (avg: 0.551)\tLoss: 3.1063 (avg: 2.6650)\tTop1: 28.125 (avg: 36.338)\tTop5: 53.125 (avg: 64.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6397\tTop 1 accuracy: 16.150\tTop 5 accuracy: 35.400\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.548 (avg: 0.542)\tLoss: 2.6452 (avg: 2.5208)\tTop1: 32.812 (avg: 39.250)\tTop5: 67.188 (avg: 67.312)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.547 (avg: 0.549)\tLoss: 2.4192 (avg: 2.5369)\tTop1: 40.625 (avg: 38.625)\tTop5: 62.500 (avg: 66.469)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.551 (avg: 0.551)\tLoss: 2.8408 (avg: 2.5868)\tTop1: 32.812 (avg: 37.583)\tTop5: 64.062 (avg: 65.667)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.540 (avg: 0.552)\tLoss: 2.7624 (avg: 2.6138)\tTop1: 39.062 (avg: 37.109)\tTop5: 62.500 (avg: 65.062)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.550 (avg: 0.553)\tLoss: 2.4561 (avg: 2.6228)\tTop1: 37.500 (avg: 36.625)\tTop5: 68.750 (avg: 64.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5759\tTop 1 accuracy: 15.550\tTop 5 accuracy: 36.800\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.547 (avg: 0.540)\tLoss: 2.1988 (avg: 2.4379)\tTop1: 45.312 (avg: 39.500)\tTop5: 73.438 (avg: 68.312)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.547 (avg: 0.547)\tLoss: 2.9798 (avg: 2.5221)\tTop1: 25.000 (avg: 38.000)\tTop5: 59.375 (avg: 66.688)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.543 (avg: 0.549)\tLoss: 2.4963 (avg: 2.5460)\tTop1: 34.375 (avg: 37.583)\tTop5: 73.438 (avg: 66.729)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.546 (avg: 0.550)\tLoss: 2.6421 (avg: 2.5732)\tTop1: 34.375 (avg: 37.281)\tTop5: 71.875 (avg: 66.047)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.548 (avg: 0.551)\tLoss: 2.7666 (avg: 2.5885)\tTop1: 39.062 (avg: 36.688)\tTop5: 60.938 (avg: 65.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8289\tTop 1 accuracy: 16.900\tTop 5 accuracy: 35.700\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.552 (avg: 0.541)\tLoss: 2.7818 (avg: 2.4467)\tTop1: 34.375 (avg: 39.438)\tTop5: 60.938 (avg: 69.062)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.548 (avg: 0.548)\tLoss: 2.5337 (avg: 2.5166)\tTop1: 35.938 (avg: 38.281)\tTop5: 64.062 (avg: 67.281)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.549 (avg: 0.550)\tLoss: 2.7012 (avg: 2.5408)\tTop1: 34.375 (avg: 37.812)\tTop5: 67.188 (avg: 66.792)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.551 (avg: 0.552)\tLoss: 2.5678 (avg: 2.5398)\tTop1: 40.625 (avg: 37.734)\tTop5: 59.375 (avg: 66.516)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.550 (avg: 0.552)\tLoss: 2.9005 (avg: 2.5543)\tTop1: 32.812 (avg: 37.675)\tTop5: 60.938 (avg: 66.325)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4214\tTop 1 accuracy: 16.200\tTop 5 accuracy: 36.850\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.549 (avg: 0.540)\tLoss: 2.1729 (avg: 2.4057)\tTop1: 53.125 (avg: 41.062)\tTop5: 68.750 (avg: 69.875)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.550 (avg: 0.549)\tLoss: 1.8382 (avg: 2.4850)\tTop1: 51.562 (avg: 39.938)\tTop5: 81.250 (avg: 68.438)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.547 (avg: 0.552)\tLoss: 2.3299 (avg: 2.4815)\tTop1: 45.312 (avg: 39.604)\tTop5: 70.312 (avg: 68.542)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.547 (avg: 0.553)\tLoss: 2.7340 (avg: 2.4926)\tTop1: 28.125 (avg: 39.047)\tTop5: 65.625 (avg: 68.172)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.538 (avg: 0.554)\tLoss: 2.7309 (avg: 2.5042)\tTop1: 40.625 (avg: 39.038)\tTop5: 67.188 (avg: 67.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8912\tTop 1 accuracy: 15.950\tTop 5 accuracy: 37.100\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.542 (avg: 0.540)\tLoss: 2.8523 (avg: 2.3829)\tTop1: 37.500 (avg: 41.938)\tTop5: 59.375 (avg: 69.938)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.547 (avg: 0.547)\tLoss: 2.1056 (avg: 2.3682)\tTop1: 50.000 (avg: 41.312)\tTop5: 78.125 (avg: 70.062)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.545 (avg: 0.548)\tLoss: 2.1688 (avg: 2.4106)\tTop1: 40.625 (avg: 40.271)\tTop5: 70.312 (avg: 69.583)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.541 (avg: 0.550)\tLoss: 2.2379 (avg: 2.4293)\tTop1: 40.625 (avg: 39.734)\tTop5: 73.438 (avg: 69.266)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.551 (avg: 0.551)\tLoss: 2.4287 (avg: 2.4577)\tTop1: 43.750 (avg: 39.038)\tTop5: 65.625 (avg: 68.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6227\tTop 1 accuracy: 15.700\tTop 5 accuracy: 36.000\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.552 (avg: 0.543)\tLoss: 1.9288 (avg: 2.3416)\tTop1: 54.688 (avg: 42.750)\tTop5: 75.000 (avg: 70.875)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.546 (avg: 0.550)\tLoss: 2.6337 (avg: 2.3361)\tTop1: 29.688 (avg: 41.844)\tTop5: 64.062 (avg: 70.812)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.547 (avg: 0.552)\tLoss: 2.3663 (avg: 2.3681)\tTop1: 39.062 (avg: 41.083)\tTop5: 68.750 (avg: 70.312)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.551 (avg: 0.553)\tLoss: 2.3312 (avg: 2.4019)\tTop1: 42.188 (avg: 40.297)\tTop5: 68.750 (avg: 69.375)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.546 (avg: 0.554)\tLoss: 2.2774 (avg: 2.4199)\tTop1: 42.188 (avg: 40.050)\tTop5: 68.750 (avg: 69.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4294\tTop 1 accuracy: 15.550\tTop 5 accuracy: 36.600\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.551 (avg: 0.544)\tLoss: 2.4261 (avg: 2.2548)\tTop1: 42.188 (avg: 42.438)\tTop5: 64.062 (avg: 72.438)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.548 (avg: 0.551)\tLoss: 2.0097 (avg: 2.3169)\tTop1: 50.000 (avg: 42.125)\tTop5: 73.438 (avg: 71.281)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.551 (avg: 0.553)\tLoss: 2.5198 (avg: 2.3342)\tTop1: 45.312 (avg: 41.688)\tTop5: 70.312 (avg: 71.458)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.551 (avg: 0.554)\tLoss: 2.1336 (avg: 2.3630)\tTop1: 50.000 (avg: 41.016)\tTop5: 70.312 (avg: 70.719)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.546 (avg: 0.555)\tLoss: 2.5216 (avg: 2.3772)\tTop1: 35.938 (avg: 40.525)\tTop5: 65.625 (avg: 70.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9641\tTop 1 accuracy: 16.450\tTop 5 accuracy: 37.550\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.545 (avg: 0.540)\tLoss: 2.2435 (avg: 2.1836)\tTop1: 42.188 (avg: 44.000)\tTop5: 67.188 (avg: 73.125)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.547 (avg: 0.547)\tLoss: 2.2511 (avg: 2.2174)\tTop1: 40.625 (avg: 43.812)\tTop5: 73.438 (avg: 72.656)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.547 (avg: 0.550)\tLoss: 2.4311 (avg: 2.2545)\tTop1: 32.812 (avg: 43.083)\tTop5: 68.750 (avg: 72.188)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.547 (avg: 0.551)\tLoss: 2.6980 (avg: 2.2762)\tTop1: 43.750 (avg: 42.797)\tTop5: 65.625 (avg: 71.953)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.548 (avg: 0.551)\tLoss: 2.3785 (avg: 2.3216)\tTop1: 46.875 (avg: 42.500)\tTop5: 67.188 (avg: 70.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8725\tTop 1 accuracy: 16.050\tTop 5 accuracy: 34.700\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.542 (avg: 0.541)\tLoss: 2.4080 (avg: 2.1855)\tTop1: 45.312 (avg: 45.250)\tTop5: 62.500 (avg: 74.438)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.547 (avg: 0.547)\tLoss: 2.2092 (avg: 2.2449)\tTop1: 39.062 (avg: 43.125)\tTop5: 76.562 (avg: 72.594)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.548 (avg: 0.550)\tLoss: 2.4515 (avg: 2.2675)\tTop1: 43.750 (avg: 42.688)\tTop5: 67.188 (avg: 72.188)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.550 (avg: 0.551)\tLoss: 2.5114 (avg: 2.2920)\tTop1: 40.625 (avg: 42.234)\tTop5: 62.500 (avg: 71.828)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.553 (avg: 0.552)\tLoss: 2.6374 (avg: 2.2984)\tTop1: 34.375 (avg: 42.100)\tTop5: 64.062 (avg: 71.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6858\tTop 1 accuracy: 15.400\tTop 5 accuracy: 37.050\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.545 (avg: 0.539)\tLoss: 2.3574 (avg: 2.1606)\tTop1: 37.500 (avg: 44.562)\tTop5: 67.188 (avg: 74.688)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.546 (avg: 0.546)\tLoss: 1.9007 (avg: 2.1847)\tTop1: 53.125 (avg: 44.812)\tTop5: 76.562 (avg: 73.719)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.544 (avg: 0.548)\tLoss: 2.2116 (avg: 2.2024)\tTop1: 35.938 (avg: 44.229)\tTop5: 71.875 (avg: 73.521)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.547 (avg: 0.549)\tLoss: 2.2772 (avg: 2.2199)\tTop1: 46.875 (avg: 43.859)\tTop5: 76.562 (avg: 73.250)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.548 (avg: 0.550)\tLoss: 2.0900 (avg: 2.2269)\tTop1: 42.188 (avg: 43.675)\tTop5: 78.125 (avg: 73.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0354\tTop 1 accuracy: 15.250\tTop 5 accuracy: 35.600\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.549 (avg: 0.540)\tLoss: 2.2021 (avg: 2.0574)\tTop1: 48.438 (avg: 47.938)\tTop5: 71.875 (avg: 75.562)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.546 (avg: 0.549)\tLoss: 2.6082 (avg: 2.1249)\tTop1: 32.812 (avg: 45.844)\tTop5: 67.188 (avg: 74.875)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.547 (avg: 0.551)\tLoss: 2.3308 (avg: 2.1439)\tTop1: 35.938 (avg: 45.625)\tTop5: 70.312 (avg: 74.021)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.548 (avg: 0.552)\tLoss: 2.1895 (avg: 2.1676)\tTop1: 45.312 (avg: 45.547)\tTop5: 71.875 (avg: 73.750)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.551 (avg: 0.552)\tLoss: 2.4161 (avg: 2.1821)\tTop1: 46.875 (avg: 45.038)\tTop5: 67.188 (avg: 73.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8959\tTop 1 accuracy: 15.000\tTop 5 accuracy: 36.200\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.545 (avg: 0.543)\tLoss: 2.0712 (avg: 2.0297)\tTop1: 46.875 (avg: 49.438)\tTop5: 79.688 (avg: 76.750)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.549 (avg: 0.550)\tLoss: 1.8934 (avg: 2.0477)\tTop1: 48.438 (avg: 48.906)\tTop5: 81.250 (avg: 76.312)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.555 (avg: 0.553)\tLoss: 2.2143 (avg: 2.0759)\tTop1: 43.750 (avg: 48.125)\tTop5: 75.000 (avg: 75.896)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.549 (avg: 0.554)\tLoss: 2.3675 (avg: 2.1058)\tTop1: 42.188 (avg: 47.016)\tTop5: 70.312 (avg: 75.453)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.551 (avg: 0.554)\tLoss: 1.9346 (avg: 2.1336)\tTop1: 51.562 (avg: 46.213)\tTop5: 78.125 (avg: 74.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9478\tTop 1 accuracy: 14.700\tTop 5 accuracy: 36.450\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.548 (avg: 0.539)\tLoss: 1.9638 (avg: 1.9932)\tTop1: 42.188 (avg: 48.625)\tTop5: 75.000 (avg: 76.062)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.543 (avg: 0.546)\tLoss: 1.9607 (avg: 2.0133)\tTop1: 46.875 (avg: 48.625)\tTop5: 79.688 (avg: 76.531)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.543 (avg: 0.548)\tLoss: 1.8013 (avg: 2.0475)\tTop1: 48.438 (avg: 47.354)\tTop5: 87.500 (avg: 76.167)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.547 (avg: 0.549)\tLoss: 1.8493 (avg: 2.0574)\tTop1: 56.250 (avg: 47.062)\tTop5: 82.812 (avg: 76.297)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.544 (avg: 0.550)\tLoss: 2.1281 (avg: 2.0843)\tTop1: 37.500 (avg: 46.413)\tTop5: 75.000 (avg: 75.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4939\tTop 1 accuracy: 15.100\tTop 5 accuracy: 35.250\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.547 (avg: 0.543)\tLoss: 1.7206 (avg: 1.9555)\tTop1: 53.125 (avg: 50.312)\tTop5: 81.250 (avg: 78.688)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.551 (avg: 0.550)\tLoss: 1.9322 (avg: 1.9816)\tTop1: 54.688 (avg: 49.281)\tTop5: 78.125 (avg: 77.719)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.548 (avg: 0.552)\tLoss: 1.9314 (avg: 2.0156)\tTop1: 46.875 (avg: 48.792)\tTop5: 76.562 (avg: 76.896)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.551 (avg: 0.553)\tLoss: 2.2088 (avg: 2.0259)\tTop1: 45.312 (avg: 48.391)\tTop5: 75.000 (avg: 76.594)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.552 (avg: 0.554)\tLoss: 2.0346 (avg: 2.0402)\tTop1: 50.000 (avg: 47.963)\tTop5: 81.250 (avg: 76.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0049\tTop 1 accuracy: 15.350\tTop 5 accuracy: 34.700\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.552 (avg: 0.544)\tLoss: 1.9708 (avg: 1.9245)\tTop1: 50.000 (avg: 49.312)\tTop5: 78.125 (avg: 79.250)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.560 (avg: 0.551)\tLoss: 1.8984 (avg: 1.9514)\tTop1: 46.875 (avg: 49.562)\tTop5: 82.812 (avg: 78.219)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.543 (avg: 0.553)\tLoss: 2.3951 (avg: 1.9710)\tTop1: 39.062 (avg: 49.000)\tTop5: 70.312 (avg: 77.896)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.547 (avg: 0.553)\tLoss: 1.5559 (avg: 1.9977)\tTop1: 57.812 (avg: 47.891)\tTop5: 84.375 (avg: 77.391)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.554 (avg: 0.554)\tLoss: 2.3859 (avg: 2.0038)\tTop1: 37.500 (avg: 47.838)\tTop5: 78.125 (avg: 77.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3035\tTop 1 accuracy: 15.050\tTop 5 accuracy: 35.600\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.548 (avg: 0.540)\tLoss: 1.6391 (avg: 1.8667)\tTop1: 50.000 (avg: 51.500)\tTop5: 87.500 (avg: 79.562)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.547 (avg: 0.547)\tLoss: 1.7487 (avg: 1.8861)\tTop1: 46.875 (avg: 50.812)\tTop5: 78.125 (avg: 78.750)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.544 (avg: 0.549)\tLoss: 1.8747 (avg: 1.9075)\tTop1: 53.125 (avg: 50.583)\tTop5: 76.562 (avg: 78.771)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.548 (avg: 0.551)\tLoss: 1.9084 (avg: 1.9134)\tTop1: 53.125 (avg: 50.125)\tTop5: 81.250 (avg: 78.734)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.548 (avg: 0.551)\tLoss: 2.0639 (avg: 1.9464)\tTop1: 43.750 (avg: 49.500)\tTop5: 78.125 (avg: 78.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2265\tTop 1 accuracy: 15.150\tTop 5 accuracy: 35.050\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.553 (avg: 0.543)\tLoss: 1.9657 (avg: 1.7158)\tTop1: 43.750 (avg: 53.375)\tTop5: 76.562 (avg: 82.688)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.551 (avg: 0.549)\tLoss: 2.2440 (avg: 1.7982)\tTop1: 51.562 (avg: 52.562)\tTop5: 71.875 (avg: 81.344)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.551 (avg: 0.552)\tLoss: 1.8638 (avg: 1.8524)\tTop1: 54.688 (avg: 51.479)\tTop5: 81.250 (avg: 80.229)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.547 (avg: 0.553)\tLoss: 1.8579 (avg: 1.8805)\tTop1: 48.438 (avg: 50.781)\tTop5: 76.562 (avg: 79.594)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.550 (avg: 0.553)\tLoss: 1.7021 (avg: 1.8851)\tTop1: 56.250 (avg: 50.375)\tTop5: 79.688 (avg: 79.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5660\tTop 1 accuracy: 14.900\tTop 5 accuracy: 34.800\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.549 (avg: 0.540)\tLoss: 1.6804 (avg: 1.6928)\tTop1: 53.125 (avg: 56.312)\tTop5: 81.250 (avg: 82.750)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.547 (avg: 0.547)\tLoss: 1.8850 (avg: 1.7341)\tTop1: 48.438 (avg: 54.625)\tTop5: 76.562 (avg: 82.250)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.550 (avg: 0.549)\tLoss: 1.9019 (avg: 1.7703)\tTop1: 51.562 (avg: 53.771)\tTop5: 75.000 (avg: 81.500)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.551 (avg: 0.550)\tLoss: 2.5407 (avg: 1.8214)\tTop1: 32.812 (avg: 52.172)\tTop5: 73.438 (avg: 80.438)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.545 (avg: 0.551)\tLoss: 1.8327 (avg: 1.8502)\tTop1: 57.812 (avg: 51.350)\tTop5: 79.688 (avg: 79.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5202\tTop 1 accuracy: 15.250\tTop 5 accuracy: 35.250\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.552 (avg: 0.541)\tLoss: 1.8838 (avg: 1.6841)\tTop1: 48.438 (avg: 54.500)\tTop5: 79.688 (avg: 81.812)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.545 (avg: 0.548)\tLoss: 1.7332 (avg: 1.7505)\tTop1: 56.250 (avg: 53.375)\tTop5: 78.125 (avg: 81.469)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.547 (avg: 0.549)\tLoss: 1.8777 (avg: 1.7683)\tTop1: 46.875 (avg: 52.771)\tTop5: 82.812 (avg: 81.438)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.549 (avg: 0.551)\tLoss: 2.3139 (avg: 1.7914)\tTop1: 40.625 (avg: 52.016)\tTop5: 71.875 (avg: 81.547)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.549 (avg: 0.551)\tLoss: 2.0904 (avg: 1.8251)\tTop1: 48.438 (avg: 51.663)\tTop5: 73.438 (avg: 81.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2570\tTop 1 accuracy: 14.850\tTop 5 accuracy: 35.300\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.548 (avg: 0.543)\tLoss: 1.3757 (avg: 1.6332)\tTop1: 59.375 (avg: 56.812)\tTop5: 96.875 (avg: 84.375)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.546 (avg: 0.550)\tLoss: 1.5062 (avg: 1.5567)\tTop1: 65.625 (avg: 59.531)\tTop5: 85.938 (avg: 85.156)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.550 (avg: 0.552)\tLoss: 1.4324 (avg: 1.5015)\tTop1: 68.750 (avg: 61.042)\tTop5: 82.812 (avg: 85.896)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.551 (avg: 0.553)\tLoss: 1.2982 (avg: 1.4623)\tTop1: 70.312 (avg: 62.141)\tTop5: 85.938 (avg: 85.984)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.550 (avg: 0.554)\tLoss: 1.2928 (avg: 1.4461)\tTop1: 70.312 (avg: 62.625)\tTop5: 89.062 (avg: 86.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2796\tTop 1 accuracy: 16.350\tTop 5 accuracy: 37.400\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.546 (avg: 0.539)\tLoss: 1.2531 (avg: 1.2644)\tTop1: 65.625 (avg: 67.562)\tTop5: 87.500 (avg: 89.000)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.548 (avg: 0.546)\tLoss: 1.3455 (avg: 1.2943)\tTop1: 73.438 (avg: 66.625)\tTop5: 85.938 (avg: 88.250)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.546 (avg: 0.549)\tLoss: 1.1689 (avg: 1.3020)\tTop1: 73.438 (avg: 66.458)\tTop5: 89.062 (avg: 87.792)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.546 (avg: 0.550)\tLoss: 1.3129 (avg: 1.3056)\tTop1: 62.500 (avg: 66.438)\tTop5: 89.062 (avg: 87.516)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.544 (avg: 0.550)\tLoss: 1.2733 (avg: 1.3047)\tTop1: 71.875 (avg: 66.475)\tTop5: 89.062 (avg: 87.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4826\tTop 1 accuracy: 16.550\tTop 5 accuracy: 37.350\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.549 (avg: 0.543)\tLoss: 1.2470 (avg: 1.2417)\tTop1: 67.188 (avg: 67.625)\tTop5: 87.500 (avg: 88.312)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.551 (avg: 0.549)\tLoss: 1.5691 (avg: 1.2370)\tTop1: 60.938 (avg: 67.500)\tTop5: 82.812 (avg: 88.281)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.551 (avg: 0.551)\tLoss: 0.9670 (avg: 1.2491)\tTop1: 71.875 (avg: 66.958)\tTop5: 93.750 (avg: 88.125)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.550 (avg: 0.553)\tLoss: 1.2111 (avg: 1.2633)\tTop1: 70.312 (avg: 67.094)\tTop5: 89.062 (avg: 88.078)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.548 (avg: 0.553)\tLoss: 1.4319 (avg: 1.2642)\tTop1: 56.250 (avg: 67.088)\tTop5: 90.625 (avg: 88.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5100\tTop 1 accuracy: 16.000\tTop 5 accuracy: 36.300\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.550 (avg: 0.543)\tLoss: 1.6418 (avg: 1.2448)\tTop1: 56.250 (avg: 68.062)\tTop5: 81.250 (avg: 87.750)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.549 (avg: 0.550)\tLoss: 1.0944 (avg: 1.2196)\tTop1: 73.438 (avg: 69.000)\tTop5: 93.750 (avg: 88.156)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.555 (avg: 0.552)\tLoss: 1.3548 (avg: 1.2365)\tTop1: 67.188 (avg: 68.458)\tTop5: 87.500 (avg: 87.979)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.550 (avg: 0.553)\tLoss: 1.1928 (avg: 1.2359)\tTop1: 67.188 (avg: 68.094)\tTop5: 93.750 (avg: 88.219)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.546 (avg: 0.554)\tLoss: 1.2540 (avg: 1.2277)\tTop1: 70.312 (avg: 68.200)\tTop5: 85.938 (avg: 88.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6580\tTop 1 accuracy: 16.300\tTop 5 accuracy: 36.500\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.545 (avg: 0.540)\tLoss: 1.1606 (avg: 1.1868)\tTop1: 71.875 (avg: 68.125)\tTop5: 85.938 (avg: 88.562)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.544 (avg: 0.547)\tLoss: 0.7559 (avg: 1.1812)\tTop1: 79.688 (avg: 68.906)\tTop5: 96.875 (avg: 88.844)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.551 (avg: 0.549)\tLoss: 1.2537 (avg: 1.1779)\tTop1: 62.500 (avg: 69.167)\tTop5: 89.062 (avg: 88.896)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.547 (avg: 0.551)\tLoss: 1.4987 (avg: 1.1941)\tTop1: 65.625 (avg: 68.734)\tTop5: 82.812 (avg: 88.656)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.548 (avg: 0.551)\tLoss: 1.1300 (avg: 1.2002)\tTop1: 71.875 (avg: 68.438)\tTop5: 92.188 (avg: 88.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6052\tTop 1 accuracy: 16.450\tTop 5 accuracy: 36.300\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.556 (avg: 0.543)\tLoss: 0.8104 (avg: 1.1402)\tTop1: 79.688 (avg: 69.875)\tTop5: 95.312 (avg: 89.625)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.548 (avg: 0.549)\tLoss: 0.9915 (avg: 1.1435)\tTop1: 68.750 (avg: 70.406)\tTop5: 95.312 (avg: 89.531)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.553 (avg: 0.552)\tLoss: 1.3634 (avg: 1.1707)\tTop1: 67.188 (avg: 69.750)\tTop5: 85.938 (avg: 89.521)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.547 (avg: 0.553)\tLoss: 1.0266 (avg: 1.1889)\tTop1: 73.438 (avg: 69.203)\tTop5: 89.062 (avg: 89.094)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.549 (avg: 0.554)\tLoss: 1.1542 (avg: 1.1896)\tTop1: 67.188 (avg: 69.200)\tTop5: 87.500 (avg: 89.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6609\tTop 1 accuracy: 16.250\tTop 5 accuracy: 36.500\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.548 (avg: 0.539)\tLoss: 1.1281 (avg: 1.2104)\tTop1: 68.750 (avg: 67.625)\tTop5: 93.750 (avg: 89.562)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.543 (avg: 0.546)\tLoss: 1.2013 (avg: 1.2049)\tTop1: 68.750 (avg: 68.031)\tTop5: 87.500 (avg: 88.812)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.549 (avg: 0.548)\tLoss: 0.8049 (avg: 1.1772)\tTop1: 81.250 (avg: 68.854)\tTop5: 92.188 (avg: 89.104)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.542 (avg: 0.549)\tLoss: 1.0512 (avg: 1.1803)\tTop1: 75.000 (avg: 68.953)\tTop5: 90.625 (avg: 89.188)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.545 (avg: 0.550)\tLoss: 0.9720 (avg: 1.1892)\tTop1: 70.312 (avg: 68.413)\tTop5: 95.312 (avg: 89.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7126\tTop 1 accuracy: 16.200\tTop 5 accuracy: 36.700\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.545 (avg: 0.539)\tLoss: 0.9253 (avg: 1.1168)\tTop1: 71.875 (avg: 71.000)\tTop5: 95.312 (avg: 89.938)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.549 (avg: 0.546)\tLoss: 1.4580 (avg: 1.1825)\tTop1: 65.625 (avg: 69.750)\tTop5: 84.375 (avg: 89.312)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.550 (avg: 0.549)\tLoss: 0.7391 (avg: 1.1670)\tTop1: 71.875 (avg: 69.854)\tTop5: 98.438 (avg: 89.292)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.544 (avg: 0.550)\tLoss: 0.9311 (avg: 1.1521)\tTop1: 78.125 (avg: 70.219)\tTop5: 92.188 (avg: 89.438)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.548 (avg: 0.551)\tLoss: 1.1859 (avg: 1.1582)\tTop1: 71.875 (avg: 69.812)\tTop5: 87.500 (avg: 89.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6836\tTop 1 accuracy: 16.100\tTop 5 accuracy: 36.100\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.544 (avg: 0.542)\tLoss: 1.4027 (avg: 1.1275)\tTop1: 71.875 (avg: 70.125)\tTop5: 81.250 (avg: 89.375)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.554 (avg: 0.549)\tLoss: 1.0083 (avg: 1.1300)\tTop1: 73.438 (avg: 70.188)\tTop5: 95.312 (avg: 89.375)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.553 (avg: 0.552)\tLoss: 1.3134 (avg: 1.1505)\tTop1: 65.625 (avg: 70.312)\tTop5: 84.375 (avg: 88.896)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.548 (avg: 0.553)\tLoss: 1.1837 (avg: 1.1386)\tTop1: 65.625 (avg: 70.156)\tTop5: 89.062 (avg: 89.297)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.551 (avg: 0.554)\tLoss: 1.0125 (avg: 1.1580)\tTop1: 75.000 (avg: 69.763)\tTop5: 92.188 (avg: 89.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7024\tTop 1 accuracy: 15.850\tTop 5 accuracy: 35.750\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.544 (avg: 0.539)\tLoss: 1.0543 (avg: 1.1725)\tTop1: 71.875 (avg: 69.375)\tTop5: 87.500 (avg: 88.938)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.545 (avg: 0.546)\tLoss: 0.9760 (avg: 1.1246)\tTop1: 68.750 (avg: 70.562)\tTop5: 92.188 (avg: 89.875)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.542 (avg: 0.548)\tLoss: 1.0759 (avg: 1.1138)\tTop1: 75.000 (avg: 70.562)\tTop5: 90.625 (avg: 90.146)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.550 (avg: 0.549)\tLoss: 1.1751 (avg: 1.1442)\tTop1: 73.438 (avg: 70.141)\tTop5: 92.188 (avg: 89.750)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.545 (avg: 0.550)\tLoss: 1.0853 (avg: 1.1413)\tTop1: 75.000 (avg: 70.225)\tTop5: 90.625 (avg: 89.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8343\tTop 1 accuracy: 16.050\tTop 5 accuracy: 35.850\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.544 (avg: 0.542)\tLoss: 1.0834 (avg: 1.1398)\tTop1: 71.875 (avg: 70.812)\tTop5: 90.625 (avg: 89.500)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.549 (avg: 0.549)\tLoss: 1.1113 (avg: 1.1202)\tTop1: 68.750 (avg: 70.875)\tTop5: 90.625 (avg: 89.469)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.550 (avg: 0.551)\tLoss: 0.9695 (avg: 1.1260)\tTop1: 70.312 (avg: 70.667)\tTop5: 93.750 (avg: 89.792)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.549 (avg: 0.552)\tLoss: 0.8563 (avg: 1.1323)\tTop1: 79.688 (avg: 70.375)\tTop5: 95.312 (avg: 89.766)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.547 (avg: 0.553)\tLoss: 1.1058 (avg: 1.1300)\tTop1: 70.312 (avg: 70.388)\tTop5: 89.062 (avg: 89.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8360\tTop 1 accuracy: 16.050\tTop 5 accuracy: 35.800\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.558 (avg: 0.543)\tLoss: 0.8471 (avg: 1.0370)\tTop1: 76.562 (avg: 71.812)\tTop5: 95.312 (avg: 90.688)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.541 (avg: 0.550)\tLoss: 1.0433 (avg: 1.0803)\tTop1: 73.438 (avg: 71.094)\tTop5: 89.062 (avg: 89.875)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.554 (avg: 0.553)\tLoss: 0.8690 (avg: 1.0920)\tTop1: 71.875 (avg: 71.417)\tTop5: 96.875 (avg: 90.000)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.549 (avg: 0.554)\tLoss: 0.9388 (avg: 1.0921)\tTop1: 75.000 (avg: 71.203)\tTop5: 89.062 (avg: 90.250)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.551 (avg: 0.554)\tLoss: 1.0744 (avg: 1.0999)\tTop1: 67.188 (avg: 70.950)\tTop5: 90.625 (avg: 90.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0814\tTop 1 accuracy: 15.950\tTop 5 accuracy: 35.950\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.547 (avg: 0.540)\tLoss: 1.1574 (avg: 1.0394)\tTop1: 70.312 (avg: 73.000)\tTop5: 89.062 (avg: 90.938)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.548 (avg: 0.547)\tLoss: 1.0255 (avg: 1.0461)\tTop1: 73.438 (avg: 72.094)\tTop5: 90.625 (avg: 91.125)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.548 (avg: 0.550)\tLoss: 1.0656 (avg: 1.0811)\tTop1: 67.188 (avg: 71.083)\tTop5: 92.188 (avg: 90.667)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.547 (avg: 0.551)\tLoss: 1.2701 (avg: 1.0969)\tTop1: 65.625 (avg: 70.797)\tTop5: 89.062 (avg: 90.375)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.548 (avg: 0.552)\tLoss: 1.1070 (avg: 1.0993)\tTop1: 71.875 (avg: 70.875)\tTop5: 87.500 (avg: 90.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6742\tTop 1 accuracy: 15.700\tTop 5 accuracy: 36.300\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.550 (avg: 0.543)\tLoss: 0.9380 (avg: 1.0018)\tTop1: 70.312 (avg: 73.312)\tTop5: 90.625 (avg: 91.000)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.560 (avg: 0.550)\tLoss: 1.0236 (avg: 1.0316)\tTop1: 78.125 (avg: 72.719)\tTop5: 87.500 (avg: 91.188)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.548 (avg: 0.552)\tLoss: 1.6283 (avg: 1.0551)\tTop1: 53.125 (avg: 71.917)\tTop5: 82.812 (avg: 90.812)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.559 (avg: 0.553)\tLoss: 1.2814 (avg: 1.0689)\tTop1: 64.062 (avg: 71.875)\tTop5: 89.062 (avg: 90.703)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.551 (avg: 0.554)\tLoss: 1.1372 (avg: 1.0803)\tTop1: 73.438 (avg: 71.800)\tTop5: 92.188 (avg: 90.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6121\tTop 1 accuracy: 15.500\tTop 5 accuracy: 36.150\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.548 (avg: 0.540)\tLoss: 1.1848 (avg: 1.0109)\tTop1: 73.438 (avg: 72.938)\tTop5: 87.500 (avg: 92.125)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.547 (avg: 0.547)\tLoss: 0.9622 (avg: 1.0713)\tTop1: 70.312 (avg: 71.719)\tTop5: 92.188 (avg: 91.062)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.544 (avg: 0.549)\tLoss: 0.9849 (avg: 1.0708)\tTop1: 67.188 (avg: 71.292)\tTop5: 93.750 (avg: 90.812)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.553 (avg: 0.550)\tLoss: 0.8348 (avg: 1.0733)\tTop1: 78.125 (avg: 71.469)\tTop5: 93.750 (avg: 90.672)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.545 (avg: 0.551)\tLoss: 1.0601 (avg: 1.0760)\tTop1: 65.625 (avg: 71.363)\tTop5: 90.625 (avg: 90.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9261\tTop 1 accuracy: 15.650\tTop 5 accuracy: 35.750\n",
            "\n",
            "SR = 0.5: top1 = 15.600000381469727\ttop5 = 38.20000076293945\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.712 (avg: 1.014)\tLoss: 5.3030 (avg: 5.3117)\tTop1: 1.562 (avg: 0.625)\tTop5: 1.562 (avg: 2.625)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.702 (avg: 0.863)\tLoss: 5.2988 (avg: 5.3056)\tTop1: 0.000 (avg: 0.625)\tTop5: 1.562 (avg: 2.562)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.699 (avg: 0.812)\tLoss: 5.3001 (avg: 5.3039)\tTop1: 0.000 (avg: 0.542)\tTop5: 0.000 (avg: 2.229)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.705 (avg: 0.786)\tLoss: 5.2989 (avg: 5.3024)\tTop1: 1.562 (avg: 0.578)\tTop5: 3.125 (avg: 2.234)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.711 (avg: 0.771)\tLoss: 5.2927 (avg: 5.3014)\tTop1: 0.000 (avg: 0.538)\tTop5: 4.688 (avg: 2.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2908\tTop 1 accuracy: 0.550\tTop 5 accuracy: 2.150\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.699 (avg: 0.692)\tLoss: 5.2395 (avg: 5.2867)\tTop1: 3.125 (avg: 0.688)\tTop5: 9.375 (avg: 3.438)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.701 (avg: 0.701)\tLoss: 5.2805 (avg: 5.2835)\tTop1: 3.125 (avg: 0.719)\tTop5: 7.812 (avg: 3.281)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.706 (avg: 0.704)\tLoss: 5.3061 (avg: 5.2788)\tTop1: 1.562 (avg: 0.896)\tTop5: 4.688 (avg: 3.729)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.708 (avg: 0.706)\tLoss: 5.2583 (avg: 5.2778)\tTop1: 0.000 (avg: 0.812)\tTop5: 3.125 (avg: 3.844)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.696 (avg: 0.707)\tLoss: 5.2068 (avg: 5.2738)\tTop1: 1.562 (avg: 0.825)\tTop5: 4.688 (avg: 3.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1880\tTop 1 accuracy: 0.700\tTop 5 accuracy: 3.900\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.709 (avg: 0.691)\tLoss: 5.2743 (avg: 5.2396)\tTop1: 0.000 (avg: 1.375)\tTop5: 3.125 (avg: 5.375)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.702 (avg: 0.701)\tLoss: 5.1868 (avg: 5.2400)\tTop1: 3.125 (avg: 1.219)\tTop5: 6.250 (avg: 5.469)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.704 (avg: 0.704)\tLoss: 5.2975 (avg: 5.2386)\tTop1: 0.000 (avg: 1.146)\tTop5: 4.688 (avg: 5.146)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.702 (avg: 0.706)\tLoss: 5.2287 (avg: 5.2341)\tTop1: 3.125 (avg: 1.312)\tTop5: 6.250 (avg: 5.281)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.704 (avg: 0.706)\tLoss: 5.1940 (avg: 5.2311)\tTop1: 0.000 (avg: 1.250)\tTop5: 7.812 (avg: 5.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0919\tTop 1 accuracy: 1.050\tTop 5 accuracy: 6.000\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.703 (avg: 0.691)\tLoss: 5.1672 (avg: 5.1971)\tTop1: 1.562 (avg: 1.625)\tTop5: 7.812 (avg: 7.750)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.703 (avg: 0.701)\tLoss: 5.2559 (avg: 5.1981)\tTop1: 0.000 (avg: 1.406)\tTop5: 3.125 (avg: 7.031)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.705 (avg: 0.704)\tLoss: 5.1605 (avg: 5.1933)\tTop1: 1.562 (avg: 1.500)\tTop5: 9.375 (avg: 6.917)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.701 (avg: 0.705)\tLoss: 5.2393 (avg: 5.1984)\tTop1: 0.000 (avg: 1.391)\tTop5: 0.000 (avg: 6.609)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.707 (avg: 0.706)\tLoss: 5.1491 (avg: 5.1980)\tTop1: 0.000 (avg: 1.400)\tTop5: 6.250 (avg: 6.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9763\tTop 1 accuracy: 1.050\tTop 5 accuracy: 6.450\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.701 (avg: 0.691)\tLoss: 5.2259 (avg: 5.1430)\tTop1: 4.688 (avg: 1.500)\tTop5: 12.500 (avg: 7.188)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.705 (avg: 0.701)\tLoss: 5.1436 (avg: 5.1437)\tTop1: 0.000 (avg: 1.438)\tTop5: 4.688 (avg: 7.562)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.702 (avg: 0.704)\tLoss: 5.0122 (avg: 5.1442)\tTop1: 1.562 (avg: 1.562)\tTop5: 7.812 (avg: 7.354)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.710 (avg: 0.706)\tLoss: 5.1235 (avg: 5.1472)\tTop1: 1.562 (avg: 1.422)\tTop5: 9.375 (avg: 7.281)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.700 (avg: 0.707)\tLoss: 5.0852 (avg: 5.1392)\tTop1: 1.562 (avg: 1.463)\tTop5: 6.250 (avg: 7.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9413\tTop 1 accuracy: 2.900\tTop 5 accuracy: 9.250\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.705 (avg: 0.693)\tLoss: 5.0976 (avg: 5.1130)\tTop1: 0.000 (avg: 1.125)\tTop5: 6.250 (avg: 7.062)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.715 (avg: 0.702)\tLoss: 5.1395 (avg: 5.0930)\tTop1: 3.125 (avg: 1.906)\tTop5: 4.688 (avg: 7.781)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.700 (avg: 0.705)\tLoss: 4.9403 (avg: 5.0862)\tTop1: 3.125 (avg: 2.000)\tTop5: 12.500 (avg: 8.250)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.703 (avg: 0.707)\tLoss: 5.0165 (avg: 5.0795)\tTop1: 6.250 (avg: 2.141)\tTop5: 15.625 (avg: 8.578)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.706 (avg: 0.707)\tLoss: 5.0595 (avg: 5.0767)\tTop1: 4.688 (avg: 2.088)\tTop5: 10.938 (avg: 8.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8738\tTop 1 accuracy: 2.250\tTop 5 accuracy: 10.000\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.705 (avg: 0.692)\tLoss: 5.0708 (avg: 5.0088)\tTop1: 0.000 (avg: 2.312)\tTop5: 7.812 (avg: 9.062)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.705 (avg: 0.701)\tLoss: 4.9394 (avg: 5.0179)\tTop1: 0.000 (avg: 2.312)\tTop5: 7.812 (avg: 9.000)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.709 (avg: 0.704)\tLoss: 5.0523 (avg: 5.0094)\tTop1: 1.562 (avg: 2.438)\tTop5: 7.812 (avg: 9.438)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.701 (avg: 0.706)\tLoss: 5.1759 (avg: 5.0078)\tTop1: 0.000 (avg: 2.375)\tTop5: 9.375 (avg: 9.766)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.706 (avg: 0.707)\tLoss: 5.1289 (avg: 5.0015)\tTop1: 1.562 (avg: 2.425)\tTop5: 6.250 (avg: 9.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8625\tTop 1 accuracy: 3.000\tTop 5 accuracy: 10.300\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.706 (avg: 0.691)\tLoss: 4.9571 (avg: 4.9798)\tTop1: 3.125 (avg: 3.188)\tTop5: 10.938 (avg: 11.125)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.701 (avg: 0.701)\tLoss: 5.1866 (avg: 4.9659)\tTop1: 1.562 (avg: 2.938)\tTop5: 6.250 (avg: 11.312)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.708 (avg: 0.704)\tLoss: 4.9850 (avg: 4.9569)\tTop1: 3.125 (avg: 3.042)\tTop5: 9.375 (avg: 11.625)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.704 (avg: 0.705)\tLoss: 4.7216 (avg: 4.9533)\tTop1: 4.688 (avg: 2.922)\tTop5: 14.062 (avg: 11.500)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.706 (avg: 0.706)\tLoss: 4.9468 (avg: 4.9586)\tTop1: 3.125 (avg: 2.863)\tTop5: 12.500 (avg: 11.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8665\tTop 1 accuracy: 2.900\tTop 5 accuracy: 12.100\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.704 (avg: 0.691)\tLoss: 4.9524 (avg: 4.9051)\tTop1: 0.000 (avg: 2.625)\tTop5: 12.500 (avg: 11.375)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.705 (avg: 0.701)\tLoss: 4.8218 (avg: 4.8934)\tTop1: 4.688 (avg: 2.875)\tTop5: 7.812 (avg: 12.562)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.693 (avg: 0.704)\tLoss: 4.7897 (avg: 4.8950)\tTop1: 6.250 (avg: 3.417)\tTop5: 17.188 (avg: 12.792)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.702 (avg: 0.705)\tLoss: 5.1007 (avg: 4.8978)\tTop1: 1.562 (avg: 3.359)\tTop5: 4.688 (avg: 12.500)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.702 (avg: 0.706)\tLoss: 4.9806 (avg: 4.8949)\tTop1: 3.125 (avg: 3.363)\tTop5: 9.375 (avg: 12.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7623\tTop 1 accuracy: 3.550\tTop 5 accuracy: 12.850\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.699 (avg: 0.691)\tLoss: 5.0034 (avg: 4.8393)\tTop1: 1.562 (avg: 3.125)\tTop5: 10.938 (avg: 14.062)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.706 (avg: 0.700)\tLoss: 4.8408 (avg: 4.8422)\tTop1: 4.688 (avg: 2.906)\tTop5: 14.062 (avg: 13.344)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.696 (avg: 0.703)\tLoss: 4.8343 (avg: 4.8485)\tTop1: 3.125 (avg: 2.938)\tTop5: 9.375 (avg: 13.375)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.707 (avg: 0.705)\tLoss: 4.7272 (avg: 4.8455)\tTop1: 3.125 (avg: 3.094)\tTop5: 18.750 (avg: 13.547)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.698 (avg: 0.706)\tLoss: 4.8572 (avg: 4.8376)\tTop1: 6.250 (avg: 3.263)\tTop5: 15.625 (avg: 13.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7747\tTop 1 accuracy: 4.300\tTop 5 accuracy: 14.500\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.703 (avg: 0.691)\tLoss: 4.7160 (avg: 4.8039)\tTop1: 1.562 (avg: 4.000)\tTop5: 14.062 (avg: 14.312)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.693 (avg: 0.701)\tLoss: 4.9613 (avg: 4.7974)\tTop1: 0.000 (avg: 4.000)\tTop5: 1.562 (avg: 14.500)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.703 (avg: 0.704)\tLoss: 4.8042 (avg: 4.7937)\tTop1: 1.562 (avg: 4.021)\tTop5: 10.938 (avg: 14.854)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.702 (avg: 0.706)\tLoss: 4.7218 (avg: 4.7879)\tTop1: 4.688 (avg: 3.891)\tTop5: 17.188 (avg: 15.188)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.704 (avg: 0.707)\tLoss: 4.7019 (avg: 4.7840)\tTop1: 4.688 (avg: 3.875)\tTop5: 14.062 (avg: 15.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6104\tTop 1 accuracy: 4.400\tTop 5 accuracy: 16.500\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.707 (avg: 0.692)\tLoss: 4.8348 (avg: 4.6935)\tTop1: 4.688 (avg: 4.875)\tTop5: 15.625 (avg: 16.812)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.701 (avg: 0.701)\tLoss: 4.6514 (avg: 4.7128)\tTop1: 9.375 (avg: 4.719)\tTop5: 15.625 (avg: 16.156)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.707 (avg: 0.704)\tLoss: 4.4527 (avg: 4.6962)\tTop1: 9.375 (avg: 4.708)\tTop5: 28.125 (avg: 16.708)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.698 (avg: 0.706)\tLoss: 4.6789 (avg: 4.6876)\tTop1: 3.125 (avg: 4.891)\tTop5: 17.188 (avg: 17.062)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.701 (avg: 0.706)\tLoss: 4.7754 (avg: 4.6978)\tTop1: 1.562 (avg: 4.925)\tTop5: 12.500 (avg: 16.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4920\tTop 1 accuracy: 3.700\tTop 5 accuracy: 15.400\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.701 (avg: 0.691)\tLoss: 4.6526 (avg: 4.6364)\tTop1: 4.688 (avg: 4.688)\tTop5: 18.750 (avg: 19.375)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.701 (avg: 0.701)\tLoss: 4.4933 (avg: 4.6704)\tTop1: 4.688 (avg: 4.156)\tTop5: 26.562 (avg: 18.281)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.699 (avg: 0.704)\tLoss: 4.6256 (avg: 4.6620)\tTop1: 0.000 (avg: 4.375)\tTop5: 12.500 (avg: 18.188)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.714 (avg: 0.706)\tLoss: 4.5900 (avg: 4.6587)\tTop1: 4.688 (avg: 4.609)\tTop5: 20.312 (avg: 18.078)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.702 (avg: 0.707)\tLoss: 4.7816 (avg: 4.6512)\tTop1: 4.688 (avg: 4.888)\tTop5: 14.062 (avg: 18.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2966\tTop 1 accuracy: 4.750\tTop 5 accuracy: 15.700\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.707 (avg: 0.694)\tLoss: 4.3833 (avg: 4.4878)\tTop1: 10.938 (avg: 6.375)\tTop5: 31.250 (avg: 21.375)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.708 (avg: 0.703)\tLoss: 4.6068 (avg: 4.5502)\tTop1: 1.562 (avg: 5.938)\tTop5: 14.062 (avg: 20.344)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.703 (avg: 0.705)\tLoss: 4.6679 (avg: 4.5522)\tTop1: 4.688 (avg: 5.875)\tTop5: 15.625 (avg: 20.271)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.703 (avg: 0.707)\tLoss: 4.4310 (avg: 4.5552)\tTop1: 7.812 (avg: 5.797)\tTop5: 25.000 (avg: 20.312)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.710 (avg: 0.708)\tLoss: 4.4813 (avg: 4.5646)\tTop1: 7.812 (avg: 5.775)\tTop5: 21.875 (avg: 20.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3779\tTop 1 accuracy: 6.250\tTop 5 accuracy: 20.000\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.707 (avg: 0.694)\tLoss: 4.6205 (avg: 4.5303)\tTop1: 7.812 (avg: 6.062)\tTop5: 18.750 (avg: 20.125)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.704 (avg: 0.703)\tLoss: 4.7056 (avg: 4.5290)\tTop1: 1.562 (avg: 6.062)\tTop5: 10.938 (avg: 19.688)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.707 (avg: 0.705)\tLoss: 4.5222 (avg: 4.5303)\tTop1: 7.812 (avg: 5.896)\tTop5: 14.062 (avg: 20.167)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.698 (avg: 0.707)\tLoss: 4.5617 (avg: 4.5212)\tTop1: 1.562 (avg: 5.984)\tTop5: 17.188 (avg: 20.500)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.704 (avg: 0.708)\tLoss: 4.6587 (avg: 4.5232)\tTop1: 6.250 (avg: 5.938)\tTop5: 15.625 (avg: 20.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4999\tTop 1 accuracy: 5.800\tTop 5 accuracy: 18.600\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.707 (avg: 0.691)\tLoss: 4.4568 (avg: 4.4695)\tTop1: 6.250 (avg: 6.938)\tTop5: 25.000 (avg: 21.812)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.704 (avg: 0.700)\tLoss: 4.5365 (avg: 4.4745)\tTop1: 12.500 (avg: 7.156)\tTop5: 21.875 (avg: 21.500)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.703 (avg: 0.703)\tLoss: 4.2390 (avg: 4.4792)\tTop1: 14.062 (avg: 7.021)\tTop5: 35.938 (avg: 21.271)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.707 (avg: 0.705)\tLoss: 4.6431 (avg: 4.4764)\tTop1: 6.250 (avg: 7.047)\tTop5: 18.750 (avg: 21.641)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.708 (avg: 0.706)\tLoss: 4.5240 (avg: 4.4604)\tTop1: 4.688 (avg: 7.175)\tTop5: 15.625 (avg: 21.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6701\tTop 1 accuracy: 5.450\tTop 5 accuracy: 19.100\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.705 (avg: 0.695)\tLoss: 4.4407 (avg: 4.3967)\tTop1: 0.000 (avg: 7.438)\tTop5: 15.625 (avg: 22.875)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.712 (avg: 0.703)\tLoss: 4.2838 (avg: 4.3962)\tTop1: 7.812 (avg: 6.719)\tTop5: 26.562 (avg: 23.750)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.701 (avg: 0.705)\tLoss: 4.1924 (avg: 4.3776)\tTop1: 10.938 (avg: 7.188)\tTop5: 35.938 (avg: 24.417)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.702 (avg: 0.707)\tLoss: 4.3333 (avg: 4.3868)\tTop1: 9.375 (avg: 7.062)\tTop5: 25.000 (avg: 23.969)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.705 (avg: 0.707)\tLoss: 4.4179 (avg: 4.3855)\tTop1: 6.250 (avg: 7.238)\tTop5: 23.438 (avg: 23.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2487\tTop 1 accuracy: 7.550\tTop 5 accuracy: 22.000\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.702 (avg: 0.692)\tLoss: 3.9741 (avg: 4.3433)\tTop1: 12.500 (avg: 7.562)\tTop5: 29.688 (avg: 23.938)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.696 (avg: 0.701)\tLoss: 4.4764 (avg: 4.3566)\tTop1: 6.250 (avg: 7.625)\tTop5: 21.875 (avg: 24.500)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.705 (avg: 0.705)\tLoss: 4.1658 (avg: 4.3424)\tTop1: 10.938 (avg: 7.542)\tTop5: 28.125 (avg: 24.708)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.713 (avg: 0.707)\tLoss: 4.3853 (avg: 4.3482)\tTop1: 7.812 (avg: 7.344)\tTop5: 20.312 (avg: 24.578)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.698 (avg: 0.707)\tLoss: 4.4402 (avg: 4.3400)\tTop1: 9.375 (avg: 7.663)\tTop5: 26.562 (avg: 25.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0411\tTop 1 accuracy: 8.300\tTop 5 accuracy: 23.050\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.701 (avg: 0.693)\tLoss: 4.2638 (avg: 4.2423)\tTop1: 7.812 (avg: 9.062)\tTop5: 34.375 (avg: 28.188)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.697 (avg: 0.701)\tLoss: 4.1937 (avg: 4.2337)\tTop1: 6.250 (avg: 9.125)\tTop5: 29.688 (avg: 27.969)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.698 (avg: 0.705)\tLoss: 4.0237 (avg: 4.2421)\tTop1: 7.812 (avg: 8.854)\tTop5: 31.250 (avg: 27.833)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.698 (avg: 0.706)\tLoss: 4.6428 (avg: 4.2648)\tTop1: 9.375 (avg: 8.797)\tTop5: 15.625 (avg: 27.578)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.706 (avg: 0.707)\tLoss: 4.5745 (avg: 4.2748)\tTop1: 3.125 (avg: 8.863)\tTop5: 20.312 (avg: 27.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6391\tTop 1 accuracy: 7.550\tTop 5 accuracy: 23.350\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.702 (avg: 0.691)\tLoss: 4.0698 (avg: 4.1486)\tTop1: 9.375 (avg: 10.625)\tTop5: 23.438 (avg: 29.562)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.704 (avg: 0.701)\tLoss: 4.3524 (avg: 4.1559)\tTop1: 12.500 (avg: 9.969)\tTop5: 28.125 (avg: 29.656)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.707 (avg: 0.704)\tLoss: 4.3891 (avg: 4.1981)\tTop1: 9.375 (avg: 9.729)\tTop5: 28.125 (avg: 28.604)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.695 (avg: 0.705)\tLoss: 3.9482 (avg: 4.2345)\tTop1: 6.250 (avg: 9.203)\tTop5: 31.250 (avg: 27.547)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.702 (avg: 0.706)\tLoss: 4.2075 (avg: 4.2437)\tTop1: 4.688 (avg: 8.988)\tTop5: 26.562 (avg: 27.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8407\tTop 1 accuracy: 8.100\tTop 5 accuracy: 24.300\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.698 (avg: 0.691)\tLoss: 4.2134 (avg: 4.1216)\tTop1: 3.125 (avg: 10.625)\tTop5: 23.438 (avg: 31.438)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.700 (avg: 0.701)\tLoss: 4.0246 (avg: 4.1491)\tTop1: 7.812 (avg: 10.000)\tTop5: 39.062 (avg: 30.719)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.701 (avg: 0.704)\tLoss: 4.0847 (avg: 4.1432)\tTop1: 15.625 (avg: 10.333)\tTop5: 29.688 (avg: 31.042)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.705 (avg: 0.706)\tLoss: 4.2680 (avg: 4.1623)\tTop1: 6.250 (avg: 9.906)\tTop5: 26.562 (avg: 29.938)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.697 (avg: 0.707)\tLoss: 4.1576 (avg: 4.1755)\tTop1: 14.062 (avg: 9.713)\tTop5: 35.938 (avg: 30.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7856\tTop 1 accuracy: 8.050\tTop 5 accuracy: 25.850\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.701 (avg: 0.691)\tLoss: 3.9224 (avg: 4.0763)\tTop1: 7.812 (avg: 10.938)\tTop5: 34.375 (avg: 32.562)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.707 (avg: 0.699)\tLoss: 4.2584 (avg: 4.1231)\tTop1: 7.812 (avg: 10.438)\tTop5: 20.312 (avg: 30.469)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.698 (avg: 0.703)\tLoss: 4.0129 (avg: 4.1222)\tTop1: 4.688 (avg: 10.062)\tTop5: 23.438 (avg: 29.833)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.703 (avg: 0.704)\tLoss: 4.1598 (avg: 4.1472)\tTop1: 4.688 (avg: 9.875)\tTop5: 25.000 (avg: 29.516)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.703 (avg: 0.706)\tLoss: 4.2373 (avg: 4.1547)\tTop1: 9.375 (avg: 9.950)\tTop5: 31.250 (avg: 29.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9584\tTop 1 accuracy: 10.700\tTop 5 accuracy: 26.350\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.703 (avg: 0.692)\tLoss: 3.9705 (avg: 4.0528)\tTop1: 10.938 (avg: 11.375)\tTop5: 31.250 (avg: 32.312)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.700 (avg: 0.700)\tLoss: 4.1206 (avg: 4.0863)\tTop1: 9.375 (avg: 10.906)\tTop5: 32.812 (avg: 30.750)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.707 (avg: 0.704)\tLoss: 4.1346 (avg: 4.1226)\tTop1: 10.938 (avg: 10.875)\tTop5: 29.688 (avg: 30.396)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.697 (avg: 0.705)\tLoss: 3.9040 (avg: 4.1280)\tTop1: 17.188 (avg: 10.969)\tTop5: 42.188 (avg: 30.469)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.701 (avg: 0.706)\tLoss: 3.8357 (avg: 4.0971)\tTop1: 20.312 (avg: 11.325)\tTop5: 43.750 (avg: 30.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4856\tTop 1 accuracy: 9.550\tTop 5 accuracy: 26.800\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.711 (avg: 0.691)\tLoss: 4.4167 (avg: 3.9873)\tTop1: 7.812 (avg: 11.875)\tTop5: 25.000 (avg: 32.438)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.697 (avg: 0.701)\tLoss: 4.0519 (avg: 4.0128)\tTop1: 7.812 (avg: 11.719)\tTop5: 25.000 (avg: 32.781)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.703 (avg: 0.704)\tLoss: 3.7888 (avg: 4.0009)\tTop1: 17.188 (avg: 12.250)\tTop5: 40.625 (avg: 33.562)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.702 (avg: 0.706)\tLoss: 3.9920 (avg: 3.9956)\tTop1: 12.500 (avg: 12.344)\tTop5: 40.625 (avg: 33.562)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.706 (avg: 0.707)\tLoss: 4.0013 (avg: 4.0025)\tTop1: 17.188 (avg: 12.400)\tTop5: 34.375 (avg: 33.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7310\tTop 1 accuracy: 10.000\tTop 5 accuracy: 28.200\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.704 (avg: 0.692)\tLoss: 3.7396 (avg: 3.8914)\tTop1: 20.312 (avg: 13.188)\tTop5: 42.188 (avg: 36.062)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.703 (avg: 0.700)\tLoss: 4.0612 (avg: 3.9515)\tTop1: 12.500 (avg: 12.969)\tTop5: 35.938 (avg: 34.969)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.703 (avg: 0.703)\tLoss: 3.9620 (avg: 3.9812)\tTop1: 9.375 (avg: 12.271)\tTop5: 31.250 (avg: 34.208)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.704 (avg: 0.705)\tLoss: 3.7179 (avg: 3.9641)\tTop1: 17.188 (avg: 12.578)\tTop5: 40.625 (avg: 34.438)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.703 (avg: 0.706)\tLoss: 3.9278 (avg: 3.9641)\tTop1: 7.812 (avg: 12.538)\tTop5: 29.688 (avg: 34.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4565\tTop 1 accuracy: 10.100\tTop 5 accuracy: 28.250\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.699 (avg: 0.692)\tLoss: 3.6551 (avg: 3.8865)\tTop1: 18.750 (avg: 13.875)\tTop5: 43.750 (avg: 36.625)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.702 (avg: 0.701)\tLoss: 4.2103 (avg: 3.9159)\tTop1: 10.938 (avg: 13.625)\tTop5: 31.250 (avg: 35.406)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.698 (avg: 0.704)\tLoss: 3.8998 (avg: 3.9235)\tTop1: 14.062 (avg: 13.438)\tTop5: 26.562 (avg: 35.083)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.709 (avg: 0.706)\tLoss: 3.9364 (avg: 3.9304)\tTop1: 18.750 (avg: 13.422)\tTop5: 34.375 (avg: 35.094)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.698 (avg: 0.707)\tLoss: 3.9882 (avg: 3.9320)\tTop1: 14.062 (avg: 13.425)\tTop5: 32.812 (avg: 35.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5191\tTop 1 accuracy: 11.450\tTop 5 accuracy: 30.300\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.710 (avg: 0.692)\tLoss: 3.5966 (avg: 3.7102)\tTop1: 17.188 (avg: 16.750)\tTop5: 43.750 (avg: 40.562)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.703 (avg: 0.701)\tLoss: 3.8664 (avg: 3.7952)\tTop1: 17.188 (avg: 15.906)\tTop5: 34.375 (avg: 38.344)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.704 (avg: 0.704)\tLoss: 3.8283 (avg: 3.8122)\tTop1: 10.938 (avg: 15.312)\tTop5: 39.062 (avg: 38.000)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.707 (avg: 0.706)\tLoss: 4.1006 (avg: 3.8242)\tTop1: 9.375 (avg: 14.922)\tTop5: 31.250 (avg: 37.766)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.706 (avg: 0.707)\tLoss: 4.2276 (avg: 3.8502)\tTop1: 12.500 (avg: 14.713)\tTop5: 21.875 (avg: 37.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9238\tTop 1 accuracy: 8.550\tTop 5 accuracy: 25.600\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.706 (avg: 0.693)\tLoss: 3.6171 (avg: 3.8420)\tTop1: 15.625 (avg: 15.062)\tTop5: 45.312 (avg: 37.062)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.698 (avg: 0.702)\tLoss: 3.9303 (avg: 3.8446)\tTop1: 15.625 (avg: 14.000)\tTop5: 39.062 (avg: 37.188)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.707 (avg: 0.704)\tLoss: 3.9229 (avg: 3.8355)\tTop1: 12.500 (avg: 14.146)\tTop5: 29.688 (avg: 37.812)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.699 (avg: 0.705)\tLoss: 3.8438 (avg: 3.8232)\tTop1: 10.938 (avg: 14.359)\tTop5: 42.188 (avg: 38.203)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.704 (avg: 0.706)\tLoss: 3.9637 (avg: 3.7993)\tTop1: 15.625 (avg: 14.863)\tTop5: 31.250 (avg: 38.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8224\tTop 1 accuracy: 10.550\tTop 5 accuracy: 30.550\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.699 (avg: 0.692)\tLoss: 3.5494 (avg: 3.6212)\tTop1: 21.875 (avg: 16.812)\tTop5: 42.188 (avg: 44.250)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.701 (avg: 0.701)\tLoss: 3.7384 (avg: 3.7511)\tTop1: 14.062 (avg: 15.125)\tTop5: 40.625 (avg: 40.469)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.703 (avg: 0.704)\tLoss: 3.6921 (avg: 3.7199)\tTop1: 12.500 (avg: 15.750)\tTop5: 37.500 (avg: 40.833)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.714 (avg: 0.706)\tLoss: 3.5204 (avg: 3.7391)\tTop1: 20.312 (avg: 15.422)\tTop5: 40.625 (avg: 40.141)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.699 (avg: 0.707)\tLoss: 3.7972 (avg: 3.7408)\tTop1: 12.500 (avg: 15.575)\tTop5: 35.938 (avg: 40.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3258\tTop 1 accuracy: 12.300\tTop 5 accuracy: 32.300\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.706 (avg: 0.694)\tLoss: 3.4657 (avg: 3.6437)\tTop1: 25.000 (avg: 15.875)\tTop5: 43.750 (avg: 41.625)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.717 (avg: 0.703)\tLoss: 3.8941 (avg: 3.6896)\tTop1: 10.938 (avg: 15.625)\tTop5: 35.938 (avg: 40.062)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.699 (avg: 0.705)\tLoss: 3.4084 (avg: 3.7303)\tTop1: 25.000 (avg: 15.938)\tTop5: 42.188 (avg: 39.875)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.702 (avg: 0.707)\tLoss: 3.6632 (avg: 3.7096)\tTop1: 10.938 (avg: 16.250)\tTop5: 39.062 (avg: 40.562)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.704 (avg: 0.708)\tLoss: 3.9670 (avg: 3.7008)\tTop1: 17.188 (avg: 16.650)\tTop5: 35.938 (avg: 40.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4182\tTop 1 accuracy: 12.050\tTop 5 accuracy: 30.150\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.704 (avg: 0.693)\tLoss: 2.8899 (avg: 3.2788)\tTop1: 31.250 (avg: 23.375)\tTop5: 57.812 (avg: 50.938)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.710 (avg: 0.702)\tLoss: 3.2789 (avg: 3.2745)\tTop1: 26.562 (avg: 23.562)\tTop5: 48.438 (avg: 50.406)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.711 (avg: 0.705)\tLoss: 3.2005 (avg: 3.2285)\tTop1: 29.688 (avg: 25.042)\tTop5: 48.438 (avg: 51.083)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.702 (avg: 0.706)\tLoss: 3.0578 (avg: 3.2174)\tTop1: 28.125 (avg: 25.141)\tTop5: 53.125 (avg: 51.531)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.705 (avg: 0.707)\tLoss: 3.4864 (avg: 3.2084)\tTop1: 25.000 (avg: 25.088)\tTop5: 42.188 (avg: 51.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2357\tTop 1 accuracy: 15.750\tTop 5 accuracy: 36.050\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.710 (avg: 0.693)\tLoss: 2.8906 (avg: 3.0902)\tTop1: 29.688 (avg: 28.750)\tTop5: 68.750 (avg: 54.250)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.697 (avg: 0.702)\tLoss: 2.8309 (avg: 3.0766)\tTop1: 39.062 (avg: 29.219)\tTop5: 62.500 (avg: 54.562)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.702 (avg: 0.706)\tLoss: 3.2587 (avg: 3.0730)\tTop1: 29.688 (avg: 28.688)\tTop5: 59.375 (avg: 55.146)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.703 (avg: 0.707)\tLoss: 3.2116 (avg: 3.0764)\tTop1: 26.562 (avg: 28.844)\tTop5: 57.812 (avg: 55.047)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.708 (avg: 0.708)\tLoss: 3.1578 (avg: 3.0720)\tTop1: 31.250 (avg: 28.675)\tTop5: 57.812 (avg: 55.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.0638\tTop 1 accuracy: 15.300\tTop 5 accuracy: 36.100\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.709 (avg: 0.694)\tLoss: 3.0309 (avg: 2.9854)\tTop1: 20.312 (avg: 28.875)\tTop5: 50.000 (avg: 56.938)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.710 (avg: 0.703)\tLoss: 3.3902 (avg: 3.0383)\tTop1: 17.188 (avg: 28.188)\tTop5: 45.312 (avg: 55.781)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.704 (avg: 0.706)\tLoss: 3.1716 (avg: 3.0247)\tTop1: 29.688 (avg: 28.729)\tTop5: 53.125 (avg: 56.125)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.711 (avg: 0.708)\tLoss: 3.0793 (avg: 3.0109)\tTop1: 20.312 (avg: 29.125)\tTop5: 57.812 (avg: 56.609)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.705 (avg: 0.709)\tLoss: 3.1464 (avg: 3.0163)\tTop1: 21.875 (avg: 29.013)\tTop5: 59.375 (avg: 56.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.1319\tTop 1 accuracy: 15.450\tTop 5 accuracy: 36.200\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.698 (avg: 0.693)\tLoss: 2.9642 (avg: 2.9331)\tTop1: 29.688 (avg: 29.750)\tTop5: 59.375 (avg: 58.375)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.703 (avg: 0.702)\tLoss: 2.6607 (avg: 2.9532)\tTop1: 39.062 (avg: 29.719)\tTop5: 59.375 (avg: 58.000)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.702 (avg: 0.704)\tLoss: 2.4938 (avg: 2.9662)\tTop1: 46.875 (avg: 30.021)\tTop5: 62.500 (avg: 57.521)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.712 (avg: 0.706)\tLoss: 2.8358 (avg: 2.9747)\tTop1: 34.375 (avg: 29.875)\tTop5: 57.812 (avg: 57.359)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.695 (avg: 0.707)\tLoss: 2.8368 (avg: 2.9761)\tTop1: 34.375 (avg: 29.525)\tTop5: 68.750 (avg: 57.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3668\tTop 1 accuracy: 15.900\tTop 5 accuracy: 36.200\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.707 (avg: 0.693)\tLoss: 3.0330 (avg: 2.9108)\tTop1: 31.250 (avg: 29.250)\tTop5: 59.375 (avg: 58.750)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.702 (avg: 0.702)\tLoss: 3.1427 (avg: 2.9245)\tTop1: 31.250 (avg: 29.969)\tTop5: 54.688 (avg: 59.250)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.701 (avg: 0.705)\tLoss: 3.1826 (avg: 2.9212)\tTop1: 21.875 (avg: 30.083)\tTop5: 46.875 (avg: 58.896)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.702 (avg: 0.707)\tLoss: 2.9467 (avg: 2.9172)\tTop1: 25.000 (avg: 30.469)\tTop5: 54.688 (avg: 58.969)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.711 (avg: 0.708)\tLoss: 3.0702 (avg: 2.9357)\tTop1: 26.562 (avg: 30.325)\tTop5: 59.375 (avg: 58.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2632\tTop 1 accuracy: 16.400\tTop 5 accuracy: 36.900\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.706 (avg: 0.694)\tLoss: 2.7794 (avg: 2.7602)\tTop1: 25.000 (avg: 33.250)\tTop5: 54.688 (avg: 61.562)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.706 (avg: 0.703)\tLoss: 2.8432 (avg: 2.8387)\tTop1: 32.812 (avg: 32.625)\tTop5: 62.500 (avg: 60.000)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.711 (avg: 0.706)\tLoss: 2.6515 (avg: 2.8762)\tTop1: 35.938 (avg: 32.042)\tTop5: 64.062 (avg: 59.500)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.705 (avg: 0.707)\tLoss: 2.8660 (avg: 2.8726)\tTop1: 32.812 (avg: 32.156)\tTop5: 54.688 (avg: 59.578)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.703 (avg: 0.708)\tLoss: 3.3623 (avg: 2.8867)\tTop1: 21.875 (avg: 31.763)\tTop5: 40.625 (avg: 59.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.1127\tTop 1 accuracy: 15.650\tTop 5 accuracy: 36.350\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.701 (avg: 0.694)\tLoss: 2.6471 (avg: 2.8122)\tTop1: 37.500 (avg: 33.000)\tTop5: 67.188 (avg: 61.312)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.703 (avg: 0.703)\tLoss: 2.8669 (avg: 2.8134)\tTop1: 32.812 (avg: 32.562)\tTop5: 54.688 (avg: 60.750)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.700 (avg: 0.705)\tLoss: 2.9721 (avg: 2.8115)\tTop1: 28.125 (avg: 32.812)\tTop5: 62.500 (avg: 60.833)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.711 (avg: 0.706)\tLoss: 2.9413 (avg: 2.8329)\tTop1: 29.688 (avg: 32.266)\tTop5: 57.812 (avg: 60.609)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.700 (avg: 0.707)\tLoss: 2.9605 (avg: 2.8564)\tTop1: 31.250 (avg: 31.813)\tTop5: 62.500 (avg: 60.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.0215\tTop 1 accuracy: 16.050\tTop 5 accuracy: 36.300\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.704 (avg: 0.693)\tLoss: 2.6158 (avg: 2.7905)\tTop1: 35.938 (avg: 33.250)\tTop5: 65.625 (avg: 60.438)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.710 (avg: 0.702)\tLoss: 2.7068 (avg: 2.7974)\tTop1: 35.938 (avg: 33.469)\tTop5: 57.812 (avg: 61.125)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.699 (avg: 0.705)\tLoss: 2.8075 (avg: 2.8178)\tTop1: 29.688 (avg: 33.292)\tTop5: 59.375 (avg: 60.500)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.703 (avg: 0.706)\tLoss: 2.4399 (avg: 2.8115)\tTop1: 35.938 (avg: 33.203)\tTop5: 64.062 (avg: 60.578)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.705 (avg: 0.707)\tLoss: 3.0241 (avg: 2.8215)\tTop1: 26.562 (avg: 32.838)\tTop5: 50.000 (avg: 60.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2730\tTop 1 accuracy: 15.600\tTop 5 accuracy: 36.850\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.703 (avg: 0.693)\tLoss: 2.7214 (avg: 2.7553)\tTop1: 31.250 (avg: 32.625)\tTop5: 67.188 (avg: 62.812)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.704 (avg: 0.702)\tLoss: 2.5280 (avg: 2.7662)\tTop1: 34.375 (avg: 32.812)\tTop5: 67.188 (avg: 61.562)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.708 (avg: 0.705)\tLoss: 2.4853 (avg: 2.7718)\tTop1: 42.188 (avg: 32.979)\tTop5: 68.750 (avg: 61.792)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.699 (avg: 0.706)\tLoss: 2.7856 (avg: 2.7729)\tTop1: 39.062 (avg: 33.078)\tTop5: 68.750 (avg: 62.172)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.704 (avg: 0.707)\tLoss: 2.8730 (avg: 2.7760)\tTop1: 26.562 (avg: 32.900)\tTop5: 62.500 (avg: 62.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2323\tTop 1 accuracy: 16.150\tTop 5 accuracy: 37.350\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.702 (avg: 0.691)\tLoss: 2.8571 (avg: 2.6846)\tTop1: 28.125 (avg: 34.250)\tTop5: 54.688 (avg: 62.625)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.688 (avg: 0.701)\tLoss: 3.0102 (avg: 2.7264)\tTop1: 32.812 (avg: 33.719)\tTop5: 59.375 (avg: 62.312)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.701 (avg: 0.704)\tLoss: 2.8658 (avg: 2.7555)\tTop1: 32.812 (avg: 33.542)\tTop5: 60.938 (avg: 62.062)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.702 (avg: 0.705)\tLoss: 2.7858 (avg: 2.7481)\tTop1: 26.562 (avg: 33.484)\tTop5: 60.938 (avg: 61.938)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.708 (avg: 0.706)\tLoss: 2.5938 (avg: 2.7408)\tTop1: 42.188 (avg: 33.413)\tTop5: 59.375 (avg: 61.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3869\tTop 1 accuracy: 15.450\tTop 5 accuracy: 37.300\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.703 (avg: 0.694)\tLoss: 2.8580 (avg: 2.6794)\tTop1: 31.250 (avg: 36.812)\tTop5: 57.812 (avg: 64.062)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.709 (avg: 0.703)\tLoss: 2.6488 (avg: 2.6954)\tTop1: 32.812 (avg: 35.562)\tTop5: 71.875 (avg: 63.438)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.700 (avg: 0.705)\tLoss: 2.4387 (avg: 2.7017)\tTop1: 43.750 (avg: 35.521)\tTop5: 68.750 (avg: 63.000)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.701 (avg: 0.707)\tLoss: 2.6117 (avg: 2.6812)\tTop1: 40.625 (avg: 35.375)\tTop5: 68.750 (avg: 63.375)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.705 (avg: 0.707)\tLoss: 3.0339 (avg: 2.7037)\tTop1: 29.688 (avg: 34.863)\tTop5: 53.125 (avg: 62.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3531\tTop 1 accuracy: 15.800\tTop 5 accuracy: 37.250\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.701 (avg: 0.692)\tLoss: 2.6447 (avg: 2.6281)\tTop1: 34.375 (avg: 36.625)\tTop5: 62.500 (avg: 65.875)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.702 (avg: 0.703)\tLoss: 2.6719 (avg: 2.6199)\tTop1: 34.375 (avg: 36.094)\tTop5: 60.938 (avg: 65.531)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.704 (avg: 0.705)\tLoss: 2.1885 (avg: 2.6154)\tTop1: 37.500 (avg: 36.688)\tTop5: 71.875 (avg: 65.375)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.712 (avg: 0.707)\tLoss: 2.5393 (avg: 2.6311)\tTop1: 39.062 (avg: 36.359)\tTop5: 64.062 (avg: 65.281)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.703 (avg: 0.708)\tLoss: 2.7574 (avg: 2.6549)\tTop1: 40.625 (avg: 35.650)\tTop5: 62.500 (avg: 64.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3201\tTop 1 accuracy: 15.700\tTop 5 accuracy: 37.700\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.714 (avg: 0.694)\tLoss: 2.6077 (avg: 2.5986)\tTop1: 28.125 (avg: 36.500)\tTop5: 70.312 (avg: 66.500)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.699 (avg: 0.703)\tLoss: 2.6811 (avg: 2.5931)\tTop1: 40.625 (avg: 36.938)\tTop5: 64.062 (avg: 66.219)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.707 (avg: 0.706)\tLoss: 2.5384 (avg: 2.5874)\tTop1: 35.938 (avg: 37.708)\tTop5: 68.750 (avg: 66.188)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.701 (avg: 0.707)\tLoss: 2.2791 (avg: 2.5899)\tTop1: 45.312 (avg: 37.234)\tTop5: 67.188 (avg: 66.016)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.710 (avg: 0.708)\tLoss: 3.0582 (avg: 2.6062)\tTop1: 25.000 (avg: 36.700)\tTop5: 54.688 (avg: 65.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4192\tTop 1 accuracy: 16.150\tTop 5 accuracy: 35.900\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.705 (avg: 0.694)\tLoss: 2.7073 (avg: 2.5553)\tTop1: 35.938 (avg: 37.250)\tTop5: 64.062 (avg: 65.625)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.705 (avg: 0.703)\tLoss: 2.7517 (avg: 2.5633)\tTop1: 37.500 (avg: 38.438)\tTop5: 59.375 (avg: 65.656)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.709 (avg: 0.706)\tLoss: 2.2573 (avg: 2.5503)\tTop1: 51.562 (avg: 38.417)\tTop5: 68.750 (avg: 65.688)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.700 (avg: 0.708)\tLoss: 2.9580 (avg: 2.5720)\tTop1: 29.688 (avg: 37.766)\tTop5: 59.375 (avg: 65.312)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.704 (avg: 0.708)\tLoss: 2.7702 (avg: 2.5803)\tTop1: 29.688 (avg: 37.325)\tTop5: 62.500 (avg: 65.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.1999\tTop 1 accuracy: 15.450\tTop 5 accuracy: 36.600\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.701 (avg: 0.695)\tLoss: 2.1987 (avg: 2.4313)\tTop1: 45.312 (avg: 39.625)\tTop5: 73.438 (avg: 68.000)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.705 (avg: 0.704)\tLoss: 2.5109 (avg: 2.4478)\tTop1: 37.500 (avg: 38.906)\tTop5: 68.750 (avg: 67.438)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.705 (avg: 0.707)\tLoss: 2.7245 (avg: 2.4796)\tTop1: 31.250 (avg: 38.333)\tTop5: 54.688 (avg: 67.583)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.709 (avg: 0.708)\tLoss: 2.3220 (avg: 2.5071)\tTop1: 40.625 (avg: 37.656)\tTop5: 70.312 (avg: 67.094)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.711 (avg: 0.709)\tLoss: 2.5241 (avg: 2.5231)\tTop1: 37.500 (avg: 37.338)\tTop5: 60.938 (avg: 67.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5267\tTop 1 accuracy: 16.150\tTop 5 accuracy: 36.600\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.703 (avg: 0.694)\tLoss: 2.3731 (avg: 2.4015)\tTop1: 34.375 (avg: 39.312)\tTop5: 73.438 (avg: 69.625)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.710 (avg: 0.703)\tLoss: 2.6674 (avg: 2.4590)\tTop1: 32.812 (avg: 38.094)\tTop5: 59.375 (avg: 67.969)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.704 (avg: 0.706)\tLoss: 2.5778 (avg: 2.4848)\tTop1: 37.500 (avg: 37.792)\tTop5: 60.938 (avg: 67.417)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.702 (avg: 0.707)\tLoss: 2.7052 (avg: 2.5029)\tTop1: 43.750 (avg: 38.078)\tTop5: 67.188 (avg: 67.406)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.704 (avg: 0.708)\tLoss: 2.5663 (avg: 2.5048)\tTop1: 35.938 (avg: 38.288)\tTop5: 68.750 (avg: 67.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2993\tTop 1 accuracy: 16.350\tTop 5 accuracy: 36.200\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.704 (avg: 0.694)\tLoss: 2.5478 (avg: 2.3716)\tTop1: 42.188 (avg: 41.312)\tTop5: 60.938 (avg: 68.188)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.705 (avg: 0.703)\tLoss: 2.5255 (avg: 2.3931)\tTop1: 34.375 (avg: 40.531)\tTop5: 64.062 (avg: 68.406)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.703 (avg: 0.706)\tLoss: 2.2174 (avg: 2.4101)\tTop1: 40.625 (avg: 40.167)\tTop5: 75.000 (avg: 68.625)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.702 (avg: 0.708)\tLoss: 2.2718 (avg: 2.4285)\tTop1: 45.312 (avg: 39.953)\tTop5: 67.188 (avg: 68.562)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.704 (avg: 0.709)\tLoss: 2.8123 (avg: 2.4489)\tTop1: 34.375 (avg: 39.450)\tTop5: 56.250 (avg: 68.062)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5055\tTop 1 accuracy: 16.100\tTop 5 accuracy: 36.900\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.712 (avg: 0.695)\tLoss: 2.2750 (avg: 2.2820)\tTop1: 43.750 (avg: 42.000)\tTop5: 68.750 (avg: 71.062)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.704 (avg: 0.703)\tLoss: 2.2877 (avg: 2.3358)\tTop1: 37.500 (avg: 41.031)\tTop5: 78.125 (avg: 70.656)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.705 (avg: 0.706)\tLoss: 2.6594 (avg: 2.3575)\tTop1: 28.125 (avg: 40.479)\tTop5: 59.375 (avg: 70.458)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.708 (avg: 0.708)\tLoss: 2.4413 (avg: 2.3773)\tTop1: 45.312 (avg: 40.297)\tTop5: 70.312 (avg: 70.172)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.709 (avg: 0.709)\tLoss: 2.8576 (avg: 2.4007)\tTop1: 37.500 (avg: 39.800)\tTop5: 54.688 (avg: 69.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.1706\tTop 1 accuracy: 15.200\tTop 5 accuracy: 36.900\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.706 (avg: 0.695)\tLoss: 2.1488 (avg: 2.2228)\tTop1: 46.875 (avg: 44.000)\tTop5: 68.750 (avg: 73.688)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.709 (avg: 0.705)\tLoss: 2.3900 (avg: 2.3036)\tTop1: 37.500 (avg: 42.688)\tTop5: 76.562 (avg: 71.875)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.702 (avg: 0.707)\tLoss: 2.5509 (avg: 2.3142)\tTop1: 29.688 (avg: 41.958)\tTop5: 65.625 (avg: 71.729)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.704 (avg: 0.708)\tLoss: 2.5930 (avg: 2.3420)\tTop1: 34.375 (avg: 41.031)\tTop5: 73.438 (avg: 71.062)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.706 (avg: 0.709)\tLoss: 2.1349 (avg: 2.3536)\tTop1: 42.188 (avg: 40.700)\tTop5: 75.000 (avg: 70.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2582\tTop 1 accuracy: 15.000\tTop 5 accuracy: 37.000\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.706 (avg: 0.695)\tLoss: 1.8258 (avg: 2.2125)\tTop1: 54.688 (avg: 44.562)\tTop5: 81.250 (avg: 71.438)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.706 (avg: 0.703)\tLoss: 2.0127 (avg: 2.2648)\tTop1: 51.562 (avg: 42.438)\tTop5: 73.438 (avg: 71.281)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.700 (avg: 0.706)\tLoss: 2.5197 (avg: 2.2816)\tTop1: 40.625 (avg: 41.854)\tTop5: 75.000 (avg: 71.021)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.708 (avg: 0.708)\tLoss: 2.6836 (avg: 2.3176)\tTop1: 25.000 (avg: 40.922)\tTop5: 67.188 (avg: 70.641)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.702 (avg: 0.709)\tLoss: 2.6883 (avg: 2.3236)\tTop1: 31.250 (avg: 40.963)\tTop5: 60.938 (avg: 70.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2739\tTop 1 accuracy: 15.450\tTop 5 accuracy: 36.750\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.709 (avg: 0.695)\tLoss: 1.8935 (avg: 2.2006)\tTop1: 51.562 (avg: 43.250)\tTop5: 78.125 (avg: 72.875)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.698 (avg: 0.704)\tLoss: 2.5619 (avg: 2.2090)\tTop1: 39.062 (avg: 43.438)\tTop5: 62.500 (avg: 72.719)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.712 (avg: 0.707)\tLoss: 2.3010 (avg: 2.2351)\tTop1: 39.062 (avg: 43.188)\tTop5: 75.000 (avg: 72.458)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.705 (avg: 0.708)\tLoss: 2.5297 (avg: 2.2642)\tTop1: 34.375 (avg: 42.469)\tTop5: 65.625 (avg: 71.922)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.710 (avg: 0.709)\tLoss: 2.0255 (avg: 2.2647)\tTop1: 43.750 (avg: 42.500)\tTop5: 79.688 (avg: 72.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4276\tTop 1 accuracy: 15.750\tTop 5 accuracy: 36.700\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.705 (avg: 0.695)\tLoss: 2.2248 (avg: 2.0746)\tTop1: 42.188 (avg: 46.250)\tTop5: 71.875 (avg: 75.375)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.705 (avg: 0.704)\tLoss: 2.3909 (avg: 2.1396)\tTop1: 40.625 (avg: 45.625)\tTop5: 71.875 (avg: 75.062)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.711 (avg: 0.707)\tLoss: 2.1707 (avg: 2.1380)\tTop1: 37.500 (avg: 45.521)\tTop5: 73.438 (avg: 75.188)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.703 (avg: 0.708)\tLoss: 2.2298 (avg: 2.1787)\tTop1: 48.438 (avg: 44.531)\tTop5: 73.438 (avg: 74.344)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.705 (avg: 0.708)\tLoss: 2.1515 (avg: 2.2085)\tTop1: 46.875 (avg: 43.725)\tTop5: 73.438 (avg: 73.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5851\tTop 1 accuracy: 15.900\tTop 5 accuracy: 37.650\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.708 (avg: 0.696)\tLoss: 2.1560 (avg: 2.0092)\tTop1: 39.062 (avg: 48.312)\tTop5: 73.438 (avg: 77.375)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.707 (avg: 0.704)\tLoss: 2.3189 (avg: 2.0684)\tTop1: 43.750 (avg: 47.500)\tTop5: 75.000 (avg: 76.062)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.706 (avg: 0.707)\tLoss: 2.4425 (avg: 2.1202)\tTop1: 34.375 (avg: 46.000)\tTop5: 62.500 (avg: 75.125)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.705 (avg: 0.708)\tLoss: 1.9648 (avg: 2.1454)\tTop1: 51.562 (avg: 45.516)\tTop5: 78.125 (avg: 74.672)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.704 (avg: 0.709)\tLoss: 2.1816 (avg: 2.1626)\tTop1: 43.750 (avg: 44.875)\tTop5: 71.875 (avg: 74.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.1052\tTop 1 accuracy: 16.900\tTop 5 accuracy: 36.900\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.706 (avg: 0.694)\tLoss: 1.8735 (avg: 1.9889)\tTop1: 46.875 (avg: 48.250)\tTop5: 82.812 (avg: 78.438)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.711 (avg: 0.703)\tLoss: 2.1321 (avg: 2.0623)\tTop1: 43.750 (avg: 46.750)\tTop5: 79.688 (avg: 76.781)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.702 (avg: 0.705)\tLoss: 1.8153 (avg: 2.1006)\tTop1: 51.562 (avg: 46.167)\tTop5: 81.250 (avg: 76.104)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.701 (avg: 0.706)\tLoss: 2.2640 (avg: 2.1277)\tTop1: 40.625 (avg: 45.422)\tTop5: 76.562 (avg: 75.531)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.705 (avg: 0.707)\tLoss: 2.7507 (avg: 2.1368)\tTop1: 31.250 (avg: 45.113)\tTop5: 64.062 (avg: 75.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3529\tTop 1 accuracy: 15.150\tTop 5 accuracy: 35.850\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.707 (avg: 0.694)\tLoss: 1.9288 (avg: 1.9408)\tTop1: 46.875 (avg: 51.000)\tTop5: 78.125 (avg: 77.812)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.703 (avg: 0.703)\tLoss: 1.9301 (avg: 2.0283)\tTop1: 53.125 (avg: 48.531)\tTop5: 75.000 (avg: 76.531)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.711 (avg: 0.706)\tLoss: 2.1392 (avg: 2.0570)\tTop1: 42.188 (avg: 47.229)\tTop5: 76.562 (avg: 76.292)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.704 (avg: 0.707)\tLoss: 1.5444 (avg: 2.0661)\tTop1: 53.125 (avg: 46.406)\tTop5: 85.938 (avg: 76.250)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.705 (avg: 0.708)\tLoss: 2.0665 (avg: 2.0717)\tTop1: 46.875 (avg: 46.663)\tTop5: 75.000 (avg: 76.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9811\tTop 1 accuracy: 15.150\tTop 5 accuracy: 35.150\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.706 (avg: 0.694)\tLoss: 1.9886 (avg: 1.9236)\tTop1: 40.625 (avg: 50.375)\tTop5: 79.688 (avg: 78.625)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.699 (avg: 0.702)\tLoss: 1.9994 (avg: 1.9491)\tTop1: 51.562 (avg: 49.781)\tTop5: 71.875 (avg: 78.031)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.702 (avg: 0.705)\tLoss: 2.3480 (avg: 1.9913)\tTop1: 40.625 (avg: 48.438)\tTop5: 67.188 (avg: 77.229)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.702 (avg: 0.706)\tLoss: 1.9624 (avg: 2.0225)\tTop1: 45.312 (avg: 48.000)\tTop5: 79.688 (avg: 76.672)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.709 (avg: 0.707)\tLoss: 1.6774 (avg: 2.0237)\tTop1: 56.250 (avg: 47.975)\tTop5: 78.125 (avg: 76.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3262\tTop 1 accuracy: 16.150\tTop 5 accuracy: 36.350\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.705 (avg: 0.694)\tLoss: 2.0394 (avg: 1.7985)\tTop1: 45.312 (avg: 53.750)\tTop5: 79.688 (avg: 82.000)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.706 (avg: 0.703)\tLoss: 1.9344 (avg: 1.8869)\tTop1: 45.312 (avg: 51.562)\tTop5: 81.250 (avg: 79.969)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.698 (avg: 0.705)\tLoss: 1.6283 (avg: 1.9339)\tTop1: 59.375 (avg: 50.062)\tTop5: 84.375 (avg: 78.875)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.700 (avg: 0.707)\tLoss: 1.9894 (avg: 1.9515)\tTop1: 43.750 (avg: 49.562)\tTop5: 84.375 (avg: 78.469)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.710 (avg: 0.708)\tLoss: 1.7706 (avg: 1.9669)\tTop1: 54.688 (avg: 48.900)\tTop5: 81.250 (avg: 78.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7252\tTop 1 accuracy: 15.700\tTop 5 accuracy: 36.400\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.700 (avg: 0.692)\tLoss: 1.8600 (avg: 1.8873)\tTop1: 48.438 (avg: 51.000)\tTop5: 78.125 (avg: 79.250)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.706 (avg: 0.701)\tLoss: 1.7743 (avg: 1.8537)\tTop1: 57.812 (avg: 51.250)\tTop5: 78.125 (avg: 79.969)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.705 (avg: 0.705)\tLoss: 1.9508 (avg: 1.8628)\tTop1: 51.562 (avg: 50.958)\tTop5: 79.688 (avg: 79.854)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.703 (avg: 0.706)\tLoss: 2.3010 (avg: 1.9009)\tTop1: 46.875 (avg: 49.953)\tTop5: 75.000 (avg: 79.172)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.697 (avg: 0.707)\tLoss: 2.1354 (avg: 1.9296)\tTop1: 39.062 (avg: 49.225)\tTop5: 73.438 (avg: 78.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2407\tTop 1 accuracy: 15.900\tTop 5 accuracy: 36.200\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.707 (avg: 0.694)\tLoss: 1.8500 (avg: 1.7547)\tTop1: 53.125 (avg: 54.688)\tTop5: 78.125 (avg: 81.688)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.697 (avg: 0.703)\tLoss: 1.9703 (avg: 1.7959)\tTop1: 43.750 (avg: 52.625)\tTop5: 84.375 (avg: 81.281)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.703 (avg: 0.706)\tLoss: 1.8010 (avg: 1.8265)\tTop1: 50.000 (avg: 51.562)\tTop5: 78.125 (avg: 80.604)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.703 (avg: 0.707)\tLoss: 2.3299 (avg: 1.8562)\tTop1: 48.438 (avg: 50.969)\tTop5: 67.188 (avg: 79.953)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.708 (avg: 0.708)\tLoss: 2.2598 (avg: 1.8717)\tTop1: 42.188 (avg: 50.350)\tTop5: 70.312 (avg: 79.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5132\tTop 1 accuracy: 15.900\tTop 5 accuracy: 37.450\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.702 (avg: 0.692)\tLoss: 1.5149 (avg: 1.6710)\tTop1: 57.812 (avg: 56.500)\tTop5: 85.938 (avg: 83.875)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.705 (avg: 0.701)\tLoss: 1.9874 (avg: 1.7010)\tTop1: 48.438 (avg: 54.938)\tTop5: 73.438 (avg: 82.938)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.711 (avg: 0.705)\tLoss: 1.9004 (avg: 1.7774)\tTop1: 48.438 (avg: 52.521)\tTop5: 78.125 (avg: 81.479)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.699 (avg: 0.707)\tLoss: 1.4732 (avg: 1.7978)\tTop1: 60.938 (avg: 51.703)\tTop5: 87.500 (avg: 81.156)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.705 (avg: 0.707)\tLoss: 1.9506 (avg: 1.8260)\tTop1: 46.875 (avg: 51.338)\tTop5: 82.812 (avg: 80.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7078\tTop 1 accuracy: 15.150\tTop 5 accuracy: 35.950\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.704 (avg: 0.694)\tLoss: 1.2906 (avg: 1.5378)\tTop1: 71.875 (avg: 58.938)\tTop5: 92.188 (avg: 85.250)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.710 (avg: 0.703)\tLoss: 1.1924 (avg: 1.4689)\tTop1: 68.750 (avg: 61.625)\tTop5: 95.312 (avg: 86.188)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.707 (avg: 0.706)\tLoss: 1.6081 (avg: 1.4594)\tTop1: 56.250 (avg: 62.292)\tTop5: 84.375 (avg: 86.312)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.703 (avg: 0.707)\tLoss: 1.1952 (avg: 1.4365)\tTop1: 65.625 (avg: 62.641)\tTop5: 92.188 (avg: 86.688)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.705 (avg: 0.708)\tLoss: 1.0655 (avg: 1.4273)\tTop1: 62.500 (avg: 62.825)\tTop5: 93.750 (avg: 86.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7302\tTop 1 accuracy: 17.300\tTop 5 accuracy: 38.400\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.708 (avg: 0.694)\tLoss: 1.0538 (avg: 1.2652)\tTop1: 65.625 (avg: 68.188)\tTop5: 90.625 (avg: 87.938)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.708 (avg: 0.703)\tLoss: 1.0835 (avg: 1.2561)\tTop1: 67.188 (avg: 67.531)\tTop5: 92.188 (avg: 88.469)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.701 (avg: 0.706)\tLoss: 1.2633 (avg: 1.2591)\tTop1: 73.438 (avg: 67.708)\tTop5: 85.938 (avg: 88.188)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.704 (avg: 0.707)\tLoss: 1.4217 (avg: 1.2842)\tTop1: 65.625 (avg: 66.891)\tTop5: 84.375 (avg: 87.797)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.702 (avg: 0.708)\tLoss: 1.2362 (avg: 1.2892)\tTop1: 65.625 (avg: 66.688)\tTop5: 87.500 (avg: 87.813)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7688\tTop 1 accuracy: 17.350\tTop 5 accuracy: 38.050\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.705 (avg: 0.695)\tLoss: 1.0930 (avg: 1.2663)\tTop1: 71.875 (avg: 67.500)\tTop5: 90.625 (avg: 87.000)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.704 (avg: 0.703)\tLoss: 1.4957 (avg: 1.2554)\tTop1: 64.062 (avg: 67.938)\tTop5: 84.375 (avg: 87.719)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.710 (avg: 0.707)\tLoss: 1.2668 (avg: 1.2410)\tTop1: 68.750 (avg: 68.062)\tTop5: 85.938 (avg: 88.000)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.703 (avg: 0.708)\tLoss: 1.1953 (avg: 1.2479)\tTop1: 71.875 (avg: 67.672)\tTop5: 92.188 (avg: 88.250)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.706 (avg: 0.709)\tLoss: 1.0832 (avg: 1.2461)\tTop1: 71.875 (avg: 67.675)\tTop5: 87.500 (avg: 88.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9306\tTop 1 accuracy: 17.300\tTop 5 accuracy: 38.150\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.709 (avg: 0.693)\tLoss: 0.9168 (avg: 1.1465)\tTop1: 75.000 (avg: 70.188)\tTop5: 95.312 (avg: 90.125)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.704 (avg: 0.702)\tLoss: 1.1423 (avg: 1.1850)\tTop1: 65.625 (avg: 69.406)\tTop5: 93.750 (avg: 89.688)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.707 (avg: 0.705)\tLoss: 1.0941 (avg: 1.1892)\tTop1: 75.000 (avg: 68.875)\tTop5: 93.750 (avg: 89.417)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.709 (avg: 0.706)\tLoss: 1.1659 (avg: 1.2062)\tTop1: 65.625 (avg: 68.594)\tTop5: 92.188 (avg: 89.172)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.708 (avg: 0.707)\tLoss: 1.2110 (avg: 1.2126)\tTop1: 62.500 (avg: 68.400)\tTop5: 89.062 (avg: 89.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9280\tTop 1 accuracy: 17.250\tTop 5 accuracy: 37.100\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.712 (avg: 0.694)\tLoss: 1.1065 (avg: 1.1977)\tTop1: 65.625 (avg: 69.312)\tTop5: 93.750 (avg: 88.625)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.712 (avg: 0.705)\tLoss: 1.3013 (avg: 1.2303)\tTop1: 56.250 (avg: 68.312)\tTop5: 95.312 (avg: 88.250)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.703 (avg: 0.708)\tLoss: 1.4084 (avg: 1.2013)\tTop1: 60.938 (avg: 68.708)\tTop5: 82.812 (avg: 88.979)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.697 (avg: 0.710)\tLoss: 0.9390 (avg: 1.1894)\tTop1: 68.750 (avg: 69.078)\tTop5: 92.188 (avg: 89.078)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.711 (avg: 0.711)\tLoss: 1.0829 (avg: 1.2013)\tTop1: 70.312 (avg: 68.825)\tTop5: 92.188 (avg: 88.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8976\tTop 1 accuracy: 17.100\tTop 5 accuracy: 37.500\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.696 (avg: 0.695)\tLoss: 1.2378 (avg: 1.1212)\tTop1: 70.312 (avg: 70.812)\tTop5: 87.500 (avg: 89.875)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.706 (avg: 0.704)\tLoss: 1.1400 (avg: 1.1467)\tTop1: 67.188 (avg: 70.250)\tTop5: 93.750 (avg: 89.812)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.711 (avg: 0.708)\tLoss: 1.2014 (avg: 1.1593)\tTop1: 70.312 (avg: 69.958)\tTop5: 84.375 (avg: 89.500)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.716 (avg: 0.710)\tLoss: 0.8883 (avg: 1.1752)\tTop1: 71.875 (avg: 69.672)\tTop5: 92.188 (avg: 89.359)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.702 (avg: 0.711)\tLoss: 1.1191 (avg: 1.1786)\tTop1: 70.312 (avg: 69.500)\tTop5: 89.062 (avg: 89.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0807\tTop 1 accuracy: 16.950\tTop 5 accuracy: 37.450\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.714 (avg: 0.696)\tLoss: 1.7217 (avg: 1.1578)\tTop1: 62.500 (avg: 69.875)\tTop5: 78.125 (avg: 89.375)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.703 (avg: 0.706)\tLoss: 1.2113 (avg: 1.1636)\tTop1: 67.188 (avg: 69.406)\tTop5: 87.500 (avg: 89.438)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.716 (avg: 0.709)\tLoss: 1.0773 (avg: 1.1402)\tTop1: 75.000 (avg: 70.000)\tTop5: 90.625 (avg: 89.667)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.702 (avg: 0.710)\tLoss: 1.1964 (avg: 1.1578)\tTop1: 62.500 (avg: 69.719)\tTop5: 89.062 (avg: 89.562)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.717 (avg: 0.711)\tLoss: 1.4586 (avg: 1.1575)\tTop1: 56.250 (avg: 69.538)\tTop5: 85.938 (avg: 89.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2865\tTop 1 accuracy: 17.350\tTop 5 accuracy: 37.200\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.704 (avg: 0.693)\tLoss: 1.0400 (avg: 1.1510)\tTop1: 75.000 (avg: 69.438)\tTop5: 90.625 (avg: 89.875)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.708 (avg: 0.703)\tLoss: 1.0371 (avg: 1.1027)\tTop1: 76.562 (avg: 70.750)\tTop5: 90.625 (avg: 90.531)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.712 (avg: 0.706)\tLoss: 1.2880 (avg: 1.1045)\tTop1: 68.750 (avg: 70.625)\tTop5: 84.375 (avg: 90.375)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.706 (avg: 0.708)\tLoss: 1.0666 (avg: 1.1292)\tTop1: 68.750 (avg: 70.172)\tTop5: 92.188 (avg: 90.031)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.709 (avg: 0.709)\tLoss: 1.5262 (avg: 1.1301)\tTop1: 60.938 (avg: 70.038)\tTop5: 82.812 (avg: 90.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3565\tTop 1 accuracy: 17.450\tTop 5 accuracy: 37.000\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.700 (avg: 0.696)\tLoss: 0.8930 (avg: 1.0830)\tTop1: 76.562 (avg: 71.375)\tTop5: 90.625 (avg: 90.125)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.705 (avg: 0.705)\tLoss: 1.4188 (avg: 1.0981)\tTop1: 68.750 (avg: 71.125)\tTop5: 82.812 (avg: 90.375)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.708 (avg: 0.708)\tLoss: 0.8473 (avg: 1.1102)\tTop1: 76.562 (avg: 70.771)\tTop5: 92.188 (avg: 90.083)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.714 (avg: 0.710)\tLoss: 0.9047 (avg: 1.1128)\tTop1: 76.562 (avg: 70.812)\tTop5: 90.625 (avg: 89.906)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.703 (avg: 0.710)\tLoss: 1.1662 (avg: 1.1274)\tTop1: 73.438 (avg: 70.400)\tTop5: 90.625 (avg: 89.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1275\tTop 1 accuracy: 16.600\tTop 5 accuracy: 37.150\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.702 (avg: 0.695)\tLoss: 1.0563 (avg: 1.0833)\tTop1: 71.875 (avg: 71.812)\tTop5: 87.500 (avg: 90.938)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.708 (avg: 0.704)\tLoss: 1.2333 (avg: 1.0924)\tTop1: 70.312 (avg: 71.688)\tTop5: 87.500 (avg: 90.875)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.702 (avg: 0.707)\tLoss: 1.1748 (avg: 1.0946)\tTop1: 68.750 (avg: 71.188)\tTop5: 85.938 (avg: 90.521)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.702 (avg: 0.708)\tLoss: 0.8914 (avg: 1.1000)\tTop1: 76.562 (avg: 71.125)\tTop5: 93.750 (avg: 90.391)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.709 (avg: 0.709)\tLoss: 1.0278 (avg: 1.1087)\tTop1: 75.000 (avg: 70.650)\tTop5: 89.062 (avg: 90.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9453\tTop 1 accuracy: 16.450\tTop 5 accuracy: 37.100\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.702 (avg: 0.692)\tLoss: 0.8753 (avg: 1.0576)\tTop1: 71.875 (avg: 72.438)\tTop5: 93.750 (avg: 90.938)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.711 (avg: 0.703)\tLoss: 0.9443 (avg: 1.0651)\tTop1: 71.875 (avg: 71.781)\tTop5: 93.750 (avg: 90.594)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.708 (avg: 0.707)\tLoss: 1.0228 (avg: 1.0750)\tTop1: 75.000 (avg: 71.500)\tTop5: 90.625 (avg: 90.417)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.703 (avg: 0.708)\tLoss: 0.8768 (avg: 1.0837)\tTop1: 75.000 (avg: 70.984)\tTop5: 95.312 (avg: 90.438)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.707 (avg: 0.710)\tLoss: 0.8239 (avg: 1.0924)\tTop1: 79.688 (avg: 70.738)\tTop5: 95.312 (avg: 90.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5546\tTop 1 accuracy: 17.000\tTop 5 accuracy: 36.900\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.713 (avg: 0.696)\tLoss: 1.0807 (avg: 0.9712)\tTop1: 68.750 (avg: 74.812)\tTop5: 90.625 (avg: 91.750)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.704 (avg: 0.705)\tLoss: 0.8308 (avg: 1.0248)\tTop1: 71.875 (avg: 72.844)\tTop5: 100.000 (avg: 91.312)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.708 (avg: 0.708)\tLoss: 1.0287 (avg: 1.0355)\tTop1: 68.750 (avg: 72.792)\tTop5: 90.625 (avg: 91.062)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.710 (avg: 0.709)\tLoss: 1.0410 (avg: 1.0576)\tTop1: 65.625 (avg: 72.141)\tTop5: 92.188 (avg: 90.609)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.708 (avg: 0.710)\tLoss: 1.2479 (avg: 1.0773)\tTop1: 67.188 (avg: 71.600)\tTop5: 87.500 (avg: 90.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2584\tTop 1 accuracy: 16.700\tTop 5 accuracy: 37.250\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.706 (avg: 0.696)\tLoss: 1.0287 (avg: 1.0682)\tTop1: 75.000 (avg: 71.812)\tTop5: 89.062 (avg: 90.562)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.713 (avg: 0.706)\tLoss: 1.0721 (avg: 1.0608)\tTop1: 71.875 (avg: 71.531)\tTop5: 90.625 (avg: 90.938)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.702 (avg: 0.709)\tLoss: 0.7496 (avg: 1.0613)\tTop1: 84.375 (avg: 71.792)\tTop5: 95.312 (avg: 91.146)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.700 (avg: 0.710)\tLoss: 1.0747 (avg: 1.0569)\tTop1: 70.312 (avg: 71.672)\tTop5: 89.062 (avg: 91.141)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.704 (avg: 0.711)\tLoss: 0.9520 (avg: 1.0706)\tTop1: 71.875 (avg: 71.325)\tTop5: 93.750 (avg: 90.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3891\tTop 1 accuracy: 16.450\tTop 5 accuracy: 36.800\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.699 (avg: 0.694)\tLoss: 1.0431 (avg: 1.0352)\tTop1: 65.625 (avg: 72.125)\tTop5: 92.188 (avg: 90.750)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.706 (avg: 0.703)\tLoss: 0.8371 (avg: 1.0125)\tTop1: 82.812 (avg: 73.156)\tTop5: 92.188 (avg: 91.281)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.712 (avg: 0.707)\tLoss: 1.3605 (avg: 1.0386)\tTop1: 67.188 (avg: 72.458)\tTop5: 87.500 (avg: 91.021)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.717 (avg: 0.708)\tLoss: 0.9479 (avg: 1.0457)\tTop1: 76.562 (avg: 72.500)\tTop5: 93.750 (avg: 91.000)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.708 (avg: 0.710)\tLoss: 0.9565 (avg: 1.0463)\tTop1: 78.125 (avg: 72.363)\tTop5: 96.875 (avg: 91.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4316\tTop 1 accuracy: 16.500\tTop 5 accuracy: 36.900\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.711 (avg: 0.697)\tLoss: 1.0382 (avg: 0.9801)\tTop1: 73.438 (avg: 73.812)\tTop5: 89.062 (avg: 91.375)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.709 (avg: 0.706)\tLoss: 0.8711 (avg: 0.9939)\tTop1: 76.562 (avg: 73.250)\tTop5: 92.188 (avg: 91.375)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.708 (avg: 0.709)\tLoss: 0.8335 (avg: 0.9932)\tTop1: 76.562 (avg: 73.646)\tTop5: 95.312 (avg: 91.667)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.710 (avg: 0.710)\tLoss: 0.8633 (avg: 1.0266)\tTop1: 78.125 (avg: 72.719)\tTop5: 93.750 (avg: 91.172)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.708 (avg: 0.711)\tLoss: 1.1468 (avg: 1.0305)\tTop1: 73.438 (avg: 72.638)\tTop5: 89.062 (avg: 91.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3777\tTop 1 accuracy: 16.950\tTop 5 accuracy: 36.850\n",
            "\n",
            "SR = 0.75: top1 = 17.30000114440918\ttop5 = 38.400001525878906\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.824 (avg: 1.171)\tLoss: 5.2988 (avg: 5.3161)\tTop1: 3.125 (avg: 0.375)\tTop5: 3.125 (avg: 1.750)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.828 (avg: 1.001)\tLoss: 5.3045 (avg: 5.3073)\tTop1: 0.000 (avg: 0.469)\tTop5: 3.125 (avg: 1.969)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.816 (avg: 0.944)\tLoss: 5.2883 (avg: 5.3041)\tTop1: 1.562 (avg: 0.500)\tTop5: 3.125 (avg: 2.125)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.823 (avg: 0.916)\tLoss: 5.2808 (avg: 5.3011)\tTop1: 1.562 (avg: 0.547)\tTop5: 4.688 (avg: 2.344)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.824 (avg: 0.899)\tLoss: 5.2617 (avg: 5.2962)\tTop1: 0.000 (avg: 0.562)\tTop5: 6.250 (avg: 2.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2877\tTop 1 accuracy: 0.900\tTop 5 accuracy: 3.400\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.825 (avg: 0.807)\tLoss: 5.2798 (avg: 5.2752)\tTop1: 0.000 (avg: 0.625)\tTop5: 1.562 (avg: 3.688)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.819 (avg: 0.818)\tLoss: 5.3947 (avg: 5.2648)\tTop1: 0.000 (avg: 0.812)\tTop5: 0.000 (avg: 4.031)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.817 (avg: 0.822)\tLoss: 5.2604 (avg: 5.2643)\tTop1: 1.562 (avg: 0.812)\tTop5: 4.688 (avg: 4.083)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.821 (avg: 0.824)\tLoss: 5.1652 (avg: 5.2576)\tTop1: 1.562 (avg: 0.859)\tTop5: 10.938 (avg: 4.281)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.822 (avg: 0.825)\tLoss: 5.2482 (avg: 5.2545)\tTop1: 0.000 (avg: 0.863)\tTop5: 1.562 (avg: 4.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1803\tTop 1 accuracy: 0.950\tTop 5 accuracy: 4.800\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.819 (avg: 0.807)\tLoss: 5.1296 (avg: 5.2100)\tTop1: 3.125 (avg: 1.000)\tTop5: 10.938 (avg: 6.000)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.823 (avg: 0.818)\tLoss: 5.1281 (avg: 5.2086)\tTop1: 1.562 (avg: 1.156)\tTop5: 14.062 (avg: 6.094)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.818 (avg: 0.822)\tLoss: 5.1563 (avg: 5.2115)\tTop1: 4.688 (avg: 1.271)\tTop5: 6.250 (avg: 5.979)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.821 (avg: 0.823)\tLoss: 5.1694 (avg: 5.2084)\tTop1: 3.125 (avg: 1.344)\tTop5: 6.250 (avg: 5.984)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.822 (avg: 0.824)\tLoss: 5.1956 (avg: 5.2067)\tTop1: 0.000 (avg: 1.263)\tTop5: 3.125 (avg: 6.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1033\tTop 1 accuracy: 1.650\tTop 5 accuracy: 7.400\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.824 (avg: 0.805)\tLoss: 5.1032 (avg: 5.1463)\tTop1: 1.562 (avg: 1.750)\tTop5: 9.375 (avg: 6.688)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.817 (avg: 0.816)\tLoss: 5.1570 (avg: 5.1701)\tTop1: 1.562 (avg: 1.438)\tTop5: 7.812 (avg: 6.719)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.820 (avg: 0.820)\tLoss: 5.1927 (avg: 5.1617)\tTop1: 0.000 (avg: 1.479)\tTop5: 6.250 (avg: 6.875)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.825 (avg: 0.821)\tLoss: 5.3104 (avg: 5.1579)\tTop1: 0.000 (avg: 1.453)\tTop5: 1.562 (avg: 7.031)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.818 (avg: 0.822)\tLoss: 5.2058 (avg: 5.1496)\tTop1: 3.125 (avg: 1.538)\tTop5: 6.250 (avg: 7.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0924\tTop 1 accuracy: 1.900\tTop 5 accuracy: 7.650\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.819 (avg: 0.808)\tLoss: 5.0468 (avg: 5.1452)\tTop1: 7.812 (avg: 2.750)\tTop5: 10.938 (avg: 7.625)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.820 (avg: 0.818)\tLoss: 5.0588 (avg: 5.1344)\tTop1: 1.562 (avg: 2.281)\tTop5: 9.375 (avg: 7.750)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.824 (avg: 0.822)\tLoss: 4.9866 (avg: 5.1100)\tTop1: 3.125 (avg: 2.229)\tTop5: 10.938 (avg: 7.896)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.827 (avg: 0.824)\tLoss: 5.0286 (avg: 5.1085)\tTop1: 1.562 (avg: 2.203)\tTop5: 14.062 (avg: 8.156)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.821 (avg: 0.825)\tLoss: 5.2014 (avg: 5.1068)\tTop1: 0.000 (avg: 2.125)\tTop5: 3.125 (avg: 8.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0707\tTop 1 accuracy: 2.200\tTop 5 accuracy: 10.050\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.823 (avg: 0.813)\tLoss: 4.7911 (avg: 5.0507)\tTop1: 1.562 (avg: 1.938)\tTop5: 9.375 (avg: 8.500)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.826 (avg: 0.824)\tLoss: 4.9515 (avg: 5.0537)\tTop1: 4.688 (avg: 2.312)\tTop5: 12.500 (avg: 8.844)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.831 (avg: 0.827)\tLoss: 5.0683 (avg: 5.0523)\tTop1: 3.125 (avg: 2.396)\tTop5: 9.375 (avg: 8.979)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.822 (avg: 0.829)\tLoss: 5.1089 (avg: 5.0516)\tTop1: 0.000 (avg: 2.281)\tTop5: 6.250 (avg: 9.031)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.827 (avg: 0.830)\tLoss: 4.9164 (avg: 5.0484)\tTop1: 0.000 (avg: 2.163)\tTop5: 7.812 (avg: 8.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8287\tTop 1 accuracy: 2.850\tTop 5 accuracy: 11.300\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.829 (avg: 0.814)\tLoss: 4.9506 (avg: 4.9950)\tTop1: 10.938 (avg: 2.688)\tTop5: 17.188 (avg: 10.250)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.829 (avg: 0.823)\tLoss: 5.2004 (avg: 5.0122)\tTop1: 0.000 (avg: 2.125)\tTop5: 4.688 (avg: 9.406)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.833 (avg: 0.827)\tLoss: 5.0459 (avg: 5.0079)\tTop1: 3.125 (avg: 2.479)\tTop5: 6.250 (avg: 9.917)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.828 (avg: 0.829)\tLoss: 5.0238 (avg: 5.0096)\tTop1: 4.688 (avg: 2.406)\tTop5: 7.812 (avg: 9.844)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.825 (avg: 0.830)\tLoss: 4.9591 (avg: 5.0067)\tTop1: 3.125 (avg: 2.338)\tTop5: 17.188 (avg: 10.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8856\tTop 1 accuracy: 2.900\tTop 5 accuracy: 11.250\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.821 (avg: 0.808)\tLoss: 4.8623 (avg: 4.9431)\tTop1: 1.562 (avg: 2.500)\tTop5: 10.938 (avg: 10.625)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.821 (avg: 0.818)\tLoss: 4.9212 (avg: 4.9694)\tTop1: 1.562 (avg: 2.594)\tTop5: 10.938 (avg: 10.250)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.823 (avg: 0.821)\tLoss: 5.0059 (avg: 4.9523)\tTop1: 0.000 (avg: 2.667)\tTop5: 18.750 (avg: 10.771)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.816 (avg: 0.823)\tLoss: 4.9964 (avg: 4.9586)\tTop1: 0.000 (avg: 2.625)\tTop5: 6.250 (avg: 10.859)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.821 (avg: 0.824)\tLoss: 5.0713 (avg: 4.9544)\tTop1: 1.562 (avg: 2.650)\tTop5: 7.812 (avg: 10.950)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8135\tTop 1 accuracy: 2.700\tTop 5 accuracy: 12.650\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.828 (avg: 0.811)\tLoss: 4.7769 (avg: 4.8785)\tTop1: 1.562 (avg: 3.438)\tTop5: 15.625 (avg: 11.938)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.822 (avg: 0.820)\tLoss: 4.6850 (avg: 4.8682)\tTop1: 6.250 (avg: 3.344)\tTop5: 9.375 (avg: 12.188)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.821 (avg: 0.824)\tLoss: 4.9369 (avg: 4.8866)\tTop1: 1.562 (avg: 3.250)\tTop5: 7.812 (avg: 11.979)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.826 (avg: 0.826)\tLoss: 4.8316 (avg: 4.8806)\tTop1: 4.688 (avg: 3.234)\tTop5: 17.188 (avg: 12.141)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.816 (avg: 0.826)\tLoss: 4.7552 (avg: 4.8753)\tTop1: 4.688 (avg: 3.225)\tTop5: 17.188 (avg: 12.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7661\tTop 1 accuracy: 3.850\tTop 5 accuracy: 13.100\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.821 (avg: 0.809)\tLoss: 4.7463 (avg: 4.8165)\tTop1: 3.125 (avg: 3.688)\tTop5: 14.062 (avg: 14.000)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.829 (avg: 0.820)\tLoss: 4.9324 (avg: 4.8414)\tTop1: 6.250 (avg: 3.781)\tTop5: 14.062 (avg: 14.000)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.824 (avg: 0.824)\tLoss: 4.8315 (avg: 4.8283)\tTop1: 3.125 (avg: 3.833)\tTop5: 14.062 (avg: 13.896)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.828 (avg: 0.826)\tLoss: 4.9071 (avg: 4.8199)\tTop1: 3.125 (avg: 3.891)\tTop5: 9.375 (avg: 14.016)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.826 (avg: 0.827)\tLoss: 4.8774 (avg: 4.8173)\tTop1: 3.125 (avg: 3.825)\tTop5: 12.500 (avg: 14.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8163\tTop 1 accuracy: 3.250\tTop 5 accuracy: 13.500\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.821 (avg: 0.808)\tLoss: 4.6665 (avg: 4.7932)\tTop1: 1.562 (avg: 3.000)\tTop5: 17.188 (avg: 14.625)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.821 (avg: 0.819)\tLoss: 4.6529 (avg: 4.7604)\tTop1: 4.688 (avg: 3.812)\tTop5: 18.750 (avg: 15.000)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.826 (avg: 0.823)\tLoss: 4.8590 (avg: 4.7615)\tTop1: 4.688 (avg: 4.083)\tTop5: 20.312 (avg: 14.750)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.826 (avg: 0.825)\tLoss: 4.7359 (avg: 4.7709)\tTop1: 4.688 (avg: 3.953)\tTop5: 18.750 (avg: 14.766)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.809 (avg: 0.826)\tLoss: 4.7509 (avg: 4.7632)\tTop1: 4.688 (avg: 3.925)\tTop5: 15.625 (avg: 15.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6716\tTop 1 accuracy: 3.750\tTop 5 accuracy: 15.100\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.816 (avg: 0.806)\tLoss: 4.6699 (avg: 4.6483)\tTop1: 7.812 (avg: 4.625)\tTop5: 17.188 (avg: 17.000)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.827 (avg: 0.817)\tLoss: 4.4016 (avg: 4.6523)\tTop1: 1.562 (avg: 4.844)\tTop5: 17.188 (avg: 16.875)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.812 (avg: 0.819)\tLoss: 4.6689 (avg: 4.6683)\tTop1: 3.125 (avg: 4.833)\tTop5: 9.375 (avg: 16.792)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.822 (avg: 0.821)\tLoss: 4.7209 (avg: 4.6986)\tTop1: 4.688 (avg: 4.609)\tTop5: 10.938 (avg: 16.328)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.824 (avg: 0.822)\tLoss: 4.7449 (avg: 4.6878)\tTop1: 4.688 (avg: 4.725)\tTop5: 14.062 (avg: 16.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9109\tTop 1 accuracy: 4.350\tTop 5 accuracy: 14.700\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.825 (avg: 0.808)\tLoss: 4.6682 (avg: 4.6486)\tTop1: 6.250 (avg: 5.250)\tTop5: 14.062 (avg: 18.125)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.828 (avg: 0.819)\tLoss: 4.7241 (avg: 4.6327)\tTop1: 1.562 (avg: 5.281)\tTop5: 9.375 (avg: 18.312)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.829 (avg: 0.823)\tLoss: 4.6394 (avg: 4.6247)\tTop1: 3.125 (avg: 5.312)\tTop5: 20.312 (avg: 18.604)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.828 (avg: 0.825)\tLoss: 4.6548 (avg: 4.6157)\tTop1: 3.125 (avg: 5.438)\tTop5: 15.625 (avg: 18.766)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.825 (avg: 0.826)\tLoss: 4.3903 (avg: 4.6208)\tTop1: 9.375 (avg: 5.238)\tTop5: 28.125 (avg: 18.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9945\tTop 1 accuracy: 5.800\tTop 5 accuracy: 18.100\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.829 (avg: 0.817)\tLoss: 4.6596 (avg: 4.5226)\tTop1: 4.688 (avg: 6.250)\tTop5: 15.625 (avg: 21.688)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.835 (avg: 0.828)\tLoss: 4.4994 (avg: 4.5189)\tTop1: 3.125 (avg: 6.062)\tTop5: 23.438 (avg: 21.688)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.828 (avg: 0.830)\tLoss: 4.4506 (avg: 4.5262)\tTop1: 6.250 (avg: 5.896)\tTop5: 29.688 (avg: 21.333)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.830 (avg: 0.832)\tLoss: 4.5213 (avg: 4.5266)\tTop1: 6.250 (avg: 5.641)\tTop5: 20.312 (avg: 21.203)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.832 (avg: 0.833)\tLoss: 4.7159 (avg: 4.5341)\tTop1: 4.688 (avg: 5.700)\tTop5: 14.062 (avg: 20.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5323\tTop 1 accuracy: 5.650\tTop 5 accuracy: 17.650\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.824 (avg: 0.812)\tLoss: 4.3604 (avg: 4.5091)\tTop1: 7.812 (avg: 5.688)\tTop5: 21.875 (avg: 21.375)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.830 (avg: 0.824)\tLoss: 4.4978 (avg: 4.4649)\tTop1: 4.688 (avg: 6.156)\tTop5: 23.438 (avg: 22.844)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.826 (avg: 0.829)\tLoss: 4.4571 (avg: 4.4872)\tTop1: 14.062 (avg: 6.062)\tTop5: 21.875 (avg: 22.062)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.831 (avg: 0.831)\tLoss: 4.5804 (avg: 4.4892)\tTop1: 1.562 (avg: 5.969)\tTop5: 15.625 (avg: 21.516)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.829 (avg: 0.832)\tLoss: 4.7326 (avg: 4.4885)\tTop1: 1.562 (avg: 6.075)\tTop5: 17.188 (avg: 21.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6083\tTop 1 accuracy: 6.050\tTop 5 accuracy: 19.550\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.825 (avg: 0.810)\tLoss: 4.6953 (avg: 4.4176)\tTop1: 1.562 (avg: 7.062)\tTop5: 12.500 (avg: 23.312)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.825 (avg: 0.820)\tLoss: 4.1810 (avg: 4.4831)\tTop1: 7.812 (avg: 6.250)\tTop5: 25.000 (avg: 21.219)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.823 (avg: 0.824)\tLoss: 4.2759 (avg: 4.4727)\tTop1: 3.125 (avg: 6.083)\tTop5: 26.562 (avg: 21.667)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.820 (avg: 0.825)\tLoss: 4.3906 (avg: 4.4563)\tTop1: 4.688 (avg: 6.484)\tTop5: 28.125 (avg: 22.375)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.826 (avg: 0.826)\tLoss: 4.4284 (avg: 4.4696)\tTop1: 9.375 (avg: 6.588)\tTop5: 25.000 (avg: 22.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7339\tTop 1 accuracy: 5.600\tTop 5 accuracy: 19.650\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.828 (avg: 0.810)\tLoss: 4.4199 (avg: 4.4026)\tTop1: 4.688 (avg: 6.625)\tTop5: 20.312 (avg: 23.062)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.831 (avg: 0.822)\tLoss: 4.2158 (avg: 4.3957)\tTop1: 6.250 (avg: 6.375)\tTop5: 28.125 (avg: 23.312)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.827 (avg: 0.826)\tLoss: 4.1599 (avg: 4.3912)\tTop1: 15.625 (avg: 6.812)\tTop5: 34.375 (avg: 23.792)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.829 (avg: 0.828)\tLoss: 4.5807 (avg: 4.3738)\tTop1: 6.250 (avg: 6.922)\tTop5: 18.750 (avg: 24.125)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.825 (avg: 0.828)\tLoss: 3.9323 (avg: 4.3797)\tTop1: 12.500 (avg: 7.175)\tTop5: 40.625 (avg: 24.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3987\tTop 1 accuracy: 6.550\tTop 5 accuracy: 21.550\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.825 (avg: 0.810)\tLoss: 4.1425 (avg: 4.2047)\tTop1: 9.375 (avg: 8.500)\tTop5: 29.688 (avg: 28.125)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.831 (avg: 0.821)\tLoss: 4.3071 (avg: 4.2259)\tTop1: 7.812 (avg: 8.469)\tTop5: 26.562 (avg: 27.688)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.824 (avg: 0.825)\tLoss: 4.1503 (avg: 4.2458)\tTop1: 7.812 (avg: 8.875)\tTop5: 32.812 (avg: 27.438)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.825 (avg: 0.827)\tLoss: 4.1303 (avg: 4.2606)\tTop1: 9.375 (avg: 8.656)\tTop5: 28.125 (avg: 27.141)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.824 (avg: 0.828)\tLoss: 4.6411 (avg: 4.2790)\tTop1: 3.125 (avg: 8.312)\tTop5: 17.188 (avg: 26.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3812\tTop 1 accuracy: 8.250\tTop 5 accuracy: 25.600\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.828 (avg: 0.810)\tLoss: 3.9408 (avg: 4.1656)\tTop1: 9.375 (avg: 9.562)\tTop5: 35.938 (avg: 28.875)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.822 (avg: 0.820)\tLoss: 4.1290 (avg: 4.2251)\tTop1: 6.250 (avg: 9.250)\tTop5: 28.125 (avg: 27.031)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.822 (avg: 0.824)\tLoss: 4.2684 (avg: 4.2221)\tTop1: 12.500 (avg: 9.000)\tTop5: 29.688 (avg: 28.208)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.826 (avg: 0.825)\tLoss: 4.1752 (avg: 4.2401)\tTop1: 9.375 (avg: 8.984)\tTop5: 28.125 (avg: 27.531)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.826 (avg: 0.826)\tLoss: 4.4794 (avg: 4.2427)\tTop1: 6.250 (avg: 8.838)\tTop5: 23.438 (avg: 27.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2661\tTop 1 accuracy: 7.350\tTop 5 accuracy: 24.650\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.823 (avg: 0.807)\tLoss: 4.0379 (avg: 4.2309)\tTop1: 10.938 (avg: 9.625)\tTop5: 29.688 (avg: 27.938)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.822 (avg: 0.818)\tLoss: 4.2648 (avg: 4.1971)\tTop1: 7.812 (avg: 9.750)\tTop5: 28.125 (avg: 29.031)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.823 (avg: 0.820)\tLoss: 4.0666 (avg: 4.1847)\tTop1: 15.625 (avg: 9.854)\tTop5: 28.125 (avg: 29.604)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.820 (avg: 0.822)\tLoss: 4.1164 (avg: 4.1979)\tTop1: 9.375 (avg: 9.719)\tTop5: 28.125 (avg: 29.219)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.824 (avg: 0.824)\tLoss: 4.1489 (avg: 4.1953)\tTop1: 9.375 (avg: 9.513)\tTop5: 26.562 (avg: 28.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1731\tTop 1 accuracy: 8.650\tTop 5 accuracy: 25.900\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.829 (avg: 0.810)\tLoss: 4.1719 (avg: 4.0467)\tTop1: 4.688 (avg: 10.750)\tTop5: 32.812 (avg: 32.438)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.825 (avg: 0.820)\tLoss: 4.0650 (avg: 4.0776)\tTop1: 12.500 (avg: 10.062)\tTop5: 31.250 (avg: 31.688)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.824 (avg: 0.824)\tLoss: 4.0846 (avg: 4.1127)\tTop1: 14.062 (avg: 10.167)\tTop5: 28.125 (avg: 30.667)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.827 (avg: 0.826)\tLoss: 4.2576 (avg: 4.1345)\tTop1: 12.500 (avg: 9.984)\tTop5: 26.562 (avg: 29.969)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.827 (avg: 0.827)\tLoss: 4.1372 (avg: 4.1353)\tTop1: 17.188 (avg: 10.375)\tTop5: 32.812 (avg: 30.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9876\tTop 1 accuracy: 9.650\tTop 5 accuracy: 27.050\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.830 (avg: 0.815)\tLoss: 3.8725 (avg: 4.0363)\tTop1: 18.750 (avg: 11.438)\tTop5: 40.625 (avg: 31.750)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.832 (avg: 0.825)\tLoss: 4.3189 (avg: 4.0806)\tTop1: 6.250 (avg: 10.312)\tTop5: 26.562 (avg: 31.219)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.832 (avg: 0.830)\tLoss: 4.3102 (avg: 4.0867)\tTop1: 7.812 (avg: 10.542)\tTop5: 29.688 (avg: 31.271)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.833 (avg: 0.831)\tLoss: 4.1201 (avg: 4.0774)\tTop1: 7.812 (avg: 10.766)\tTop5: 35.938 (avg: 31.312)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.833 (avg: 0.832)\tLoss: 4.4167 (avg: 4.0814)\tTop1: 9.375 (avg: 10.613)\tTop5: 18.750 (avg: 31.013)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9048\tTop 1 accuracy: 9.300\tTop 5 accuracy: 26.800\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.839 (avg: 0.813)\tLoss: 4.0172 (avg: 3.9098)\tTop1: 15.625 (avg: 14.875)\tTop5: 35.938 (avg: 36.000)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.834 (avg: 0.825)\tLoss: 4.4218 (avg: 3.9986)\tTop1: 1.562 (avg: 13.000)\tTop5: 26.562 (avg: 33.875)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.831 (avg: 0.829)\tLoss: 3.9258 (avg: 4.0138)\tTop1: 12.500 (avg: 12.104)\tTop5: 31.250 (avg: 33.083)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.832 (avg: 0.831)\tLoss: 3.9993 (avg: 4.0312)\tTop1: 10.938 (avg: 12.000)\tTop5: 34.375 (avg: 32.797)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.829 (avg: 0.832)\tLoss: 4.2662 (avg: 4.0352)\tTop1: 7.812 (avg: 12.038)\tTop5: 29.688 (avg: 32.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2077\tTop 1 accuracy: 9.200\tTop 5 accuracy: 26.650\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.825 (avg: 0.807)\tLoss: 3.6733 (avg: 3.8693)\tTop1: 17.188 (avg: 14.125)\tTop5: 48.438 (avg: 36.062)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.811 (avg: 0.817)\tLoss: 3.9273 (avg: 3.8652)\tTop1: 14.062 (avg: 13.688)\tTop5: 28.125 (avg: 36.656)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.819 (avg: 0.821)\tLoss: 4.1279 (avg: 3.8813)\tTop1: 7.812 (avg: 13.583)\tTop5: 31.250 (avg: 35.958)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.818 (avg: 0.822)\tLoss: 3.6944 (avg: 3.9245)\tTop1: 17.188 (avg: 13.094)\tTop5: 35.938 (avg: 35.078)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.815 (avg: 0.823)\tLoss: 4.1404 (avg: 3.9459)\tTop1: 14.062 (avg: 13.175)\tTop5: 28.125 (avg: 34.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5464\tTop 1 accuracy: 11.250\tTop 5 accuracy: 28.750\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.821 (avg: 0.808)\tLoss: 3.5976 (avg: 3.8584)\tTop1: 28.125 (avg: 13.875)\tTop5: 45.312 (avg: 36.375)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.822 (avg: 0.818)\tLoss: 3.5024 (avg: 3.8858)\tTop1: 26.562 (avg: 13.969)\tTop5: 39.062 (avg: 35.812)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.821 (avg: 0.822)\tLoss: 3.8228 (avg: 3.8962)\tTop1: 17.188 (avg: 13.562)\tTop5: 35.938 (avg: 35.104)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.815 (avg: 0.823)\tLoss: 3.7074 (avg: 3.9070)\tTop1: 20.312 (avg: 13.562)\tTop5: 37.500 (avg: 34.938)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.826 (avg: 0.824)\tLoss: 3.8180 (avg: 3.9051)\tTop1: 15.625 (avg: 13.888)\tTop5: 39.062 (avg: 35.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5901\tTop 1 accuracy: 11.450\tTop 5 accuracy: 30.700\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.818 (avg: 0.804)\tLoss: 4.0990 (avg: 3.7821)\tTop1: 10.938 (avg: 15.875)\tTop5: 35.938 (avg: 39.375)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.818 (avg: 0.815)\tLoss: 3.9993 (avg: 3.8502)\tTop1: 14.062 (avg: 14.281)\tTop5: 39.062 (avg: 37.188)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.818 (avg: 0.819)\tLoss: 4.0325 (avg: 3.8633)\tTop1: 12.500 (avg: 14.125)\tTop5: 31.250 (avg: 36.917)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.818 (avg: 0.821)\tLoss: 3.7226 (avg: 3.8840)\tTop1: 20.312 (avg: 13.844)\tTop5: 46.875 (avg: 36.672)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.815 (avg: 0.822)\tLoss: 4.1542 (avg: 3.8989)\tTop1: 6.250 (avg: 13.788)\tTop5: 29.688 (avg: 36.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8641\tTop 1 accuracy: 11.000\tTop 5 accuracy: 28.450\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.818 (avg: 0.805)\tLoss: 3.8408 (avg: 3.8265)\tTop1: 14.062 (avg: 14.125)\tTop5: 43.750 (avg: 38.812)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.822 (avg: 0.815)\tLoss: 3.7070 (avg: 3.8112)\tTop1: 17.188 (avg: 14.406)\tTop5: 40.625 (avg: 38.875)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.820 (avg: 0.819)\tLoss: 4.1230 (avg: 3.7923)\tTop1: 9.375 (avg: 14.833)\tTop5: 32.812 (avg: 39.146)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.814 (avg: 0.821)\tLoss: 4.0237 (avg: 3.8204)\tTop1: 15.625 (avg: 14.812)\tTop5: 32.812 (avg: 38.266)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.822 (avg: 0.822)\tLoss: 3.6976 (avg: 3.8179)\tTop1: 9.375 (avg: 14.713)\tTop5: 39.062 (avg: 38.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0210\tTop 1 accuracy: 10.650\tTop 5 accuracy: 30.200\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.822 (avg: 0.804)\tLoss: 3.7585 (avg: 3.5959)\tTop1: 12.500 (avg: 18.062)\tTop5: 37.500 (avg: 42.438)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.813 (avg: 0.813)\tLoss: 3.5424 (avg: 3.6635)\tTop1: 14.062 (avg: 16.375)\tTop5: 43.750 (avg: 40.906)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.820 (avg: 0.817)\tLoss: 3.6541 (avg: 3.6469)\tTop1: 14.062 (avg: 16.771)\tTop5: 42.188 (avg: 41.938)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.817 (avg: 0.818)\tLoss: 3.8487 (avg: 3.6807)\tTop1: 14.062 (avg: 16.547)\tTop5: 37.500 (avg: 41.078)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.814 (avg: 0.820)\tLoss: 3.5326 (avg: 3.7058)\tTop1: 25.000 (avg: 16.425)\tTop5: 48.438 (avg: 40.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8733\tTop 1 accuracy: 11.650\tTop 5 accuracy: 31.550\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.820 (avg: 0.806)\tLoss: 3.7715 (avg: 3.5602)\tTop1: 15.625 (avg: 18.125)\tTop5: 40.625 (avg: 44.875)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.818 (avg: 0.817)\tLoss: 3.2901 (avg: 3.6007)\tTop1: 23.438 (avg: 18.031)\tTop5: 48.438 (avg: 43.594)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.827 (avg: 0.821)\tLoss: 3.3980 (avg: 3.6231)\tTop1: 23.438 (avg: 17.812)\tTop5: 50.000 (avg: 42.917)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.820 (avg: 0.822)\tLoss: 3.4301 (avg: 3.6571)\tTop1: 20.312 (avg: 17.500)\tTop5: 46.875 (avg: 41.922)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.823 (avg: 0.823)\tLoss: 3.9446 (avg: 3.6541)\tTop1: 9.375 (avg: 17.700)\tTop5: 29.688 (avg: 41.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6293\tTop 1 accuracy: 11.350\tTop 5 accuracy: 29.600\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.825 (avg: 0.810)\tLoss: 3.4018 (avg: 3.4722)\tTop1: 20.312 (avg: 18.562)\tTop5: 50.000 (avg: 45.438)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.828 (avg: 0.823)\tLoss: 3.4655 (avg: 3.5282)\tTop1: 20.312 (avg: 17.688)\tTop5: 43.750 (avg: 44.031)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.826 (avg: 0.826)\tLoss: 3.9526 (avg: 3.5509)\tTop1: 12.500 (avg: 17.771)\tTop5: 37.500 (avg: 43.792)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.829 (avg: 0.828)\tLoss: 3.3244 (avg: 3.5874)\tTop1: 23.438 (avg: 17.484)\tTop5: 46.875 (avg: 43.000)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.828 (avg: 0.829)\tLoss: 3.8633 (avg: 3.6062)\tTop1: 15.625 (avg: 17.300)\tTop5: 31.250 (avg: 42.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7715\tTop 1 accuracy: 12.450\tTop 5 accuracy: 32.050\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.824 (avg: 0.812)\tLoss: 3.1693 (avg: 3.2578)\tTop1: 21.875 (avg: 24.500)\tTop5: 46.875 (avg: 51.375)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.827 (avg: 0.823)\tLoss: 3.2022 (avg: 3.2092)\tTop1: 25.000 (avg: 24.750)\tTop5: 54.688 (avg: 52.125)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.825 (avg: 0.826)\tLoss: 2.7179 (avg: 3.1893)\tTop1: 43.750 (avg: 25.583)\tTop5: 70.312 (avg: 52.521)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.833 (avg: 0.828)\tLoss: 3.2867 (avg: 3.1399)\tTop1: 21.875 (avg: 25.875)\tTop5: 50.000 (avg: 54.109)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.827 (avg: 0.830)\tLoss: 3.4084 (avg: 3.1167)\tTop1: 20.312 (avg: 26.488)\tTop5: 40.625 (avg: 54.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.1156\tTop 1 accuracy: 15.400\tTop 5 accuracy: 38.050\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.818 (avg: 0.807)\tLoss: 2.7944 (avg: 2.9406)\tTop1: 29.688 (avg: 30.500)\tTop5: 65.625 (avg: 56.875)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.825 (avg: 0.817)\tLoss: 3.0318 (avg: 2.9475)\tTop1: 23.438 (avg: 29.906)\tTop5: 57.812 (avg: 57.438)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.822 (avg: 0.821)\tLoss: 2.7905 (avg: 2.9486)\tTop1: 34.375 (avg: 29.604)\tTop5: 54.688 (avg: 57.625)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.819 (avg: 0.822)\tLoss: 3.3124 (avg: 2.9678)\tTop1: 28.125 (avg: 29.312)\tTop5: 56.250 (avg: 57.344)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.817 (avg: 0.823)\tLoss: 3.2686 (avg: 2.9678)\tTop1: 17.188 (avg: 29.325)\tTop5: 43.750 (avg: 57.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.1016\tTop 1 accuracy: 16.100\tTop 5 accuracy: 36.950\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.831 (avg: 0.810)\tLoss: 3.0140 (avg: 2.9574)\tTop1: 34.375 (avg: 29.500)\tTop5: 56.250 (avg: 58.500)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.822 (avg: 0.820)\tLoss: 2.6726 (avg: 2.9102)\tTop1: 39.062 (avg: 30.469)\tTop5: 67.188 (avg: 59.281)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.820 (avg: 0.823)\tLoss: 3.3483 (avg: 2.9065)\tTop1: 23.438 (avg: 30.750)\tTop5: 54.688 (avg: 58.896)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.816 (avg: 0.825)\tLoss: 2.8762 (avg: 2.9122)\tTop1: 26.562 (avg: 30.734)\tTop5: 64.062 (avg: 58.750)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.823 (avg: 0.826)\tLoss: 3.1921 (avg: 2.9082)\tTop1: 23.438 (avg: 30.513)\tTop5: 53.125 (avg: 58.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.1551\tTop 1 accuracy: 15.850\tTop 5 accuracy: 37.000\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.821 (avg: 0.807)\tLoss: 2.9300 (avg: 2.8303)\tTop1: 31.250 (avg: 32.188)\tTop5: 60.938 (avg: 62.125)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.821 (avg: 0.818)\tLoss: 2.5693 (avg: 2.8094)\tTop1: 39.062 (avg: 32.312)\tTop5: 62.500 (avg: 61.844)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.823 (avg: 0.821)\tLoss: 2.9046 (avg: 2.8311)\tTop1: 39.062 (avg: 32.146)\tTop5: 54.688 (avg: 60.750)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.822 (avg: 0.823)\tLoss: 2.9452 (avg: 2.8407)\tTop1: 31.250 (avg: 31.766)\tTop5: 59.375 (avg: 60.438)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.819 (avg: 0.825)\tLoss: 2.6974 (avg: 2.8553)\tTop1: 37.500 (avg: 32.062)\tTop5: 57.812 (avg: 59.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3197\tTop 1 accuracy: 16.000\tTop 5 accuracy: 37.400\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.821 (avg: 0.807)\tLoss: 3.2882 (avg: 2.7928)\tTop1: 20.312 (avg: 32.188)\tTop5: 54.688 (avg: 60.875)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.818 (avg: 0.817)\tLoss: 2.7867 (avg: 2.7784)\tTop1: 34.375 (avg: 33.219)\tTop5: 57.812 (avg: 60.781)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.831 (avg: 0.821)\tLoss: 3.2535 (avg: 2.8102)\tTop1: 28.125 (avg: 32.667)\tTop5: 53.125 (avg: 60.521)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.823 (avg: 0.823)\tLoss: 2.9176 (avg: 2.8163)\tTop1: 37.500 (avg: 32.500)\tTop5: 64.062 (avg: 60.391)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.822 (avg: 0.824)\tLoss: 2.8852 (avg: 2.8188)\tTop1: 28.125 (avg: 32.425)\tTop5: 64.062 (avg: 60.563)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2079\tTop 1 accuracy: 17.050\tTop 5 accuracy: 37.850\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.821 (avg: 0.806)\tLoss: 2.7342 (avg: 2.7520)\tTop1: 35.938 (avg: 33.062)\tTop5: 60.938 (avg: 64.375)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.821 (avg: 0.815)\tLoss: 2.6919 (avg: 2.7505)\tTop1: 31.250 (avg: 33.500)\tTop5: 65.625 (avg: 63.406)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.821 (avg: 0.819)\tLoss: 2.6674 (avg: 2.7786)\tTop1: 35.938 (avg: 33.125)\tTop5: 57.812 (avg: 61.875)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.821 (avg: 0.821)\tLoss: 3.2601 (avg: 2.7574)\tTop1: 21.875 (avg: 33.453)\tTop5: 46.875 (avg: 62.109)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.826 (avg: 0.822)\tLoss: 2.7504 (avg: 2.7649)\tTop1: 31.250 (avg: 33.138)\tTop5: 62.500 (avg: 61.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2311\tTop 1 accuracy: 16.250\tTop 5 accuracy: 38.350\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.827 (avg: 0.814)\tLoss: 3.0440 (avg: 2.6858)\tTop1: 26.562 (avg: 34.312)\tTop5: 62.500 (avg: 63.938)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.828 (avg: 0.825)\tLoss: 2.3031 (avg: 2.6815)\tTop1: 40.625 (avg: 34.219)\tTop5: 71.875 (avg: 63.594)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.827 (avg: 0.828)\tLoss: 3.2188 (avg: 2.7158)\tTop1: 29.688 (avg: 34.250)\tTop5: 50.000 (avg: 63.062)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.828 (avg: 0.830)\tLoss: 2.6504 (avg: 2.7154)\tTop1: 34.375 (avg: 34.109)\tTop5: 65.625 (avg: 63.172)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.830 (avg: 0.831)\tLoss: 2.8381 (avg: 2.7278)\tTop1: 31.250 (avg: 34.025)\tTop5: 53.125 (avg: 62.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3680\tTop 1 accuracy: 17.950\tTop 5 accuracy: 37.300\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.834 (avg: 0.820)\tLoss: 2.6288 (avg: 2.6250)\tTop1: 35.938 (avg: 35.688)\tTop5: 60.938 (avg: 65.938)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.824 (avg: 0.831)\tLoss: 2.8120 (avg: 2.6071)\tTop1: 35.938 (avg: 36.406)\tTop5: 59.375 (avg: 65.312)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.833 (avg: 0.834)\tLoss: 3.1625 (avg: 2.6379)\tTop1: 20.312 (avg: 35.792)\tTop5: 51.562 (avg: 64.750)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.836 (avg: 0.836)\tLoss: 2.7253 (avg: 2.6575)\tTop1: 40.625 (avg: 35.438)\tTop5: 64.062 (avg: 64.250)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.827 (avg: 0.837)\tLoss: 2.8320 (avg: 2.6770)\tTop1: 34.375 (avg: 34.900)\tTop5: 60.938 (avg: 63.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4574\tTop 1 accuracy: 17.300\tTop 5 accuracy: 37.650\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.840 (avg: 0.821)\tLoss: 2.5856 (avg: 2.6080)\tTop1: 43.750 (avg: 37.562)\tTop5: 59.375 (avg: 65.562)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.838 (avg: 0.832)\tLoss: 2.5403 (avg: 2.6286)\tTop1: 34.375 (avg: 36.719)\tTop5: 68.750 (avg: 65.344)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.833 (avg: 0.835)\tLoss: 2.5954 (avg: 2.6501)\tTop1: 34.375 (avg: 36.292)\tTop5: 70.312 (avg: 64.792)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.838 (avg: 0.837)\tLoss: 2.1323 (avg: 2.6511)\tTop1: 45.312 (avg: 36.156)\tTop5: 78.125 (avg: 64.656)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.837 (avg: 0.838)\tLoss: 2.6473 (avg: 2.6516)\tTop1: 37.500 (avg: 35.838)\tTop5: 60.938 (avg: 64.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5592\tTop 1 accuracy: 16.750\tTop 5 accuracy: 38.400\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.830 (avg: 0.814)\tLoss: 2.1319 (avg: 2.5053)\tTop1: 48.438 (avg: 38.188)\tTop5: 75.000 (avg: 67.750)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.828 (avg: 0.824)\tLoss: 2.9757 (avg: 2.5800)\tTop1: 32.812 (avg: 36.938)\tTop5: 59.375 (avg: 66.094)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.817 (avg: 0.826)\tLoss: 2.8225 (avg: 2.5879)\tTop1: 34.375 (avg: 36.438)\tTop5: 64.062 (avg: 66.000)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.824 (avg: 0.827)\tLoss: 2.6080 (avg: 2.5946)\tTop1: 29.688 (avg: 36.016)\tTop5: 60.938 (avg: 65.594)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.822 (avg: 0.827)\tLoss: 2.6970 (avg: 2.5997)\tTop1: 39.062 (avg: 36.250)\tTop5: 60.938 (avg: 65.312)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4297\tTop 1 accuracy: 16.350\tTop 5 accuracy: 37.800\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.827 (avg: 0.810)\tLoss: 2.3398 (avg: 2.4471)\tTop1: 42.188 (avg: 40.500)\tTop5: 71.875 (avg: 68.375)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.826 (avg: 0.821)\tLoss: 2.5849 (avg: 2.5054)\tTop1: 34.375 (avg: 38.969)\tTop5: 62.500 (avg: 67.469)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.822 (avg: 0.824)\tLoss: 2.2719 (avg: 2.5233)\tTop1: 40.625 (avg: 38.833)\tTop5: 71.875 (avg: 67.104)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.821 (avg: 0.826)\tLoss: 2.6874 (avg: 2.5349)\tTop1: 34.375 (avg: 38.219)\tTop5: 64.062 (avg: 66.672)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.825 (avg: 0.827)\tLoss: 2.9232 (avg: 2.5494)\tTop1: 29.688 (avg: 37.700)\tTop5: 54.688 (avg: 66.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6406\tTop 1 accuracy: 16.900\tTop 5 accuracy: 37.650\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.823 (avg: 0.807)\tLoss: 2.1740 (avg: 2.3793)\tTop1: 53.125 (avg: 41.875)\tTop5: 67.188 (avg: 68.938)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.819 (avg: 0.819)\tLoss: 2.2760 (avg: 2.4215)\tTop1: 43.750 (avg: 40.156)\tTop5: 70.312 (avg: 69.000)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.824 (avg: 0.822)\tLoss: 2.8440 (avg: 2.4802)\tTop1: 34.375 (avg: 39.062)\tTop5: 59.375 (avg: 67.917)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.824 (avg: 0.824)\tLoss: 2.6450 (avg: 2.5059)\tTop1: 39.062 (avg: 38.312)\tTop5: 68.750 (avg: 67.328)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.821 (avg: 0.825)\tLoss: 2.5674 (avg: 2.5160)\tTop1: 42.188 (avg: 37.888)\tTop5: 67.188 (avg: 67.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3870\tTop 1 accuracy: 17.450\tTop 5 accuracy: 37.800\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.819 (avg: 0.807)\tLoss: 2.1593 (avg: 2.3987)\tTop1: 37.500 (avg: 40.500)\tTop5: 79.688 (avg: 69.500)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.823 (avg: 0.818)\tLoss: 2.2272 (avg: 2.4323)\tTop1: 43.750 (avg: 39.406)\tTop5: 73.438 (avg: 69.219)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.824 (avg: 0.822)\tLoss: 2.5868 (avg: 2.4693)\tTop1: 39.062 (avg: 38.979)\tTop5: 62.500 (avg: 68.312)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.823 (avg: 0.824)\tLoss: 2.5143 (avg: 2.4707)\tTop1: 35.938 (avg: 39.078)\tTop5: 67.188 (avg: 68.109)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.824 (avg: 0.825)\tLoss: 2.0748 (avg: 2.4723)\tTop1: 48.438 (avg: 39.213)\tTop5: 71.875 (avg: 68.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5949\tTop 1 accuracy: 17.100\tTop 5 accuracy: 37.900\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.820 (avg: 0.804)\tLoss: 2.4096 (avg: 2.3190)\tTop1: 42.188 (avg: 41.938)\tTop5: 70.312 (avg: 70.562)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.824 (avg: 0.816)\tLoss: 2.0635 (avg: 2.3729)\tTop1: 43.750 (avg: 41.344)\tTop5: 81.250 (avg: 70.281)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.822 (avg: 0.821)\tLoss: 2.4005 (avg: 2.3864)\tTop1: 35.938 (avg: 40.875)\tTop5: 71.875 (avg: 70.229)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.822 (avg: 0.823)\tLoss: 2.6213 (avg: 2.4213)\tTop1: 40.625 (avg: 40.406)\tTop5: 64.062 (avg: 69.344)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.821 (avg: 0.824)\tLoss: 2.1319 (avg: 2.4211)\tTop1: 48.438 (avg: 40.350)\tTop5: 73.438 (avg: 69.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4525\tTop 1 accuracy: 17.450\tTop 5 accuracy: 38.300\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.822 (avg: 0.810)\tLoss: 2.4397 (avg: 2.3269)\tTop1: 25.000 (avg: 41.688)\tTop5: 73.438 (avg: 71.625)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.826 (avg: 0.820)\tLoss: 2.0337 (avg: 2.3259)\tTop1: 53.125 (avg: 41.906)\tTop5: 81.250 (avg: 72.000)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.824 (avg: 0.824)\tLoss: 2.3972 (avg: 2.3281)\tTop1: 34.375 (avg: 41.667)\tTop5: 70.312 (avg: 71.688)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.826 (avg: 0.825)\tLoss: 2.1768 (avg: 2.3542)\tTop1: 40.625 (avg: 41.188)\tTop5: 78.125 (avg: 70.750)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.823 (avg: 0.826)\tLoss: 2.6744 (avg: 2.3800)\tTop1: 28.125 (avg: 40.750)\tTop5: 65.625 (avg: 70.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6278\tTop 1 accuracy: 16.600\tTop 5 accuracy: 38.050\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.828 (avg: 0.814)\tLoss: 2.3109 (avg: 2.2079)\tTop1: 45.312 (avg: 44.312)\tTop5: 68.750 (avg: 72.938)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.831 (avg: 0.825)\tLoss: 2.3467 (avg: 2.2607)\tTop1: 39.062 (avg: 43.812)\tTop5: 75.000 (avg: 72.125)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.830 (avg: 0.829)\tLoss: 2.5710 (avg: 2.2756)\tTop1: 32.812 (avg: 43.396)\tTop5: 70.312 (avg: 71.833)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.830 (avg: 0.830)\tLoss: 2.1094 (avg: 2.2968)\tTop1: 48.438 (avg: 43.062)\tTop5: 70.312 (avg: 71.500)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.828 (avg: 0.831)\tLoss: 2.5747 (avg: 2.3122)\tTop1: 34.375 (avg: 42.550)\tTop5: 68.750 (avg: 71.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7986\tTop 1 accuracy: 17.100\tTop 5 accuracy: 37.150\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.831 (avg: 0.816)\tLoss: 2.2559 (avg: 2.1713)\tTop1: 43.750 (avg: 44.938)\tTop5: 78.125 (avg: 74.125)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.829 (avg: 0.827)\tLoss: 2.1881 (avg: 2.2132)\tTop1: 46.875 (avg: 43.719)\tTop5: 73.438 (avg: 73.312)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.827 (avg: 0.830)\tLoss: 2.5585 (avg: 2.2334)\tTop1: 32.812 (avg: 43.312)\tTop5: 68.750 (avg: 72.812)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.832 (avg: 0.832)\tLoss: 2.3874 (avg: 2.2539)\tTop1: 37.500 (avg: 42.906)\tTop5: 75.000 (avg: 72.891)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.832 (avg: 0.832)\tLoss: 2.1919 (avg: 2.2743)\tTop1: 39.062 (avg: 42.188)\tTop5: 75.000 (avg: 72.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7248\tTop 1 accuracy: 17.150\tTop 5 accuracy: 37.300\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.816 (avg: 0.812)\tLoss: 2.2871 (avg: 2.1713)\tTop1: 42.188 (avg: 43.938)\tTop5: 62.500 (avg: 74.250)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.828 (avg: 0.822)\tLoss: 2.1485 (avg: 2.1668)\tTop1: 50.000 (avg: 44.094)\tTop5: 70.312 (avg: 74.281)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.830 (avg: 0.827)\tLoss: 2.1938 (avg: 2.1916)\tTop1: 40.625 (avg: 43.917)\tTop5: 75.000 (avg: 73.771)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.829 (avg: 0.829)\tLoss: 2.1074 (avg: 2.2028)\tTop1: 43.750 (avg: 43.766)\tTop5: 75.000 (avg: 73.516)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.832 (avg: 0.830)\tLoss: 2.1113 (avg: 2.2263)\tTop1: 46.875 (avg: 43.363)\tTop5: 76.562 (avg: 73.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8703\tTop 1 accuracy: 15.950\tTop 5 accuracy: 37.200\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.838 (avg: 0.817)\tLoss: 1.9620 (avg: 2.0918)\tTop1: 50.000 (avg: 48.812)\tTop5: 75.000 (avg: 74.688)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.823 (avg: 0.828)\tLoss: 2.0690 (avg: 2.1165)\tTop1: 40.625 (avg: 47.500)\tTop5: 78.125 (avg: 74.719)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.837 (avg: 0.830)\tLoss: 2.2139 (avg: 2.1608)\tTop1: 54.688 (avg: 45.833)\tTop5: 68.750 (avg: 74.250)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.838 (avg: 0.832)\tLoss: 2.0107 (avg: 2.1686)\tTop1: 40.625 (avg: 45.375)\tTop5: 76.562 (avg: 74.125)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.832 (avg: 0.834)\tLoss: 2.2393 (avg: 2.1702)\tTop1: 40.625 (avg: 45.238)\tTop5: 71.875 (avg: 73.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6003\tTop 1 accuracy: 15.650\tTop 5 accuracy: 36.450\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.821 (avg: 0.815)\tLoss: 2.1363 (avg: 1.9709)\tTop1: 43.750 (avg: 49.500)\tTop5: 76.562 (avg: 78.750)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.825 (avg: 0.825)\tLoss: 2.3175 (avg: 2.0132)\tTop1: 40.625 (avg: 47.906)\tTop5: 79.688 (avg: 77.844)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.831 (avg: 0.829)\tLoss: 2.1998 (avg: 2.0684)\tTop1: 43.750 (avg: 46.542)\tTop5: 70.312 (avg: 76.521)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.828 (avg: 0.831)\tLoss: 2.0224 (avg: 2.0875)\tTop1: 51.562 (avg: 46.125)\tTop5: 78.125 (avg: 76.141)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.826 (avg: 0.832)\tLoss: 2.0089 (avg: 2.1214)\tTop1: 50.000 (avg: 45.300)\tTop5: 79.688 (avg: 75.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2121\tTop 1 accuracy: 16.550\tTop 5 accuracy: 37.200\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.833 (avg: 0.815)\tLoss: 1.9179 (avg: 1.8865)\tTop1: 48.438 (avg: 51.062)\tTop5: 76.562 (avg: 79.188)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.828 (avg: 0.825)\tLoss: 1.8912 (avg: 1.9610)\tTop1: 53.125 (avg: 49.406)\tTop5: 73.438 (avg: 77.469)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.825 (avg: 0.829)\tLoss: 2.1450 (avg: 2.0001)\tTop1: 40.625 (avg: 48.271)\tTop5: 73.438 (avg: 76.938)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.832 (avg: 0.830)\tLoss: 2.5218 (avg: 2.0320)\tTop1: 42.188 (avg: 47.906)\tTop5: 64.062 (avg: 76.391)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.821 (avg: 0.831)\tLoss: 2.1308 (avg: 2.0547)\tTop1: 40.625 (avg: 47.300)\tTop5: 78.125 (avg: 76.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1884\tTop 1 accuracy: 16.800\tTop 5 accuracy: 37.450\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.825 (avg: 0.806)\tLoss: 2.1833 (avg: 1.9641)\tTop1: 37.500 (avg: 49.000)\tTop5: 75.000 (avg: 77.188)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.820 (avg: 0.817)\tLoss: 1.9926 (avg: 1.9632)\tTop1: 45.312 (avg: 49.125)\tTop5: 76.562 (avg: 77.188)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.824 (avg: 0.820)\tLoss: 2.4147 (avg: 1.9851)\tTop1: 45.312 (avg: 48.875)\tTop5: 70.312 (avg: 77.000)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.823 (avg: 0.822)\tLoss: 1.8398 (avg: 2.0089)\tTop1: 53.125 (avg: 48.250)\tTop5: 84.375 (avg: 77.000)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.823 (avg: 0.823)\tLoss: 1.9548 (avg: 2.0219)\tTop1: 48.438 (avg: 47.775)\tTop5: 82.812 (avg: 76.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6738\tTop 1 accuracy: 17.750\tTop 5 accuracy: 38.250\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.823 (avg: 0.809)\tLoss: 1.9734 (avg: 1.7722)\tTop1: 54.688 (avg: 54.000)\tTop5: 73.438 (avg: 81.938)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.819 (avg: 0.819)\tLoss: 2.3440 (avg: 1.8764)\tTop1: 45.312 (avg: 51.344)\tTop5: 67.188 (avg: 80.250)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.826 (avg: 0.822)\tLoss: 1.8404 (avg: 1.8938)\tTop1: 54.688 (avg: 50.562)\tTop5: 76.562 (avg: 79.604)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.824 (avg: 0.824)\tLoss: 2.0358 (avg: 1.9334)\tTop1: 45.312 (avg: 49.547)\tTop5: 79.688 (avg: 79.016)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.823 (avg: 0.825)\tLoss: 2.2460 (avg: 1.9609)\tTop1: 42.188 (avg: 48.863)\tTop5: 70.312 (avg: 78.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0840\tTop 1 accuracy: 16.050\tTop 5 accuracy: 36.000\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.829 (avg: 0.813)\tLoss: 1.7711 (avg: 1.8865)\tTop1: 53.125 (avg: 50.188)\tTop5: 78.125 (avg: 79.750)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.821 (avg: 0.824)\tLoss: 1.7074 (avg: 1.8659)\tTop1: 51.562 (avg: 50.406)\tTop5: 89.062 (avg: 80.281)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.830 (avg: 0.828)\tLoss: 2.0585 (avg: 1.8862)\tTop1: 51.562 (avg: 50.229)\tTop5: 76.562 (avg: 79.438)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.831 (avg: 0.829)\tLoss: 1.8474 (avg: 1.9142)\tTop1: 46.875 (avg: 49.453)\tTop5: 78.125 (avg: 78.953)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.827 (avg: 0.830)\tLoss: 1.9215 (avg: 1.9325)\tTop1: 56.250 (avg: 49.288)\tTop5: 78.125 (avg: 78.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9111\tTop 1 accuracy: 16.200\tTop 5 accuracy: 36.150\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.828 (avg: 0.816)\tLoss: 1.5845 (avg: 1.7238)\tTop1: 51.562 (avg: 53.250)\tTop5: 82.812 (avg: 82.438)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.826 (avg: 0.826)\tLoss: 1.6574 (avg: 1.7637)\tTop1: 53.125 (avg: 52.719)\tTop5: 81.250 (avg: 81.594)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.822 (avg: 0.829)\tLoss: 1.9587 (avg: 1.8067)\tTop1: 40.625 (avg: 51.583)\tTop5: 82.812 (avg: 80.729)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.836 (avg: 0.831)\tLoss: 2.0829 (avg: 1.8450)\tTop1: 43.750 (avg: 51.031)\tTop5: 84.375 (avg: 80.047)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.824 (avg: 0.832)\tLoss: 1.7415 (avg: 1.8736)\tTop1: 54.688 (avg: 50.538)\tTop5: 81.250 (avg: 79.562)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1276\tTop 1 accuracy: 16.450\tTop 5 accuracy: 36.600\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.827 (avg: 0.809)\tLoss: 1.4402 (avg: 1.7066)\tTop1: 65.625 (avg: 55.125)\tTop5: 87.500 (avg: 82.125)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.828 (avg: 0.819)\tLoss: 1.5331 (avg: 1.7770)\tTop1: 56.250 (avg: 52.875)\tTop5: 79.688 (avg: 81.031)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.824 (avg: 0.822)\tLoss: 2.1062 (avg: 1.8063)\tTop1: 37.500 (avg: 52.354)\tTop5: 79.688 (avg: 80.708)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.826 (avg: 0.824)\tLoss: 1.6052 (avg: 1.7967)\tTop1: 59.375 (avg: 52.406)\tTop5: 85.938 (avg: 80.969)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.825 (avg: 0.826)\tLoss: 1.6993 (avg: 1.8152)\tTop1: 54.688 (avg: 51.975)\tTop5: 87.500 (avg: 80.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6596\tTop 1 accuracy: 16.800\tTop 5 accuracy: 36.600\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.829 (avg: 0.814)\tLoss: 1.5846 (avg: 1.6548)\tTop1: 51.562 (avg: 57.438)\tTop5: 78.125 (avg: 82.250)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.830 (avg: 0.822)\tLoss: 1.3872 (avg: 1.7215)\tTop1: 62.500 (avg: 55.000)\tTop5: 87.500 (avg: 81.562)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.831 (avg: 0.826)\tLoss: 2.0053 (avg: 1.7323)\tTop1: 46.875 (avg: 54.458)\tTop5: 84.375 (avg: 81.688)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.825 (avg: 0.828)\tLoss: 1.7113 (avg: 1.7542)\tTop1: 53.125 (avg: 53.656)\tTop5: 81.250 (avg: 81.500)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.824 (avg: 0.829)\tLoss: 2.0789 (avg: 1.7734)\tTop1: 50.000 (avg: 53.075)\tTop5: 75.000 (avg: 81.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1468\tTop 1 accuracy: 15.750\tTop 5 accuracy: 36.050\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.820 (avg: 0.809)\tLoss: 1.9064 (avg: 1.5662)\tTop1: 46.875 (avg: 58.438)\tTop5: 81.250 (avg: 85.375)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.823 (avg: 0.820)\tLoss: 1.4925 (avg: 1.6009)\tTop1: 70.312 (avg: 57.344)\tTop5: 84.375 (avg: 84.562)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.818 (avg: 0.823)\tLoss: 1.5959 (avg: 1.6295)\tTop1: 54.688 (avg: 55.979)\tTop5: 89.062 (avg: 84.250)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.824 (avg: 0.825)\tLoss: 1.8419 (avg: 1.6820)\tTop1: 43.750 (avg: 54.672)\tTop5: 79.688 (avg: 83.578)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.827 (avg: 0.826)\tLoss: 1.8770 (avg: 1.7190)\tTop1: 51.562 (avg: 53.988)\tTop5: 76.562 (avg: 82.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0501\tTop 1 accuracy: 15.950\tTop 5 accuracy: 35.500\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.821 (avg: 0.810)\tLoss: 1.3830 (avg: 1.5240)\tTop1: 62.500 (avg: 58.125)\tTop5: 89.062 (avg: 85.875)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.824 (avg: 0.820)\tLoss: 1.5347 (avg: 1.5308)\tTop1: 56.250 (avg: 58.469)\tTop5: 84.375 (avg: 85.656)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.827 (avg: 0.824)\tLoss: 1.4721 (avg: 1.6017)\tTop1: 59.375 (avg: 56.583)\tTop5: 90.625 (avg: 84.625)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.823 (avg: 0.825)\tLoss: 1.4348 (avg: 1.6208)\tTop1: 62.500 (avg: 55.828)\tTop5: 90.625 (avg: 84.469)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.822 (avg: 0.826)\tLoss: 1.5074 (avg: 1.6427)\tTop1: 50.000 (avg: 55.213)\tTop5: 85.938 (avg: 84.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2297\tTop 1 accuracy: 16.450\tTop 5 accuracy: 36.300\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.823 (avg: 0.808)\tLoss: 1.5667 (avg: 1.4367)\tTop1: 53.125 (avg: 62.625)\tTop5: 89.062 (avg: 87.000)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.828 (avg: 0.819)\tLoss: 1.9822 (avg: 1.4867)\tTop1: 51.562 (avg: 60.500)\tTop5: 82.812 (avg: 86.250)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.818 (avg: 0.823)\tLoss: 1.6217 (avg: 1.5317)\tTop1: 51.562 (avg: 58.792)\tTop5: 87.500 (avg: 85.708)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.823 (avg: 0.824)\tLoss: 1.6912 (avg: 1.5709)\tTop1: 56.250 (avg: 57.859)\tTop5: 82.812 (avg: 85.188)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.827 (avg: 0.825)\tLoss: 1.8138 (avg: 1.5995)\tTop1: 45.312 (avg: 56.975)\tTop5: 81.250 (avg: 84.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3105\tTop 1 accuracy: 16.500\tTop 5 accuracy: 38.000\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.827 (avg: 0.808)\tLoss: 1.1308 (avg: 1.3403)\tTop1: 71.875 (avg: 63.125)\tTop5: 89.062 (avg: 87.375)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.821 (avg: 0.820)\tLoss: 1.2919 (avg: 1.2626)\tTop1: 75.000 (avg: 66.406)\tTop5: 85.938 (avg: 89.000)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.832 (avg: 0.824)\tLoss: 0.8876 (avg: 1.2271)\tTop1: 79.688 (avg: 67.438)\tTop5: 96.875 (avg: 89.562)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.826 (avg: 0.826)\tLoss: 1.2724 (avg: 1.2156)\tTop1: 64.062 (avg: 67.844)\tTop5: 87.500 (avg: 89.688)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.825 (avg: 0.827)\tLoss: 0.9730 (avg: 1.2019)\tTop1: 73.438 (avg: 68.513)\tTop5: 93.750 (avg: 89.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2889\tTop 1 accuracy: 17.950\tTop 5 accuracy: 38.150\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.827 (avg: 0.815)\tLoss: 1.2679 (avg: 1.0550)\tTop1: 60.938 (avg: 71.625)\tTop5: 92.188 (avg: 91.375)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.830 (avg: 0.826)\tLoss: 0.9346 (avg: 1.0598)\tTop1: 71.875 (avg: 72.156)\tTop5: 98.438 (avg: 91.219)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.819 (avg: 0.829)\tLoss: 0.8413 (avg: 1.0649)\tTop1: 79.688 (avg: 72.188)\tTop5: 95.312 (avg: 90.958)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.831 (avg: 0.830)\tLoss: 0.5652 (avg: 1.0458)\tTop1: 87.500 (avg: 72.938)\tTop5: 95.312 (avg: 91.281)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.832 (avg: 0.832)\tLoss: 1.1699 (avg: 1.0542)\tTop1: 71.875 (avg: 72.850)\tTop5: 90.625 (avg: 91.313)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3042\tTop 1 accuracy: 17.900\tTop 5 accuracy: 37.650\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.830 (avg: 0.817)\tLoss: 0.7291 (avg: 1.0481)\tTop1: 79.688 (avg: 73.250)\tTop5: 96.875 (avg: 91.250)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.834 (avg: 0.827)\tLoss: 0.9876 (avg: 1.0269)\tTop1: 73.438 (avg: 74.250)\tTop5: 90.625 (avg: 91.156)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.831 (avg: 0.831)\tLoss: 0.9692 (avg: 1.0121)\tTop1: 71.875 (avg: 74.104)\tTop5: 95.312 (avg: 91.667)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.830 (avg: 0.833)\tLoss: 0.8882 (avg: 1.0171)\tTop1: 75.000 (avg: 73.656)\tTop5: 90.625 (avg: 91.797)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.831 (avg: 0.833)\tLoss: 0.7016 (avg: 1.0230)\tTop1: 79.688 (avg: 73.363)\tTop5: 95.312 (avg: 91.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6111\tTop 1 accuracy: 18.000\tTop 5 accuracy: 37.750\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.825 (avg: 0.809)\tLoss: 0.7467 (avg: 0.9670)\tTop1: 84.375 (avg: 75.312)\tTop5: 96.875 (avg: 92.688)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.823 (avg: 0.819)\tLoss: 0.9350 (avg: 0.9926)\tTop1: 81.250 (avg: 74.531)\tTop5: 92.188 (avg: 91.531)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.822 (avg: 0.823)\tLoss: 0.9308 (avg: 1.0007)\tTop1: 70.312 (avg: 74.542)\tTop5: 93.750 (avg: 91.604)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.824 (avg: 0.824)\tLoss: 0.8788 (avg: 0.9899)\tTop1: 78.125 (avg: 74.812)\tTop5: 93.750 (avg: 91.453)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.823 (avg: 0.826)\tLoss: 0.8382 (avg: 0.9927)\tTop1: 76.562 (avg: 74.650)\tTop5: 89.062 (avg: 91.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6873\tTop 1 accuracy: 18.200\tTop 5 accuracy: 37.500\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.811 (avg: 0.809)\tLoss: 0.6686 (avg: 0.9265)\tTop1: 81.250 (avg: 76.000)\tTop5: 95.312 (avg: 92.312)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.829 (avg: 0.820)\tLoss: 0.8575 (avg: 0.9325)\tTop1: 71.875 (avg: 75.344)\tTop5: 95.312 (avg: 92.219)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.826 (avg: 0.824)\tLoss: 0.9775 (avg: 0.9409)\tTop1: 75.000 (avg: 75.292)\tTop5: 90.625 (avg: 92.104)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.821 (avg: 0.827)\tLoss: 1.3136 (avg: 0.9441)\tTop1: 64.062 (avg: 75.359)\tTop5: 85.938 (avg: 92.203)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.826 (avg: 0.828)\tLoss: 0.9590 (avg: 0.9609)\tTop1: 75.000 (avg: 75.013)\tTop5: 93.750 (avg: 92.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7720\tTop 1 accuracy: 18.100\tTop 5 accuracy: 37.550\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.826 (avg: 0.808)\tLoss: 0.9257 (avg: 0.8698)\tTop1: 73.438 (avg: 77.938)\tTop5: 92.188 (avg: 92.438)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.823 (avg: 0.819)\tLoss: 0.8678 (avg: 0.8974)\tTop1: 79.688 (avg: 76.750)\tTop5: 90.625 (avg: 92.531)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.822 (avg: 0.822)\tLoss: 1.0791 (avg: 0.9204)\tTop1: 73.438 (avg: 75.958)\tTop5: 90.625 (avg: 92.250)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.822 (avg: 0.824)\tLoss: 1.1703 (avg: 0.9215)\tTop1: 73.438 (avg: 75.828)\tTop5: 90.625 (avg: 92.516)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.821 (avg: 0.825)\tLoss: 1.1451 (avg: 0.9340)\tTop1: 65.625 (avg: 75.763)\tTop5: 90.625 (avg: 92.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7449\tTop 1 accuracy: 17.950\tTop 5 accuracy: 37.500\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.823 (avg: 0.808)\tLoss: 0.8678 (avg: 0.9341)\tTop1: 81.250 (avg: 76.250)\tTop5: 93.750 (avg: 91.875)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.819 (avg: 0.818)\tLoss: 0.8851 (avg: 0.8913)\tTop1: 78.125 (avg: 76.969)\tTop5: 96.875 (avg: 92.719)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.823 (avg: 0.822)\tLoss: 1.0810 (avg: 0.9230)\tTop1: 70.312 (avg: 76.021)\tTop5: 89.062 (avg: 92.354)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.818 (avg: 0.823)\tLoss: 0.7783 (avg: 0.9348)\tTop1: 78.125 (avg: 75.906)\tTop5: 95.312 (avg: 92.188)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.821 (avg: 0.824)\tLoss: 0.7186 (avg: 0.9281)\tTop1: 78.125 (avg: 76.025)\tTop5: 93.750 (avg: 92.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7949\tTop 1 accuracy: 17.600\tTop 5 accuracy: 38.000\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.818 (avg: 0.806)\tLoss: 1.1662 (avg: 0.8300)\tTop1: 73.438 (avg: 77.875)\tTop5: 85.938 (avg: 93.750)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.821 (avg: 0.816)\tLoss: 0.7818 (avg: 0.8610)\tTop1: 79.688 (avg: 77.438)\tTop5: 95.312 (avg: 93.062)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.821 (avg: 0.820)\tLoss: 1.1712 (avg: 0.8809)\tTop1: 71.875 (avg: 76.708)\tTop5: 90.625 (avg: 92.917)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.828 (avg: 0.822)\tLoss: 0.5889 (avg: 0.9011)\tTop1: 81.250 (avg: 76.125)\tTop5: 98.438 (avg: 92.734)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.823 (avg: 0.823)\tLoss: 0.6971 (avg: 0.9005)\tTop1: 79.688 (avg: 75.975)\tTop5: 95.312 (avg: 92.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2094\tTop 1 accuracy: 17.500\tTop 5 accuracy: 37.350\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.824 (avg: 0.809)\tLoss: 0.9665 (avg: 0.8151)\tTop1: 79.688 (avg: 79.250)\tTop5: 89.062 (avg: 93.625)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.824 (avg: 0.819)\tLoss: 1.0764 (avg: 0.8330)\tTop1: 70.312 (avg: 77.969)\tTop5: 92.188 (avg: 93.562)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.818 (avg: 0.822)\tLoss: 0.7571 (avg: 0.8377)\tTop1: 79.688 (avg: 77.854)\tTop5: 95.312 (avg: 93.500)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.823 (avg: 0.824)\tLoss: 1.1906 (avg: 0.8709)\tTop1: 68.750 (avg: 77.203)\tTop5: 87.500 (avg: 92.984)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.826 (avg: 0.825)\tLoss: 1.0073 (avg: 0.8805)\tTop1: 71.875 (avg: 77.175)\tTop5: 92.188 (avg: 92.813)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2495\tTop 1 accuracy: 17.500\tTop 5 accuracy: 36.600\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.832 (avg: 0.814)\tLoss: 1.0177 (avg: 0.8455)\tTop1: 70.312 (avg: 77.938)\tTop5: 92.188 (avg: 93.062)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.826 (avg: 0.825)\tLoss: 1.0431 (avg: 0.8371)\tTop1: 70.312 (avg: 78.156)\tTop5: 92.188 (avg: 93.406)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.832 (avg: 0.827)\tLoss: 1.1244 (avg: 0.8736)\tTop1: 60.938 (avg: 77.167)\tTop5: 90.625 (avg: 93.042)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.831 (avg: 0.829)\tLoss: 0.7348 (avg: 0.8737)\tTop1: 71.875 (avg: 76.922)\tTop5: 95.312 (avg: 93.219)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.830 (avg: 0.830)\tLoss: 0.9202 (avg: 0.8725)\tTop1: 81.250 (avg: 76.950)\tTop5: 90.625 (avg: 93.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2575\tTop 1 accuracy: 17.600\tTop 5 accuracy: 37.050\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.828 (avg: 0.815)\tLoss: 0.9944 (avg: 0.8673)\tTop1: 75.000 (avg: 77.562)\tTop5: 89.062 (avg: 92.875)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.834 (avg: 0.825)\tLoss: 0.7568 (avg: 0.8266)\tTop1: 79.688 (avg: 77.906)\tTop5: 93.750 (avg: 93.812)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.821 (avg: 0.828)\tLoss: 0.8727 (avg: 0.8491)\tTop1: 75.000 (avg: 76.917)\tTop5: 95.312 (avg: 93.438)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.828 (avg: 0.830)\tLoss: 0.7795 (avg: 0.8457)\tTop1: 82.812 (avg: 77.188)\tTop5: 93.750 (avg: 93.453)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.838 (avg: 0.832)\tLoss: 1.3117 (avg: 0.8616)\tTop1: 71.875 (avg: 77.075)\tTop5: 87.500 (avg: 93.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2763\tTop 1 accuracy: 18.050\tTop 5 accuracy: 37.200\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.823 (avg: 0.815)\tLoss: 1.0125 (avg: 0.8198)\tTop1: 79.688 (avg: 78.562)\tTop5: 92.188 (avg: 93.812)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.826 (avg: 0.826)\tLoss: 0.9752 (avg: 0.8348)\tTop1: 76.562 (avg: 77.844)\tTop5: 92.188 (avg: 93.625)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.832 (avg: 0.830)\tLoss: 0.6391 (avg: 0.8441)\tTop1: 85.938 (avg: 77.458)\tTop5: 96.875 (avg: 93.500)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.833 (avg: 0.831)\tLoss: 1.1694 (avg: 0.8457)\tTop1: 67.188 (avg: 77.719)\tTop5: 90.625 (avg: 93.406)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.828 (avg: 0.832)\tLoss: 1.1031 (avg: 0.8470)\tTop1: 71.875 (avg: 77.825)\tTop5: 89.062 (avg: 93.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.4847\tTop 1 accuracy: 17.550\tTop 5 accuracy: 36.650\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.837 (avg: 0.813)\tLoss: 1.2302 (avg: 0.8437)\tTop1: 73.438 (avg: 77.750)\tTop5: 84.375 (avg: 93.812)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.834 (avg: 0.827)\tLoss: 0.6645 (avg: 0.8164)\tTop1: 84.375 (avg: 79.094)\tTop5: 93.750 (avg: 94.000)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.841 (avg: 0.831)\tLoss: 0.4692 (avg: 0.8322)\tTop1: 84.375 (avg: 78.479)\tTop5: 100.000 (avg: 93.667)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.836 (avg: 0.833)\tLoss: 0.6125 (avg: 0.8348)\tTop1: 87.500 (avg: 78.219)\tTop5: 93.750 (avg: 93.484)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.833 (avg: 0.835)\tLoss: 0.8894 (avg: 0.8404)\tTop1: 76.562 (avg: 78.013)\tTop5: 95.312 (avg: 93.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3552\tTop 1 accuracy: 17.050\tTop 5 accuracy: 37.150\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.829 (avg: 0.813)\tLoss: 1.3086 (avg: 0.8233)\tTop1: 71.875 (avg: 78.000)\tTop5: 90.625 (avg: 94.500)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.835 (avg: 0.825)\tLoss: 1.1390 (avg: 0.8134)\tTop1: 71.875 (avg: 78.156)\tTop5: 89.062 (avg: 93.969)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.832 (avg: 0.829)\tLoss: 0.6949 (avg: 0.8061)\tTop1: 84.375 (avg: 78.583)\tTop5: 95.312 (avg: 94.167)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.832 (avg: 0.832)\tLoss: 0.8011 (avg: 0.8116)\tTop1: 82.812 (avg: 78.375)\tTop5: 90.625 (avg: 93.984)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.825 (avg: 0.833)\tLoss: 1.1470 (avg: 0.8195)\tTop1: 70.312 (avg: 78.188)\tTop5: 84.375 (avg: 93.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2427\tTop 1 accuracy: 17.050\tTop 5 accuracy: 37.600\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.825 (avg: 0.816)\tLoss: 0.7467 (avg: 0.8112)\tTop1: 82.812 (avg: 79.625)\tTop5: 92.188 (avg: 93.875)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.831 (avg: 0.826)\tLoss: 0.9795 (avg: 0.8261)\tTop1: 73.438 (avg: 78.812)\tTop5: 93.750 (avg: 93.688)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.831 (avg: 0.830)\tLoss: 0.7838 (avg: 0.8101)\tTop1: 81.250 (avg: 79.188)\tTop5: 95.312 (avg: 94.104)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.819 (avg: 0.831)\tLoss: 0.6151 (avg: 0.7941)\tTop1: 81.250 (avg: 79.297)\tTop5: 96.875 (avg: 94.328)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.831 (avg: 0.831)\tLoss: 0.5867 (avg: 0.8059)\tTop1: 84.375 (avg: 78.775)\tTop5: 95.312 (avg: 94.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.6358\tTop 1 accuracy: 17.200\tTop 5 accuracy: 37.050\n",
            "\n",
            "SR = 1.0: top1 = 16.75\ttop5 = 38.400001525878906\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BCQ-VU3BgSl8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8090c4a7-ec9a-4d6d-9a57-ae677def629c"
      },
      "cell_type": "code",
      "source": [
        "print(sr_top1s)\n",
        "print(sr_top5s)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor(13.8000, device='cuda:0'), tensor(16.1500, device='cuda:0'), tensor(15.6000, device='cuda:0'), tensor(17.3000, device='cuda:0'), tensor(16.7500, device='cuda:0')]\n",
            "[tensor(34.2000, device='cuda:0'), tensor(38.6500, device='cuda:0'), tensor(38.2000, device='cuda:0'), tensor(38.4000, device='cuda:0'), tensor(38.4000, device='cuda:0')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-BUZVDJhMfqo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102343
        },
        "outputId": "5743680b-565b-4021-9fda-03d4f6a32183"
      },
      "cell_type": "code",
      "source": [
        "# pct_3x3\n",
        "pct_list = [0.0078125, 0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875]\n",
        "pct_top1s = []\n",
        "pct_top5s = []\n",
        "pct_batch_times = []\n",
        "for pct in pct_list:\n",
        "  model = SqueezeNet_MetaParam(version=1.0, pct=pct)\n",
        "  batch_time, top1, top5 = test_model(model)\n",
        "  pct_top1s.append(top1)\n",
        "  pct_top5s.append(top5)\n",
        "  pct_batch_times.append(batch_time)\n",
        "  print(\"pct_3x3 = {0}: top1 = {1} \\t top5 = {2} \\t batch time = {3}\\n\".format(pct, top1, top5, batch_time))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.334 (avg: 0.458)\tLoss: 5.2963 (avg: 5.3144)\tTop1: 0.000 (avg: 0.250)\tTop5: 0.000 (avg: 1.875)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.334 (avg: 0.399)\tLoss: 5.2989 (avg: 5.3068)\tTop1: 0.000 (avg: 0.312)\tTop5: 0.000 (avg: 1.938)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.331 (avg: 0.379)\tLoss: 5.2989 (avg: 5.3037)\tTop1: 0.000 (avg: 0.438)\tTop5: 3.125 (avg: 2.125)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.331 (avg: 0.369)\tLoss: 5.2497 (avg: 5.3010)\tTop1: 1.562 (avg: 0.469)\tTop5: 4.688 (avg: 2.219)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.336 (avg: 0.363)\tLoss: 5.2765 (avg: 5.2967)\tTop1: 0.000 (avg: 0.488)\tTop5: 3.125 (avg: 2.312)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1562\tTop 1 accuracy: 0.450\tTop 5 accuracy: 2.350\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.331 (avg: 0.329)\tLoss: 5.2758 (avg: 5.2724)\tTop1: 0.000 (avg: 0.375)\tTop5: 4.688 (avg: 3.312)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.330 (avg: 0.333)\tLoss: 5.2763 (avg: 5.2759)\tTop1: 0.000 (avg: 0.438)\tTop5: 0.000 (avg: 3.156)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.330 (avg: 0.334)\tLoss: 5.2978 (avg: 5.2755)\tTop1: 0.000 (avg: 0.479)\tTop5: 1.562 (avg: 3.333)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.324 (avg: 0.334)\tLoss: 5.2434 (avg: 5.2750)\tTop1: 1.562 (avg: 0.531)\tTop5: 1.562 (avg: 3.422)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.331 (avg: 0.334)\tLoss: 5.2644 (avg: 5.2709)\tTop1: 1.562 (avg: 0.625)\tTop5: 3.125 (avg: 3.563)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1178\tTop 1 accuracy: 0.750\tTop 5 accuracy: 3.400\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.330 (avg: 0.328)\tLoss: 5.2805 (avg: 5.2664)\tTop1: 3.125 (avg: 1.188)\tTop5: 4.688 (avg: 3.875)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.330 (avg: 0.332)\tLoss: 5.2712 (avg: 5.2538)\tTop1: 1.562 (avg: 1.031)\tTop5: 4.688 (avg: 4.375)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.329 (avg: 0.334)\tLoss: 5.2232 (avg: 5.2523)\tTop1: 1.562 (avg: 0.958)\tTop5: 4.688 (avg: 4.646)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.331 (avg: 0.334)\tLoss: 5.3485 (avg: 5.2436)\tTop1: 0.000 (avg: 0.953)\tTop5: 1.562 (avg: 4.484)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.327 (avg: 0.335)\tLoss: 5.2585 (avg: 5.2422)\tTop1: 0.000 (avg: 0.950)\tTop5: 4.688 (avg: 4.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2012\tTop 1 accuracy: 0.950\tTop 5 accuracy: 4.950\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.328 (avg: 0.328)\tLoss: 5.2874 (avg: 5.2187)\tTop1: 0.000 (avg: 0.812)\tTop5: 0.000 (avg: 4.750)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.330 (avg: 0.332)\tLoss: 5.1314 (avg: 5.2196)\tTop1: 0.000 (avg: 1.062)\tTop5: 9.375 (avg: 5.094)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.325 (avg: 0.334)\tLoss: 5.2046 (avg: 5.2168)\tTop1: 1.562 (avg: 1.062)\tTop5: 3.125 (avg: 4.688)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.328 (avg: 0.334)\tLoss: 5.2208 (avg: 5.2202)\tTop1: 0.000 (avg: 1.062)\tTop5: 4.688 (avg: 4.469)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.330 (avg: 0.335)\tLoss: 5.1498 (avg: 5.2141)\tTop1: 3.125 (avg: 1.062)\tTop5: 7.812 (avg: 4.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1717\tTop 1 accuracy: 0.650\tTop 5 accuracy: 4.100\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.329 (avg: 0.328)\tLoss: 5.2602 (avg: 5.1990)\tTop1: 0.000 (avg: 1.000)\tTop5: 3.125 (avg: 4.750)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.330 (avg: 0.332)\tLoss: 5.0746 (avg: 5.1936)\tTop1: 3.125 (avg: 1.156)\tTop5: 6.250 (avg: 5.281)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.329 (avg: 0.333)\tLoss: 5.3445 (avg: 5.1986)\tTop1: 0.000 (avg: 1.062)\tTop5: 1.562 (avg: 5.271)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.332 (avg: 0.334)\tLoss: 5.2161 (avg: 5.2004)\tTop1: 1.562 (avg: 1.031)\tTop5: 1.562 (avg: 4.922)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.331 (avg: 0.334)\tLoss: 5.2654 (avg: 5.1974)\tTop1: 0.000 (avg: 1.013)\tTop5: 3.125 (avg: 5.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1931\tTop 1 accuracy: 0.850\tTop 5 accuracy: 4.400\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.332 (avg: 0.328)\tLoss: 5.2215 (avg: 5.1979)\tTop1: 0.000 (avg: 0.875)\tTop5: 4.688 (avg: 5.312)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.331 (avg: 0.332)\tLoss: 5.0210 (avg: 5.1923)\tTop1: 3.125 (avg: 0.969)\tTop5: 14.062 (avg: 5.344)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.330 (avg: 0.333)\tLoss: 5.2609 (avg: 5.1942)\tTop1: 0.000 (avg: 1.062)\tTop5: 1.562 (avg: 5.188)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.329 (avg: 0.334)\tLoss: 5.1500 (avg: 5.1862)\tTop1: 1.562 (avg: 1.125)\tTop5: 6.250 (avg: 5.328)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.332 (avg: 0.334)\tLoss: 5.1803 (avg: 5.1871)\tTop1: 1.562 (avg: 1.088)\tTop5: 4.688 (avg: 5.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1953\tTop 1 accuracy: 0.800\tTop 5 accuracy: 4.400\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.330 (avg: 0.328)\tLoss: 5.3299 (avg: 5.1729)\tTop1: 1.562 (avg: 1.250)\tTop5: 3.125 (avg: 5.875)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.328 (avg: 0.332)\tLoss: 5.1453 (avg: 5.1638)\tTop1: 1.562 (avg: 1.375)\tTop5: 6.250 (avg: 5.781)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.328 (avg: 0.333)\tLoss: 5.1951 (avg: 5.1702)\tTop1: 3.125 (avg: 1.333)\tTop5: 7.812 (avg: 5.729)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.330 (avg: 0.334)\tLoss: 5.2761 (avg: 5.1758)\tTop1: 0.000 (avg: 1.297)\tTop5: 3.125 (avg: 5.625)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.331 (avg: 0.334)\tLoss: 5.2376 (avg: 5.1783)\tTop1: 3.125 (avg: 1.300)\tTop5: 3.125 (avg: 5.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1225\tTop 1 accuracy: 0.700\tTop 5 accuracy: 4.150\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.334 (avg: 0.328)\tLoss: 5.0858 (avg: 5.1807)\tTop1: 1.562 (avg: 1.188)\tTop5: 6.250 (avg: 6.062)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.328 (avg: 0.332)\tLoss: 5.1148 (avg: 5.1675)\tTop1: 1.562 (avg: 1.156)\tTop5: 9.375 (avg: 6.344)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.331 (avg: 0.333)\tLoss: 5.0842 (avg: 5.1730)\tTop1: 3.125 (avg: 1.062)\tTop5: 9.375 (avg: 5.917)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.328 (avg: 0.334)\tLoss: 5.1878 (avg: 5.1684)\tTop1: 1.562 (avg: 1.188)\tTop5: 4.688 (avg: 5.984)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.324 (avg: 0.333)\tLoss: 5.2021 (avg: 5.1711)\tTop1: 1.562 (avg: 1.163)\tTop5: 9.375 (avg: 5.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1613\tTop 1 accuracy: 1.000\tTop 5 accuracy: 5.650\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.328 (avg: 0.328)\tLoss: 5.2439 (avg: 5.1728)\tTop1: 0.000 (avg: 1.188)\tTop5: 0.000 (avg: 5.938)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.329 (avg: 0.332)\tLoss: 5.2433 (avg: 5.1713)\tTop1: 1.562 (avg: 1.000)\tTop5: 1.562 (avg: 5.812)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.328 (avg: 0.333)\tLoss: 5.0014 (avg: 5.1624)\tTop1: 0.000 (avg: 1.000)\tTop5: 17.188 (avg: 5.979)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.328 (avg: 0.334)\tLoss: 5.2009 (avg: 5.1655)\tTop1: 0.000 (avg: 0.938)\tTop5: 3.125 (avg: 5.688)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.331 (avg: 0.334)\tLoss: 5.1736 (avg: 5.1645)\tTop1: 1.562 (avg: 0.950)\tTop5: 4.688 (avg: 5.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2114\tTop 1 accuracy: 1.100\tTop 5 accuracy: 5.600\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.330 (avg: 0.327)\tLoss: 5.1217 (avg: 5.1501)\tTop1: 3.125 (avg: 1.125)\tTop5: 6.250 (avg: 6.312)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.328 (avg: 0.332)\tLoss: 5.1902 (avg: 5.1539)\tTop1: 0.000 (avg: 1.062)\tTop5: 7.812 (avg: 5.938)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.330 (avg: 0.333)\tLoss: 5.2341 (avg: 5.1460)\tTop1: 1.562 (avg: 1.125)\tTop5: 4.688 (avg: 6.146)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.330 (avg: 0.334)\tLoss: 5.1512 (avg: 5.1437)\tTop1: 1.562 (avg: 1.234)\tTop5: 9.375 (avg: 6.016)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.330 (avg: 0.334)\tLoss: 5.2516 (avg: 5.1546)\tTop1: 0.000 (avg: 1.175)\tTop5: 3.125 (avg: 5.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1819\tTop 1 accuracy: 1.150\tTop 5 accuracy: 5.600\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.330 (avg: 0.328)\tLoss: 5.1791 (avg: 5.1652)\tTop1: 1.562 (avg: 1.188)\tTop5: 4.688 (avg: 6.000)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.330 (avg: 0.332)\tLoss: 5.1277 (avg: 5.1624)\tTop1: 1.562 (avg: 1.250)\tTop5: 6.250 (avg: 6.250)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.330 (avg: 0.333)\tLoss: 5.0169 (avg: 5.1560)\tTop1: 4.688 (avg: 1.229)\tTop5: 9.375 (avg: 6.375)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.330 (avg: 0.334)\tLoss: 5.0461 (avg: 5.1495)\tTop1: 4.688 (avg: 1.156)\tTop5: 9.375 (avg: 6.219)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.333 (avg: 0.334)\tLoss: 5.0800 (avg: 5.1499)\tTop1: 1.562 (avg: 1.200)\tTop5: 6.250 (avg: 6.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1866\tTop 1 accuracy: 0.850\tTop 5 accuracy: 5.150\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.330 (avg: 0.327)\tLoss: 5.0192 (avg: 5.1335)\tTop1: 4.688 (avg: 1.125)\tTop5: 12.500 (avg: 6.438)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.332 (avg: 0.332)\tLoss: 5.1709 (avg: 5.1407)\tTop1: 3.125 (avg: 1.156)\tTop5: 4.688 (avg: 5.969)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.327 (avg: 0.333)\tLoss: 5.2164 (avg: 5.1321)\tTop1: 1.562 (avg: 1.271)\tTop5: 1.562 (avg: 6.396)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.331 (avg: 0.334)\tLoss: 5.1456 (avg: 5.1352)\tTop1: 1.562 (avg: 1.312)\tTop5: 6.250 (avg: 6.406)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.328 (avg: 0.334)\tLoss: 5.1559 (avg: 5.1406)\tTop1: 1.562 (avg: 1.175)\tTop5: 6.250 (avg: 6.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2225\tTop 1 accuracy: 0.950\tTop 5 accuracy: 5.750\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.330 (avg: 0.328)\tLoss: 5.0504 (avg: 5.1380)\tTop1: 4.688 (avg: 1.875)\tTop5: 10.938 (avg: 6.125)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.329 (avg: 0.332)\tLoss: 5.0980 (avg: 5.1331)\tTop1: 1.562 (avg: 1.625)\tTop5: 7.812 (avg: 6.406)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.329 (avg: 0.333)\tLoss: 5.1252 (avg: 5.1236)\tTop1: 1.562 (avg: 1.583)\tTop5: 4.688 (avg: 6.521)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.328 (avg: 0.334)\tLoss: 5.0872 (avg: 5.1216)\tTop1: 3.125 (avg: 1.516)\tTop5: 12.500 (avg: 6.719)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.329 (avg: 0.334)\tLoss: 5.2245 (avg: 5.1217)\tTop1: 0.000 (avg: 1.475)\tTop5: 3.125 (avg: 6.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0506\tTop 1 accuracy: 1.800\tTop 5 accuracy: 6.150\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.329 (avg: 0.328)\tLoss: 5.1092 (avg: 5.0953)\tTop1: 0.000 (avg: 1.812)\tTop5: 9.375 (avg: 8.438)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.329 (avg: 0.332)\tLoss: 4.9940 (avg: 5.1068)\tTop1: 3.125 (avg: 1.750)\tTop5: 7.812 (avg: 7.719)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.329 (avg: 0.333)\tLoss: 5.2009 (avg: 5.1040)\tTop1: 1.562 (avg: 1.771)\tTop5: 9.375 (avg: 7.792)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.330 (avg: 0.334)\tLoss: 5.0094 (avg: 5.1100)\tTop1: 0.000 (avg: 1.688)\tTop5: 6.250 (avg: 7.484)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.324 (avg: 0.334)\tLoss: 4.9648 (avg: 5.1108)\tTop1: 6.250 (avg: 1.713)\tTop5: 12.500 (avg: 7.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0731\tTop 1 accuracy: 1.100\tTop 5 accuracy: 6.650\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.332 (avg: 0.328)\tLoss: 4.9544 (avg: 5.0999)\tTop1: 6.250 (avg: 1.750)\tTop5: 12.500 (avg: 7.688)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.329 (avg: 0.332)\tLoss: 5.0364 (avg: 5.1135)\tTop1: 1.562 (avg: 1.438)\tTop5: 12.500 (avg: 7.375)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.328 (avg: 0.333)\tLoss: 5.0650 (avg: 5.1083)\tTop1: 3.125 (avg: 1.646)\tTop5: 10.938 (avg: 7.646)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.327 (avg: 0.334)\tLoss: 5.0207 (avg: 5.0959)\tTop1: 4.688 (avg: 1.859)\tTop5: 9.375 (avg: 7.984)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.332 (avg: 0.334)\tLoss: 5.0932 (avg: 5.0973)\tTop1: 0.000 (avg: 1.775)\tTop5: 7.812 (avg: 8.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1654\tTop 1 accuracy: 1.650\tTop 5 accuracy: 7.950\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.329 (avg: 0.328)\tLoss: 5.0461 (avg: 5.1051)\tTop1: 1.562 (avg: 1.562)\tTop5: 9.375 (avg: 8.438)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.329 (avg: 0.332)\tLoss: 5.1400 (avg: 5.0868)\tTop1: 1.562 (avg: 1.812)\tTop5: 3.125 (avg: 8.094)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.327 (avg: 0.333)\tLoss: 5.1172 (avg: 5.0914)\tTop1: 0.000 (avg: 1.750)\tTop5: 4.688 (avg: 8.188)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.330 (avg: 0.334)\tLoss: 5.1053 (avg: 5.0988)\tTop1: 0.000 (avg: 1.750)\tTop5: 9.375 (avg: 8.172)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.327 (avg: 0.334)\tLoss: 5.2008 (avg: 5.0872)\tTop1: 1.562 (avg: 1.825)\tTop5: 7.812 (avg: 8.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9132\tTop 1 accuracy: 2.400\tTop 5 accuracy: 7.800\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.329 (avg: 0.328)\tLoss: 5.1844 (avg: 5.0653)\tTop1: 3.125 (avg: 2.250)\tTop5: 4.688 (avg: 7.812)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.332 (avg: 0.332)\tLoss: 5.2524 (avg: 5.0871)\tTop1: 1.562 (avg: 2.062)\tTop5: 4.688 (avg: 7.656)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.327 (avg: 0.333)\tLoss: 5.0666 (avg: 5.0886)\tTop1: 3.125 (avg: 2.000)\tTop5: 12.500 (avg: 8.021)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.326 (avg: 0.334)\tLoss: 4.9400 (avg: 5.0724)\tTop1: 4.688 (avg: 2.078)\tTop5: 14.062 (avg: 8.516)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.330 (avg: 0.335)\tLoss: 5.0583 (avg: 5.0666)\tTop1: 4.688 (avg: 2.150)\tTop5: 9.375 (avg: 8.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8454\tTop 1 accuracy: 2.000\tTop 5 accuracy: 7.650\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.336 (avg: 0.328)\tLoss: 5.0861 (avg: 5.0302)\tTop1: 0.000 (avg: 2.500)\tTop5: 6.250 (avg: 9.875)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.330 (avg: 0.332)\tLoss: 5.0447 (avg: 5.0452)\tTop1: 1.562 (avg: 2.219)\tTop5: 9.375 (avg: 9.688)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.327 (avg: 0.333)\tLoss: 4.8922 (avg: 5.0493)\tTop1: 1.562 (avg: 2.104)\tTop5: 7.812 (avg: 8.938)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.329 (avg: 0.334)\tLoss: 5.0787 (avg: 5.0533)\tTop1: 4.688 (avg: 2.078)\tTop5: 6.250 (avg: 9.047)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.327 (avg: 0.335)\tLoss: 5.0788 (avg: 5.0613)\tTop1: 0.000 (avg: 2.000)\tTop5: 7.812 (avg: 8.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9352\tTop 1 accuracy: 2.100\tTop 5 accuracy: 8.700\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.332 (avg: 0.328)\tLoss: 4.9464 (avg: 5.0140)\tTop1: 0.000 (avg: 2.375)\tTop5: 7.812 (avg: 10.500)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.329 (avg: 0.332)\tLoss: 5.0084 (avg: 5.0387)\tTop1: 3.125 (avg: 2.688)\tTop5: 10.938 (avg: 10.000)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.332 (avg: 0.334)\tLoss: 5.1904 (avg: 5.0511)\tTop1: 0.000 (avg: 2.333)\tTop5: 7.812 (avg: 9.583)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.331 (avg: 0.334)\tLoss: 5.0637 (avg: 5.0546)\tTop1: 3.125 (avg: 2.344)\tTop5: 9.375 (avg: 9.297)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.329 (avg: 0.335)\tLoss: 5.1293 (avg: 5.0526)\tTop1: 1.562 (avg: 2.225)\tTop5: 7.812 (avg: 9.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7959\tTop 1 accuracy: 1.950\tTop 5 accuracy: 8.700\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.324 (avg: 0.328)\tLoss: 5.0758 (avg: 5.0290)\tTop1: 1.562 (avg: 2.562)\tTop5: 9.375 (avg: 9.875)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.328 (avg: 0.332)\tLoss: 4.9792 (avg: 5.0369)\tTop1: 1.562 (avg: 2.375)\tTop5: 9.375 (avg: 9.531)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.329 (avg: 0.333)\tLoss: 5.0793 (avg: 5.0319)\tTop1: 6.250 (avg: 2.396)\tTop5: 12.500 (avg: 9.854)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.329 (avg: 0.334)\tLoss: 5.0828 (avg: 5.0265)\tTop1: 7.812 (avg: 2.438)\tTop5: 14.062 (avg: 9.875)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.327 (avg: 0.334)\tLoss: 4.9431 (avg: 5.0244)\tTop1: 1.562 (avg: 2.438)\tTop5: 6.250 (avg: 9.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9145\tTop 1 accuracy: 2.000\tTop 5 accuracy: 8.900\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.330 (avg: 0.329)\tLoss: 5.1020 (avg: 5.0629)\tTop1: 0.000 (avg: 1.812)\tTop5: 6.250 (avg: 8.375)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.330 (avg: 0.333)\tLoss: 4.9844 (avg: 5.0158)\tTop1: 3.125 (avg: 2.250)\tTop5: 12.500 (avg: 9.125)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.327 (avg: 0.334)\tLoss: 5.0128 (avg: 5.0138)\tTop1: 1.562 (avg: 2.250)\tTop5: 6.250 (avg: 9.083)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.330 (avg: 0.335)\tLoss: 5.1265 (avg: 5.0183)\tTop1: 1.562 (avg: 2.359)\tTop5: 6.250 (avg: 9.594)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.331 (avg: 0.335)\tLoss: 5.0313 (avg: 5.0186)\tTop1: 3.125 (avg: 2.425)\tTop5: 10.938 (avg: 9.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9428\tTop 1 accuracy: 2.500\tTop 5 accuracy: 9.850\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.330 (avg: 0.329)\tLoss: 5.1636 (avg: 4.9840)\tTop1: 1.562 (avg: 2.812)\tTop5: 10.938 (avg: 10.875)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.332 (avg: 0.333)\tLoss: 4.9808 (avg: 5.0064)\tTop1: 6.250 (avg: 2.781)\tTop5: 15.625 (avg: 10.438)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.328 (avg: 0.334)\tLoss: 5.0861 (avg: 4.9993)\tTop1: 0.000 (avg: 2.750)\tTop5: 7.812 (avg: 10.500)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.328 (avg: 0.335)\tLoss: 5.0822 (avg: 4.9969)\tTop1: 0.000 (avg: 2.688)\tTop5: 9.375 (avg: 10.531)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.330 (avg: 0.335)\tLoss: 4.9297 (avg: 4.9903)\tTop1: 1.562 (avg: 2.725)\tTop5: 6.250 (avg: 10.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9284\tTop 1 accuracy: 2.300\tTop 5 accuracy: 9.550\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.330 (avg: 0.329)\tLoss: 5.1020 (avg: 4.9898)\tTop1: 0.000 (avg: 2.688)\tTop5: 3.125 (avg: 11.812)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.329 (avg: 0.333)\tLoss: 4.9957 (avg: 4.9807)\tTop1: 7.812 (avg: 2.938)\tTop5: 10.938 (avg: 11.594)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.327 (avg: 0.334)\tLoss: 4.9389 (avg: 4.9795)\tTop1: 3.125 (avg: 2.833)\tTop5: 6.250 (avg: 11.167)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.329 (avg: 0.335)\tLoss: 4.9079 (avg: 4.9862)\tTop1: 3.125 (avg: 2.875)\tTop5: 17.188 (avg: 11.000)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.332 (avg: 0.335)\tLoss: 4.8977 (avg: 4.9859)\tTop1: 0.000 (avg: 2.763)\tTop5: 9.375 (avg: 10.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8893\tTop 1 accuracy: 2.350\tTop 5 accuracy: 10.250\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.328 (avg: 0.328)\tLoss: 4.9296 (avg: 4.9638)\tTop1: 3.125 (avg: 3.750)\tTop5: 7.812 (avg: 11.688)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.332 (avg: 0.332)\tLoss: 4.9454 (avg: 4.9608)\tTop1: 1.562 (avg: 3.281)\tTop5: 7.812 (avg: 11.156)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.328 (avg: 0.334)\tLoss: 5.0062 (avg: 4.9542)\tTop1: 3.125 (avg: 3.188)\tTop5: 10.938 (avg: 11.688)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.330 (avg: 0.335)\tLoss: 5.1585 (avg: 4.9608)\tTop1: 1.562 (avg: 2.859)\tTop5: 4.688 (avg: 11.094)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.332 (avg: 0.335)\tLoss: 4.8384 (avg: 4.9550)\tTop1: 3.125 (avg: 2.813)\tTop5: 18.750 (avg: 11.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7866\tTop 1 accuracy: 2.700\tTop 5 accuracy: 12.150\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.329 (avg: 0.327)\tLoss: 4.9248 (avg: 4.9041)\tTop1: 0.000 (avg: 3.250)\tTop5: 12.500 (avg: 12.250)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.331 (avg: 0.332)\tLoss: 4.7940 (avg: 4.9122)\tTop1: 6.250 (avg: 2.938)\tTop5: 14.062 (avg: 12.062)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.332 (avg: 0.334)\tLoss: 4.8622 (avg: 4.9188)\tTop1: 0.000 (avg: 2.750)\tTop5: 10.938 (avg: 11.771)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.330 (avg: 0.335)\tLoss: 4.8218 (avg: 4.9207)\tTop1: 6.250 (avg: 3.109)\tTop5: 10.938 (avg: 12.047)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.331 (avg: 0.335)\tLoss: 4.7122 (avg: 4.9298)\tTop1: 7.812 (avg: 3.075)\tTop5: 18.750 (avg: 11.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7973\tTop 1 accuracy: 3.050\tTop 5 accuracy: 12.750\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.332 (avg: 0.329)\tLoss: 4.9573 (avg: 4.8427)\tTop1: 3.125 (avg: 3.812)\tTop5: 12.500 (avg: 13.938)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.323 (avg: 0.333)\tLoss: 5.0453 (avg: 4.8751)\tTop1: 0.000 (avg: 3.562)\tTop5: 12.500 (avg: 13.250)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.329 (avg: 0.334)\tLoss: 4.9513 (avg: 4.8864)\tTop1: 4.688 (avg: 3.771)\tTop5: 12.500 (avg: 13.292)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.332 (avg: 0.335)\tLoss: 4.9336 (avg: 4.8935)\tTop1: 1.562 (avg: 3.656)\tTop5: 12.500 (avg: 12.859)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.326 (avg: 0.335)\tLoss: 4.7003 (avg: 4.8998)\tTop1: 1.562 (avg: 3.538)\tTop5: 18.750 (avg: 12.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8289\tTop 1 accuracy: 3.750\tTop 5 accuracy: 12.300\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.330 (avg: 0.330)\tLoss: 4.7713 (avg: 4.8484)\tTop1: 3.125 (avg: 3.375)\tTop5: 14.062 (avg: 13.625)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.328 (avg: 0.333)\tLoss: 4.7071 (avg: 4.8513)\tTop1: 1.562 (avg: 3.344)\tTop5: 15.625 (avg: 13.750)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.330 (avg: 0.334)\tLoss: 5.0356 (avg: 4.8575)\tTop1: 3.125 (avg: 3.458)\tTop5: 10.938 (avg: 13.604)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.329 (avg: 0.335)\tLoss: 5.0577 (avg: 4.8623)\tTop1: 1.562 (avg: 3.328)\tTop5: 6.250 (avg: 13.062)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.337 (avg: 0.335)\tLoss: 5.2631 (avg: 4.8742)\tTop1: 0.000 (avg: 3.400)\tTop5: 1.562 (avg: 12.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8708\tTop 1 accuracy: 3.050\tTop 5 accuracy: 12.000\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.331 (avg: 0.329)\tLoss: 4.7192 (avg: 4.8489)\tTop1: 3.125 (avg: 3.688)\tTop5: 14.062 (avg: 13.500)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.332 (avg: 0.333)\tLoss: 4.8829 (avg: 4.8534)\tTop1: 3.125 (avg: 3.500)\tTop5: 9.375 (avg: 13.188)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.324 (avg: 0.335)\tLoss: 4.6294 (avg: 4.8608)\tTop1: 3.125 (avg: 3.292)\tTop5: 21.875 (avg: 12.854)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.330 (avg: 0.335)\tLoss: 4.8147 (avg: 4.8517)\tTop1: 3.125 (avg: 3.422)\tTop5: 9.375 (avg: 13.125)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.330 (avg: 0.336)\tLoss: 4.9356 (avg: 4.8591)\tTop1: 1.562 (avg: 3.338)\tTop5: 10.938 (avg: 12.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8088\tTop 1 accuracy: 4.100\tTop 5 accuracy: 13.350\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.326 (avg: 0.330)\tLoss: 4.8675 (avg: 4.8185)\tTop1: 1.562 (avg: 3.188)\tTop5: 17.188 (avg: 14.938)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.332 (avg: 0.334)\tLoss: 4.6318 (avg: 4.8009)\tTop1: 6.250 (avg: 3.500)\tTop5: 17.188 (avg: 14.719)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.329 (avg: 0.335)\tLoss: 5.0801 (avg: 4.8195)\tTop1: 0.000 (avg: 3.625)\tTop5: 10.938 (avg: 14.021)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.336 (avg: 0.335)\tLoss: 4.6962 (avg: 4.8242)\tTop1: 3.125 (avg: 3.516)\tTop5: 12.500 (avg: 13.938)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.326 (avg: 0.335)\tLoss: 4.9089 (avg: 4.8285)\tTop1: 4.688 (avg: 3.438)\tTop5: 12.500 (avg: 13.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9252\tTop 1 accuracy: 3.700\tTop 5 accuracy: 14.100\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.333 (avg: 0.329)\tLoss: 4.8090 (avg: 4.7450)\tTop1: 4.688 (avg: 4.750)\tTop5: 9.375 (avg: 16.500)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.331 (avg: 0.333)\tLoss: 4.5956 (avg: 4.7696)\tTop1: 1.562 (avg: 4.406)\tTop5: 23.438 (avg: 15.812)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.330 (avg: 0.334)\tLoss: 4.8651 (avg: 4.7914)\tTop1: 6.250 (avg: 4.167)\tTop5: 14.062 (avg: 15.104)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.332 (avg: 0.335)\tLoss: 4.9200 (avg: 4.7966)\tTop1: 3.125 (avg: 4.047)\tTop5: 12.500 (avg: 14.844)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.329 (avg: 0.335)\tLoss: 4.8309 (avg: 4.7955)\tTop1: 3.125 (avg: 4.000)\tTop5: 14.062 (avg: 14.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9394\tTop 1 accuracy: 3.100\tTop 5 accuracy: 13.800\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.332 (avg: 0.329)\tLoss: 4.5420 (avg: 4.7366)\tTop1: 7.812 (avg: 5.562)\tTop5: 21.875 (avg: 16.750)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.337 (avg: 0.333)\tLoss: 4.9774 (avg: 4.7077)\tTop1: 3.125 (avg: 4.969)\tTop5: 17.188 (avg: 17.469)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.327 (avg: 0.334)\tLoss: 4.7007 (avg: 4.6925)\tTop1: 6.250 (avg: 5.208)\tTop5: 14.062 (avg: 17.771)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.330 (avg: 0.334)\tLoss: 4.4455 (avg: 4.6728)\tTop1: 7.812 (avg: 5.562)\tTop5: 20.312 (avg: 18.328)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.327 (avg: 0.334)\tLoss: 4.6111 (avg: 4.6694)\tTop1: 9.375 (avg: 5.463)\tTop5: 21.875 (avg: 18.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5604\tTop 1 accuracy: 4.600\tTop 5 accuracy: 17.200\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.330 (avg: 0.329)\tLoss: 4.4751 (avg: 4.6447)\tTop1: 9.375 (avg: 5.688)\tTop5: 23.438 (avg: 19.250)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.332 (avg: 0.333)\tLoss: 4.8754 (avg: 4.6528)\tTop1: 3.125 (avg: 5.656)\tTop5: 18.750 (avg: 18.500)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.330 (avg: 0.334)\tLoss: 4.8348 (avg: 4.6412)\tTop1: 3.125 (avg: 6.021)\tTop5: 14.062 (avg: 18.771)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.328 (avg: 0.335)\tLoss: 4.6248 (avg: 4.6346)\tTop1: 3.125 (avg: 5.906)\tTop5: 10.938 (avg: 18.656)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.334 (avg: 0.335)\tLoss: 4.5706 (avg: 4.6363)\tTop1: 3.125 (avg: 5.925)\tTop5: 10.938 (avg: 18.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5987\tTop 1 accuracy: 5.450\tTop 5 accuracy: 17.550\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.332 (avg: 0.327)\tLoss: 4.5422 (avg: 4.5442)\tTop1: 6.250 (avg: 7.688)\tTop5: 21.875 (avg: 22.500)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.332 (avg: 0.332)\tLoss: 4.6856 (avg: 4.5862)\tTop1: 4.688 (avg: 6.719)\tTop5: 20.312 (avg: 20.594)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.331 (avg: 0.334)\tLoss: 4.4844 (avg: 4.6090)\tTop1: 4.688 (avg: 6.292)\tTop5: 17.188 (avg: 19.792)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.330 (avg: 0.335)\tLoss: 4.5878 (avg: 4.6188)\tTop1: 10.938 (avg: 6.109)\tTop5: 23.438 (avg: 19.469)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.332 (avg: 0.335)\tLoss: 4.6751 (avg: 4.6206)\tTop1: 1.562 (avg: 5.950)\tTop5: 9.375 (avg: 19.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4870\tTop 1 accuracy: 5.850\tTop 5 accuracy: 17.700\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.332 (avg: 0.329)\tLoss: 4.4103 (avg: 4.5484)\tTop1: 7.812 (avg: 6.562)\tTop5: 21.875 (avg: 21.250)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.329 (avg: 0.333)\tLoss: 4.6672 (avg: 4.5871)\tTop1: 9.375 (avg: 6.219)\tTop5: 17.188 (avg: 19.844)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.326 (avg: 0.334)\tLoss: 4.8694 (avg: 4.5969)\tTop1: 4.688 (avg: 6.375)\tTop5: 10.938 (avg: 19.646)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.330 (avg: 0.334)\tLoss: 4.7104 (avg: 4.6062)\tTop1: 3.125 (avg: 6.219)\tTop5: 15.625 (avg: 19.656)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.334 (avg: 0.335)\tLoss: 4.4321 (avg: 4.6077)\tTop1: 4.688 (avg: 6.363)\tTop5: 32.812 (avg: 19.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5149\tTop 1 accuracy: 5.950\tTop 5 accuracy: 16.750\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.332 (avg: 0.329)\tLoss: 4.4637 (avg: 4.5454)\tTop1: 6.250 (avg: 7.062)\tTop5: 28.125 (avg: 22.125)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.330 (avg: 0.333)\tLoss: 4.4513 (avg: 4.5830)\tTop1: 4.688 (avg: 6.156)\tTop5: 20.312 (avg: 20.219)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.330 (avg: 0.335)\tLoss: 4.2171 (avg: 4.5859)\tTop1: 12.500 (avg: 6.583)\tTop5: 31.250 (avg: 20.083)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.328 (avg: 0.335)\tLoss: 4.3795 (avg: 4.5836)\tTop1: 6.250 (avg: 6.484)\tTop5: 18.750 (avg: 20.312)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.330 (avg: 0.336)\tLoss: 4.5641 (avg: 4.5982)\tTop1: 4.688 (avg: 6.388)\tTop5: 23.438 (avg: 20.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3909\tTop 1 accuracy: 5.550\tTop 5 accuracy: 17.650\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.332 (avg: 0.329)\tLoss: 4.5911 (avg: 4.5922)\tTop1: 4.688 (avg: 5.625)\tTop5: 23.438 (avg: 19.688)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.332 (avg: 0.333)\tLoss: 4.5288 (avg: 4.5997)\tTop1: 1.562 (avg: 6.156)\tTop5: 14.062 (avg: 19.531)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.329 (avg: 0.334)\tLoss: 4.8864 (avg: 4.5881)\tTop1: 6.250 (avg: 6.354)\tTop5: 18.750 (avg: 20.000)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.331 (avg: 0.335)\tLoss: 4.5686 (avg: 4.5788)\tTop1: 6.250 (avg: 6.109)\tTop5: 20.312 (avg: 20.500)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.329 (avg: 0.336)\tLoss: 4.6962 (avg: 4.5882)\tTop1: 6.250 (avg: 6.163)\tTop5: 20.312 (avg: 20.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4947\tTop 1 accuracy: 5.750\tTop 5 accuracy: 18.150\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.331 (avg: 0.330)\tLoss: 4.5261 (avg: 4.5887)\tTop1: 6.250 (avg: 6.125)\tTop5: 20.312 (avg: 20.188)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.332 (avg: 0.334)\tLoss: 4.8105 (avg: 4.6062)\tTop1: 9.375 (avg: 6.438)\tTop5: 21.875 (avg: 20.000)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.328 (avg: 0.335)\tLoss: 4.5807 (avg: 4.5891)\tTop1: 7.812 (avg: 6.396)\tTop5: 17.188 (avg: 19.938)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.331 (avg: 0.336)\tLoss: 4.5066 (avg: 4.5959)\tTop1: 7.812 (avg: 6.203)\tTop5: 21.875 (avg: 19.922)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.328 (avg: 0.336)\tLoss: 4.6150 (avg: 4.5827)\tTop1: 4.688 (avg: 6.388)\tTop5: 17.188 (avg: 20.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6290\tTop 1 accuracy: 5.700\tTop 5 accuracy: 17.600\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.330 (avg: 0.329)\tLoss: 4.3350 (avg: 4.5492)\tTop1: 10.938 (avg: 7.312)\tTop5: 26.562 (avg: 21.938)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.335 (avg: 0.334)\tLoss: 4.5021 (avg: 4.5586)\tTop1: 7.812 (avg: 6.562)\tTop5: 25.000 (avg: 21.219)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.327 (avg: 0.335)\tLoss: 4.4356 (avg: 4.5714)\tTop1: 7.812 (avg: 6.583)\tTop5: 20.312 (avg: 21.292)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.324 (avg: 0.335)\tLoss: 4.6635 (avg: 4.5776)\tTop1: 7.812 (avg: 6.703)\tTop5: 15.625 (avg: 21.094)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.331 (avg: 0.335)\tLoss: 4.5643 (avg: 4.5742)\tTop1: 3.125 (avg: 6.613)\tTop5: 20.312 (avg: 20.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5731\tTop 1 accuracy: 5.250\tTop 5 accuracy: 17.550\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.330 (avg: 0.326)\tLoss: 4.4070 (avg: 4.5505)\tTop1: 14.062 (avg: 6.625)\tTop5: 32.812 (avg: 21.062)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.333 (avg: 0.332)\tLoss: 4.3594 (avg: 4.5535)\tTop1: 9.375 (avg: 6.625)\tTop5: 26.562 (avg: 21.250)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.330 (avg: 0.334)\tLoss: 4.4429 (avg: 4.5513)\tTop1: 7.812 (avg: 7.000)\tTop5: 18.750 (avg: 21.292)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.329 (avg: 0.334)\tLoss: 4.6799 (avg: 4.5601)\tTop1: 10.938 (avg: 6.734)\tTop5: 14.062 (avg: 21.266)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.333 (avg: 0.335)\tLoss: 4.4716 (avg: 4.5652)\tTop1: 3.125 (avg: 6.588)\tTop5: 25.000 (avg: 20.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4788\tTop 1 accuracy: 6.100\tTop 5 accuracy: 18.000\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.331 (avg: 0.329)\tLoss: 4.5697 (avg: 4.5554)\tTop1: 9.375 (avg: 7.062)\tTop5: 17.188 (avg: 21.125)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.330 (avg: 0.333)\tLoss: 4.4215 (avg: 4.5358)\tTop1: 4.688 (avg: 6.875)\tTop5: 23.438 (avg: 21.625)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.332 (avg: 0.335)\tLoss: 4.9144 (avg: 4.5537)\tTop1: 6.250 (avg: 6.771)\tTop5: 12.500 (avg: 21.375)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.330 (avg: 0.335)\tLoss: 4.6890 (avg: 4.5552)\tTop1: 6.250 (avg: 6.781)\tTop5: 20.312 (avg: 21.359)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.330 (avg: 0.336)\tLoss: 4.6648 (avg: 4.5542)\tTop1: 7.812 (avg: 6.763)\tTop5: 15.625 (avg: 21.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3600\tTop 1 accuracy: 6.300\tTop 5 accuracy: 18.900\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.331 (avg: 0.329)\tLoss: 4.7375 (avg: 4.5333)\tTop1: 4.688 (avg: 6.250)\tTop5: 18.750 (avg: 21.562)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.330 (avg: 0.333)\tLoss: 4.5886 (avg: 4.5304)\tTop1: 3.125 (avg: 6.156)\tTop5: 17.188 (avg: 21.281)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.331 (avg: 0.335)\tLoss: 4.6707 (avg: 4.5279)\tTop1: 3.125 (avg: 6.354)\tTop5: 17.188 (avg: 21.438)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.330 (avg: 0.335)\tLoss: 4.8311 (avg: 4.5344)\tTop1: 1.562 (avg: 6.531)\tTop5: 25.000 (avg: 21.547)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.332 (avg: 0.336)\tLoss: 4.5879 (avg: 4.5424)\tTop1: 1.562 (avg: 6.538)\tTop5: 7.812 (avg: 21.313)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3945\tTop 1 accuracy: 6.500\tTop 5 accuracy: 18.600\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.332 (avg: 0.329)\tLoss: 4.5850 (avg: 4.5003)\tTop1: 3.125 (avg: 6.438)\tTop5: 21.875 (avg: 23.062)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.329 (avg: 0.334)\tLoss: 4.7244 (avg: 4.5328)\tTop1: 3.125 (avg: 6.500)\tTop5: 18.750 (avg: 22.219)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.329 (avg: 0.335)\tLoss: 4.3246 (avg: 4.5339)\tTop1: 6.250 (avg: 6.312)\tTop5: 21.875 (avg: 21.208)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.331 (avg: 0.336)\tLoss: 4.6061 (avg: 4.5314)\tTop1: 4.688 (avg: 6.578)\tTop5: 25.000 (avg: 21.750)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.332 (avg: 0.336)\tLoss: 4.6362 (avg: 4.5351)\tTop1: 9.375 (avg: 6.775)\tTop5: 15.625 (avg: 21.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3762\tTop 1 accuracy: 6.500\tTop 5 accuracy: 18.250\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.329 (avg: 0.328)\tLoss: 4.6155 (avg: 4.5227)\tTop1: 14.062 (avg: 7.875)\tTop5: 21.875 (avg: 21.938)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.334 (avg: 0.333)\tLoss: 4.5531 (avg: 4.5108)\tTop1: 3.125 (avg: 7.188)\tTop5: 20.312 (avg: 21.812)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.330 (avg: 0.335)\tLoss: 4.7333 (avg: 4.5115)\tTop1: 3.125 (avg: 6.833)\tTop5: 20.312 (avg: 22.021)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.327 (avg: 0.335)\tLoss: 4.4608 (avg: 4.5150)\tTop1: 6.250 (avg: 6.969)\tTop5: 23.438 (avg: 22.047)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.329 (avg: 0.336)\tLoss: 4.4491 (avg: 4.5227)\tTop1: 7.812 (avg: 7.063)\tTop5: 21.875 (avg: 21.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1702\tTop 1 accuracy: 6.300\tTop 5 accuracy: 19.800\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.330 (avg: 0.329)\tLoss: 4.4824 (avg: 4.4998)\tTop1: 10.938 (avg: 7.562)\tTop5: 39.062 (avg: 23.500)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.331 (avg: 0.334)\tLoss: 4.4372 (avg: 4.5028)\tTop1: 3.125 (avg: 7.188)\tTop5: 18.750 (avg: 22.406)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.329 (avg: 0.335)\tLoss: 4.1786 (avg: 4.5004)\tTop1: 9.375 (avg: 7.354)\tTop5: 28.125 (avg: 22.708)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.327 (avg: 0.335)\tLoss: 4.2721 (avg: 4.5137)\tTop1: 10.938 (avg: 7.312)\tTop5: 29.688 (avg: 22.547)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.330 (avg: 0.335)\tLoss: 4.6269 (avg: 4.5135)\tTop1: 6.250 (avg: 7.263)\tTop5: 20.312 (avg: 22.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2361\tTop 1 accuracy: 6.250\tTop 5 accuracy: 19.550\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.326 (avg: 0.325)\tLoss: 4.4142 (avg: 4.4604)\tTop1: 3.125 (avg: 8.688)\tTop5: 25.000 (avg: 23.438)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.330 (avg: 0.331)\tLoss: 4.6859 (avg: 4.4889)\tTop1: 4.688 (avg: 7.906)\tTop5: 12.500 (avg: 21.938)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.332 (avg: 0.334)\tLoss: 4.3223 (avg: 4.4903)\tTop1: 12.500 (avg: 8.062)\tTop5: 29.688 (avg: 22.396)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.332 (avg: 0.334)\tLoss: 4.3685 (avg: 4.4926)\tTop1: 4.688 (avg: 7.875)\tTop5: 18.750 (avg: 22.469)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.330 (avg: 0.335)\tLoss: 4.5023 (avg: 4.4987)\tTop1: 3.125 (avg: 7.650)\tTop5: 25.000 (avg: 22.325)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3167\tTop 1 accuracy: 6.500\tTop 5 accuracy: 19.550\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.335 (avg: 0.330)\tLoss: 4.3937 (avg: 4.4670)\tTop1: 7.812 (avg: 7.125)\tTop5: 25.000 (avg: 23.938)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.333 (avg: 0.334)\tLoss: 4.4045 (avg: 4.4655)\tTop1: 7.812 (avg: 7.375)\tTop5: 20.312 (avg: 23.469)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.332 (avg: 0.336)\tLoss: 4.2017 (avg: 4.4880)\tTop1: 9.375 (avg: 7.375)\tTop5: 32.812 (avg: 23.250)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.332 (avg: 0.337)\tLoss: 4.5574 (avg: 4.4904)\tTop1: 7.812 (avg: 7.219)\tTop5: 26.562 (avg: 23.188)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.334 (avg: 0.337)\tLoss: 4.4318 (avg: 4.4911)\tTop1: 4.688 (avg: 7.200)\tTop5: 23.438 (avg: 23.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2965\tTop 1 accuracy: 6.650\tTop 5 accuracy: 19.500\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.331 (avg: 0.331)\tLoss: 4.4093 (avg: 4.4838)\tTop1: 4.688 (avg: 7.562)\tTop5: 26.562 (avg: 24.500)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.335 (avg: 0.335)\tLoss: 4.3021 (avg: 4.4711)\tTop1: 7.812 (avg: 7.750)\tTop5: 23.438 (avg: 23.812)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.330 (avg: 0.336)\tLoss: 4.7035 (avg: 4.4794)\tTop1: 6.250 (avg: 7.833)\tTop5: 25.000 (avg: 23.104)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.336 (avg: 0.337)\tLoss: 4.3466 (avg: 4.4749)\tTop1: 9.375 (avg: 7.844)\tTop5: 32.812 (avg: 23.031)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.334 (avg: 0.338)\tLoss: 4.5492 (avg: 4.4806)\tTop1: 3.125 (avg: 7.675)\tTop5: 28.125 (avg: 22.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0912\tTop 1 accuracy: 6.400\tTop 5 accuracy: 20.250\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.333 (avg: 0.331)\tLoss: 4.4341 (avg: 4.4697)\tTop1: 4.688 (avg: 6.688)\tTop5: 23.438 (avg: 22.312)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.332 (avg: 0.335)\tLoss: 4.5220 (avg: 4.4397)\tTop1: 4.688 (avg: 7.188)\tTop5: 20.312 (avg: 23.438)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.332 (avg: 0.336)\tLoss: 4.4112 (avg: 4.4491)\tTop1: 7.812 (avg: 7.333)\tTop5: 23.438 (avg: 23.146)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.335 (avg: 0.337)\tLoss: 4.5934 (avg: 4.4542)\tTop1: 3.125 (avg: 7.250)\tTop5: 17.188 (avg: 23.609)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.333 (avg: 0.338)\tLoss: 4.4705 (avg: 4.4697)\tTop1: 6.250 (avg: 7.338)\tTop5: 25.000 (avg: 23.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3591\tTop 1 accuracy: 6.350\tTop 5 accuracy: 20.150\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.334 (avg: 0.331)\tLoss: 4.4332 (avg: 4.4447)\tTop1: 14.062 (avg: 8.188)\tTop5: 23.438 (avg: 24.375)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.332 (avg: 0.335)\tLoss: 4.7487 (avg: 4.4538)\tTop1: 3.125 (avg: 7.875)\tTop5: 12.500 (avg: 24.250)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.329 (avg: 0.336)\tLoss: 4.7874 (avg: 4.4460)\tTop1: 6.250 (avg: 8.125)\tTop5: 21.875 (avg: 24.896)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.332 (avg: 0.337)\tLoss: 4.3932 (avg: 4.4489)\tTop1: 4.688 (avg: 7.812)\tTop5: 21.875 (avg: 24.547)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.331 (avg: 0.338)\tLoss: 4.5166 (avg: 4.4550)\tTop1: 4.688 (avg: 7.675)\tTop5: 17.188 (avg: 24.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2539\tTop 1 accuracy: 7.300\tTop 5 accuracy: 20.800\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.333 (avg: 0.331)\tLoss: 4.3693 (avg: 4.4232)\tTop1: 4.688 (avg: 8.250)\tTop5: 23.438 (avg: 25.562)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.333 (avg: 0.335)\tLoss: 4.6509 (avg: 4.4392)\tTop1: 7.812 (avg: 7.969)\tTop5: 18.750 (avg: 23.688)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.331 (avg: 0.336)\tLoss: 4.5554 (avg: 4.4312)\tTop1: 10.938 (avg: 7.917)\tTop5: 29.688 (avg: 23.979)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.333 (avg: 0.336)\tLoss: 4.5238 (avg: 4.4372)\tTop1: 3.125 (avg: 7.844)\tTop5: 20.312 (avg: 23.875)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.331 (avg: 0.337)\tLoss: 4.5190 (avg: 4.4377)\tTop1: 9.375 (avg: 7.900)\tTop5: 28.125 (avg: 24.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1876\tTop 1 accuracy: 7.700\tTop 5 accuracy: 20.400\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.327 (avg: 0.327)\tLoss: 4.3487 (avg: 4.4000)\tTop1: 12.500 (avg: 8.938)\tTop5: 31.250 (avg: 26.688)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.332 (avg: 0.332)\tLoss: 4.5331 (avg: 4.4275)\tTop1: 9.375 (avg: 8.219)\tTop5: 23.438 (avg: 24.969)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.332 (avg: 0.335)\tLoss: 4.2600 (avg: 4.4255)\tTop1: 17.188 (avg: 8.042)\tTop5: 26.562 (avg: 24.438)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.329 (avg: 0.336)\tLoss: 4.5046 (avg: 4.4305)\tTop1: 7.812 (avg: 7.859)\tTop5: 25.000 (avg: 24.234)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.338 (avg: 0.337)\tLoss: 4.4830 (avg: 4.4319)\tTop1: 6.250 (avg: 8.050)\tTop5: 21.875 (avg: 24.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3389\tTop 1 accuracy: 6.850\tTop 5 accuracy: 20.550\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.329 (avg: 0.330)\tLoss: 4.4341 (avg: 4.4234)\tTop1: 12.500 (avg: 8.125)\tTop5: 31.250 (avg: 23.750)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.333 (avg: 0.334)\tLoss: 4.3598 (avg: 4.4121)\tTop1: 10.938 (avg: 7.969)\tTop5: 25.000 (avg: 23.875)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.331 (avg: 0.336)\tLoss: 4.4793 (avg: 4.4039)\tTop1: 6.250 (avg: 7.833)\tTop5: 21.875 (avg: 24.417)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.332 (avg: 0.336)\tLoss: 4.4165 (avg: 4.4031)\tTop1: 10.938 (avg: 7.969)\tTop5: 21.875 (avg: 24.453)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.328 (avg: 0.337)\tLoss: 4.3739 (avg: 4.4145)\tTop1: 7.812 (avg: 8.062)\tTop5: 28.125 (avg: 24.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0423\tTop 1 accuracy: 7.600\tTop 5 accuracy: 21.650\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.332 (avg: 0.330)\tLoss: 4.4597 (avg: 4.4337)\tTop1: 6.250 (avg: 7.438)\tTop5: 20.312 (avg: 24.562)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.333 (avg: 0.335)\tLoss: 4.4128 (avg: 4.4166)\tTop1: 3.125 (avg: 8.062)\tTop5: 20.312 (avg: 25.000)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.329 (avg: 0.336)\tLoss: 4.4977 (avg: 4.4124)\tTop1: 10.938 (avg: 7.958)\tTop5: 26.562 (avg: 24.688)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.331 (avg: 0.337)\tLoss: 4.2908 (avg: 4.3980)\tTop1: 7.812 (avg: 8.031)\tTop5: 23.438 (avg: 24.797)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.333 (avg: 0.338)\tLoss: 4.2698 (avg: 4.4070)\tTop1: 9.375 (avg: 7.763)\tTop5: 28.125 (avg: 24.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9715\tTop 1 accuracy: 8.100\tTop 5 accuracy: 20.350\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.331 (avg: 0.331)\tLoss: 4.2925 (avg: 4.3183)\tTop1: 6.250 (avg: 9.875)\tTop5: 23.438 (avg: 26.938)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.335 (avg: 0.335)\tLoss: 4.2880 (avg: 4.3552)\tTop1: 6.250 (avg: 9.281)\tTop5: 28.125 (avg: 26.281)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.329 (avg: 0.337)\tLoss: 4.5061 (avg: 4.3686)\tTop1: 9.375 (avg: 9.000)\tTop5: 18.750 (avg: 25.458)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.332 (avg: 0.337)\tLoss: 4.4327 (avg: 4.3830)\tTop1: 6.250 (avg: 8.672)\tTop5: 18.750 (avg: 24.781)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.333 (avg: 0.338)\tLoss: 4.5772 (avg: 4.3920)\tTop1: 4.688 (avg: 8.738)\tTop5: 25.000 (avg: 24.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0684\tTop 1 accuracy: 7.800\tTop 5 accuracy: 21.150\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.333 (avg: 0.332)\tLoss: 4.3522 (avg: 4.3539)\tTop1: 12.500 (avg: 9.250)\tTop5: 28.125 (avg: 25.188)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.331 (avg: 0.336)\tLoss: 4.5885 (avg: 4.3515)\tTop1: 6.250 (avg: 9.156)\tTop5: 18.750 (avg: 25.344)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.332 (avg: 0.337)\tLoss: 4.4883 (avg: 4.3574)\tTop1: 7.812 (avg: 9.000)\tTop5: 34.375 (avg: 25.417)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.330 (avg: 0.338)\tLoss: 4.2568 (avg: 4.3724)\tTop1: 9.375 (avg: 8.906)\tTop5: 26.562 (avg: 24.984)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.331 (avg: 0.338)\tLoss: 4.3887 (avg: 4.3761)\tTop1: 14.062 (avg: 8.825)\tTop5: 32.812 (avg: 25.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0321\tTop 1 accuracy: 7.650\tTop 5 accuracy: 22.050\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.335 (avg: 0.332)\tLoss: 4.2494 (avg: 4.3198)\tTop1: 9.375 (avg: 10.125)\tTop5: 23.438 (avg: 27.875)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.333 (avg: 0.336)\tLoss: 4.4887 (avg: 4.3646)\tTop1: 10.938 (avg: 9.469)\tTop5: 23.438 (avg: 26.375)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.324 (avg: 0.336)\tLoss: 4.0765 (avg: 4.3569)\tTop1: 9.375 (avg: 9.167)\tTop5: 31.250 (avg: 26.354)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.340 (avg: 0.337)\tLoss: 4.5647 (avg: 4.3560)\tTop1: 3.125 (avg: 8.969)\tTop5: 18.750 (avg: 26.109)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.334 (avg: 0.337)\tLoss: 4.6061 (avg: 4.3702)\tTop1: 4.688 (avg: 8.600)\tTop5: 15.625 (avg: 25.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0355\tTop 1 accuracy: 7.400\tTop 5 accuracy: 21.700\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.327 (avg: 0.327)\tLoss: 4.3605 (avg: 4.3742)\tTop1: 10.938 (avg: 8.812)\tTop5: 26.562 (avg: 25.188)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.336 (avg: 0.333)\tLoss: 4.4474 (avg: 4.3763)\tTop1: 12.500 (avg: 8.438)\tTop5: 25.000 (avg: 25.344)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.332 (avg: 0.335)\tLoss: 4.3620 (avg: 4.3637)\tTop1: 12.500 (avg: 8.625)\tTop5: 29.688 (avg: 25.583)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.332 (avg: 0.335)\tLoss: 4.3664 (avg: 4.3615)\tTop1: 10.938 (avg: 8.797)\tTop5: 25.000 (avg: 25.766)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.333 (avg: 0.336)\tLoss: 4.3871 (avg: 4.3659)\tTop1: 10.938 (avg: 8.575)\tTop5: 20.312 (avg: 25.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1480\tTop 1 accuracy: 8.200\tTop 5 accuracy: 21.200\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.333 (avg: 0.332)\tLoss: 4.7595 (avg: 4.3388)\tTop1: 7.812 (avg: 9.562)\tTop5: 20.312 (avg: 25.875)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.333 (avg: 0.335)\tLoss: 4.2388 (avg: 4.3461)\tTop1: 7.812 (avg: 9.000)\tTop5: 23.438 (avg: 24.969)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.330 (avg: 0.337)\tLoss: 4.2739 (avg: 4.3425)\tTop1: 4.688 (avg: 9.333)\tTop5: 23.438 (avg: 25.500)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.332 (avg: 0.338)\tLoss: 4.6331 (avg: 4.3539)\tTop1: 3.125 (avg: 9.047)\tTop5: 20.312 (avg: 25.578)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.330 (avg: 0.338)\tLoss: 4.4139 (avg: 4.3589)\tTop1: 6.250 (avg: 8.988)\tTop5: 26.562 (avg: 25.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1037\tTop 1 accuracy: 7.000\tTop 5 accuracy: 21.650\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.333 (avg: 0.332)\tLoss: 4.3824 (avg: 4.2866)\tTop1: 6.250 (avg: 9.188)\tTop5: 21.875 (avg: 28.750)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.335 (avg: 0.335)\tLoss: 4.6899 (avg: 4.3336)\tTop1: 9.375 (avg: 9.031)\tTop5: 15.625 (avg: 26.906)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.330 (avg: 0.337)\tLoss: 4.3195 (avg: 4.3194)\tTop1: 10.938 (avg: 9.167)\tTop5: 26.562 (avg: 27.021)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.332 (avg: 0.337)\tLoss: 4.4260 (avg: 4.3240)\tTop1: 7.812 (avg: 8.984)\tTop5: 23.438 (avg: 26.609)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.330 (avg: 0.338)\tLoss: 4.3662 (avg: 4.3407)\tTop1: 6.250 (avg: 8.788)\tTop5: 28.125 (avg: 26.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9161\tTop 1 accuracy: 9.050\tTop 5 accuracy: 22.650\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.332 (avg: 0.331)\tLoss: 4.5825 (avg: 4.3088)\tTop1: 6.250 (avg: 8.500)\tTop5: 23.438 (avg: 26.062)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.333 (avg: 0.335)\tLoss: 4.4625 (avg: 4.3246)\tTop1: 10.938 (avg: 8.969)\tTop5: 23.438 (avg: 25.875)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.333 (avg: 0.336)\tLoss: 4.3622 (avg: 4.3283)\tTop1: 10.938 (avg: 8.896)\tTop5: 21.875 (avg: 25.917)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.335 (avg: 0.337)\tLoss: 4.3178 (avg: 4.3358)\tTop1: 10.938 (avg: 8.984)\tTop5: 28.125 (avg: 25.625)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.331 (avg: 0.338)\tLoss: 4.3343 (avg: 4.3292)\tTop1: 10.938 (avg: 9.075)\tTop5: 29.688 (avg: 26.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8897\tTop 1 accuracy: 7.500\tTop 5 accuracy: 22.250\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.334 (avg: 0.331)\tLoss: 4.4506 (avg: 4.2549)\tTop1: 4.688 (avg: 9.750)\tTop5: 18.750 (avg: 28.250)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.337 (avg: 0.335)\tLoss: 4.1980 (avg: 4.2874)\tTop1: 9.375 (avg: 9.531)\tTop5: 29.688 (avg: 27.750)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.329 (avg: 0.337)\tLoss: 3.9812 (avg: 4.2506)\tTop1: 12.500 (avg: 9.979)\tTop5: 31.250 (avg: 28.271)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.332 (avg: 0.337)\tLoss: 4.4471 (avg: 4.2628)\tTop1: 6.250 (avg: 9.953)\tTop5: 25.000 (avg: 28.297)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.334 (avg: 0.338)\tLoss: 4.2592 (avg: 4.2548)\tTop1: 9.375 (avg: 10.038)\tTop5: 23.438 (avg: 28.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8841\tTop 1 accuracy: 8.400\tTop 5 accuracy: 22.900\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.335 (avg: 0.332)\tLoss: 4.2047 (avg: 4.1846)\tTop1: 12.500 (avg: 11.125)\tTop5: 28.125 (avg: 30.625)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.334 (avg: 0.335)\tLoss: 4.2722 (avg: 4.2026)\tTop1: 14.062 (avg: 10.906)\tTop5: 25.000 (avg: 30.812)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.333 (avg: 0.335)\tLoss: 4.4524 (avg: 4.2189)\tTop1: 4.688 (avg: 10.729)\tTop5: 21.875 (avg: 29.792)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.330 (avg: 0.337)\tLoss: 4.4794 (avg: 4.2313)\tTop1: 9.375 (avg: 10.266)\tTop5: 25.000 (avg: 29.078)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.334 (avg: 0.337)\tLoss: 4.4968 (avg: 4.2371)\tTop1: 10.938 (avg: 10.500)\tTop5: 25.000 (avg: 29.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8520\tTop 1 accuracy: 8.750\tTop 5 accuracy: 22.650\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.328 (avg: 0.327)\tLoss: 4.4803 (avg: 4.2479)\tTop1: 7.812 (avg: 10.812)\tTop5: 21.875 (avg: 29.500)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.332 (avg: 0.332)\tLoss: 4.2399 (avg: 4.2292)\tTop1: 12.500 (avg: 11.219)\tTop5: 32.812 (avg: 29.438)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.330 (avg: 0.335)\tLoss: 4.5077 (avg: 4.2268)\tTop1: 6.250 (avg: 11.125)\tTop5: 21.875 (avg: 29.583)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.331 (avg: 0.336)\tLoss: 4.4871 (avg: 4.2403)\tTop1: 4.688 (avg: 10.734)\tTop5: 15.625 (avg: 28.812)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.332 (avg: 0.337)\tLoss: 4.1773 (avg: 4.2343)\tTop1: 9.375 (avg: 10.563)\tTop5: 31.250 (avg: 29.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8704\tTop 1 accuracy: 9.250\tTop 5 accuracy: 23.450\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.329 (avg: 0.331)\tLoss: 4.4106 (avg: 4.2245)\tTop1: 4.688 (avg: 10.938)\tTop5: 20.312 (avg: 30.625)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.335 (avg: 0.336)\tLoss: 4.0083 (avg: 4.2200)\tTop1: 7.812 (avg: 10.438)\tTop5: 29.688 (avg: 30.062)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.334 (avg: 0.337)\tLoss: 3.9282 (avg: 4.2207)\tTop1: 17.188 (avg: 10.708)\tTop5: 32.812 (avg: 29.875)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.332 (avg: 0.338)\tLoss: 4.0310 (avg: 4.2220)\tTop1: 7.812 (avg: 10.938)\tTop5: 35.938 (avg: 29.750)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.334 (avg: 0.338)\tLoss: 4.1517 (avg: 4.2259)\tTop1: 14.062 (avg: 10.675)\tTop5: 23.438 (avg: 29.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8544\tTop 1 accuracy: 8.500\tTop 5 accuracy: 23.350\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.332 (avg: 0.331)\tLoss: 4.3794 (avg: 4.1632)\tTop1: 12.500 (avg: 10.688)\tTop5: 26.562 (avg: 30.375)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.335 (avg: 0.335)\tLoss: 4.2021 (avg: 4.2281)\tTop1: 15.625 (avg: 10.438)\tTop5: 25.000 (avg: 29.500)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.330 (avg: 0.337)\tLoss: 4.3421 (avg: 4.2293)\tTop1: 12.500 (avg: 10.750)\tTop5: 21.875 (avg: 29.458)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.332 (avg: 0.337)\tLoss: 4.0694 (avg: 4.2183)\tTop1: 14.062 (avg: 10.953)\tTop5: 26.562 (avg: 29.750)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.335 (avg: 0.338)\tLoss: 4.4669 (avg: 4.2254)\tTop1: 9.375 (avg: 10.938)\tTop5: 20.312 (avg: 29.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8713\tTop 1 accuracy: 8.700\tTop 5 accuracy: 23.450\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.333 (avg: 0.331)\tLoss: 4.1409 (avg: 4.2007)\tTop1: 12.500 (avg: 11.312)\tTop5: 25.000 (avg: 29.188)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.333 (avg: 0.335)\tLoss: 4.0793 (avg: 4.2280)\tTop1: 9.375 (avg: 10.656)\tTop5: 28.125 (avg: 29.062)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.334 (avg: 0.336)\tLoss: 4.2403 (avg: 4.2195)\tTop1: 14.062 (avg: 10.583)\tTop5: 39.062 (avg: 29.354)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.332 (avg: 0.337)\tLoss: 3.9817 (avg: 4.2234)\tTop1: 14.062 (avg: 10.750)\tTop5: 31.250 (avg: 29.688)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.328 (avg: 0.338)\tLoss: 4.2742 (avg: 4.2236)\tTop1: 9.375 (avg: 10.913)\tTop5: 21.875 (avg: 29.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8241\tTop 1 accuracy: 8.400\tTop 5 accuracy: 23.200\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.340 (avg: 0.332)\tLoss: 4.3220 (avg: 4.2354)\tTop1: 12.500 (avg: 11.438)\tTop5: 35.938 (avg: 28.062)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.332 (avg: 0.336)\tLoss: 4.2094 (avg: 4.2276)\tTop1: 10.938 (avg: 11.219)\tTop5: 26.562 (avg: 28.531)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.334 (avg: 0.337)\tLoss: 4.3028 (avg: 4.2243)\tTop1: 15.625 (avg: 11.000)\tTop5: 35.938 (avg: 29.167)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.333 (avg: 0.338)\tLoss: 4.0379 (avg: 4.2224)\tTop1: 18.750 (avg: 11.062)\tTop5: 34.375 (avg: 29.266)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.331 (avg: 0.338)\tLoss: 4.1958 (avg: 4.2199)\tTop1: 10.938 (avg: 10.850)\tTop5: 28.125 (avg: 29.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8236\tTop 1 accuracy: 8.750\tTop 5 accuracy: 23.250\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.340 (avg: 0.332)\tLoss: 4.2721 (avg: 4.1887)\tTop1: 15.625 (avg: 11.938)\tTop5: 29.688 (avg: 30.562)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.327 (avg: 0.336)\tLoss: 4.2913 (avg: 4.2111)\tTop1: 7.812 (avg: 11.469)\tTop5: 28.125 (avg: 29.812)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.333 (avg: 0.336)\tLoss: 4.2983 (avg: 4.2275)\tTop1: 12.500 (avg: 11.375)\tTop5: 29.688 (avg: 30.083)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.332 (avg: 0.337)\tLoss: 4.0108 (avg: 4.2201)\tTop1: 14.062 (avg: 11.312)\tTop5: 28.125 (avg: 29.719)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.333 (avg: 0.338)\tLoss: 4.0640 (avg: 4.2204)\tTop1: 12.500 (avg: 11.138)\tTop5: 28.125 (avg: 29.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8394\tTop 1 accuracy: 8.950\tTop 5 accuracy: 23.600\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.329 (avg: 0.329)\tLoss: 4.4744 (avg: 4.2283)\tTop1: 6.250 (avg: 10.875)\tTop5: 20.312 (avg: 28.062)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.337 (avg: 0.333)\tLoss: 4.2488 (avg: 4.2078)\tTop1: 12.500 (avg: 11.312)\tTop5: 28.125 (avg: 28.719)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.333 (avg: 0.335)\tLoss: 4.3225 (avg: 4.2222)\tTop1: 7.812 (avg: 11.188)\tTop5: 23.438 (avg: 29.042)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.332 (avg: 0.336)\tLoss: 4.2393 (avg: 4.2220)\tTop1: 6.250 (avg: 10.875)\tTop5: 31.250 (avg: 29.234)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.334 (avg: 0.337)\tLoss: 4.0127 (avg: 4.2181)\tTop1: 14.062 (avg: 11.025)\tTop5: 28.125 (avg: 29.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8767\tTop 1 accuracy: 9.200\tTop 5 accuracy: 24.100\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.333 (avg: 0.331)\tLoss: 3.7502 (avg: 4.1417)\tTop1: 18.750 (avg: 12.500)\tTop5: 37.500 (avg: 31.500)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.331 (avg: 0.335)\tLoss: 4.0545 (avg: 4.1670)\tTop1: 21.875 (avg: 11.469)\tTop5: 42.188 (avg: 30.906)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.331 (avg: 0.337)\tLoss: 4.1139 (avg: 4.2052)\tTop1: 15.625 (avg: 11.438)\tTop5: 29.688 (avg: 29.833)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.337 (avg: 0.337)\tLoss: 3.8452 (avg: 4.2053)\tTop1: 15.625 (avg: 11.391)\tTop5: 42.188 (avg: 29.781)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.333 (avg: 0.338)\tLoss: 4.0775 (avg: 4.2148)\tTop1: 9.375 (avg: 11.250)\tTop5: 42.188 (avg: 29.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8215\tTop 1 accuracy: 9.050\tTop 5 accuracy: 23.550\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.335 (avg: 0.332)\tLoss: 4.1064 (avg: 4.1685)\tTop1: 21.875 (avg: 14.375)\tTop5: 35.938 (avg: 31.688)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.337 (avg: 0.336)\tLoss: 4.1228 (avg: 4.1956)\tTop1: 6.250 (avg: 12.469)\tTop5: 21.875 (avg: 29.875)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.329 (avg: 0.337)\tLoss: 4.2504 (avg: 4.2102)\tTop1: 7.812 (avg: 11.562)\tTop5: 28.125 (avg: 29.271)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.332 (avg: 0.337)\tLoss: 4.5697 (avg: 4.2112)\tTop1: 10.938 (avg: 11.719)\tTop5: 28.125 (avg: 29.375)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.333 (avg: 0.338)\tLoss: 3.9476 (avg: 4.2133)\tTop1: 14.062 (avg: 11.338)\tTop5: 35.938 (avg: 29.563)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8047\tTop 1 accuracy: 8.950\tTop 5 accuracy: 24.000\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.333 (avg: 0.331)\tLoss: 4.2165 (avg: 4.2480)\tTop1: 6.250 (avg: 10.250)\tTop5: 32.812 (avg: 28.812)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.334 (avg: 0.335)\tLoss: 3.9450 (avg: 4.2085)\tTop1: 20.312 (avg: 11.062)\tTop5: 39.062 (avg: 29.688)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.334 (avg: 0.337)\tLoss: 4.1013 (avg: 4.2169)\tTop1: 12.500 (avg: 11.104)\tTop5: 29.688 (avg: 29.792)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.332 (avg: 0.338)\tLoss: 3.9686 (avg: 4.2104)\tTop1: 12.500 (avg: 10.969)\tTop5: 34.375 (avg: 29.547)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.338 (avg: 0.338)\tLoss: 4.2931 (avg: 4.2132)\tTop1: 17.188 (avg: 11.213)\tTop5: 32.812 (avg: 29.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8258\tTop 1 accuracy: 9.350\tTop 5 accuracy: 23.800\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.335 (avg: 0.331)\tLoss: 4.0344 (avg: 4.1832)\tTop1: 15.625 (avg: 10.750)\tTop5: 32.812 (avg: 30.125)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.338 (avg: 0.336)\tLoss: 4.1107 (avg: 4.1876)\tTop1: 17.188 (avg: 11.188)\tTop5: 29.688 (avg: 30.469)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.332 (avg: 0.337)\tLoss: 3.9993 (avg: 4.1993)\tTop1: 15.625 (avg: 11.208)\tTop5: 31.250 (avg: 29.917)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.332 (avg: 0.337)\tLoss: 3.8930 (avg: 4.1945)\tTop1: 18.750 (avg: 11.312)\tTop5: 31.250 (avg: 30.047)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.332 (avg: 0.338)\tLoss: 4.1778 (avg: 4.2106)\tTop1: 10.938 (avg: 11.275)\tTop5: 31.250 (avg: 29.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8595\tTop 1 accuracy: 8.900\tTop 5 accuracy: 23.300\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.334 (avg: 0.331)\tLoss: 4.2290 (avg: 4.2229)\tTop1: 6.250 (avg: 11.125)\tTop5: 26.562 (avg: 30.250)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.329 (avg: 0.334)\tLoss: 4.1702 (avg: 4.2432)\tTop1: 9.375 (avg: 10.812)\tTop5: 34.375 (avg: 29.344)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.332 (avg: 0.336)\tLoss: 3.9242 (avg: 4.2241)\tTop1: 12.500 (avg: 10.917)\tTop5: 39.062 (avg: 30.125)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.330 (avg: 0.336)\tLoss: 4.1758 (avg: 4.2204)\tTop1: 12.500 (avg: 10.953)\tTop5: 29.688 (avg: 29.875)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.333 (avg: 0.337)\tLoss: 4.3603 (avg: 4.2104)\tTop1: 14.062 (avg: 11.238)\tTop5: 28.125 (avg: 30.013)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8183\tTop 1 accuracy: 8.600\tTop 5 accuracy: 23.700\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.327 (avg: 0.329)\tLoss: 4.3261 (avg: 4.2043)\tTop1: 9.375 (avg: 10.625)\tTop5: 18.750 (avg: 30.625)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.332 (avg: 0.332)\tLoss: 4.2426 (avg: 4.1956)\tTop1: 10.938 (avg: 11.406)\tTop5: 34.375 (avg: 30.188)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.329 (avg: 0.335)\tLoss: 4.2212 (avg: 4.2009)\tTop1: 14.062 (avg: 11.021)\tTop5: 32.812 (avg: 30.000)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.334 (avg: 0.336)\tLoss: 4.2983 (avg: 4.2025)\tTop1: 9.375 (avg: 11.094)\tTop5: 25.000 (avg: 29.984)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.332 (avg: 0.336)\tLoss: 4.4296 (avg: 4.2089)\tTop1: 10.938 (avg: 11.163)\tTop5: 28.125 (avg: 29.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9003\tTop 1 accuracy: 8.900\tTop 5 accuracy: 23.300\n",
            "\n",
            "pct_3x3 = 0.0078125: top1 = 9.200000762939453 \t top5 = 24.100000381469727 \t batch time = 0.2858937606215477\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.342 (avg: 0.411)\tLoss: 5.2979 (avg: 5.3092)\tTop1: 0.000 (avg: 0.250)\tTop5: 1.562 (avg: 2.000)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.342 (avg: 0.381)\tLoss: 5.2997 (avg: 5.3043)\tTop1: 0.000 (avg: 0.438)\tTop5: 0.000 (avg: 1.938)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.352 (avg: 0.371)\tLoss: 5.2985 (avg: 5.3024)\tTop1: 0.000 (avg: 0.417)\tTop5: 1.562 (avg: 2.062)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.338 (avg: 0.366)\tLoss: 5.2979 (avg: 5.3014)\tTop1: 0.000 (avg: 0.391)\tTop5: 1.562 (avg: 2.062)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.351 (avg: 0.363)\tLoss: 5.2985 (avg: 5.3009)\tTop1: 0.000 (avg: 0.413)\tTop5: 1.562 (avg: 2.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3002\tTop 1 accuracy: 0.500\tTop 5 accuracy: 1.850\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.351 (avg: 0.344)\tLoss: 5.3004 (avg: 5.2972)\tTop1: 0.000 (avg: 0.750)\tTop5: 0.000 (avg: 3.250)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.339 (avg: 0.348)\tLoss: 5.2994 (avg: 5.2976)\tTop1: 0.000 (avg: 0.531)\tTop5: 1.562 (avg: 2.812)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.347 (avg: 0.350)\tLoss: 5.2960 (avg: 5.2975)\tTop1: 1.562 (avg: 0.562)\tTop5: 3.125 (avg: 2.812)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.344 (avg: 0.351)\tLoss: 5.2994 (avg: 5.2969)\tTop1: 0.000 (avg: 0.656)\tTop5: 0.000 (avg: 2.875)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.356 (avg: 0.351)\tLoss: 5.3092 (avg: 5.2964)\tTop1: 0.000 (avg: 0.625)\tTop5: 0.000 (avg: 2.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2970\tTop 1 accuracy: 0.350\tTop 5 accuracy: 2.200\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.353 (avg: 0.345)\tLoss: 5.2378 (avg: 5.2824)\tTop1: 1.562 (avg: 0.562)\tTop5: 4.688 (avg: 2.688)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.341 (avg: 0.349)\tLoss: 5.2932 (avg: 5.2786)\tTop1: 0.000 (avg: 0.531)\tTop5: 4.688 (avg: 3.156)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.348 (avg: 0.350)\tLoss: 5.2740 (avg: 5.2717)\tTop1: 0.000 (avg: 0.646)\tTop5: 3.125 (avg: 3.312)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.347 (avg: 0.351)\tLoss: 5.2627 (avg: 5.2668)\tTop1: 0.000 (avg: 0.734)\tTop5: 7.812 (avg: 3.719)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.360 (avg: 0.351)\tLoss: 5.2976 (avg: 5.2686)\tTop1: 0.000 (avg: 0.675)\tTop5: 3.125 (avg: 3.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2988\tTop 1 accuracy: 0.850\tTop 5 accuracy: 3.950\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.352 (avg: 0.344)\tLoss: 5.2538 (avg: 5.2655)\tTop1: 0.000 (avg: 1.000)\tTop5: 3.125 (avg: 4.438)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.343 (avg: 0.348)\tLoss: 5.2541 (avg: 5.2521)\tTop1: 3.125 (avg: 0.969)\tTop5: 6.250 (avg: 4.656)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.339 (avg: 0.350)\tLoss: 5.1553 (avg: 5.2511)\tTop1: 3.125 (avg: 0.958)\tTop5: 6.250 (avg: 4.375)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.346 (avg: 0.350)\tLoss: 5.2599 (avg: 5.2574)\tTop1: 1.562 (avg: 0.984)\tTop5: 3.125 (avg: 4.297)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.352 (avg: 0.351)\tLoss: 5.1237 (avg: 5.2526)\tTop1: 1.562 (avg: 1.013)\tTop5: 6.250 (avg: 4.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3938\tTop 1 accuracy: 0.950\tTop 5 accuracy: 3.650\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.353 (avg: 0.341)\tLoss: 5.2545 (avg: 5.2253)\tTop1: 0.000 (avg: 1.188)\tTop5: 1.562 (avg: 4.812)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.337 (avg: 0.347)\tLoss: 5.3284 (avg: 5.2313)\tTop1: 0.000 (avg: 1.156)\tTop5: 3.125 (avg: 4.312)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.340 (avg: 0.348)\tLoss: 5.1931 (avg: 5.2289)\tTop1: 3.125 (avg: 1.125)\tTop5: 7.812 (avg: 4.708)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.341 (avg: 0.349)\tLoss: 5.2202 (avg: 5.2290)\tTop1: 3.125 (avg: 1.062)\tTop5: 6.250 (avg: 4.625)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.356 (avg: 0.350)\tLoss: 5.2319 (avg: 5.2292)\tTop1: 0.000 (avg: 1.050)\tTop5: 3.125 (avg: 4.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2548\tTop 1 accuracy: 1.000\tTop 5 accuracy: 4.100\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.349 (avg: 0.342)\tLoss: 5.2183 (avg: 5.2148)\tTop1: 0.000 (avg: 1.188)\tTop5: 3.125 (avg: 4.938)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.339 (avg: 0.346)\tLoss: 5.3357 (avg: 5.2263)\tTop1: 0.000 (avg: 1.094)\tTop5: 3.125 (avg: 4.906)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.346 (avg: 0.348)\tLoss: 5.2394 (avg: 5.2194)\tTop1: 0.000 (avg: 1.021)\tTop5: 4.688 (avg: 4.979)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.344 (avg: 0.349)\tLoss: 5.1526 (avg: 5.2166)\tTop1: 1.562 (avg: 0.969)\tTop5: 7.812 (avg: 4.906)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.352 (avg: 0.350)\tLoss: 5.2295 (avg: 5.2148)\tTop1: 0.000 (avg: 1.050)\tTop5: 3.125 (avg: 5.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2395\tTop 1 accuracy: 1.300\tTop 5 accuracy: 4.650\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.354 (avg: 0.343)\tLoss: 5.2452 (avg: 5.2052)\tTop1: 0.000 (avg: 1.375)\tTop5: 4.688 (avg: 4.750)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.341 (avg: 0.347)\tLoss: 5.0437 (avg: 5.1959)\tTop1: 0.000 (avg: 1.062)\tTop5: 9.375 (avg: 4.906)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.345 (avg: 0.349)\tLoss: 5.2106 (avg: 5.1905)\tTop1: 1.562 (avg: 1.042)\tTop5: 7.812 (avg: 5.229)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.343 (avg: 0.349)\tLoss: 5.2091 (avg: 5.1908)\tTop1: 0.000 (avg: 1.016)\tTop5: 9.375 (avg: 5.438)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.355 (avg: 0.350)\tLoss: 5.2229 (avg: 5.1905)\tTop1: 3.125 (avg: 1.088)\tTop5: 4.688 (avg: 5.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1693\tTop 1 accuracy: 1.150\tTop 5 accuracy: 5.150\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.347 (avg: 0.343)\tLoss: 5.1649 (avg: 5.1798)\tTop1: 4.688 (avg: 1.688)\tTop5: 7.812 (avg: 5.312)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.339 (avg: 0.347)\tLoss: 5.2255 (avg: 5.1807)\tTop1: 0.000 (avg: 1.500)\tTop5: 4.688 (avg: 5.281)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.342 (avg: 0.348)\tLoss: 4.9881 (avg: 5.1777)\tTop1: 1.562 (avg: 1.458)\tTop5: 10.938 (avg: 5.521)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.347 (avg: 0.349)\tLoss: 5.1327 (avg: 5.1726)\tTop1: 3.125 (avg: 1.406)\tTop5: 9.375 (avg: 5.828)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.350 (avg: 0.350)\tLoss: 5.3340 (avg: 5.1724)\tTop1: 0.000 (avg: 1.363)\tTop5: 1.562 (avg: 5.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2457\tTop 1 accuracy: 1.000\tTop 5 accuracy: 4.950\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.347 (avg: 0.343)\tLoss: 5.1846 (avg: 5.1450)\tTop1: 0.000 (avg: 0.750)\tTop5: 6.250 (avg: 6.188)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.339 (avg: 0.347)\tLoss: 5.1630 (avg: 5.1427)\tTop1: 0.000 (avg: 1.062)\tTop5: 4.688 (avg: 6.094)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.343 (avg: 0.348)\tLoss: 5.1254 (avg: 5.1490)\tTop1: 3.125 (avg: 1.208)\tTop5: 7.812 (avg: 5.938)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.345 (avg: 0.349)\tLoss: 4.9632 (avg: 5.1518)\tTop1: 3.125 (avg: 1.109)\tTop5: 9.375 (avg: 5.828)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.349 (avg: 0.349)\tLoss: 5.2223 (avg: 5.1503)\tTop1: 0.000 (avg: 1.138)\tTop5: 4.688 (avg: 6.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2477\tTop 1 accuracy: 1.400\tTop 5 accuracy: 5.700\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.358 (avg: 0.342)\tLoss: 4.8693 (avg: 5.1096)\tTop1: 3.125 (avg: 1.375)\tTop5: 14.062 (avg: 6.688)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.343 (avg: 0.346)\tLoss: 5.1424 (avg: 5.1243)\tTop1: 0.000 (avg: 1.062)\tTop5: 9.375 (avg: 6.375)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.342 (avg: 0.348)\tLoss: 5.2863 (avg: 5.1226)\tTop1: 0.000 (avg: 1.250)\tTop5: 3.125 (avg: 6.500)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.343 (avg: 0.349)\tLoss: 5.1893 (avg: 5.1223)\tTop1: 1.562 (avg: 1.281)\tTop5: 3.125 (avg: 6.516)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.350 (avg: 0.349)\tLoss: 5.1539 (avg: 5.1239)\tTop1: 0.000 (avg: 1.338)\tTop5: 3.125 (avg: 6.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1211\tTop 1 accuracy: 1.700\tTop 5 accuracy: 6.350\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.352 (avg: 0.343)\tLoss: 5.1407 (avg: 5.0870)\tTop1: 0.000 (avg: 2.125)\tTop5: 6.250 (avg: 8.438)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.339 (avg: 0.347)\tLoss: 5.1600 (avg: 5.1037)\tTop1: 0.000 (avg: 1.688)\tTop5: 7.812 (avg: 7.500)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.345 (avg: 0.349)\tLoss: 5.1340 (avg: 5.1030)\tTop1: 3.125 (avg: 1.688)\tTop5: 7.812 (avg: 7.438)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.347 (avg: 0.350)\tLoss: 5.1265 (avg: 5.1040)\tTop1: 1.562 (avg: 1.656)\tTop5: 6.250 (avg: 7.125)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.343 (avg: 0.349)\tLoss: 5.0280 (avg: 5.1055)\tTop1: 1.562 (avg: 1.588)\tTop5: 7.812 (avg: 6.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0945\tTop 1 accuracy: 1.300\tTop 5 accuracy: 7.050\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.351 (avg: 0.342)\tLoss: 4.9542 (avg: 5.0726)\tTop1: 0.000 (avg: 1.250)\tTop5: 7.812 (avg: 6.875)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.339 (avg: 0.347)\tLoss: 5.1140 (avg: 5.0874)\tTop1: 1.562 (avg: 1.562)\tTop5: 7.812 (avg: 7.031)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.345 (avg: 0.348)\tLoss: 5.2153 (avg: 5.0945)\tTop1: 0.000 (avg: 1.333)\tTop5: 3.125 (avg: 6.708)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.345 (avg: 0.349)\tLoss: 4.9981 (avg: 5.0872)\tTop1: 3.125 (avg: 1.438)\tTop5: 12.500 (avg: 7.047)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.351 (avg: 0.350)\tLoss: 5.1483 (avg: 5.0876)\tTop1: 1.562 (avg: 1.400)\tTop5: 4.688 (avg: 7.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9942\tTop 1 accuracy: 1.300\tTop 5 accuracy: 7.100\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.353 (avg: 0.343)\tLoss: 5.0857 (avg: 5.0784)\tTop1: 3.125 (avg: 1.812)\tTop5: 10.938 (avg: 8.750)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.338 (avg: 0.347)\tLoss: 5.0405 (avg: 5.0896)\tTop1: 0.000 (avg: 1.750)\tTop5: 9.375 (avg: 7.969)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.343 (avg: 0.349)\tLoss: 5.0604 (avg: 5.0907)\tTop1: 1.562 (avg: 1.729)\tTop5: 9.375 (avg: 7.667)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.344 (avg: 0.349)\tLoss: 5.0523 (avg: 5.0817)\tTop1: 3.125 (avg: 1.766)\tTop5: 7.812 (avg: 7.828)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.349 (avg: 0.350)\tLoss: 4.8739 (avg: 5.0813)\tTop1: 0.000 (avg: 1.663)\tTop5: 15.625 (avg: 7.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9381\tTop 1 accuracy: 1.200\tTop 5 accuracy: 6.300\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.350 (avg: 0.343)\tLoss: 4.9650 (avg: 5.0742)\tTop1: 3.125 (avg: 1.875)\tTop5: 12.500 (avg: 7.812)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.339 (avg: 0.347)\tLoss: 5.0445 (avg: 5.0795)\tTop1: 0.000 (avg: 1.625)\tTop5: 10.938 (avg: 7.344)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.340 (avg: 0.348)\tLoss: 5.0302 (avg: 5.0588)\tTop1: 1.562 (avg: 1.833)\tTop5: 7.812 (avg: 7.500)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.347 (avg: 0.349)\tLoss: 5.0035 (avg: 5.0478)\tTop1: 3.125 (avg: 1.766)\tTop5: 12.500 (avg: 7.625)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.351 (avg: 0.349)\tLoss: 5.1590 (avg: 5.0471)\tTop1: 1.562 (avg: 1.738)\tTop5: 3.125 (avg: 7.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0343\tTop 1 accuracy: 1.000\tTop 5 accuracy: 7.300\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.351 (avg: 0.343)\tLoss: 5.1281 (avg: 4.9947)\tTop1: 0.000 (avg: 2.062)\tTop5: 7.812 (avg: 10.625)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.339 (avg: 0.347)\tLoss: 5.0381 (avg: 5.0058)\tTop1: 1.562 (avg: 2.219)\tTop5: 3.125 (avg: 9.500)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.343 (avg: 0.349)\tLoss: 4.9492 (avg: 5.0105)\tTop1: 6.250 (avg: 2.250)\tTop5: 9.375 (avg: 9.021)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.347 (avg: 0.349)\tLoss: 4.7658 (avg: 5.0105)\tTop1: 3.125 (avg: 2.203)\tTop5: 14.062 (avg: 9.000)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.351 (avg: 0.350)\tLoss: 5.0372 (avg: 5.0180)\tTop1: 0.000 (avg: 2.025)\tTop5: 7.812 (avg: 8.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8482\tTop 1 accuracy: 1.900\tTop 5 accuracy: 8.500\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.353 (avg: 0.344)\tLoss: 5.0147 (avg: 4.9658)\tTop1: 0.000 (avg: 1.875)\tTop5: 4.688 (avg: 9.250)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.340 (avg: 0.347)\tLoss: 5.0579 (avg: 4.9876)\tTop1: 3.125 (avg: 2.219)\tTop5: 9.375 (avg: 9.031)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.344 (avg: 0.349)\tLoss: 4.9793 (avg: 4.9898)\tTop1: 4.688 (avg: 2.312)\tTop5: 15.625 (avg: 8.896)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.344 (avg: 0.349)\tLoss: 5.0033 (avg: 4.9923)\tTop1: 0.000 (avg: 2.219)\tTop5: 12.500 (avg: 8.750)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.354 (avg: 0.349)\tLoss: 5.0210 (avg: 4.9915)\tTop1: 0.000 (avg: 2.150)\tTop5: 3.125 (avg: 8.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8947\tTop 1 accuracy: 2.300\tTop 5 accuracy: 10.100\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.350 (avg: 0.343)\tLoss: 5.1087 (avg: 4.9489)\tTop1: 1.562 (avg: 2.562)\tTop5: 9.375 (avg: 10.938)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.338 (avg: 0.348)\tLoss: 5.0550 (avg: 4.9481)\tTop1: 0.000 (avg: 2.438)\tTop5: 6.250 (avg: 10.219)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.350 (avg: 0.349)\tLoss: 4.8332 (avg: 4.9495)\tTop1: 0.000 (avg: 2.312)\tTop5: 10.938 (avg: 9.938)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.343 (avg: 0.350)\tLoss: 4.8856 (avg: 4.9630)\tTop1: 1.562 (avg: 2.250)\tTop5: 10.938 (avg: 9.844)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.357 (avg: 0.349)\tLoss: 4.9700 (avg: 4.9542)\tTop1: 0.000 (avg: 2.300)\tTop5: 6.250 (avg: 10.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0138\tTop 1 accuracy: 2.150\tTop 5 accuracy: 9.650\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.347 (avg: 0.343)\tLoss: 4.9034 (avg: 4.9679)\tTop1: 4.688 (avg: 2.625)\tTop5: 7.812 (avg: 9.812)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.342 (avg: 0.347)\tLoss: 5.2095 (avg: 4.9677)\tTop1: 0.000 (avg: 2.469)\tTop5: 9.375 (avg: 9.844)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.343 (avg: 0.349)\tLoss: 4.7865 (avg: 4.9661)\tTop1: 1.562 (avg: 2.458)\tTop5: 7.812 (avg: 9.896)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.345 (avg: 0.349)\tLoss: 5.1116 (avg: 4.9657)\tTop1: 1.562 (avg: 2.469)\tTop5: 6.250 (avg: 10.203)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.353 (avg: 0.350)\tLoss: 4.8230 (avg: 4.9525)\tTop1: 6.250 (avg: 2.575)\tTop5: 15.625 (avg: 10.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8899\tTop 1 accuracy: 2.250\tTop 5 accuracy: 10.600\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.352 (avg: 0.342)\tLoss: 5.0089 (avg: 4.8758)\tTop1: 3.125 (avg: 2.938)\tTop5: 4.688 (avg: 11.562)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.339 (avg: 0.347)\tLoss: 4.8412 (avg: 4.8808)\tTop1: 3.125 (avg: 3.125)\tTop5: 17.188 (avg: 12.312)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.344 (avg: 0.349)\tLoss: 4.9535 (avg: 4.8979)\tTop1: 3.125 (avg: 2.979)\tTop5: 7.812 (avg: 11.604)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.341 (avg: 0.349)\tLoss: 4.8654 (avg: 4.8986)\tTop1: 3.125 (avg: 2.859)\tTop5: 7.812 (avg: 11.516)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.354 (avg: 0.350)\tLoss: 4.9538 (avg: 4.8970)\tTop1: 3.125 (avg: 2.888)\tTop5: 12.500 (avg: 11.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2015\tTop 1 accuracy: 2.350\tTop 5 accuracy: 11.450\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.353 (avg: 0.343)\tLoss: 4.8708 (avg: 4.8736)\tTop1: 1.562 (avg: 2.875)\tTop5: 10.938 (avg: 11.750)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.340 (avg: 0.347)\tLoss: 4.9324 (avg: 4.8580)\tTop1: 1.562 (avg: 3.250)\tTop5: 9.375 (avg: 12.281)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.343 (avg: 0.349)\tLoss: 4.7712 (avg: 4.8596)\tTop1: 6.250 (avg: 3.396)\tTop5: 17.188 (avg: 12.604)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.343 (avg: 0.350)\tLoss: 4.9541 (avg: 4.8527)\tTop1: 3.125 (avg: 3.109)\tTop5: 7.812 (avg: 12.453)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.350 (avg: 0.350)\tLoss: 5.0231 (avg: 4.8563)\tTop1: 1.562 (avg: 3.213)\tTop5: 9.375 (avg: 12.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8077\tTop 1 accuracy: 3.450\tTop 5 accuracy: 12.600\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.360 (avg: 0.343)\tLoss: 4.8749 (avg: 4.7992)\tTop1: 3.125 (avg: 3.938)\tTop5: 17.188 (avg: 13.750)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.341 (avg: 0.347)\tLoss: 4.8859 (avg: 4.8325)\tTop1: 1.562 (avg: 3.656)\tTop5: 10.938 (avg: 13.156)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.340 (avg: 0.349)\tLoss: 4.9201 (avg: 4.8344)\tTop1: 1.562 (avg: 3.479)\tTop5: 4.688 (avg: 13.333)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.344 (avg: 0.349)\tLoss: 4.7206 (avg: 4.8227)\tTop1: 4.688 (avg: 3.609)\tTop5: 12.500 (avg: 13.422)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.352 (avg: 0.350)\tLoss: 4.9149 (avg: 4.8284)\tTop1: 3.125 (avg: 3.450)\tTop5: 12.500 (avg: 13.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7461\tTop 1 accuracy: 3.600\tTop 5 accuracy: 12.700\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.352 (avg: 0.344)\tLoss: 4.9705 (avg: 4.7390)\tTop1: 1.562 (avg: 3.938)\tTop5: 10.938 (avg: 15.625)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.337 (avg: 0.347)\tLoss: 4.8010 (avg: 4.7593)\tTop1: 4.688 (avg: 4.062)\tTop5: 7.812 (avg: 14.938)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.342 (avg: 0.348)\tLoss: 4.8920 (avg: 4.7741)\tTop1: 6.250 (avg: 3.771)\tTop5: 17.188 (avg: 14.479)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.344 (avg: 0.349)\tLoss: 4.7845 (avg: 4.7802)\tTop1: 3.125 (avg: 3.875)\tTop5: 14.062 (avg: 14.656)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.351 (avg: 0.349)\tLoss: 4.9367 (avg: 4.7954)\tTop1: 3.125 (avg: 3.813)\tTop5: 15.625 (avg: 14.313)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8311\tTop 1 accuracy: 3.750\tTop 5 accuracy: 14.150\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.352 (avg: 0.343)\tLoss: 4.6677 (avg: 4.7179)\tTop1: 10.938 (avg: 4.750)\tTop5: 18.750 (avg: 15.438)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.338 (avg: 0.347)\tLoss: 4.7385 (avg: 4.7383)\tTop1: 4.688 (avg: 4.438)\tTop5: 18.750 (avg: 15.469)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.340 (avg: 0.349)\tLoss: 4.6784 (avg: 4.7412)\tTop1: 3.125 (avg: 4.271)\tTop5: 18.750 (avg: 15.562)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.337 (avg: 0.348)\tLoss: 4.5536 (avg: 4.7438)\tTop1: 4.688 (avg: 4.172)\tTop5: 17.188 (avg: 15.344)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.350 (avg: 0.349)\tLoss: 4.6556 (avg: 4.7504)\tTop1: 4.688 (avg: 4.213)\tTop5: 14.062 (avg: 15.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4843\tTop 1 accuracy: 4.600\tTop 5 accuracy: 16.350\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.351 (avg: 0.343)\tLoss: 4.8539 (avg: 4.7054)\tTop1: 4.688 (avg: 5.312)\tTop5: 6.250 (avg: 16.750)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.343 (avg: 0.348)\tLoss: 4.8391 (avg: 4.6888)\tTop1: 0.000 (avg: 4.688)\tTop5: 4.688 (avg: 16.406)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.343 (avg: 0.349)\tLoss: 4.8427 (avg: 4.7043)\tTop1: 4.688 (avg: 4.458)\tTop5: 18.750 (avg: 15.875)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.344 (avg: 0.350)\tLoss: 4.5393 (avg: 4.6985)\tTop1: 7.812 (avg: 4.578)\tTop5: 20.312 (avg: 15.906)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.350 (avg: 0.350)\tLoss: 4.6924 (avg: 4.7073)\tTop1: 6.250 (avg: 4.463)\tTop5: 18.750 (avg: 15.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6729\tTop 1 accuracy: 3.950\tTop 5 accuracy: 14.500\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.352 (avg: 0.344)\tLoss: 4.6000 (avg: 4.6340)\tTop1: 6.250 (avg: 5.188)\tTop5: 17.188 (avg: 17.750)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.341 (avg: 0.348)\tLoss: 4.7379 (avg: 4.6477)\tTop1: 6.250 (avg: 5.344)\tTop5: 15.625 (avg: 17.094)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.346 (avg: 0.349)\tLoss: 4.5688 (avg: 4.6335)\tTop1: 3.125 (avg: 5.188)\tTop5: 17.188 (avg: 17.521)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.345 (avg: 0.350)\tLoss: 4.7341 (avg: 4.6558)\tTop1: 4.688 (avg: 4.906)\tTop5: 15.625 (avg: 17.094)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.351 (avg: 0.350)\tLoss: 4.6532 (avg: 4.6497)\tTop1: 0.000 (avg: 4.738)\tTop5: 20.312 (avg: 17.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5377\tTop 1 accuracy: 5.100\tTop 5 accuracy: 17.050\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.352 (avg: 0.344)\tLoss: 4.4912 (avg: 4.6755)\tTop1: 3.125 (avg: 4.312)\tTop5: 20.312 (avg: 15.750)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.340 (avg: 0.348)\tLoss: 4.8201 (avg: 4.6664)\tTop1: 0.000 (avg: 4.344)\tTop5: 14.062 (avg: 16.156)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.344 (avg: 0.349)\tLoss: 4.5691 (avg: 4.6539)\tTop1: 6.250 (avg: 4.708)\tTop5: 21.875 (avg: 17.000)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.345 (avg: 0.350)\tLoss: 4.5884 (avg: 4.6313)\tTop1: 7.812 (avg: 4.953)\tTop5: 25.000 (avg: 17.484)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.350 (avg: 0.350)\tLoss: 4.4815 (avg: 4.6319)\tTop1: 3.125 (avg: 4.788)\tTop5: 25.000 (avg: 17.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4693\tTop 1 accuracy: 5.200\tTop 5 accuracy: 17.900\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.351 (avg: 0.344)\tLoss: 4.4168 (avg: 4.5501)\tTop1: 9.375 (avg: 5.875)\tTop5: 25.000 (avg: 18.250)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.341 (avg: 0.347)\tLoss: 4.3188 (avg: 4.5611)\tTop1: 6.250 (avg: 5.719)\tTop5: 18.750 (avg: 17.844)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.343 (avg: 0.349)\tLoss: 4.5705 (avg: 4.5785)\tTop1: 7.812 (avg: 5.750)\tTop5: 17.188 (avg: 17.583)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.344 (avg: 0.350)\tLoss: 4.7354 (avg: 4.6014)\tTop1: 4.688 (avg: 5.516)\tTop5: 17.188 (avg: 17.422)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.355 (avg: 0.350)\tLoss: 4.3136 (avg: 4.6033)\tTop1: 9.375 (avg: 5.563)\tTop5: 28.125 (avg: 17.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4327\tTop 1 accuracy: 5.700\tTop 5 accuracy: 19.050\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.347 (avg: 0.340)\tLoss: 4.5419 (avg: 4.4532)\tTop1: 4.688 (avg: 7.688)\tTop5: 20.312 (avg: 23.250)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.341 (avg: 0.346)\tLoss: 4.4512 (avg: 4.5233)\tTop1: 3.125 (avg: 5.969)\tTop5: 20.312 (avg: 19.844)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.343 (avg: 0.348)\tLoss: 4.4805 (avg: 4.5270)\tTop1: 9.375 (avg: 6.042)\tTop5: 18.750 (avg: 19.625)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.346 (avg: 0.349)\tLoss: 4.3252 (avg: 4.5260)\tTop1: 6.250 (avg: 5.859)\tTop5: 26.562 (avg: 19.609)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.349 (avg: 0.350)\tLoss: 4.5404 (avg: 4.5272)\tTop1: 1.562 (avg: 5.975)\tTop5: 17.188 (avg: 19.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3462\tTop 1 accuracy: 6.150\tTop 5 accuracy: 19.050\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.356 (avg: 0.343)\tLoss: 4.3421 (avg: 4.5195)\tTop1: 4.688 (avg: 6.188)\tTop5: 31.250 (avg: 21.875)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.343 (avg: 0.347)\tLoss: 4.3994 (avg: 4.5060)\tTop1: 7.812 (avg: 6.812)\tTop5: 23.438 (avg: 21.469)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.337 (avg: 0.347)\tLoss: 4.7000 (avg: 4.5109)\tTop1: 6.250 (avg: 6.604)\tTop5: 12.500 (avg: 20.938)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.344 (avg: 0.348)\tLoss: 4.5260 (avg: 4.5164)\tTop1: 4.688 (avg: 6.562)\tTop5: 12.500 (avg: 20.516)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.353 (avg: 0.349)\tLoss: 4.5915 (avg: 4.5229)\tTop1: 3.125 (avg: 6.313)\tTop5: 25.000 (avg: 20.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5472\tTop 1 accuracy: 4.250\tTop 5 accuracy: 13.750\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.353 (avg: 0.344)\tLoss: 4.4567 (avg: 4.5060)\tTop1: 6.250 (avg: 6.250)\tTop5: 21.875 (avg: 20.312)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.341 (avg: 0.348)\tLoss: 4.1838 (avg: 4.4828)\tTop1: 4.688 (avg: 6.469)\tTop5: 28.125 (avg: 21.031)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.342 (avg: 0.349)\tLoss: 4.2806 (avg: 4.4833)\tTop1: 10.938 (avg: 6.625)\tTop5: 23.438 (avg: 21.229)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.344 (avg: 0.350)\tLoss: 4.5800 (avg: 4.4842)\tTop1: 4.688 (avg: 6.516)\tTop5: 17.188 (avg: 20.938)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.354 (avg: 0.350)\tLoss: 4.4835 (avg: 4.4823)\tTop1: 6.250 (avg: 6.400)\tTop5: 15.625 (avg: 21.013)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3244\tTop 1 accuracy: 4.800\tTop 5 accuracy: 18.400\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.352 (avg: 0.343)\tLoss: 4.4536 (avg: 4.3664)\tTop1: 7.812 (avg: 8.188)\tTop5: 21.875 (avg: 24.562)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.339 (avg: 0.347)\tLoss: 4.3170 (avg: 4.3170)\tTop1: 6.250 (avg: 8.750)\tTop5: 26.562 (avg: 25.562)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.343 (avg: 0.349)\tLoss: 4.3228 (avg: 4.3041)\tTop1: 4.688 (avg: 8.500)\tTop5: 21.875 (avg: 25.625)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.345 (avg: 0.350)\tLoss: 4.0049 (avg: 4.2807)\tTop1: 17.188 (avg: 8.719)\tTop5: 37.500 (avg: 26.188)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.352 (avg: 0.350)\tLoss: 4.0563 (avg: 4.2572)\tTop1: 10.938 (avg: 9.350)\tTop5: 32.812 (avg: 26.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8468\tTop 1 accuracy: 8.500\tTop 5 accuracy: 24.450\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.347 (avg: 0.344)\tLoss: 4.4735 (avg: 4.1776)\tTop1: 4.688 (avg: 11.062)\tTop5: 18.750 (avg: 30.188)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.342 (avg: 0.348)\tLoss: 4.0594 (avg: 4.1703)\tTop1: 12.500 (avg: 10.875)\tTop5: 31.250 (avg: 29.844)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.344 (avg: 0.349)\tLoss: 4.3503 (avg: 4.1951)\tTop1: 14.062 (avg: 10.229)\tTop5: 25.000 (avg: 29.396)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.341 (avg: 0.349)\tLoss: 4.3162 (avg: 4.1970)\tTop1: 7.812 (avg: 10.094)\tTop5: 18.750 (avg: 28.938)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.356 (avg: 0.350)\tLoss: 3.8573 (avg: 4.1867)\tTop1: 17.188 (avg: 10.288)\tTop5: 37.500 (avg: 29.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9226\tTop 1 accuracy: 8.450\tTop 5 accuracy: 25.300\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.355 (avg: 0.343)\tLoss: 4.4983 (avg: 4.1180)\tTop1: 4.688 (avg: 11.750)\tTop5: 23.438 (avg: 32.812)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.338 (avg: 0.347)\tLoss: 4.0171 (avg: 4.1357)\tTop1: 17.188 (avg: 11.562)\tTop5: 37.500 (avg: 31.312)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.352 (avg: 0.349)\tLoss: 3.8991 (avg: 4.1452)\tTop1: 14.062 (avg: 10.979)\tTop5: 34.375 (avg: 30.771)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.342 (avg: 0.349)\tLoss: 4.2603 (avg: 4.1506)\tTop1: 4.688 (avg: 11.094)\tTop5: 21.875 (avg: 30.625)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.354 (avg: 0.350)\tLoss: 4.1439 (avg: 4.1558)\tTop1: 9.375 (avg: 10.888)\tTop5: 31.250 (avg: 30.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6908\tTop 1 accuracy: 8.550\tTop 5 accuracy: 26.050\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.351 (avg: 0.343)\tLoss: 4.2427 (avg: 4.1121)\tTop1: 12.500 (avg: 11.750)\tTop5: 21.875 (avg: 30.500)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.341 (avg: 0.347)\tLoss: 3.9708 (avg: 4.1266)\tTop1: 10.938 (avg: 11.750)\tTop5: 28.125 (avg: 30.875)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.345 (avg: 0.349)\tLoss: 4.7074 (avg: 4.1362)\tTop1: 9.375 (avg: 11.438)\tTop5: 23.438 (avg: 30.688)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.344 (avg: 0.349)\tLoss: 3.9663 (avg: 4.1371)\tTop1: 18.750 (avg: 11.156)\tTop5: 34.375 (avg: 30.656)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.356 (avg: 0.350)\tLoss: 4.1612 (avg: 4.1382)\tTop1: 6.250 (avg: 11.088)\tTop5: 39.062 (avg: 30.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8439\tTop 1 accuracy: 8.800\tTop 5 accuracy: 25.800\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.355 (avg: 0.343)\tLoss: 4.0025 (avg: 4.1006)\tTop1: 12.500 (avg: 11.062)\tTop5: 37.500 (avg: 32.688)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.338 (avg: 0.346)\tLoss: 4.1490 (avg: 4.1073)\tTop1: 12.500 (avg: 11.125)\tTop5: 28.125 (avg: 32.531)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.348 (avg: 0.348)\tLoss: 4.1131 (avg: 4.1231)\tTop1: 9.375 (avg: 11.271)\tTop5: 23.438 (avg: 31.292)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.342 (avg: 0.349)\tLoss: 4.2369 (avg: 4.1255)\tTop1: 7.812 (avg: 11.234)\tTop5: 29.688 (avg: 31.156)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.350 (avg: 0.349)\tLoss: 4.2913 (avg: 4.1271)\tTop1: 7.812 (avg: 11.188)\tTop5: 23.438 (avg: 30.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7609\tTop 1 accuracy: 9.000\tTop 5 accuracy: 26.100\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.351 (avg: 0.344)\tLoss: 4.3075 (avg: 4.1227)\tTop1: 12.500 (avg: 11.750)\tTop5: 26.562 (avg: 30.375)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.341 (avg: 0.348)\tLoss: 3.8453 (avg: 4.1006)\tTop1: 12.500 (avg: 11.594)\tTop5: 34.375 (avg: 30.719)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.350 (avg: 0.349)\tLoss: 4.0819 (avg: 4.1248)\tTop1: 12.500 (avg: 11.167)\tTop5: 28.125 (avg: 30.312)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.346 (avg: 0.350)\tLoss: 3.9345 (avg: 4.1194)\tTop1: 20.312 (avg: 11.469)\tTop5: 39.062 (avg: 30.828)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.349 (avg: 0.350)\tLoss: 3.9440 (avg: 4.1244)\tTop1: 15.625 (avg: 11.250)\tTop5: 42.188 (avg: 30.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7604\tTop 1 accuracy: 8.450\tTop 5 accuracy: 26.100\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.353 (avg: 0.342)\tLoss: 4.1348 (avg: 4.0638)\tTop1: 10.938 (avg: 11.688)\tTop5: 29.688 (avg: 33.562)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.340 (avg: 0.347)\tLoss: 3.8437 (avg: 4.0885)\tTop1: 23.438 (avg: 11.781)\tTop5: 46.875 (avg: 32.094)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.343 (avg: 0.349)\tLoss: 4.0924 (avg: 4.0956)\tTop1: 12.500 (avg: 11.438)\tTop5: 31.250 (avg: 31.625)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.341 (avg: 0.350)\tLoss: 3.9957 (avg: 4.1013)\tTop1: 14.062 (avg: 11.438)\tTop5: 35.938 (avg: 31.656)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.351 (avg: 0.350)\tLoss: 3.9921 (avg: 4.1071)\tTop1: 14.062 (avg: 11.200)\tTop5: 28.125 (avg: 31.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7199\tTop 1 accuracy: 8.800\tTop 5 accuracy: 26.450\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.352 (avg: 0.343)\tLoss: 4.0481 (avg: 4.1146)\tTop1: 10.938 (avg: 12.312)\tTop5: 29.688 (avg: 30.688)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.341 (avg: 0.347)\tLoss: 4.3758 (avg: 4.1139)\tTop1: 9.375 (avg: 11.688)\tTop5: 28.125 (avg: 30.938)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.345 (avg: 0.349)\tLoss: 3.9250 (avg: 4.1019)\tTop1: 9.375 (avg: 11.417)\tTop5: 37.500 (avg: 31.167)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.344 (avg: 0.350)\tLoss: 4.0896 (avg: 4.0837)\tTop1: 12.500 (avg: 11.609)\tTop5: 28.125 (avg: 31.734)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.355 (avg: 0.351)\tLoss: 4.1784 (avg: 4.0970)\tTop1: 17.188 (avg: 11.375)\tTop5: 32.812 (avg: 31.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7335\tTop 1 accuracy: 8.150\tTop 5 accuracy: 26.050\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.353 (avg: 0.344)\tLoss: 4.1373 (avg: 4.1254)\tTop1: 4.688 (avg: 10.375)\tTop5: 21.875 (avg: 31.062)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.342 (avg: 0.348)\tLoss: 4.3764 (avg: 4.1210)\tTop1: 6.250 (avg: 11.375)\tTop5: 26.562 (avg: 31.188)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.344 (avg: 0.350)\tLoss: 4.1182 (avg: 4.1027)\tTop1: 9.375 (avg: 11.042)\tTop5: 34.375 (avg: 31.104)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.338 (avg: 0.350)\tLoss: 4.4456 (avg: 4.0904)\tTop1: 12.500 (avg: 10.906)\tTop5: 26.562 (avg: 31.469)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.352 (avg: 0.350)\tLoss: 4.0567 (avg: 4.0963)\tTop1: 6.250 (avg: 11.013)\tTop5: 31.250 (avg: 31.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7632\tTop 1 accuracy: 9.250\tTop 5 accuracy: 26.500\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.354 (avg: 0.344)\tLoss: 3.9439 (avg: 4.0746)\tTop1: 7.812 (avg: 11.000)\tTop5: 35.938 (avg: 32.250)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.345 (avg: 0.349)\tLoss: 4.4231 (avg: 4.0609)\tTop1: 10.938 (avg: 11.688)\tTop5: 32.812 (avg: 33.656)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.349 (avg: 0.350)\tLoss: 4.0234 (avg: 4.0706)\tTop1: 9.375 (avg: 11.771)\tTop5: 29.688 (avg: 33.104)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.346 (avg: 0.351)\tLoss: 4.1607 (avg: 4.0713)\tTop1: 9.375 (avg: 11.797)\tTop5: 29.688 (avg: 32.516)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.355 (avg: 0.351)\tLoss: 4.1204 (avg: 4.0778)\tTop1: 10.938 (avg: 11.613)\tTop5: 34.375 (avg: 32.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7441\tTop 1 accuracy: 9.300\tTop 5 accuracy: 27.550\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.344 (avg: 0.341)\tLoss: 4.4003 (avg: 4.0617)\tTop1: 9.375 (avg: 11.312)\tTop5: 29.688 (avg: 31.750)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.338 (avg: 0.345)\tLoss: 4.2285 (avg: 4.0470)\tTop1: 14.062 (avg: 12.031)\tTop5: 23.438 (avg: 32.469)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.344 (avg: 0.348)\tLoss: 3.9534 (avg: 4.0555)\tTop1: 15.625 (avg: 11.979)\tTop5: 43.750 (avg: 32.500)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.343 (avg: 0.348)\tLoss: 4.0453 (avg: 4.0669)\tTop1: 10.938 (avg: 11.719)\tTop5: 31.250 (avg: 32.094)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.355 (avg: 0.349)\tLoss: 3.8030 (avg: 4.0633)\tTop1: 15.625 (avg: 11.825)\tTop5: 35.938 (avg: 32.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7038\tTop 1 accuracy: 9.250\tTop 5 accuracy: 27.450\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.351 (avg: 0.344)\tLoss: 3.7214 (avg: 4.0151)\tTop1: 21.875 (avg: 12.062)\tTop5: 46.875 (avg: 33.000)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.339 (avg: 0.349)\tLoss: 4.6094 (avg: 4.0452)\tTop1: 4.688 (avg: 12.188)\tTop5: 20.312 (avg: 32.906)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.343 (avg: 0.350)\tLoss: 4.0982 (avg: 4.0416)\tTop1: 12.500 (avg: 12.021)\tTop5: 31.250 (avg: 32.771)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.344 (avg: 0.351)\tLoss: 4.0056 (avg: 4.0449)\tTop1: 12.500 (avg: 11.922)\tTop5: 31.250 (avg: 32.516)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.355 (avg: 0.351)\tLoss: 4.2249 (avg: 4.0516)\tTop1: 20.312 (avg: 11.800)\tTop5: 32.812 (avg: 32.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7931\tTop 1 accuracy: 9.600\tTop 5 accuracy: 27.250\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.353 (avg: 0.345)\tLoss: 3.8806 (avg: 4.0678)\tTop1: 9.375 (avg: 10.938)\tTop5: 40.625 (avg: 32.812)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.345 (avg: 0.349)\tLoss: 3.9731 (avg: 4.0503)\tTop1: 7.812 (avg: 11.344)\tTop5: 29.688 (avg: 32.594)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.342 (avg: 0.350)\tLoss: 4.4350 (avg: 4.0506)\tTop1: 9.375 (avg: 11.479)\tTop5: 18.750 (avg: 32.458)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.343 (avg: 0.351)\tLoss: 4.1862 (avg: 4.0446)\tTop1: 9.375 (avg: 11.531)\tTop5: 25.000 (avg: 32.328)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.352 (avg: 0.351)\tLoss: 3.8935 (avg: 4.0479)\tTop1: 15.625 (avg: 11.875)\tTop5: 31.250 (avg: 32.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6616\tTop 1 accuracy: 10.000\tTop 5 accuracy: 27.100\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.349 (avg: 0.344)\tLoss: 4.3113 (avg: 3.9554)\tTop1: 10.938 (avg: 13.188)\tTop5: 34.375 (avg: 35.438)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.338 (avg: 0.349)\tLoss: 4.2388 (avg: 4.0296)\tTop1: 6.250 (avg: 12.000)\tTop5: 20.312 (avg: 33.594)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.344 (avg: 0.350)\tLoss: 3.7308 (avg: 4.0355)\tTop1: 10.938 (avg: 12.042)\tTop5: 40.625 (avg: 33.521)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.344 (avg: 0.351)\tLoss: 4.0674 (avg: 4.0433)\tTop1: 10.938 (avg: 12.188)\tTop5: 31.250 (avg: 33.281)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.350 (avg: 0.351)\tLoss: 4.2075 (avg: 4.0355)\tTop1: 14.062 (avg: 12.188)\tTop5: 28.125 (avg: 33.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6628\tTop 1 accuracy: 9.800\tTop 5 accuracy: 28.200\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.357 (avg: 0.344)\tLoss: 4.0277 (avg: 3.9937)\tTop1: 6.250 (avg: 12.312)\tTop5: 32.812 (avg: 34.938)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.341 (avg: 0.348)\tLoss: 4.2552 (avg: 4.0346)\tTop1: 6.250 (avg: 12.281)\tTop5: 25.000 (avg: 33.844)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.348 (avg: 0.349)\tLoss: 4.0063 (avg: 4.0165)\tTop1: 12.500 (avg: 12.062)\tTop5: 35.938 (avg: 33.812)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.346 (avg: 0.350)\tLoss: 3.8172 (avg: 4.0179)\tTop1: 17.188 (avg: 11.953)\tTop5: 39.062 (avg: 33.484)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.356 (avg: 0.351)\tLoss: 3.9714 (avg: 4.0234)\tTop1: 18.750 (avg: 12.063)\tTop5: 37.500 (avg: 33.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6989\tTop 1 accuracy: 10.050\tTop 5 accuracy: 28.150\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.355 (avg: 0.342)\tLoss: 3.9098 (avg: 3.9865)\tTop1: 12.500 (avg: 12.312)\tTop5: 37.500 (avg: 34.188)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.339 (avg: 0.347)\tLoss: 3.8290 (avg: 3.9841)\tTop1: 15.625 (avg: 12.406)\tTop5: 25.000 (avg: 34.406)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.345 (avg: 0.348)\tLoss: 3.9173 (avg: 3.9877)\tTop1: 15.625 (avg: 12.521)\tTop5: 40.625 (avg: 34.188)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.350 (avg: 0.349)\tLoss: 4.0391 (avg: 3.9959)\tTop1: 7.812 (avg: 12.406)\tTop5: 29.688 (avg: 33.984)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.357 (avg: 0.350)\tLoss: 4.0744 (avg: 4.0097)\tTop1: 12.500 (avg: 12.188)\tTop5: 31.250 (avg: 33.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6269\tTop 1 accuracy: 9.450\tTop 5 accuracy: 27.450\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.351 (avg: 0.342)\tLoss: 3.9715 (avg: 3.9563)\tTop1: 9.375 (avg: 13.938)\tTop5: 26.562 (avg: 35.188)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.339 (avg: 0.348)\tLoss: 4.5261 (avg: 3.9784)\tTop1: 4.688 (avg: 13.375)\tTop5: 26.562 (avg: 34.250)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.345 (avg: 0.350)\tLoss: 3.9894 (avg: 3.9889)\tTop1: 10.938 (avg: 13.479)\tTop5: 31.250 (avg: 34.042)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.346 (avg: 0.351)\tLoss: 4.1454 (avg: 3.9921)\tTop1: 10.938 (avg: 13.297)\tTop5: 31.250 (avg: 33.984)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.353 (avg: 0.351)\tLoss: 4.0060 (avg: 4.0045)\tTop1: 10.938 (avg: 12.813)\tTop5: 35.938 (avg: 33.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6744\tTop 1 accuracy: 9.450\tTop 5 accuracy: 28.150\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.355 (avg: 0.345)\tLoss: 4.0408 (avg: 3.9292)\tTop1: 7.812 (avg: 13.625)\tTop5: 34.375 (avg: 36.312)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.342 (avg: 0.349)\tLoss: 4.0666 (avg: 3.9388)\tTop1: 9.375 (avg: 13.719)\tTop5: 26.562 (avg: 35.781)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.353 (avg: 0.350)\tLoss: 3.9995 (avg: 3.9732)\tTop1: 6.250 (avg: 12.938)\tTop5: 31.250 (avg: 34.750)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.348 (avg: 0.351)\tLoss: 4.4241 (avg: 3.9827)\tTop1: 7.812 (avg: 12.812)\tTop5: 28.125 (avg: 34.484)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.359 (avg: 0.351)\tLoss: 4.0782 (avg: 3.9858)\tTop1: 10.938 (avg: 12.788)\tTop5: 31.250 (avg: 34.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7295\tTop 1 accuracy: 9.850\tTop 5 accuracy: 28.350\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.355 (avg: 0.345)\tLoss: 3.7565 (avg: 3.9745)\tTop1: 18.750 (avg: 13.688)\tTop5: 42.188 (avg: 34.500)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.340 (avg: 0.349)\tLoss: 4.1343 (avg: 3.9516)\tTop1: 4.688 (avg: 13.469)\tTop5: 29.688 (avg: 35.250)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.345 (avg: 0.350)\tLoss: 4.0916 (avg: 3.9718)\tTop1: 7.812 (avg: 13.229)\tTop5: 29.688 (avg: 34.625)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.338 (avg: 0.351)\tLoss: 4.4386 (avg: 3.9845)\tTop1: 4.688 (avg: 13.141)\tTop5: 23.438 (avg: 34.141)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.353 (avg: 0.351)\tLoss: 3.8509 (avg: 3.9851)\tTop1: 12.500 (avg: 13.088)\tTop5: 40.625 (avg: 34.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6538\tTop 1 accuracy: 10.350\tTop 5 accuracy: 28.650\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.351 (avg: 0.345)\tLoss: 3.9309 (avg: 3.9164)\tTop1: 14.062 (avg: 13.750)\tTop5: 32.812 (avg: 36.438)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.339 (avg: 0.349)\tLoss: 3.9699 (avg: 3.9451)\tTop1: 14.062 (avg: 13.438)\tTop5: 29.688 (avg: 35.406)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.344 (avg: 0.351)\tLoss: 3.9631 (avg: 3.9659)\tTop1: 12.500 (avg: 13.167)\tTop5: 37.500 (avg: 34.875)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.345 (avg: 0.351)\tLoss: 3.8986 (avg: 3.9666)\tTop1: 10.938 (avg: 13.062)\tTop5: 29.688 (avg: 34.688)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.350 (avg: 0.351)\tLoss: 4.1112 (avg: 3.9685)\tTop1: 7.812 (avg: 13.250)\tTop5: 29.688 (avg: 34.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6328\tTop 1 accuracy: 9.750\tTop 5 accuracy: 27.650\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.348 (avg: 0.343)\tLoss: 4.1503 (avg: 3.9422)\tTop1: 15.625 (avg: 14.000)\tTop5: 29.688 (avg: 34.875)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.342 (avg: 0.347)\tLoss: 4.0320 (avg: 3.9936)\tTop1: 10.938 (avg: 12.594)\tTop5: 25.000 (avg: 33.000)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.349 (avg: 0.349)\tLoss: 3.9988 (avg: 3.9683)\tTop1: 18.750 (avg: 13.417)\tTop5: 34.375 (avg: 34.354)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.347 (avg: 0.350)\tLoss: 4.1979 (avg: 3.9566)\tTop1: 12.500 (avg: 13.516)\tTop5: 29.688 (avg: 34.828)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.351 (avg: 0.351)\tLoss: 4.0088 (avg: 3.9531)\tTop1: 7.812 (avg: 13.688)\tTop5: 32.812 (avg: 34.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6929\tTop 1 accuracy: 10.250\tTop 5 accuracy: 29.700\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.353 (avg: 0.345)\tLoss: 3.8928 (avg: 3.9031)\tTop1: 14.062 (avg: 13.188)\tTop5: 35.938 (avg: 37.312)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.340 (avg: 0.349)\tLoss: 4.1965 (avg: 3.9388)\tTop1: 7.812 (avg: 12.781)\tTop5: 25.000 (avg: 35.594)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.345 (avg: 0.351)\tLoss: 4.1613 (avg: 3.9345)\tTop1: 10.938 (avg: 12.896)\tTop5: 32.812 (avg: 35.688)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.344 (avg: 0.351)\tLoss: 3.9732 (avg: 3.9508)\tTop1: 9.375 (avg: 12.891)\tTop5: 39.062 (avg: 35.172)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.348 (avg: 0.351)\tLoss: 3.7186 (avg: 3.9556)\tTop1: 20.312 (avg: 12.900)\tTop5: 43.750 (avg: 34.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6611\tTop 1 accuracy: 10.550\tTop 5 accuracy: 28.950\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.352 (avg: 0.344)\tLoss: 3.8008 (avg: 3.8982)\tTop1: 17.188 (avg: 13.750)\tTop5: 40.625 (avg: 37.188)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.340 (avg: 0.348)\tLoss: 3.9278 (avg: 3.9226)\tTop1: 10.938 (avg: 13.844)\tTop5: 35.938 (avg: 36.281)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.345 (avg: 0.350)\tLoss: 3.9602 (avg: 3.9410)\tTop1: 17.188 (avg: 13.500)\tTop5: 31.250 (avg: 35.708)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.348 (avg: 0.351)\tLoss: 4.0438 (avg: 3.9487)\tTop1: 12.500 (avg: 13.438)\tTop5: 35.938 (avg: 35.438)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.350 (avg: 0.351)\tLoss: 4.1331 (avg: 3.9521)\tTop1: 10.938 (avg: 13.200)\tTop5: 34.375 (avg: 35.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6560\tTop 1 accuracy: 9.950\tTop 5 accuracy: 28.550\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.352 (avg: 0.345)\tLoss: 3.7481 (avg: 3.8975)\tTop1: 21.875 (avg: 13.188)\tTop5: 42.188 (avg: 36.188)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.340 (avg: 0.349)\tLoss: 3.7234 (avg: 3.8854)\tTop1: 14.062 (avg: 13.938)\tTop5: 34.375 (avg: 36.219)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.347 (avg: 0.351)\tLoss: 3.7891 (avg: 3.8859)\tTop1: 10.938 (avg: 13.667)\tTop5: 34.375 (avg: 36.583)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.348 (avg: 0.351)\tLoss: 4.0755 (avg: 3.9091)\tTop1: 7.812 (avg: 13.422)\tTop5: 29.688 (avg: 36.172)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.349 (avg: 0.352)\tLoss: 3.9328 (avg: 3.9228)\tTop1: 12.500 (avg: 13.488)\tTop5: 37.500 (avg: 35.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7066\tTop 1 accuracy: 10.350\tTop 5 accuracy: 29.550\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.345 (avg: 0.342)\tLoss: 3.6859 (avg: 3.8568)\tTop1: 25.000 (avg: 13.562)\tTop5: 48.438 (avg: 37.688)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.343 (avg: 0.347)\tLoss: 4.0689 (avg: 3.9197)\tTop1: 15.625 (avg: 13.188)\tTop5: 31.250 (avg: 35.594)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.348 (avg: 0.349)\tLoss: 4.2511 (avg: 3.9352)\tTop1: 10.938 (avg: 13.750)\tTop5: 28.125 (avg: 35.188)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.345 (avg: 0.350)\tLoss: 3.6888 (avg: 3.9340)\tTop1: 14.062 (avg: 14.219)\tTop5: 40.625 (avg: 35.469)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.353 (avg: 0.351)\tLoss: 4.1193 (avg: 3.9250)\tTop1: 10.938 (avg: 14.125)\tTop5: 32.812 (avg: 35.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5712\tTop 1 accuracy: 10.500\tTop 5 accuracy: 28.550\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.357 (avg: 0.345)\tLoss: 3.6707 (avg: 3.9351)\tTop1: 26.562 (avg: 12.938)\tTop5: 42.188 (avg: 35.250)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.342 (avg: 0.349)\tLoss: 3.6153 (avg: 3.9403)\tTop1: 21.875 (avg: 13.094)\tTop5: 34.375 (avg: 35.250)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.346 (avg: 0.350)\tLoss: 3.5479 (avg: 3.9198)\tTop1: 15.625 (avg: 13.292)\tTop5: 43.750 (avg: 35.583)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.346 (avg: 0.351)\tLoss: 3.6824 (avg: 3.9078)\tTop1: 12.500 (avg: 13.422)\tTop5: 43.750 (avg: 35.859)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.358 (avg: 0.351)\tLoss: 4.3570 (avg: 3.9160)\tTop1: 6.250 (avg: 13.125)\tTop5: 28.125 (avg: 35.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6476\tTop 1 accuracy: 11.300\tTop 5 accuracy: 30.150\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.356 (avg: 0.345)\tLoss: 3.7864 (avg: 3.7960)\tTop1: 21.875 (avg: 15.125)\tTop5: 39.062 (avg: 39.562)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.340 (avg: 0.349)\tLoss: 3.8590 (avg: 3.8239)\tTop1: 12.500 (avg: 14.188)\tTop5: 37.500 (avg: 37.656)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.351 (avg: 0.350)\tLoss: 3.5452 (avg: 3.8609)\tTop1: 20.312 (avg: 14.146)\tTop5: 46.875 (avg: 37.583)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.348 (avg: 0.351)\tLoss: 3.5538 (avg: 3.8721)\tTop1: 14.062 (avg: 13.859)\tTop5: 48.438 (avg: 37.391)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.355 (avg: 0.351)\tLoss: 3.9911 (avg: 3.8934)\tTop1: 15.625 (avg: 13.738)\tTop5: 34.375 (avg: 36.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6586\tTop 1 accuracy: 10.150\tTop 5 accuracy: 29.450\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.354 (avg: 0.345)\tLoss: 3.9403 (avg: 3.8482)\tTop1: 14.062 (avg: 14.688)\tTop5: 37.500 (avg: 37.750)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.341 (avg: 0.349)\tLoss: 3.7472 (avg: 3.8730)\tTop1: 17.188 (avg: 14.531)\tTop5: 32.812 (avg: 36.844)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.345 (avg: 0.351)\tLoss: 3.8659 (avg: 3.8768)\tTop1: 15.625 (avg: 14.146)\tTop5: 32.812 (avg: 36.729)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.339 (avg: 0.350)\tLoss: 4.1909 (avg: 3.8734)\tTop1: 6.250 (avg: 14.047)\tTop5: 28.125 (avg: 36.953)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.353 (avg: 0.351)\tLoss: 4.3567 (avg: 3.8983)\tTop1: 10.938 (avg: 13.650)\tTop5: 25.000 (avg: 36.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7566\tTop 1 accuracy: 11.850\tTop 5 accuracy: 30.300\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.351 (avg: 0.345)\tLoss: 3.7601 (avg: 3.8486)\tTop1: 20.312 (avg: 14.562)\tTop5: 39.062 (avg: 37.875)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.338 (avg: 0.349)\tLoss: 4.1801 (avg: 3.8329)\tTop1: 9.375 (avg: 14.938)\tTop5: 34.375 (avg: 38.406)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.348 (avg: 0.350)\tLoss: 3.7383 (avg: 3.8556)\tTop1: 12.500 (avg: 14.875)\tTop5: 40.625 (avg: 37.604)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.344 (avg: 0.351)\tLoss: 3.6585 (avg: 3.8678)\tTop1: 15.625 (avg: 14.562)\tTop5: 34.375 (avg: 37.000)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.349 (avg: 0.351)\tLoss: 4.1559 (avg: 3.8786)\tTop1: 6.250 (avg: 14.375)\tTop5: 25.000 (avg: 36.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6491\tTop 1 accuracy: 10.300\tTop 5 accuracy: 30.200\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.353 (avg: 0.344)\tLoss: 3.9262 (avg: 3.8560)\tTop1: 9.375 (avg: 15.375)\tTop5: 29.688 (avg: 37.312)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.348 (avg: 0.349)\tLoss: 3.8285 (avg: 3.8622)\tTop1: 18.750 (avg: 14.281)\tTop5: 37.500 (avg: 36.625)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.343 (avg: 0.350)\tLoss: 4.0210 (avg: 3.8674)\tTop1: 10.938 (avg: 14.333)\tTop5: 31.250 (avg: 36.958)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.346 (avg: 0.351)\tLoss: 3.7929 (avg: 3.8654)\tTop1: 21.875 (avg: 14.422)\tTop5: 37.500 (avg: 36.938)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.351 (avg: 0.351)\tLoss: 3.9589 (avg: 3.8605)\tTop1: 14.062 (avg: 14.475)\tTop5: 34.375 (avg: 37.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8613\tTop 1 accuracy: 11.150\tTop 5 accuracy: 29.800\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.352 (avg: 0.345)\tLoss: 3.5239 (avg: 3.8165)\tTop1: 26.562 (avg: 15.125)\tTop5: 45.312 (avg: 38.312)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.342 (avg: 0.349)\tLoss: 3.6237 (avg: 3.7967)\tTop1: 15.625 (avg: 15.844)\tTop5: 40.625 (avg: 38.938)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.343 (avg: 0.350)\tLoss: 3.9043 (avg: 3.7942)\tTop1: 14.062 (avg: 15.667)\tTop5: 39.062 (avg: 39.167)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.345 (avg: 0.351)\tLoss: 3.6893 (avg: 3.7810)\tTop1: 26.562 (avg: 15.906)\tTop5: 40.625 (avg: 39.406)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.354 (avg: 0.351)\tLoss: 3.7136 (avg: 3.7736)\tTop1: 12.500 (avg: 16.000)\tTop5: 42.188 (avg: 39.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6200\tTop 1 accuracy: 11.700\tTop 5 accuracy: 30.700\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.351 (avg: 0.345)\tLoss: 3.4147 (avg: 3.7349)\tTop1: 20.312 (avg: 17.375)\tTop5: 48.438 (avg: 39.562)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.344 (avg: 0.349)\tLoss: 3.8365 (avg: 3.7297)\tTop1: 15.625 (avg: 16.094)\tTop5: 35.938 (avg: 39.938)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.342 (avg: 0.350)\tLoss: 3.7061 (avg: 3.7269)\tTop1: 17.188 (avg: 16.688)\tTop5: 40.625 (avg: 40.354)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.341 (avg: 0.351)\tLoss: 3.6608 (avg: 3.7537)\tTop1: 20.312 (avg: 16.562)\tTop5: 42.188 (avg: 39.719)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.349 (avg: 0.351)\tLoss: 4.1559 (avg: 3.7583)\tTop1: 10.938 (avg: 16.425)\tTop5: 37.500 (avg: 39.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6184\tTop 1 accuracy: 11.650\tTop 5 accuracy: 30.400\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.354 (avg: 0.345)\tLoss: 3.6959 (avg: 3.7564)\tTop1: 15.625 (avg: 16.750)\tTop5: 42.188 (avg: 39.812)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.344 (avg: 0.349)\tLoss: 3.6392 (avg: 3.7119)\tTop1: 10.938 (avg: 17.188)\tTop5: 43.750 (avg: 41.156)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.346 (avg: 0.350)\tLoss: 4.3000 (avg: 3.7304)\tTop1: 4.688 (avg: 16.875)\tTop5: 34.375 (avg: 40.625)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.340 (avg: 0.351)\tLoss: 3.4081 (avg: 3.7408)\tTop1: 23.438 (avg: 16.625)\tTop5: 50.000 (avg: 40.125)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.350 (avg: 0.351)\tLoss: 3.7913 (avg: 3.7439)\tTop1: 15.625 (avg: 16.550)\tTop5: 35.938 (avg: 40.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5837\tTop 1 accuracy: 11.800\tTop 5 accuracy: 31.000\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.350 (avg: 0.344)\tLoss: 3.7755 (avg: 3.7669)\tTop1: 18.750 (avg: 16.812)\tTop5: 37.500 (avg: 39.250)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.342 (avg: 0.348)\tLoss: 3.8646 (avg: 3.7668)\tTop1: 15.625 (avg: 16.625)\tTop5: 32.812 (avg: 39.125)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.339 (avg: 0.348)\tLoss: 3.7326 (avg: 3.7761)\tTop1: 17.188 (avg: 16.625)\tTop5: 39.062 (avg: 39.271)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.344 (avg: 0.349)\tLoss: 3.6743 (avg: 3.7475)\tTop1: 18.750 (avg: 16.812)\tTop5: 42.188 (avg: 39.922)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.355 (avg: 0.350)\tLoss: 3.9199 (avg: 3.7466)\tTop1: 15.625 (avg: 16.825)\tTop5: 42.188 (avg: 40.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6280\tTop 1 accuracy: 11.900\tTop 5 accuracy: 31.050\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.354 (avg: 0.345)\tLoss: 3.7914 (avg: 3.7051)\tTop1: 20.312 (avg: 17.500)\tTop5: 42.188 (avg: 41.375)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.341 (avg: 0.349)\tLoss: 4.1748 (avg: 3.7259)\tTop1: 9.375 (avg: 17.656)\tTop5: 23.438 (avg: 40.562)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.345 (avg: 0.350)\tLoss: 3.8198 (avg: 3.7329)\tTop1: 12.500 (avg: 17.271)\tTop5: 46.875 (avg: 40.333)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.345 (avg: 0.351)\tLoss: 3.8148 (avg: 3.7384)\tTop1: 18.750 (avg: 17.234)\tTop5: 42.188 (avg: 40.234)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.353 (avg: 0.352)\tLoss: 3.8166 (avg: 3.7393)\tTop1: 23.438 (avg: 17.138)\tTop5: 40.625 (avg: 40.325)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5603\tTop 1 accuracy: 11.450\tTop 5 accuracy: 30.900\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.353 (avg: 0.345)\tLoss: 3.7025 (avg: 3.7601)\tTop1: 15.625 (avg: 15.938)\tTop5: 42.188 (avg: 38.875)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.341 (avg: 0.349)\tLoss: 3.7061 (avg: 3.7238)\tTop1: 10.938 (avg: 16.719)\tTop5: 43.750 (avg: 40.000)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.344 (avg: 0.351)\tLoss: 3.6996 (avg: 3.7282)\tTop1: 12.500 (avg: 16.667)\tTop5: 40.625 (avg: 40.083)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.341 (avg: 0.351)\tLoss: 3.7567 (avg: 3.7370)\tTop1: 20.312 (avg: 16.781)\tTop5: 39.062 (avg: 40.562)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.353 (avg: 0.352)\tLoss: 4.0228 (avg: 3.7378)\tTop1: 6.250 (avg: 16.838)\tTop5: 32.812 (avg: 40.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6042\tTop 1 accuracy: 11.900\tTop 5 accuracy: 30.850\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.353 (avg: 0.345)\tLoss: 3.7818 (avg: 3.7512)\tTop1: 17.188 (avg: 17.188)\tTop5: 28.125 (avg: 39.625)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.341 (avg: 0.349)\tLoss: 3.7894 (avg: 3.7456)\tTop1: 14.062 (avg: 17.375)\tTop5: 34.375 (avg: 39.625)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.347 (avg: 0.350)\tLoss: 3.4799 (avg: 3.7255)\tTop1: 12.500 (avg: 17.562)\tTop5: 50.000 (avg: 40.729)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.348 (avg: 0.351)\tLoss: 3.6165 (avg: 3.7423)\tTop1: 14.062 (avg: 16.922)\tTop5: 40.625 (avg: 40.234)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.347 (avg: 0.352)\tLoss: 3.7961 (avg: 3.7343)\tTop1: 15.625 (avg: 16.975)\tTop5: 40.625 (avg: 40.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6364\tTop 1 accuracy: 12.050\tTop 5 accuracy: 31.100\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.352 (avg: 0.345)\tLoss: 3.7338 (avg: 3.6749)\tTop1: 18.750 (avg: 17.438)\tTop5: 35.938 (avg: 41.312)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.337 (avg: 0.349)\tLoss: 3.5685 (avg: 3.7053)\tTop1: 15.625 (avg: 17.188)\tTop5: 43.750 (avg: 40.531)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.346 (avg: 0.349)\tLoss: 3.6496 (avg: 3.7134)\tTop1: 14.062 (avg: 17.250)\tTop5: 42.188 (avg: 40.875)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.341 (avg: 0.350)\tLoss: 3.9099 (avg: 3.7196)\tTop1: 6.250 (avg: 17.375)\tTop5: 31.250 (avg: 40.562)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.363 (avg: 0.350)\tLoss: 3.5226 (avg: 3.7285)\tTop1: 18.750 (avg: 17.413)\tTop5: 46.875 (avg: 40.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6339\tTop 1 accuracy: 11.900\tTop 5 accuracy: 30.800\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.355 (avg: 0.345)\tLoss: 3.6054 (avg: 3.6861)\tTop1: 23.438 (avg: 18.938)\tTop5: 48.438 (avg: 42.250)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.341 (avg: 0.349)\tLoss: 3.6712 (avg: 3.6974)\tTop1: 14.062 (avg: 18.219)\tTop5: 40.625 (avg: 41.531)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.347 (avg: 0.350)\tLoss: 3.5040 (avg: 3.7096)\tTop1: 23.438 (avg: 17.750)\tTop5: 50.000 (avg: 41.104)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.342 (avg: 0.351)\tLoss: 3.6619 (avg: 3.7320)\tTop1: 18.750 (avg: 17.375)\tTop5: 40.625 (avg: 40.422)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.355 (avg: 0.352)\tLoss: 3.5955 (avg: 3.7302)\tTop1: 21.875 (avg: 17.450)\tTop5: 39.062 (avg: 40.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6043\tTop 1 accuracy: 11.800\tTop 5 accuracy: 31.450\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.352 (avg: 0.345)\tLoss: 3.3807 (avg: 3.6837)\tTop1: 10.938 (avg: 17.250)\tTop5: 46.875 (avg: 41.625)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.340 (avg: 0.347)\tLoss: 3.7061 (avg: 3.7251)\tTop1: 14.062 (avg: 16.844)\tTop5: 48.438 (avg: 40.500)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.343 (avg: 0.349)\tLoss: 3.8908 (avg: 3.7197)\tTop1: 20.312 (avg: 17.500)\tTop5: 39.062 (avg: 41.021)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.345 (avg: 0.350)\tLoss: 3.7038 (avg: 3.7259)\tTop1: 15.625 (avg: 17.141)\tTop5: 46.875 (avg: 40.922)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.355 (avg: 0.351)\tLoss: 3.7512 (avg: 3.7288)\tTop1: 14.062 (avg: 17.088)\tTop5: 35.938 (avg: 40.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5904\tTop 1 accuracy: 11.900\tTop 5 accuracy: 31.550\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.354 (avg: 0.344)\tLoss: 3.5056 (avg: 3.7332)\tTop1: 25.000 (avg: 17.062)\tTop5: 43.750 (avg: 40.125)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.342 (avg: 0.349)\tLoss: 3.5540 (avg: 3.7318)\tTop1: 15.625 (avg: 17.062)\tTop5: 48.438 (avg: 40.281)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.350 (avg: 0.350)\tLoss: 3.7277 (avg: 3.7342)\tTop1: 14.062 (avg: 16.958)\tTop5: 34.375 (avg: 40.354)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.343 (avg: 0.351)\tLoss: 3.7233 (avg: 3.7260)\tTop1: 23.438 (avg: 17.219)\tTop5: 42.188 (avg: 40.672)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.356 (avg: 0.352)\tLoss: 3.7212 (avg: 3.7263)\tTop1: 20.312 (avg: 17.150)\tTop5: 39.062 (avg: 40.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6166\tTop 1 accuracy: 11.600\tTop 5 accuracy: 31.400\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.358 (avg: 0.345)\tLoss: 3.5091 (avg: 3.6749)\tTop1: 20.312 (avg: 16.812)\tTop5: 45.312 (avg: 42.312)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.340 (avg: 0.349)\tLoss: 3.8002 (avg: 3.6987)\tTop1: 10.938 (avg: 17.719)\tTop5: 35.938 (avg: 42.062)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.347 (avg: 0.351)\tLoss: 3.4523 (avg: 3.7044)\tTop1: 23.438 (avg: 17.312)\tTop5: 51.562 (avg: 41.438)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.345 (avg: 0.351)\tLoss: 3.6982 (avg: 3.7226)\tTop1: 21.875 (avg: 17.047)\tTop5: 42.188 (avg: 40.938)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.354 (avg: 0.352)\tLoss: 3.4527 (avg: 3.7242)\tTop1: 17.188 (avg: 16.750)\tTop5: 46.875 (avg: 40.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5530\tTop 1 accuracy: 11.900\tTop 5 accuracy: 31.850\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.347 (avg: 0.344)\tLoss: 3.8538 (avg: 3.7330)\tTop1: 17.188 (avg: 17.938)\tTop5: 34.375 (avg: 39.375)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.339 (avg: 0.348)\tLoss: 3.4928 (avg: 3.7426)\tTop1: 23.438 (avg: 16.844)\tTop5: 37.500 (avg: 40.125)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.344 (avg: 0.350)\tLoss: 3.5756 (avg: 3.7284)\tTop1: 12.500 (avg: 17.042)\tTop5: 46.875 (avg: 40.312)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.343 (avg: 0.351)\tLoss: 3.5078 (avg: 3.7227)\tTop1: 20.312 (avg: 16.828)\tTop5: 45.312 (avg: 40.562)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.350 (avg: 0.351)\tLoss: 3.5039 (avg: 3.7207)\tTop1: 21.875 (avg: 16.938)\tTop5: 51.562 (avg: 40.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6372\tTop 1 accuracy: 11.750\tTop 5 accuracy: 31.250\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.348 (avg: 0.342)\tLoss: 3.8212 (avg: 3.7227)\tTop1: 10.938 (avg: 17.062)\tTop5: 43.750 (avg: 40.312)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.342 (avg: 0.347)\tLoss: 3.7315 (avg: 3.6974)\tTop1: 25.000 (avg: 17.625)\tTop5: 42.188 (avg: 41.250)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.346 (avg: 0.350)\tLoss: 3.5413 (avg: 3.7118)\tTop1: 18.750 (avg: 17.750)\tTop5: 35.938 (avg: 40.708)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.347 (avg: 0.350)\tLoss: 3.7200 (avg: 3.7117)\tTop1: 17.188 (avg: 17.641)\tTop5: 35.938 (avg: 40.766)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.356 (avg: 0.351)\tLoss: 3.8370 (avg: 3.7202)\tTop1: 21.875 (avg: 17.413)\tTop5: 42.188 (avg: 40.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5714\tTop 1 accuracy: 11.950\tTop 5 accuracy: 31.500\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.351 (avg: 0.344)\tLoss: 3.7976 (avg: 3.7588)\tTop1: 12.500 (avg: 17.250)\tTop5: 34.375 (avg: 40.438)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.342 (avg: 0.348)\tLoss: 3.6371 (avg: 3.7176)\tTop1: 18.750 (avg: 16.594)\tTop5: 43.750 (avg: 40.781)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.345 (avg: 0.350)\tLoss: 3.3681 (avg: 3.7158)\tTop1: 17.188 (avg: 16.479)\tTop5: 45.312 (avg: 40.354)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.344 (avg: 0.351)\tLoss: 3.5631 (avg: 3.7246)\tTop1: 17.188 (avg: 16.750)\tTop5: 35.938 (avg: 40.297)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.349 (avg: 0.351)\tLoss: 3.6034 (avg: 3.7187)\tTop1: 14.062 (avg: 17.388)\tTop5: 43.750 (avg: 40.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6233\tTop 1 accuracy: 11.750\tTop 5 accuracy: 31.200\n",
            "\n",
            "pct_3x3 = 0.125: top1 = 11.90000057220459 \t top5 = 31.85000228881836 \t batch time = 0.2848074659705162\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.351 (avg: 0.423)\tLoss: 5.2953 (avg: 5.3094)\tTop1: 0.000 (avg: 0.562)\tTop5: 3.125 (avg: 2.312)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.359 (avg: 0.393)\tLoss: 5.2965 (avg: 5.3036)\tTop1: 0.000 (avg: 0.469)\tTop5: 3.125 (avg: 2.531)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.363 (avg: 0.383)\tLoss: 5.2947 (avg: 5.3024)\tTop1: 0.000 (avg: 0.458)\tTop5: 3.125 (avg: 2.354)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.353 (avg: 0.379)\tLoss: 5.2965 (avg: 5.3013)\tTop1: 0.000 (avg: 0.484)\tTop5: 3.125 (avg: 2.375)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.355 (avg: 0.376)\tLoss: 5.2988 (avg: 5.3006)\tTop1: 0.000 (avg: 0.438)\tTop5: 0.000 (avg: 2.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3004\tTop 1 accuracy: 0.400\tTop 5 accuracy: 2.550\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.366 (avg: 0.356)\tLoss: 5.2613 (avg: 5.2922)\tTop1: 3.125 (avg: 0.375)\tTop5: 4.688 (avg: 3.062)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 5.2740 (avg: 5.2887)\tTop1: 0.000 (avg: 0.531)\tTop5: 0.000 (avg: 3.156)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 5.2595 (avg: 5.2869)\tTop1: 3.125 (avg: 0.604)\tTop5: 4.688 (avg: 3.250)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.349 (avg: 0.362)\tLoss: 5.3219 (avg: 5.2850)\tTop1: 0.000 (avg: 0.719)\tTop5: 0.000 (avg: 3.266)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 5.2522 (avg: 5.2833)\tTop1: 3.125 (avg: 0.688)\tTop5: 7.812 (avg: 3.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2359\tTop 1 accuracy: 0.900\tTop 5 accuracy: 4.050\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.363 (avg: 0.355)\tLoss: 5.2626 (avg: 5.2738)\tTop1: 3.125 (avg: 0.875)\tTop5: 4.688 (avg: 3.438)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 5.2670 (avg: 5.2668)\tTop1: 0.000 (avg: 1.031)\tTop5: 7.812 (avg: 4.094)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 5.1786 (avg: 5.2590)\tTop1: 1.562 (avg: 1.000)\tTop5: 6.250 (avg: 4.125)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 5.2566 (avg: 5.2515)\tTop1: 0.000 (avg: 1.094)\tTop5: 1.562 (avg: 4.188)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.365 (avg: 0.362)\tLoss: 5.2950 (avg: 5.2440)\tTop1: 0.000 (avg: 1.138)\tTop5: 3.125 (avg: 4.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1703\tTop 1 accuracy: 1.050\tTop 5 accuracy: 5.300\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.362 (avg: 0.356)\tLoss: 5.3260 (avg: 5.2115)\tTop1: 0.000 (avg: 1.000)\tTop5: 6.250 (avg: 5.188)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.352 (avg: 0.360)\tLoss: 5.2104 (avg: 5.2143)\tTop1: 1.562 (avg: 0.969)\tTop5: 4.688 (avg: 5.250)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 5.3016 (avg: 5.2192)\tTop1: 0.000 (avg: 0.979)\tTop5: 3.125 (avg: 5.146)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 5.0660 (avg: 5.2155)\tTop1: 3.125 (avg: 0.969)\tTop5: 18.750 (avg: 5.375)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 5.2606 (avg: 5.2110)\tTop1: 0.000 (avg: 1.025)\tTop5: 3.125 (avg: 5.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0233\tTop 1 accuracy: 1.350\tTop 5 accuracy: 5.600\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.360 (avg: 0.354)\tLoss: 5.0871 (avg: 5.1893)\tTop1: 1.562 (avg: 1.500)\tTop5: 6.250 (avg: 6.438)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.357 (avg: 0.359)\tLoss: 5.2787 (avg: 5.1903)\tTop1: 1.562 (avg: 1.281)\tTop5: 6.250 (avg: 6.281)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.353 (avg: 0.360)\tLoss: 5.1921 (avg: 5.1952)\tTop1: 1.562 (avg: 1.438)\tTop5: 4.688 (avg: 6.438)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 4.9695 (avg: 5.1873)\tTop1: 6.250 (avg: 1.562)\tTop5: 9.375 (avg: 6.562)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.366 (avg: 0.361)\tLoss: 5.1286 (avg: 5.1790)\tTop1: 0.000 (avg: 1.588)\tTop5: 6.250 (avg: 6.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0472\tTop 1 accuracy: 2.550\tTop 5 accuracy: 7.750\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.364 (avg: 0.355)\tLoss: 5.1066 (avg: 5.1270)\tTop1: 3.125 (avg: 1.500)\tTop5: 7.812 (avg: 7.188)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.345 (avg: 0.359)\tLoss: 5.1720 (avg: 5.1388)\tTop1: 3.125 (avg: 1.500)\tTop5: 7.812 (avg: 7.281)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 5.1282 (avg: 5.1444)\tTop1: 1.562 (avg: 1.458)\tTop5: 7.812 (avg: 7.250)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 5.1846 (avg: 5.1550)\tTop1: 1.562 (avg: 1.297)\tTop5: 3.125 (avg: 6.703)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.353 (avg: 0.361)\tLoss: 5.2572 (avg: 5.1550)\tTop1: 3.125 (avg: 1.388)\tTop5: 9.375 (avg: 6.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1254\tTop 1 accuracy: 1.800\tTop 5 accuracy: 7.000\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.362 (avg: 0.351)\tLoss: 5.1101 (avg: 5.1231)\tTop1: 1.562 (avg: 1.812)\tTop5: 10.938 (avg: 7.875)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.354 (avg: 0.358)\tLoss: 5.0773 (avg: 5.1136)\tTop1: 3.125 (avg: 1.875)\tTop5: 10.938 (avg: 7.844)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.363 (avg: 0.360)\tLoss: 5.1829 (avg: 5.1319)\tTop1: 0.000 (avg: 1.812)\tTop5: 6.250 (avg: 7.562)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 5.0600 (avg: 5.1266)\tTop1: 0.000 (avg: 1.781)\tTop5: 9.375 (avg: 7.703)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.363 (avg: 0.361)\tLoss: 5.0085 (avg: 5.1287)\tTop1: 3.125 (avg: 1.738)\tTop5: 9.375 (avg: 7.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0921\tTop 1 accuracy: 1.400\tTop 5 accuracy: 6.750\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.360 (avg: 0.354)\tLoss: 5.1642 (avg: 5.1035)\tTop1: 3.125 (avg: 1.688)\tTop5: 9.375 (avg: 7.812)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 5.1106 (avg: 5.1031)\tTop1: 0.000 (avg: 1.531)\tTop5: 4.688 (avg: 7.375)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.359 (avg: 0.360)\tLoss: 5.0424 (avg: 5.1011)\tTop1: 3.125 (avg: 1.708)\tTop5: 7.812 (avg: 7.604)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 4.9708 (avg: 5.1048)\tTop1: 3.125 (avg: 1.688)\tTop5: 12.500 (avg: 7.578)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 5.1132 (avg: 5.0970)\tTop1: 4.688 (avg: 1.850)\tTop5: 12.500 (avg: 7.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9301\tTop 1 accuracy: 1.650\tTop 5 accuracy: 8.250\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.357 (avg: 0.355)\tLoss: 5.0371 (avg: 5.0884)\tTop1: 0.000 (avg: 1.812)\tTop5: 10.938 (avg: 7.375)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 5.1524 (avg: 5.0817)\tTop1: 0.000 (avg: 2.031)\tTop5: 4.688 (avg: 7.906)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 4.9919 (avg: 5.0672)\tTop1: 1.562 (avg: 2.062)\tTop5: 7.812 (avg: 8.312)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.363 (avg: 0.362)\tLoss: 5.0168 (avg: 5.0637)\tTop1: 4.688 (avg: 2.219)\tTop5: 10.938 (avg: 8.281)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.364 (avg: 0.362)\tLoss: 5.0564 (avg: 5.0590)\tTop1: 0.000 (avg: 2.163)\tTop5: 3.125 (avg: 8.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0377\tTop 1 accuracy: 2.250\tTop 5 accuracy: 10.200\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.367 (avg: 0.357)\tLoss: 5.0337 (avg: 5.0331)\tTop1: 6.250 (avg: 2.375)\tTop5: 7.812 (avg: 9.500)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.346 (avg: 0.359)\tLoss: 4.9911 (avg: 5.0246)\tTop1: 3.125 (avg: 2.656)\tTop5: 14.062 (avg: 9.406)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.358 (avg: 0.360)\tLoss: 5.0146 (avg: 5.0181)\tTop1: 3.125 (avg: 2.396)\tTop5: 6.250 (avg: 9.479)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.9488 (avg: 5.0156)\tTop1: 6.250 (avg: 2.656)\tTop5: 10.938 (avg: 9.578)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.365 (avg: 0.362)\tLoss: 5.0860 (avg: 5.0200)\tTop1: 0.000 (avg: 2.525)\tTop5: 3.125 (avg: 9.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0330\tTop 1 accuracy: 2.200\tTop 5 accuracy: 9.200\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.358 (avg: 0.355)\tLoss: 4.9072 (avg: 4.9728)\tTop1: 3.125 (avg: 2.812)\tTop5: 10.938 (avg: 10.938)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 5.0367 (avg: 4.9786)\tTop1: 4.688 (avg: 2.688)\tTop5: 7.812 (avg: 10.656)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.350 (avg: 0.361)\tLoss: 5.0305 (avg: 4.9857)\tTop1: 0.000 (avg: 2.542)\tTop5: 12.500 (avg: 10.479)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.359 (avg: 0.361)\tLoss: 4.9197 (avg: 4.9862)\tTop1: 4.688 (avg: 2.500)\tTop5: 10.938 (avg: 10.359)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 4.7549 (avg: 4.9776)\tTop1: 4.688 (avg: 2.600)\tTop5: 12.500 (avg: 10.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8068\tTop 1 accuracy: 2.750\tTop 5 accuracy: 10.850\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.364 (avg: 0.355)\tLoss: 4.9386 (avg: 4.9322)\tTop1: 3.125 (avg: 2.938)\tTop5: 17.188 (avg: 11.438)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 4.9646 (avg: 4.9288)\tTop1: 1.562 (avg: 2.875)\tTop5: 10.938 (avg: 11.656)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.350 (avg: 0.360)\tLoss: 4.7551 (avg: 4.9250)\tTop1: 3.125 (avg: 3.104)\tTop5: 17.188 (avg: 11.958)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 4.9424 (avg: 4.9421)\tTop1: 1.562 (avg: 3.016)\tTop5: 7.812 (avg: 11.641)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.359 (avg: 0.361)\tLoss: 4.9008 (avg: 4.9497)\tTop1: 1.562 (avg: 2.875)\tTop5: 9.375 (avg: 11.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8809\tTop 1 accuracy: 2.450\tTop 5 accuracy: 10.550\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.362 (avg: 0.355)\tLoss: 4.9275 (avg: 4.8634)\tTop1: 3.125 (avg: 3.375)\tTop5: 10.938 (avg: 13.500)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 4.9123 (avg: 4.8976)\tTop1: 1.562 (avg: 2.938)\tTop5: 6.250 (avg: 12.688)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 4.8825 (avg: 4.9038)\tTop1: 4.688 (avg: 3.188)\tTop5: 12.500 (avg: 12.458)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 4.9002 (avg: 4.9037)\tTop1: 3.125 (avg: 3.172)\tTop5: 9.375 (avg: 12.219)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.363 (avg: 0.362)\tLoss: 4.9596 (avg: 4.9063)\tTop1: 1.562 (avg: 3.200)\tTop5: 10.938 (avg: 12.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8132\tTop 1 accuracy: 3.150\tTop 5 accuracy: 12.250\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.366 (avg: 0.355)\tLoss: 4.8901 (avg: 4.8599)\tTop1: 3.125 (avg: 3.562)\tTop5: 15.625 (avg: 14.312)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.352 (avg: 0.360)\tLoss: 4.9558 (avg: 4.8594)\tTop1: 3.125 (avg: 3.406)\tTop5: 7.812 (avg: 13.375)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.353 (avg: 0.361)\tLoss: 5.0772 (avg: 4.8723)\tTop1: 1.562 (avg: 3.312)\tTop5: 6.250 (avg: 13.292)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.361 (avg: 0.362)\tLoss: 4.9222 (avg: 4.8731)\tTop1: 4.688 (avg: 3.422)\tTop5: 12.500 (avg: 13.094)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 4.7355 (avg: 4.8733)\tTop1: 6.250 (avg: 3.375)\tTop5: 12.500 (avg: 12.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5226\tTop 1 accuracy: 3.550\tTop 5 accuracy: 13.550\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.357 (avg: 0.355)\tLoss: 4.9235 (avg: 4.8387)\tTop1: 4.688 (avg: 3.938)\tTop5: 20.312 (avg: 14.312)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 4.7837 (avg: 4.8141)\tTop1: 3.125 (avg: 3.719)\tTop5: 10.938 (avg: 13.906)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.360 (avg: 0.361)\tLoss: 4.8928 (avg: 4.8067)\tTop1: 3.125 (avg: 3.688)\tTop5: 10.938 (avg: 13.958)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 4.7962 (avg: 4.8084)\tTop1: 1.562 (avg: 3.609)\tTop5: 15.625 (avg: 14.172)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.365 (avg: 0.363)\tLoss: 4.8480 (avg: 4.8157)\tTop1: 1.562 (avg: 3.450)\tTop5: 14.062 (avg: 13.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7448\tTop 1 accuracy: 4.700\tTop 5 accuracy: 13.950\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.360 (avg: 0.356)\tLoss: 4.6911 (avg: 4.7744)\tTop1: 7.812 (avg: 3.875)\tTop5: 18.750 (avg: 14.188)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 4.6901 (avg: 4.7712)\tTop1: 4.688 (avg: 3.844)\tTop5: 18.750 (avg: 14.688)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 4.7581 (avg: 4.7848)\tTop1: 7.812 (avg: 3.917)\tTop5: 17.188 (avg: 14.167)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 4.9350 (avg: 4.7825)\tTop1: 1.562 (avg: 4.062)\tTop5: 10.938 (avg: 14.234)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 4.7809 (avg: 4.7822)\tTop1: 3.125 (avg: 3.875)\tTop5: 9.375 (avg: 14.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5655\tTop 1 accuracy: 4.500\tTop 5 accuracy: 17.600\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.357 (avg: 0.356)\tLoss: 4.8070 (avg: 4.7124)\tTop1: 0.000 (avg: 4.125)\tTop5: 12.500 (avg: 16.125)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 4.7408 (avg: 4.7095)\tTop1: 3.125 (avg: 3.969)\tTop5: 14.062 (avg: 16.188)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 4.7108 (avg: 4.7241)\tTop1: 6.250 (avg: 4.021)\tTop5: 14.062 (avg: 15.958)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.366 (avg: 0.362)\tLoss: 4.9045 (avg: 4.7378)\tTop1: 1.562 (avg: 3.969)\tTop5: 10.938 (avg: 15.453)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.370 (avg: 0.363)\tLoss: 4.7927 (avg: 4.7548)\tTop1: 0.000 (avg: 3.700)\tTop5: 10.938 (avg: 14.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7360\tTop 1 accuracy: 2.850\tTop 5 accuracy: 14.700\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.358 (avg: 0.352)\tLoss: 4.5968 (avg: 4.6843)\tTop1: 1.562 (avg: 4.625)\tTop5: 12.500 (avg: 16.250)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.352 (avg: 0.357)\tLoss: 4.7660 (avg: 4.6849)\tTop1: 1.562 (avg: 4.781)\tTop5: 9.375 (avg: 16.250)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.352 (avg: 0.359)\tLoss: 4.8878 (avg: 4.6850)\tTop1: 3.125 (avg: 4.688)\tTop5: 7.812 (avg: 16.750)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.359 (avg: 0.360)\tLoss: 4.7366 (avg: 4.6768)\tTop1: 3.125 (avg: 4.750)\tTop5: 7.812 (avg: 16.516)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.365 (avg: 0.361)\tLoss: 4.5223 (avg: 4.6778)\tTop1: 4.688 (avg: 4.850)\tTop5: 21.875 (avg: 16.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5683\tTop 1 accuracy: 4.400\tTop 5 accuracy: 15.750\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.360 (avg: 0.355)\tLoss: 4.4024 (avg: 4.5985)\tTop1: 7.812 (avg: 5.375)\tTop5: 23.438 (avg: 18.375)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 4.3841 (avg: 4.6316)\tTop1: 7.812 (avg: 4.906)\tTop5: 20.312 (avg: 17.062)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.354 (avg: 0.362)\tLoss: 4.5079 (avg: 4.6231)\tTop1: 7.812 (avg: 4.938)\tTop5: 17.188 (avg: 16.979)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 4.6803 (avg: 4.6274)\tTop1: 6.250 (avg: 5.047)\tTop5: 21.875 (avg: 17.203)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 4.6741 (avg: 4.6405)\tTop1: 0.000 (avg: 4.963)\tTop5: 25.000 (avg: 16.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5008\tTop 1 accuracy: 4.750\tTop 5 accuracy: 16.450\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.363 (avg: 0.356)\tLoss: 4.7362 (avg: 4.5874)\tTop1: 4.688 (avg: 5.562)\tTop5: 15.625 (avg: 19.750)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.352 (avg: 0.360)\tLoss: 4.6726 (avg: 4.6017)\tTop1: 1.562 (avg: 5.062)\tTop5: 18.750 (avg: 18.562)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 4.5567 (avg: 4.5924)\tTop1: 9.375 (avg: 5.333)\tTop5: 23.438 (avg: 18.771)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 4.5417 (avg: 4.6007)\tTop1: 6.250 (avg: 5.141)\tTop5: 17.188 (avg: 18.750)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.360 (avg: 0.363)\tLoss: 4.5621 (avg: 4.6000)\tTop1: 6.250 (avg: 5.138)\tTop5: 17.188 (avg: 18.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7215\tTop 1 accuracy: 4.650\tTop 5 accuracy: 16.500\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.360 (avg: 0.355)\tLoss: 4.5808 (avg: 4.5546)\tTop1: 4.688 (avg: 5.438)\tTop5: 18.750 (avg: 18.438)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.358 (avg: 0.359)\tLoss: 4.5259 (avg: 4.5884)\tTop1: 7.812 (avg: 5.156)\tTop5: 23.438 (avg: 18.188)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.351 (avg: 0.360)\tLoss: 4.6276 (avg: 4.5812)\tTop1: 6.250 (avg: 5.417)\tTop5: 15.625 (avg: 18.792)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 4.0806 (avg: 4.5729)\tTop1: 7.812 (avg: 5.516)\tTop5: 26.562 (avg: 19.047)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.363 (avg: 0.362)\tLoss: 4.7071 (avg: 4.5748)\tTop1: 4.688 (avg: 5.575)\tTop5: 18.750 (avg: 18.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0183\tTop 1 accuracy: 5.750\tTop 5 accuracy: 18.350\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.359 (avg: 0.354)\tLoss: 4.4853 (avg: 4.4638)\tTop1: 6.250 (avg: 6.875)\tTop5: 17.188 (avg: 21.375)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.352 (avg: 0.359)\tLoss: 4.6372 (avg: 4.5239)\tTop1: 3.125 (avg: 5.844)\tTop5: 15.625 (avg: 19.344)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.360 (avg: 0.361)\tLoss: 4.2472 (avg: 4.5080)\tTop1: 6.250 (avg: 5.979)\tTop5: 25.000 (avg: 19.979)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 4.4972 (avg: 4.5113)\tTop1: 4.688 (avg: 5.781)\tTop5: 15.625 (avg: 19.938)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 4.5195 (avg: 4.5355)\tTop1: 6.250 (avg: 5.525)\tTop5: 18.750 (avg: 19.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2998\tTop 1 accuracy: 5.800\tTop 5 accuracy: 20.200\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.360 (avg: 0.355)\tLoss: 4.7543 (avg: 4.4792)\tTop1: 3.125 (avg: 6.875)\tTop5: 7.812 (avg: 21.438)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 4.5944 (avg: 4.4766)\tTop1: 6.250 (avg: 6.531)\tTop5: 21.875 (avg: 20.656)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 4.3500 (avg: 4.4988)\tTop1: 6.250 (avg: 6.042)\tTop5: 20.312 (avg: 20.146)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 4.6328 (avg: 4.4970)\tTop1: 3.125 (avg: 6.266)\tTop5: 15.625 (avg: 20.547)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.361 (avg: 0.362)\tLoss: 4.5956 (avg: 4.4983)\tTop1: 1.562 (avg: 6.075)\tTop5: 14.062 (avg: 20.813)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2725\tTop 1 accuracy: 5.900\tTop 5 accuracy: 20.600\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.366 (avg: 0.356)\tLoss: 4.5754 (avg: 4.4056)\tTop1: 4.688 (avg: 7.312)\tTop5: 17.188 (avg: 22.875)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.351 (avg: 0.360)\tLoss: 4.3795 (avg: 4.3957)\tTop1: 7.812 (avg: 7.062)\tTop5: 25.000 (avg: 23.156)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 4.6119 (avg: 4.3972)\tTop1: 7.812 (avg: 7.062)\tTop5: 25.000 (avg: 23.292)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.354 (avg: 0.362)\tLoss: 4.4899 (avg: 4.4069)\tTop1: 10.938 (avg: 7.141)\tTop5: 25.000 (avg: 23.156)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 4.3453 (avg: 4.4236)\tTop1: 10.938 (avg: 7.250)\tTop5: 29.688 (avg: 23.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2711\tTop 1 accuracy: 5.750\tTop 5 accuracy: 20.400\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.362 (avg: 0.355)\tLoss: 4.5328 (avg: 4.4140)\tTop1: 7.812 (avg: 8.250)\tTop5: 17.188 (avg: 22.250)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 4.3818 (avg: 4.3924)\tTop1: 6.250 (avg: 7.719)\tTop5: 28.125 (avg: 22.906)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 4.4286 (avg: 4.4207)\tTop1: 3.125 (avg: 7.208)\tTop5: 21.875 (avg: 22.188)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 4.2085 (avg: 4.4172)\tTop1: 15.625 (avg: 7.375)\tTop5: 37.500 (avg: 22.656)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 4.3040 (avg: 4.4285)\tTop1: 6.250 (avg: 7.150)\tTop5: 28.125 (avg: 22.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6217\tTop 1 accuracy: 6.250\tTop 5 accuracy: 21.100\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.361 (avg: 0.355)\tLoss: 4.3078 (avg: 4.3292)\tTop1: 9.375 (avg: 7.375)\tTop5: 26.562 (avg: 24.438)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 4.4450 (avg: 4.3943)\tTop1: 1.562 (avg: 7.125)\tTop5: 12.500 (avg: 22.062)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.360 (avg: 0.361)\tLoss: 4.4032 (avg: 4.3927)\tTop1: 3.125 (avg: 7.125)\tTop5: 17.188 (avg: 22.167)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 4.4023 (avg: 4.3961)\tTop1: 6.250 (avg: 6.953)\tTop5: 20.312 (avg: 22.266)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 4.5077 (avg: 4.4056)\tTop1: 6.250 (avg: 6.925)\tTop5: 29.688 (avg: 22.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4018\tTop 1 accuracy: 5.450\tTop 5 accuracy: 21.100\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.359 (avg: 0.352)\tLoss: 4.5339 (avg: 4.3399)\tTop1: 1.562 (avg: 7.750)\tTop5: 17.188 (avg: 25.562)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.356 (avg: 0.358)\tLoss: 4.3943 (avg: 4.3553)\tTop1: 6.250 (avg: 7.656)\tTop5: 21.875 (avg: 24.969)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 4.4048 (avg: 4.3388)\tTop1: 4.688 (avg: 7.729)\tTop5: 29.688 (avg: 25.229)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 4.4703 (avg: 4.3511)\tTop1: 1.562 (avg: 7.812)\tTop5: 18.750 (avg: 24.781)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.367 (avg: 0.362)\tLoss: 4.2427 (avg: 4.3498)\tTop1: 9.375 (avg: 7.825)\tTop5: 25.000 (avg: 24.813)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3622\tTop 1 accuracy: 7.100\tTop 5 accuracy: 23.450\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.363 (avg: 0.355)\tLoss: 4.3034 (avg: 4.2018)\tTop1: 4.688 (avg: 9.438)\tTop5: 23.438 (avg: 28.312)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 4.1988 (avg: 4.2505)\tTop1: 7.812 (avg: 9.094)\tTop5: 31.250 (avg: 27.000)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.4083 (avg: 4.2725)\tTop1: 7.812 (avg: 8.979)\tTop5: 25.000 (avg: 26.271)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 4.1924 (avg: 4.2949)\tTop1: 9.375 (avg: 8.688)\tTop5: 29.688 (avg: 25.594)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.363 (avg: 0.362)\tLoss: 4.3895 (avg: 4.3037)\tTop1: 6.250 (avg: 8.600)\tTop5: 23.438 (avg: 25.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1960\tTop 1 accuracy: 6.600\tTop 5 accuracy: 22.650\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.359 (avg: 0.354)\tLoss: 4.4171 (avg: 4.2848)\tTop1: 7.812 (avg: 8.500)\tTop5: 18.750 (avg: 25.500)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.356 (avg: 0.358)\tLoss: 4.3333 (avg: 4.2719)\tTop1: 6.250 (avg: 8.750)\tTop5: 31.250 (avg: 26.938)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 4.3909 (avg: 4.2767)\tTop1: 7.812 (avg: 8.458)\tTop5: 29.688 (avg: 26.875)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.362 (avg: 0.360)\tLoss: 4.2614 (avg: 4.2950)\tTop1: 7.812 (avg: 8.172)\tTop5: 28.125 (avg: 26.172)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.365 (avg: 0.361)\tLoss: 4.4182 (avg: 4.2907)\tTop1: 3.125 (avg: 8.088)\tTop5: 20.312 (avg: 25.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4186\tTop 1 accuracy: 7.350\tTop 5 accuracy: 22.400\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.362 (avg: 0.355)\tLoss: 4.2587 (avg: 4.2524)\tTop1: 7.812 (avg: 8.625)\tTop5: 26.562 (avg: 26.750)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.352 (avg: 0.359)\tLoss: 4.0587 (avg: 4.2432)\tTop1: 12.500 (avg: 8.719)\tTop5: 34.375 (avg: 26.875)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.5842 (avg: 4.2555)\tTop1: 6.250 (avg: 8.896)\tTop5: 17.188 (avg: 27.062)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 4.3208 (avg: 4.2609)\tTop1: 10.938 (avg: 8.688)\tTop5: 28.125 (avg: 26.812)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.364 (avg: 0.362)\tLoss: 4.5382 (avg: 4.2681)\tTop1: 6.250 (avg: 8.725)\tTop5: 28.125 (avg: 26.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1948\tTop 1 accuracy: 7.300\tTop 5 accuracy: 24.300\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.361 (avg: 0.355)\tLoss: 4.0733 (avg: 4.0798)\tTop1: 9.375 (avg: 11.812)\tTop5: 32.812 (avg: 30.938)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.358 (avg: 0.360)\tLoss: 4.3749 (avg: 4.0570)\tTop1: 3.125 (avg: 11.656)\tTop5: 29.688 (avg: 31.625)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 4.0339 (avg: 4.0212)\tTop1: 17.188 (avg: 12.021)\tTop5: 39.062 (avg: 32.917)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 4.6371 (avg: 4.0152)\tTop1: 9.375 (avg: 12.359)\tTop5: 14.062 (avg: 33.188)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.364 (avg: 0.363)\tLoss: 3.6739 (avg: 4.0000)\tTop1: 15.625 (avg: 12.713)\tTop5: 42.188 (avg: 33.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1298\tTop 1 accuracy: 10.250\tTop 5 accuracy: 27.950\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.362 (avg: 0.356)\tLoss: 3.8427 (avg: 3.9313)\tTop1: 12.500 (avg: 13.812)\tTop5: 40.625 (avg: 36.438)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.352 (avg: 0.360)\tLoss: 3.9523 (avg: 3.9387)\tTop1: 10.938 (avg: 13.812)\tTop5: 34.375 (avg: 35.875)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 3.6385 (avg: 3.9324)\tTop1: 17.188 (avg: 13.729)\tTop5: 34.375 (avg: 35.854)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.351 (avg: 0.362)\tLoss: 3.8611 (avg: 3.9194)\tTop1: 17.188 (avg: 14.203)\tTop5: 37.500 (avg: 36.453)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.363 (avg: 0.362)\tLoss: 4.0047 (avg: 3.9273)\tTop1: 15.625 (avg: 14.138)\tTop5: 32.812 (avg: 36.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9775\tTop 1 accuracy: 10.150\tTop 5 accuracy: 28.400\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.360 (avg: 0.356)\tLoss: 3.5970 (avg: 3.9001)\tTop1: 18.750 (avg: 14.750)\tTop5: 37.500 (avg: 36.500)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.0326 (avg: 3.8932)\tTop1: 15.625 (avg: 14.438)\tTop5: 37.500 (avg: 36.219)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 4.1550 (avg: 3.8970)\tTop1: 18.750 (avg: 14.667)\tTop5: 34.375 (avg: 36.500)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 3.7108 (avg: 3.9048)\tTop1: 12.500 (avg: 14.422)\tTop5: 43.750 (avg: 36.078)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.367 (avg: 0.362)\tLoss: 3.8208 (avg: 3.9045)\tTop1: 18.750 (avg: 14.425)\tTop5: 35.938 (avg: 36.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0435\tTop 1 accuracy: 10.650\tTop 5 accuracy: 28.750\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.365 (avg: 0.355)\tLoss: 4.0449 (avg: 3.8770)\tTop1: 15.625 (avg: 14.938)\tTop5: 37.500 (avg: 36.875)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.352 (avg: 0.359)\tLoss: 3.9560 (avg: 3.8690)\tTop1: 17.188 (avg: 15.156)\tTop5: 39.062 (avg: 37.156)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 3.9943 (avg: 3.8836)\tTop1: 17.188 (avg: 14.812)\tTop5: 32.812 (avg: 36.750)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.362 (avg: 0.362)\tLoss: 3.7403 (avg: 3.8939)\tTop1: 12.500 (avg: 14.469)\tTop5: 37.500 (avg: 36.516)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.364 (avg: 0.363)\tLoss: 3.8585 (avg: 3.8925)\tTop1: 20.312 (avg: 14.688)\tTop5: 34.375 (avg: 36.625)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9614\tTop 1 accuracy: 11.300\tTop 5 accuracy: 29.050\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.356 (avg: 0.353)\tLoss: 4.0057 (avg: 3.9013)\tTop1: 9.375 (avg: 16.062)\tTop5: 32.812 (avg: 37.250)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.358 (avg: 0.357)\tLoss: 3.9687 (avg: 3.8842)\tTop1: 10.938 (avg: 15.875)\tTop5: 28.125 (avg: 37.406)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 3.8124 (avg: 3.8888)\tTop1: 15.625 (avg: 15.229)\tTop5: 43.750 (avg: 37.083)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 4.0035 (avg: 3.8835)\tTop1: 21.875 (avg: 15.328)\tTop5: 29.688 (avg: 36.953)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.361 (avg: 0.362)\tLoss: 3.6217 (avg: 3.8727)\tTop1: 14.062 (avg: 15.163)\tTop5: 40.625 (avg: 37.062)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8296\tTop 1 accuracy: 10.650\tTop 5 accuracy: 28.950\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.367 (avg: 0.356)\tLoss: 3.4936 (avg: 3.8425)\tTop1: 14.062 (avg: 15.125)\tTop5: 42.188 (avg: 37.125)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.350 (avg: 0.360)\tLoss: 3.9117 (avg: 3.8427)\tTop1: 14.062 (avg: 14.844)\tTop5: 34.375 (avg: 36.656)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 3.7147 (avg: 3.8358)\tTop1: 14.062 (avg: 14.688)\tTop5: 39.062 (avg: 37.188)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.361 (avg: 0.362)\tLoss: 3.7985 (avg: 3.8629)\tTop1: 15.625 (avg: 14.641)\tTop5: 39.062 (avg: 36.922)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 3.9818 (avg: 3.8669)\tTop1: 15.625 (avg: 14.950)\tTop5: 26.562 (avg: 36.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9692\tTop 1 accuracy: 10.650\tTop 5 accuracy: 29.800\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.361 (avg: 0.356)\tLoss: 3.4782 (avg: 3.8249)\tTop1: 28.125 (avg: 16.312)\tTop5: 45.312 (avg: 38.812)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.9432 (avg: 3.8527)\tTop1: 17.188 (avg: 15.094)\tTop5: 37.500 (avg: 37.719)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.363 (avg: 0.362)\tLoss: 3.7815 (avg: 3.8580)\tTop1: 9.375 (avg: 14.604)\tTop5: 40.625 (avg: 37.125)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.357 (avg: 0.363)\tLoss: 3.6380 (avg: 3.8607)\tTop1: 20.312 (avg: 15.016)\tTop5: 45.312 (avg: 37.078)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.362 (avg: 0.363)\tLoss: 3.5871 (avg: 3.8561)\tTop1: 12.500 (avg: 14.900)\tTop5: 40.625 (avg: 37.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9548\tTop 1 accuracy: 10.750\tTop 5 accuracy: 28.200\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.360 (avg: 0.355)\tLoss: 3.7786 (avg: 3.7834)\tTop1: 15.625 (avg: 16.312)\tTop5: 39.062 (avg: 38.562)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 3.7309 (avg: 3.8283)\tTop1: 15.625 (avg: 15.562)\tTop5: 32.812 (avg: 37.594)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.366 (avg: 0.360)\tLoss: 3.8186 (avg: 3.8450)\tTop1: 15.625 (avg: 15.604)\tTop5: 43.750 (avg: 37.792)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.7323 (avg: 3.8446)\tTop1: 15.625 (avg: 15.547)\tTop5: 35.938 (avg: 37.656)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 4.0216 (avg: 3.8404)\tTop1: 6.250 (avg: 15.525)\tTop5: 39.062 (avg: 37.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0394\tTop 1 accuracy: 11.350\tTop 5 accuracy: 29.450\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.358 (avg: 0.356)\tLoss: 3.7369 (avg: 3.8398)\tTop1: 14.062 (avg: 16.062)\tTop5: 37.500 (avg: 38.062)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 3.7967 (avg: 3.8185)\tTop1: 17.188 (avg: 16.125)\tTop5: 39.062 (avg: 38.250)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 3.7225 (avg: 3.8157)\tTop1: 12.500 (avg: 15.938)\tTop5: 42.188 (avg: 38.458)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.366 (avg: 0.362)\tLoss: 4.0222 (avg: 3.8281)\tTop1: 10.938 (avg: 15.812)\tTop5: 35.938 (avg: 38.125)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.363 (avg: 0.363)\tLoss: 3.7959 (avg: 3.8305)\tTop1: 18.750 (avg: 15.713)\tTop5: 42.188 (avg: 38.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9496\tTop 1 accuracy: 11.350\tTop 5 accuracy: 30.150\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.365 (avg: 0.356)\tLoss: 4.1531 (avg: 3.7884)\tTop1: 14.062 (avg: 17.562)\tTop5: 31.250 (avg: 40.188)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.8878 (avg: 3.7797)\tTop1: 10.938 (avg: 17.125)\tTop5: 39.062 (avg: 39.281)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.361 (avg: 0.362)\tLoss: 3.7820 (avg: 3.7976)\tTop1: 15.625 (avg: 16.729)\tTop5: 35.938 (avg: 38.708)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.359 (avg: 0.363)\tLoss: 3.6802 (avg: 3.8019)\tTop1: 9.375 (avg: 16.359)\tTop5: 42.188 (avg: 38.828)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.354 (avg: 0.363)\tLoss: 3.5093 (avg: 3.8180)\tTop1: 29.688 (avg: 16.300)\tTop5: 48.438 (avg: 38.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9566\tTop 1 accuracy: 11.000\tTop 5 accuracy: 29.500\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.359 (avg: 0.356)\tLoss: 4.0078 (avg: 3.7772)\tTop1: 15.625 (avg: 16.500)\tTop5: 25.000 (avg: 39.688)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.361 (avg: 0.360)\tLoss: 3.7435 (avg: 3.7925)\tTop1: 17.188 (avg: 16.094)\tTop5: 42.188 (avg: 39.312)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 3.3238 (avg: 3.8072)\tTop1: 21.875 (avg: 15.792)\tTop5: 50.000 (avg: 38.646)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 3.6486 (avg: 3.8014)\tTop1: 14.062 (avg: 15.906)\tTop5: 40.625 (avg: 38.750)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.363 (avg: 0.363)\tLoss: 3.8394 (avg: 3.8109)\tTop1: 9.375 (avg: 15.763)\tTop5: 39.062 (avg: 38.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8570\tTop 1 accuracy: 11.000\tTop 5 accuracy: 30.750\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.362 (avg: 0.356)\tLoss: 4.0953 (avg: 3.7697)\tTop1: 12.500 (avg: 15.875)\tTop5: 31.250 (avg: 41.062)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.351 (avg: 0.360)\tLoss: 3.8654 (avg: 3.7665)\tTop1: 15.625 (avg: 16.312)\tTop5: 34.375 (avg: 40.656)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.6764 (avg: 3.7574)\tTop1: 12.500 (avg: 16.458)\tTop5: 40.625 (avg: 40.208)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 4.1392 (avg: 3.7844)\tTop1: 12.500 (avg: 16.172)\tTop5: 31.250 (avg: 39.078)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.353 (avg: 0.362)\tLoss: 3.6945 (avg: 3.7999)\tTop1: 15.625 (avg: 16.125)\tTop5: 42.188 (avg: 39.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0461\tTop 1 accuracy: 11.250\tTop 5 accuracy: 30.100\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.357 (avg: 0.356)\tLoss: 3.8184 (avg: 3.7428)\tTop1: 18.750 (avg: 17.062)\tTop5: 35.938 (avg: 38.312)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.360 (avg: 0.360)\tLoss: 3.8319 (avg: 3.7614)\tTop1: 14.062 (avg: 16.781)\tTop5: 35.938 (avg: 38.906)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 3.8214 (avg: 3.8059)\tTop1: 20.312 (avg: 16.542)\tTop5: 39.062 (avg: 38.021)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 3.6261 (avg: 3.7964)\tTop1: 21.875 (avg: 16.625)\tTop5: 50.000 (avg: 38.562)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.361 (avg: 0.363)\tLoss: 3.4920 (avg: 3.7868)\tTop1: 23.438 (avg: 16.500)\tTop5: 46.875 (avg: 38.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9929\tTop 1 accuracy: 11.400\tTop 5 accuracy: 30.500\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.363 (avg: 0.356)\tLoss: 4.0035 (avg: 3.7414)\tTop1: 12.500 (avg: 16.000)\tTop5: 34.375 (avg: 39.188)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.353 (avg: 0.361)\tLoss: 3.9755 (avg: 3.7982)\tTop1: 18.750 (avg: 15.656)\tTop5: 31.250 (avg: 38.594)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.362 (avg: 0.362)\tLoss: 3.6305 (avg: 3.7934)\tTop1: 23.438 (avg: 15.896)\tTop5: 45.312 (avg: 38.708)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 3.8495 (avg: 3.7765)\tTop1: 15.625 (avg: 16.156)\tTop5: 37.500 (avg: 38.844)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.359 (avg: 0.363)\tLoss: 3.5663 (avg: 3.7884)\tTop1: 17.188 (avg: 16.250)\tTop5: 42.188 (avg: 38.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6650\tTop 1 accuracy: 11.600\tTop 5 accuracy: 30.150\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.363 (avg: 0.356)\tLoss: 3.6820 (avg: 3.7308)\tTop1: 20.312 (avg: 17.938)\tTop5: 34.375 (avg: 40.062)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.350 (avg: 0.361)\tLoss: 3.9150 (avg: 3.7527)\tTop1: 10.938 (avg: 16.750)\tTop5: 37.500 (avg: 39.094)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 4.0126 (avg: 3.7479)\tTop1: 15.625 (avg: 17.333)\tTop5: 45.312 (avg: 40.021)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.363 (avg: 0.363)\tLoss: 3.4387 (avg: 3.7693)\tTop1: 17.188 (avg: 16.797)\tTop5: 48.438 (avg: 39.359)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.364 (avg: 0.363)\tLoss: 3.2511 (avg: 3.7751)\tTop1: 23.438 (avg: 16.450)\tTop5: 53.125 (avg: 39.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0194\tTop 1 accuracy: 11.000\tTop 5 accuracy: 30.500\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.366 (avg: 0.356)\tLoss: 3.9268 (avg: 3.7222)\tTop1: 10.938 (avg: 17.125)\tTop5: 34.375 (avg: 40.812)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.352 (avg: 0.360)\tLoss: 3.8691 (avg: 3.7103)\tTop1: 12.500 (avg: 17.906)\tTop5: 31.250 (avg: 41.156)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.351 (avg: 0.361)\tLoss: 4.0235 (avg: 3.7575)\tTop1: 10.938 (avg: 17.021)\tTop5: 37.500 (avg: 39.688)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.352 (avg: 0.361)\tLoss: 3.8104 (avg: 3.7599)\tTop1: 12.500 (avg: 16.750)\tTop5: 31.250 (avg: 39.516)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.362 (avg: 0.361)\tLoss: 4.0142 (avg: 3.7641)\tTop1: 10.938 (avg: 16.600)\tTop5: 37.500 (avg: 39.562)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9636\tTop 1 accuracy: 11.350\tTop 5 accuracy: 30.450\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.361 (avg: 0.356)\tLoss: 3.9916 (avg: 3.6637)\tTop1: 15.625 (avg: 17.938)\tTop5: 37.500 (avg: 41.000)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.358 (avg: 0.360)\tLoss: 3.7574 (avg: 3.7002)\tTop1: 15.625 (avg: 17.781)\tTop5: 37.500 (avg: 40.438)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.353 (avg: 0.362)\tLoss: 3.5611 (avg: 3.7300)\tTop1: 14.062 (avg: 16.896)\tTop5: 39.062 (avg: 40.438)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 3.4902 (avg: 3.7326)\tTop1: 21.875 (avg: 16.859)\tTop5: 39.062 (avg: 40.172)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.364 (avg: 0.363)\tLoss: 3.6490 (avg: 3.7495)\tTop1: 10.938 (avg: 16.613)\tTop5: 32.812 (avg: 39.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9690\tTop 1 accuracy: 10.650\tTop 5 accuracy: 29.450\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.366 (avg: 0.356)\tLoss: 3.5649 (avg: 3.7721)\tTop1: 25.000 (avg: 17.062)\tTop5: 43.750 (avg: 40.250)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 3.7616 (avg: 3.7614)\tTop1: 21.875 (avg: 17.062)\tTop5: 45.312 (avg: 40.500)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 3.3293 (avg: 3.7519)\tTop1: 25.000 (avg: 17.000)\tTop5: 51.562 (avg: 40.667)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.356 (avg: 0.363)\tLoss: 3.8234 (avg: 3.7535)\tTop1: 18.750 (avg: 16.609)\tTop5: 40.625 (avg: 40.375)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.360 (avg: 0.363)\tLoss: 3.6313 (avg: 3.7442)\tTop1: 17.188 (avg: 16.675)\tTop5: 45.312 (avg: 40.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9834\tTop 1 accuracy: 11.700\tTop 5 accuracy: 30.300\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.362 (avg: 0.355)\tLoss: 3.6200 (avg: 3.7050)\tTop1: 25.000 (avg: 16.125)\tTop5: 45.312 (avg: 39.812)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.9099 (avg: 3.7139)\tTop1: 15.625 (avg: 16.875)\tTop5: 37.500 (avg: 40.938)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.362 (avg: 0.360)\tLoss: 3.3242 (avg: 3.7212)\tTop1: 23.438 (avg: 17.042)\tTop5: 48.438 (avg: 40.667)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.361 (avg: 0.362)\tLoss: 3.7514 (avg: 3.7112)\tTop1: 14.062 (avg: 16.906)\tTop5: 28.125 (avg: 40.641)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.363 (avg: 0.362)\tLoss: 3.7163 (avg: 3.7229)\tTop1: 20.312 (avg: 17.088)\tTop5: 32.812 (avg: 40.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0331\tTop 1 accuracy: 10.750\tTop 5 accuracy: 29.250\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.362 (avg: 0.356)\tLoss: 3.4650 (avg: 3.6598)\tTop1: 18.750 (avg: 19.125)\tTop5: 45.312 (avg: 43.625)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 4.1629 (avg: 3.7033)\tTop1: 14.062 (avg: 17.844)\tTop5: 31.250 (avg: 41.375)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.361 (avg: 0.362)\tLoss: 4.1511 (avg: 3.7134)\tTop1: 12.500 (avg: 17.188)\tTop5: 31.250 (avg: 40.917)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 3.7695 (avg: 3.7141)\tTop1: 20.312 (avg: 17.000)\tTop5: 42.188 (avg: 40.562)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 3.4359 (avg: 3.7213)\tTop1: 25.000 (avg: 16.900)\tTop5: 51.562 (avg: 40.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9448\tTop 1 accuracy: 11.250\tTop 5 accuracy: 30.900\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.359 (avg: 0.356)\tLoss: 3.5584 (avg: 3.7058)\tTop1: 9.375 (avg: 18.125)\tTop5: 32.812 (avg: 41.000)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 4.0275 (avg: 3.7073)\tTop1: 15.625 (avg: 17.438)\tTop5: 37.500 (avg: 40.781)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.362 (avg: 0.361)\tLoss: 3.7495 (avg: 3.7125)\tTop1: 14.062 (avg: 17.375)\tTop5: 32.812 (avg: 40.292)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 3.6275 (avg: 3.7036)\tTop1: 15.625 (avg: 17.328)\tTop5: 42.188 (avg: 40.469)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.364 (avg: 0.363)\tLoss: 3.8619 (avg: 3.7083)\tTop1: 17.188 (avg: 17.150)\tTop5: 39.062 (avg: 40.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7896\tTop 1 accuracy: 11.150\tTop 5 accuracy: 30.550\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.364 (avg: 0.355)\tLoss: 3.5553 (avg: 3.7050)\tTop1: 17.188 (avg: 16.625)\tTop5: 43.750 (avg: 41.000)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 3.4148 (avg: 3.6874)\tTop1: 21.875 (avg: 17.875)\tTop5: 39.062 (avg: 41.719)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 3.8121 (avg: 3.6862)\tTop1: 9.375 (avg: 17.458)\tTop5: 37.500 (avg: 41.604)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.353 (avg: 0.361)\tLoss: 3.5194 (avg: 3.6931)\tTop1: 14.062 (avg: 17.281)\tTop5: 45.312 (avg: 41.969)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.362 (avg: 0.362)\tLoss: 3.7582 (avg: 3.7020)\tTop1: 17.188 (avg: 17.200)\tTop5: 42.188 (avg: 41.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0188\tTop 1 accuracy: 11.100\tTop 5 accuracy: 31.000\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.359 (avg: 0.357)\tLoss: 3.5261 (avg: 3.6823)\tTop1: 17.188 (avg: 17.938)\tTop5: 43.750 (avg: 42.562)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 3.7248 (avg: 3.6664)\tTop1: 17.188 (avg: 17.688)\tTop5: 35.938 (avg: 42.406)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.361 (avg: 0.362)\tLoss: 3.8614 (avg: 3.6687)\tTop1: 10.938 (avg: 17.854)\tTop5: 35.938 (avg: 42.292)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.361 (avg: 0.363)\tLoss: 3.5461 (avg: 3.6817)\tTop1: 17.188 (avg: 17.422)\tTop5: 42.188 (avg: 41.547)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.365 (avg: 0.363)\tLoss: 3.8631 (avg: 3.6854)\tTop1: 18.750 (avg: 17.225)\tTop5: 43.750 (avg: 41.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9959\tTop 1 accuracy: 11.650\tTop 5 accuracy: 30.400\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.361 (avg: 0.355)\tLoss: 3.6237 (avg: 3.6607)\tTop1: 23.438 (avg: 19.438)\tTop5: 43.750 (avg: 41.500)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.353 (avg: 0.360)\tLoss: 3.8076 (avg: 3.6633)\tTop1: 15.625 (avg: 18.094)\tTop5: 39.062 (avg: 41.250)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 3.9591 (avg: 3.6474)\tTop1: 10.938 (avg: 18.125)\tTop5: 31.250 (avg: 41.792)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.363 (avg: 0.362)\tLoss: 4.0698 (avg: 3.6725)\tTop1: 14.062 (avg: 17.844)\tTop5: 29.688 (avg: 41.641)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.359 (avg: 0.363)\tLoss: 3.6378 (avg: 3.6735)\tTop1: 14.062 (avg: 17.725)\tTop5: 43.750 (avg: 41.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0150\tTop 1 accuracy: 11.250\tTop 5 accuracy: 31.450\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.359 (avg: 0.354)\tLoss: 3.3903 (avg: 3.6021)\tTop1: 21.875 (avg: 18.625)\tTop5: 46.875 (avg: 43.312)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 3.5299 (avg: 3.6230)\tTop1: 14.062 (avg: 17.938)\tTop5: 45.312 (avg: 42.125)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.8865 (avg: 3.6356)\tTop1: 15.625 (avg: 18.417)\tTop5: 34.375 (avg: 42.854)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.353 (avg: 0.361)\tLoss: 3.5569 (avg: 3.6487)\tTop1: 21.875 (avg: 17.844)\tTop5: 45.312 (avg: 42.031)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.362 (avg: 0.362)\tLoss: 3.5701 (avg: 3.6720)\tTop1: 25.000 (avg: 17.688)\tTop5: 43.750 (avg: 41.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8047\tTop 1 accuracy: 10.800\tTop 5 accuracy: 30.350\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.361 (avg: 0.356)\tLoss: 3.6183 (avg: 3.6183)\tTop1: 17.188 (avg: 18.812)\tTop5: 45.312 (avg: 42.688)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 3.7063 (avg: 3.6238)\tTop1: 15.625 (avg: 18.719)\tTop5: 35.938 (avg: 42.375)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.361 (avg: 0.362)\tLoss: 3.5666 (avg: 3.6424)\tTop1: 18.750 (avg: 18.167)\tTop5: 45.312 (avg: 42.229)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 3.7955 (avg: 3.6455)\tTop1: 18.750 (avg: 18.141)\tTop5: 42.188 (avg: 42.250)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.359 (avg: 0.363)\tLoss: 3.9694 (avg: 3.6553)\tTop1: 15.625 (avg: 17.850)\tTop5: 31.250 (avg: 41.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7340\tTop 1 accuracy: 11.200\tTop 5 accuracy: 30.450\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.358 (avg: 0.356)\tLoss: 3.5195 (avg: 3.6122)\tTop1: 21.875 (avg: 18.875)\tTop5: 39.062 (avg: 43.000)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 3.6614 (avg: 3.5941)\tTop1: 26.562 (avg: 19.188)\tTop5: 42.188 (avg: 43.594)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 3.7205 (avg: 3.6160)\tTop1: 18.750 (avg: 18.938)\tTop5: 42.188 (avg: 42.667)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.359 (avg: 0.363)\tLoss: 4.0345 (avg: 3.6403)\tTop1: 17.188 (avg: 18.312)\tTop5: 35.938 (avg: 42.625)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.362 (avg: 0.363)\tLoss: 3.7649 (avg: 3.6471)\tTop1: 9.375 (avg: 17.913)\tTop5: 35.938 (avg: 42.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7455\tTop 1 accuracy: 12.000\tTop 5 accuracy: 31.050\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.364 (avg: 0.356)\tLoss: 3.4725 (avg: 3.6146)\tTop1: 12.500 (avg: 18.438)\tTop5: 51.562 (avg: 42.688)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.353 (avg: 0.360)\tLoss: 3.4401 (avg: 3.6151)\tTop1: 21.875 (avg: 18.375)\tTop5: 50.000 (avg: 42.969)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 3.5088 (avg: 3.6326)\tTop1: 17.188 (avg: 17.688)\tTop5: 42.188 (avg: 42.104)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.357 (avg: 0.363)\tLoss: 3.5531 (avg: 3.6337)\tTop1: 21.875 (avg: 17.906)\tTop5: 37.500 (avg: 42.281)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.362 (avg: 0.363)\tLoss: 3.7617 (avg: 3.6361)\tTop1: 15.625 (avg: 17.700)\tTop5: 45.312 (avg: 42.313)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0913\tTop 1 accuracy: 12.050\tTop 5 accuracy: 31.850\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.362 (avg: 0.357)\tLoss: 3.3515 (avg: 3.4975)\tTop1: 20.312 (avg: 20.062)\tTop5: 48.438 (avg: 45.812)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.8284 (avg: 3.5698)\tTop1: 10.938 (avg: 18.750)\tTop5: 34.375 (avg: 43.719)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 3.6901 (avg: 3.5723)\tTop1: 26.562 (avg: 18.583)\tTop5: 46.875 (avg: 43.312)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.362 (avg: 0.363)\tLoss: 3.1777 (avg: 3.5985)\tTop1: 28.125 (avg: 18.266)\tTop5: 53.125 (avg: 42.859)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.372 (avg: 0.363)\tLoss: 3.5949 (avg: 3.6188)\tTop1: 20.312 (avg: 18.300)\tTop5: 40.625 (avg: 42.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9558\tTop 1 accuracy: 11.700\tTop 5 accuracy: 30.800\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.361 (avg: 0.354)\tLoss: 3.5896 (avg: 3.5482)\tTop1: 12.500 (avg: 19.312)\tTop5: 40.625 (avg: 44.000)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.349 (avg: 0.359)\tLoss: 3.5129 (avg: 3.5689)\tTop1: 14.062 (avg: 19.594)\tTop5: 37.500 (avg: 43.375)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.8318 (avg: 3.5782)\tTop1: 18.750 (avg: 19.646)\tTop5: 48.438 (avg: 43.646)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.360 (avg: 0.361)\tLoss: 3.8801 (avg: 3.5978)\tTop1: 21.875 (avg: 19.172)\tTop5: 39.062 (avg: 43.016)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 3.7896 (avg: 3.6158)\tTop1: 18.750 (avg: 18.775)\tTop5: 40.625 (avg: 42.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9433\tTop 1 accuracy: 11.900\tTop 5 accuracy: 30.650\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.363 (avg: 0.356)\tLoss: 3.1636 (avg: 3.5178)\tTop1: 23.438 (avg: 20.750)\tTop5: 46.875 (avg: 45.125)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 3.4787 (avg: 3.5118)\tTop1: 15.625 (avg: 20.969)\tTop5: 43.750 (avg: 45.812)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 3.6460 (avg: 3.5146)\tTop1: 21.875 (avg: 20.604)\tTop5: 51.562 (avg: 45.896)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.352 (avg: 0.363)\tLoss: 3.5176 (avg: 3.5263)\tTop1: 28.125 (avg: 20.156)\tTop5: 43.750 (avg: 45.562)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.362 (avg: 0.364)\tLoss: 3.7120 (avg: 3.5189)\tTop1: 15.625 (avg: 20.338)\tTop5: 48.438 (avg: 45.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8569\tTop 1 accuracy: 12.450\tTop 5 accuracy: 32.600\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.365 (avg: 0.356)\tLoss: 3.2221 (avg: 3.5352)\tTop1: 21.875 (avg: 19.375)\tTop5: 54.688 (avg: 45.562)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.352 (avg: 0.360)\tLoss: 3.6362 (avg: 3.5488)\tTop1: 25.000 (avg: 19.781)\tTop5: 43.750 (avg: 45.062)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 3.0752 (avg: 3.5186)\tTop1: 21.875 (avg: 20.396)\tTop5: 53.125 (avg: 45.604)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.356 (avg: 0.363)\tLoss: 3.6068 (avg: 3.5094)\tTop1: 14.062 (avg: 20.375)\tTop5: 40.625 (avg: 45.891)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.361 (avg: 0.363)\tLoss: 3.4662 (avg: 3.5002)\tTop1: 18.750 (avg: 20.663)\tTop5: 46.875 (avg: 45.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9128\tTop 1 accuracy: 12.550\tTop 5 accuracy: 32.650\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.361 (avg: 0.356)\tLoss: 3.4849 (avg: 3.5517)\tTop1: 25.000 (avg: 20.875)\tTop5: 42.188 (avg: 45.000)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 3.4322 (avg: 3.5172)\tTop1: 17.188 (avg: 20.062)\tTop5: 50.000 (avg: 45.500)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.348 (avg: 0.362)\tLoss: 3.5953 (avg: 3.5014)\tTop1: 15.625 (avg: 20.771)\tTop5: 45.312 (avg: 45.375)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 3.2972 (avg: 3.5051)\tTop1: 25.000 (avg: 20.766)\tTop5: 46.875 (avg: 45.188)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.363 (avg: 0.362)\tLoss: 3.6268 (avg: 3.4925)\tTop1: 25.000 (avg: 20.988)\tTop5: 34.375 (avg: 45.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8984\tTop 1 accuracy: 12.650\tTop 5 accuracy: 32.550\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.366 (avg: 0.356)\tLoss: 3.2950 (avg: 3.4710)\tTop1: 23.438 (avg: 21.188)\tTop5: 48.438 (avg: 46.000)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 3.6170 (avg: 3.4848)\tTop1: 17.188 (avg: 20.781)\tTop5: 42.188 (avg: 45.969)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.351 (avg: 0.361)\tLoss: 3.8357 (avg: 3.4918)\tTop1: 18.750 (avg: 20.542)\tTop5: 34.375 (avg: 46.042)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.363 (avg: 0.362)\tLoss: 3.3198 (avg: 3.4891)\tTop1: 29.688 (avg: 20.703)\tTop5: 46.875 (avg: 46.016)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.360 (avg: 0.363)\tLoss: 3.4366 (avg: 3.4873)\tTop1: 18.750 (avg: 20.575)\tTop5: 39.062 (avg: 46.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8808\tTop 1 accuracy: 12.750\tTop 5 accuracy: 32.200\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.358 (avg: 0.357)\tLoss: 3.6090 (avg: 3.4980)\tTop1: 20.312 (avg: 20.688)\tTop5: 46.875 (avg: 45.438)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.3920 (avg: 3.4853)\tTop1: 32.812 (avg: 20.906)\tTop5: 50.000 (avg: 46.094)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 3.1940 (avg: 3.4748)\tTop1: 25.000 (avg: 21.250)\tTop5: 53.125 (avg: 46.292)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.357 (avg: 0.363)\tLoss: 3.4359 (avg: 3.4851)\tTop1: 21.875 (avg: 20.922)\tTop5: 45.312 (avg: 46.266)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.369 (avg: 0.363)\tLoss: 3.7077 (avg: 3.4857)\tTop1: 20.312 (avg: 20.763)\tTop5: 40.625 (avg: 46.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9383\tTop 1 accuracy: 12.350\tTop 5 accuracy: 32.400\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.363 (avg: 0.355)\tLoss: 3.3164 (avg: 3.4888)\tTop1: 21.875 (avg: 20.750)\tTop5: 46.875 (avg: 45.188)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.354 (avg: 0.359)\tLoss: 3.5536 (avg: 3.4881)\tTop1: 15.625 (avg: 20.656)\tTop5: 45.312 (avg: 46.094)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.5719 (avg: 3.5038)\tTop1: 23.438 (avg: 20.375)\tTop5: 46.875 (avg: 45.458)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.361 (avg: 0.362)\tLoss: 3.1804 (avg: 3.4876)\tTop1: 20.312 (avg: 20.703)\tTop5: 56.250 (avg: 46.125)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.360 (avg: 0.363)\tLoss: 3.4769 (avg: 3.4819)\tTop1: 25.000 (avg: 21.213)\tTop5: 53.125 (avg: 46.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8940\tTop 1 accuracy: 12.450\tTop 5 accuracy: 32.400\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.363 (avg: 0.356)\tLoss: 3.5240 (avg: 3.4223)\tTop1: 17.188 (avg: 21.812)\tTop5: 51.562 (avg: 46.750)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.5237 (avg: 3.4686)\tTop1: 17.188 (avg: 20.812)\tTop5: 39.062 (avg: 45.781)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 3.5236 (avg: 3.4849)\tTop1: 20.312 (avg: 20.562)\tTop5: 51.562 (avg: 45.771)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.359 (avg: 0.363)\tLoss: 3.4433 (avg: 3.4872)\tTop1: 20.312 (avg: 20.719)\tTop5: 48.438 (avg: 45.922)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.365 (avg: 0.363)\tLoss: 3.6679 (avg: 3.4813)\tTop1: 15.625 (avg: 20.863)\tTop5: 45.312 (avg: 46.063)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0232\tTop 1 accuracy: 12.700\tTop 5 accuracy: 32.600\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.361 (avg: 0.356)\tLoss: 3.6888 (avg: 3.4668)\tTop1: 17.188 (avg: 21.438)\tTop5: 39.062 (avg: 46.188)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.352 (avg: 0.361)\tLoss: 3.7296 (avg: 3.4827)\tTop1: 28.125 (avg: 21.188)\tTop5: 40.625 (avg: 46.156)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 3.4244 (avg: 3.4840)\tTop1: 21.875 (avg: 21.083)\tTop5: 39.062 (avg: 46.208)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.354 (avg: 0.363)\tLoss: 3.6398 (avg: 3.4747)\tTop1: 21.875 (avg: 21.109)\tTop5: 46.875 (avg: 46.406)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 3.4766 (avg: 3.4800)\tTop1: 26.562 (avg: 20.913)\tTop5: 51.562 (avg: 46.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9709\tTop 1 accuracy: 12.600\tTop 5 accuracy: 32.450\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.349 (avg: 0.355)\tLoss: 3.4085 (avg: 3.4939)\tTop1: 17.188 (avg: 22.250)\tTop5: 50.000 (avg: 46.500)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.356 (avg: 0.358)\tLoss: 3.3790 (avg: 3.5027)\tTop1: 26.562 (avg: 21.281)\tTop5: 50.000 (avg: 45.500)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 3.6280 (avg: 3.4984)\tTop1: 18.750 (avg: 20.979)\tTop5: 37.500 (avg: 45.396)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.362 (avg: 0.362)\tLoss: 3.3029 (avg: 3.4852)\tTop1: 31.250 (avg: 20.828)\tTop5: 48.438 (avg: 45.906)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.363 (avg: 0.362)\tLoss: 3.2249 (avg: 3.4737)\tTop1: 26.562 (avg: 20.913)\tTop5: 57.812 (avg: 46.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9113\tTop 1 accuracy: 12.600\tTop 5 accuracy: 32.450\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.362 (avg: 0.356)\tLoss: 3.3315 (avg: 3.4790)\tTop1: 26.562 (avg: 20.625)\tTop5: 51.562 (avg: 47.438)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 3.7563 (avg: 3.4677)\tTop1: 14.062 (avg: 21.938)\tTop5: 35.938 (avg: 47.000)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.361 (avg: 0.362)\tLoss: 3.2065 (avg: 3.4530)\tTop1: 20.312 (avg: 21.688)\tTop5: 56.250 (avg: 47.292)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.359 (avg: 0.363)\tLoss: 3.6815 (avg: 3.4626)\tTop1: 18.750 (avg: 21.547)\tTop5: 42.188 (avg: 47.094)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.366 (avg: 0.363)\tLoss: 3.1374 (avg: 3.4748)\tTop1: 26.562 (avg: 21.025)\tTop5: 53.125 (avg: 46.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9367\tTop 1 accuracy: 12.450\tTop 5 accuracy: 32.850\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.360 (avg: 0.356)\tLoss: 3.5819 (avg: 3.4875)\tTop1: 12.500 (avg: 19.625)\tTop5: 39.062 (avg: 46.250)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 3.5802 (avg: 3.4821)\tTop1: 23.438 (avg: 20.250)\tTop5: 43.750 (avg: 46.719)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 3.4861 (avg: 3.4860)\tTop1: 21.875 (avg: 20.521)\tTop5: 43.750 (avg: 46.396)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.362 (avg: 0.363)\tLoss: 3.4688 (avg: 3.4829)\tTop1: 23.438 (avg: 20.703)\tTop5: 50.000 (avg: 46.297)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.362 (avg: 0.363)\tLoss: 3.5459 (avg: 3.4727)\tTop1: 15.625 (avg: 20.900)\tTop5: 43.750 (avg: 46.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0506\tTop 1 accuracy: 12.250\tTop 5 accuracy: 32.300\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.363 (avg: 0.355)\tLoss: 3.5154 (avg: 3.4394)\tTop1: 21.875 (avg: 22.438)\tTop5: 51.562 (avg: 47.875)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 3.4634 (avg: 3.4960)\tTop1: 15.625 (avg: 21.062)\tTop5: 48.438 (avg: 47.062)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.361 (avg: 0.362)\tLoss: 3.4643 (avg: 3.4719)\tTop1: 7.812 (avg: 21.188)\tTop5: 46.875 (avg: 46.812)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.365 (avg: 0.362)\tLoss: 3.3884 (avg: 3.4778)\tTop1: 23.438 (avg: 21.234)\tTop5: 45.312 (avg: 46.922)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.360 (avg: 0.363)\tLoss: 3.1746 (avg: 3.4732)\tTop1: 29.688 (avg: 21.025)\tTop5: 59.375 (avg: 46.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0115\tTop 1 accuracy: 12.600\tTop 5 accuracy: 32.750\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.364 (avg: 0.356)\tLoss: 3.3217 (avg: 3.4492)\tTop1: 20.312 (avg: 21.125)\tTop5: 48.438 (avg: 46.938)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 3.3365 (avg: 3.4475)\tTop1: 14.062 (avg: 21.219)\tTop5: 43.750 (avg: 47.312)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.362 (avg: 0.361)\tLoss: 3.6611 (avg: 3.4596)\tTop1: 14.062 (avg: 21.250)\tTop5: 37.500 (avg: 46.646)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 3.4527 (avg: 3.4527)\tTop1: 23.438 (avg: 21.219)\tTop5: 45.312 (avg: 46.844)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.366 (avg: 0.363)\tLoss: 3.5636 (avg: 3.4706)\tTop1: 20.312 (avg: 21.088)\tTop5: 43.750 (avg: 46.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9317\tTop 1 accuracy: 12.650\tTop 5 accuracy: 32.350\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.368 (avg: 0.356)\tLoss: 3.6633 (avg: 3.4491)\tTop1: 15.625 (avg: 21.312)\tTop5: 39.062 (avg: 46.500)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 3.4743 (avg: 3.4008)\tTop1: 23.438 (avg: 22.062)\tTop5: 46.875 (avg: 47.906)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.366 (avg: 0.362)\tLoss: 3.5592 (avg: 3.4320)\tTop1: 21.875 (avg: 21.917)\tTop5: 42.188 (avg: 46.750)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 3.5928 (avg: 3.4486)\tTop1: 17.188 (avg: 21.609)\tTop5: 53.125 (avg: 46.516)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.359 (avg: 0.363)\tLoss: 3.2630 (avg: 3.4663)\tTop1: 28.125 (avg: 21.325)\tTop5: 48.438 (avg: 46.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9906\tTop 1 accuracy: 12.600\tTop 5 accuracy: 32.400\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.358 (avg: 0.357)\tLoss: 3.7621 (avg: 3.4316)\tTop1: 15.625 (avg: 23.375)\tTop5: 40.625 (avg: 48.000)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.6542 (avg: 3.4507)\tTop1: 20.312 (avg: 21.625)\tTop5: 43.750 (avg: 47.531)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 3.3968 (avg: 3.4592)\tTop1: 25.000 (avg: 21.625)\tTop5: 45.312 (avg: 47.062)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.360 (avg: 0.363)\tLoss: 3.0420 (avg: 3.4567)\tTop1: 26.562 (avg: 21.516)\tTop5: 60.938 (avg: 46.906)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.365 (avg: 0.363)\tLoss: 3.1114 (avg: 3.4642)\tTop1: 26.562 (avg: 21.275)\tTop5: 51.562 (avg: 46.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9129\tTop 1 accuracy: 12.600\tTop 5 accuracy: 32.100\n",
            "\n",
            "pct_3x3 = 0.25: top1 = 12.450000762939453 \t top5 = 32.85000228881836 \t batch time = 0.28719843178987503\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.378 (avg: 0.453)\tLoss: 5.3025 (avg: 5.3108)\tTop1: 0.000 (avg: 0.250)\tTop5: 0.000 (avg: 2.062)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.375 (avg: 0.419)\tLoss: 5.2989 (avg: 5.3052)\tTop1: 1.562 (avg: 0.406)\tTop5: 3.125 (avg: 2.281)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.383 (avg: 0.407)\tLoss: 5.2996 (avg: 5.3029)\tTop1: 0.000 (avg: 0.396)\tTop5: 3.125 (avg: 2.438)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.374 (avg: 0.401)\tLoss: 5.2974 (avg: 5.3018)\tTop1: 0.000 (avg: 0.469)\tTop5: 4.688 (avg: 2.438)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.377 (avg: 0.398)\tLoss: 5.2988 (avg: 5.3014)\tTop1: 0.000 (avg: 0.388)\tTop5: 0.000 (avg: 2.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2981\tTop 1 accuracy: 0.550\tTop 5 accuracy: 2.450\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.387 (avg: 0.375)\tLoss: 5.2988 (avg: 5.2979)\tTop1: 0.000 (avg: 0.812)\tTop5: 0.000 (avg: 3.250)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.372 (avg: 0.378)\tLoss: 5.2978 (avg: 5.2980)\tTop1: 0.000 (avg: 0.688)\tTop5: 3.125 (avg: 3.062)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.369 (avg: 0.380)\tLoss: 5.2962 (avg: 5.2978)\tTop1: 0.000 (avg: 0.625)\tTop5: 3.125 (avg: 3.021)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.385 (avg: 0.380)\tLoss: 5.2967 (avg: 5.2977)\tTop1: 0.000 (avg: 0.594)\tTop5: 4.688 (avg: 3.000)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.375 (avg: 0.381)\tLoss: 5.2927 (avg: 5.2974)\tTop1: 1.562 (avg: 0.638)\tTop5: 6.250 (avg: 3.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2983\tTop 1 accuracy: 1.000\tTop 5 accuracy: 3.350\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.373 (avg: 0.374)\tLoss: 5.2575 (avg: 5.2895)\tTop1: 3.125 (avg: 0.812)\tTop5: 6.250 (avg: 3.812)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.378 (avg: 0.379)\tLoss: 5.3098 (avg: 5.2877)\tTop1: 0.000 (avg: 1.031)\tTop5: 0.000 (avg: 3.688)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.381 (avg: 0.380)\tLoss: 5.2695 (avg: 5.2810)\tTop1: 0.000 (avg: 1.042)\tTop5: 6.250 (avg: 3.875)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.374 (avg: 0.381)\tLoss: 5.2941 (avg: 5.2800)\tTop1: 3.125 (avg: 1.000)\tTop5: 6.250 (avg: 3.906)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.387 (avg: 0.382)\tLoss: 5.3003 (avg: 5.2777)\tTop1: 0.000 (avg: 1.000)\tTop5: 6.250 (avg: 3.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2765\tTop 1 accuracy: 1.000\tTop 5 accuracy: 4.400\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.383 (avg: 0.375)\tLoss: 5.2861 (avg: 5.2323)\tTop1: 0.000 (avg: 1.062)\tTop5: 0.000 (avg: 4.500)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.374 (avg: 0.379)\tLoss: 5.2490 (avg: 5.2325)\tTop1: 0.000 (avg: 0.906)\tTop5: 1.562 (avg: 4.406)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.372 (avg: 0.380)\tLoss: 5.2640 (avg: 5.2351)\tTop1: 0.000 (avg: 1.021)\tTop5: 7.812 (avg: 4.667)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.385 (avg: 0.381)\tLoss: 5.2731 (avg: 5.2361)\tTop1: 0.000 (avg: 1.062)\tTop5: 0.000 (avg: 4.594)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.374 (avg: 0.382)\tLoss: 5.2916 (avg: 5.2362)\tTop1: 1.562 (avg: 1.088)\tTop5: 6.250 (avg: 4.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2370\tTop 1 accuracy: 1.000\tTop 5 accuracy: 5.550\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.371 (avg: 0.373)\tLoss: 5.1375 (avg: 5.1976)\tTop1: 0.000 (avg: 1.250)\tTop5: 7.812 (avg: 6.125)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.372 (avg: 0.376)\tLoss: 5.2179 (avg: 5.2071)\tTop1: 0.000 (avg: 1.250)\tTop5: 3.125 (avg: 5.312)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.372 (avg: 0.378)\tLoss: 5.2315 (avg: 5.2120)\tTop1: 1.562 (avg: 1.250)\tTop5: 1.562 (avg: 5.479)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.370 (avg: 0.379)\tLoss: 5.1954 (avg: 5.2139)\tTop1: 0.000 (avg: 1.203)\tTop5: 7.812 (avg: 5.359)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.383 (avg: 0.380)\tLoss: 5.1769 (avg: 5.2103)\tTop1: 0.000 (avg: 1.200)\tTop5: 1.562 (avg: 5.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2522\tTop 1 accuracy: 1.100\tTop 5 accuracy: 4.350\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.374 (avg: 0.373)\tLoss: 5.2219 (avg: 5.1929)\tTop1: 0.000 (avg: 1.125)\tTop5: 3.125 (avg: 5.000)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.380 (avg: 0.378)\tLoss: 5.2125 (avg: 5.1895)\tTop1: 0.000 (avg: 1.062)\tTop5: 4.688 (avg: 5.625)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.380 (avg: 0.379)\tLoss: 5.2186 (avg: 5.1891)\tTop1: 0.000 (avg: 1.125)\tTop5: 3.125 (avg: 5.625)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.383 (avg: 0.381)\tLoss: 5.1872 (avg: 5.1824)\tTop1: 3.125 (avg: 1.219)\tTop5: 10.938 (avg: 5.906)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.375 (avg: 0.381)\tLoss: 5.0935 (avg: 5.1792)\tTop1: 1.562 (avg: 1.275)\tTop5: 7.812 (avg: 5.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0875\tTop 1 accuracy: 1.550\tTop 5 accuracy: 6.350\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.373 (avg: 0.374)\tLoss: 5.1148 (avg: 5.1396)\tTop1: 1.562 (avg: 1.312)\tTop5: 9.375 (avg: 6.688)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.375 (avg: 0.378)\tLoss: 5.1854 (avg: 5.1632)\tTop1: 0.000 (avg: 1.094)\tTop5: 7.812 (avg: 6.125)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.379 (avg: 0.380)\tLoss: 5.1750 (avg: 5.1677)\tTop1: 1.562 (avg: 1.229)\tTop5: 6.250 (avg: 6.021)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.371 (avg: 0.380)\tLoss: 5.2308 (avg: 5.1687)\tTop1: 1.562 (avg: 1.188)\tTop5: 4.688 (avg: 5.969)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.382 (avg: 0.381)\tLoss: 5.1726 (avg: 5.1656)\tTop1: 0.000 (avg: 1.238)\tTop5: 3.125 (avg: 6.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1931\tTop 1 accuracy: 1.250\tTop 5 accuracy: 5.800\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.382 (avg: 0.374)\tLoss: 5.1510 (avg: 5.1498)\tTop1: 4.688 (avg: 2.188)\tTop5: 9.375 (avg: 6.875)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.379 (avg: 0.379)\tLoss: 5.0526 (avg: 5.1476)\tTop1: 3.125 (avg: 1.688)\tTop5: 12.500 (avg: 6.594)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.372 (avg: 0.380)\tLoss: 4.9677 (avg: 5.1431)\tTop1: 4.688 (avg: 1.479)\tTop5: 7.812 (avg: 6.604)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.381 (avg: 0.381)\tLoss: 5.0903 (avg: 5.1335)\tTop1: 4.688 (avg: 1.547)\tTop5: 10.938 (avg: 6.875)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.371 (avg: 0.382)\tLoss: 5.1960 (avg: 5.1357)\tTop1: 1.562 (avg: 1.575)\tTop5: 9.375 (avg: 6.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0868\tTop 1 accuracy: 1.800\tTop 5 accuracy: 6.050\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.371 (avg: 0.374)\tLoss: 5.1955 (avg: 5.1204)\tTop1: 0.000 (avg: 1.312)\tTop5: 4.688 (avg: 7.438)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.379 (avg: 0.379)\tLoss: 5.0320 (avg: 5.1234)\tTop1: 1.562 (avg: 1.406)\tTop5: 6.250 (avg: 6.594)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.373 (avg: 0.380)\tLoss: 5.1795 (avg: 5.1153)\tTop1: 0.000 (avg: 1.417)\tTop5: 7.812 (avg: 6.771)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.367 (avg: 0.381)\tLoss: 5.0151 (avg: 5.1191)\tTop1: 3.125 (avg: 1.578)\tTop5: 15.625 (avg: 6.906)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.380 (avg: 0.381)\tLoss: 5.1514 (avg: 5.1187)\tTop1: 0.000 (avg: 1.500)\tTop5: 6.250 (avg: 7.013)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9658\tTop 1 accuracy: 1.850\tTop 5 accuracy: 7.150\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.385 (avg: 0.374)\tLoss: 5.0817 (avg: 5.0719)\tTop1: 1.562 (avg: 1.688)\tTop5: 6.250 (avg: 7.250)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.374 (avg: 0.379)\tLoss: 5.1980 (avg: 5.0868)\tTop1: 1.562 (avg: 1.469)\tTop5: 6.250 (avg: 7.281)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.374 (avg: 0.381)\tLoss: 5.1067 (avg: 5.0963)\tTop1: 0.000 (avg: 1.438)\tTop5: 9.375 (avg: 7.146)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.377 (avg: 0.381)\tLoss: 5.0750 (avg: 5.0941)\tTop1: 1.562 (avg: 1.484)\tTop5: 9.375 (avg: 7.172)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.367 (avg: 0.381)\tLoss: 4.9591 (avg: 5.0974)\tTop1: 3.125 (avg: 1.413)\tTop5: 12.500 (avg: 7.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0111\tTop 1 accuracy: 2.250\tTop 5 accuracy: 8.250\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.374 (avg: 0.372)\tLoss: 4.9985 (avg: 5.0473)\tTop1: 1.562 (avg: 1.688)\tTop5: 12.500 (avg: 9.438)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.376 (avg: 0.378)\tLoss: 4.8986 (avg: 5.0521)\tTop1: 1.562 (avg: 1.719)\tTop5: 12.500 (avg: 9.062)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.380 (avg: 0.380)\tLoss: 5.1778 (avg: 5.0707)\tTop1: 0.000 (avg: 1.625)\tTop5: 4.688 (avg: 8.312)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.380 (avg: 0.381)\tLoss: 5.1426 (avg: 5.0769)\tTop1: 0.000 (avg: 1.656)\tTop5: 3.125 (avg: 7.953)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.381 (avg: 0.382)\tLoss: 5.0826 (avg: 5.0822)\tTop1: 1.562 (avg: 1.650)\tTop5: 7.812 (avg: 7.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9913\tTop 1 accuracy: 1.700\tTop 5 accuracy: 8.950\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.380 (avg: 0.375)\tLoss: 5.1263 (avg: 5.0598)\tTop1: 3.125 (avg: 2.375)\tTop5: 9.375 (avg: 8.000)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.374 (avg: 0.379)\tLoss: 5.1916 (avg: 5.0359)\tTop1: 0.000 (avg: 2.312)\tTop5: 3.125 (avg: 8.406)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.377 (avg: 0.381)\tLoss: 5.1274 (avg: 5.0529)\tTop1: 1.562 (avg: 2.500)\tTop5: 3.125 (avg: 8.333)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.384 (avg: 0.382)\tLoss: 4.9514 (avg: 5.0539)\tTop1: 9.375 (avg: 2.391)\tTop5: 10.938 (avg: 8.516)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.377 (avg: 0.383)\tLoss: 5.0466 (avg: 5.0577)\tTop1: 3.125 (avg: 2.275)\tTop5: 9.375 (avg: 8.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1718\tTop 1 accuracy: 1.800\tTop 5 accuracy: 8.300\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.375 (avg: 0.373)\tLoss: 5.0261 (avg: 5.0271)\tTop1: 3.125 (avg: 2.562)\tTop5: 9.375 (avg: 9.125)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.374 (avg: 0.378)\tLoss: 4.8727 (avg: 5.0289)\tTop1: 6.250 (avg: 2.594)\tTop5: 12.500 (avg: 9.062)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.379 (avg: 0.380)\tLoss: 5.0120 (avg: 5.0399)\tTop1: 4.688 (avg: 2.542)\tTop5: 7.812 (avg: 8.812)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.382 (avg: 0.381)\tLoss: 4.8888 (avg: 5.0375)\tTop1: 1.562 (avg: 2.438)\tTop5: 10.938 (avg: 8.906)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.383 (avg: 0.382)\tLoss: 5.0040 (avg: 5.0330)\tTop1: 0.000 (avg: 2.413)\tTop5: 10.938 (avg: 9.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1284\tTop 1 accuracy: 1.450\tTop 5 accuracy: 9.100\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.388 (avg: 0.375)\tLoss: 4.8447 (avg: 4.9633)\tTop1: 1.562 (avg: 2.438)\tTop5: 7.812 (avg: 10.625)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.372 (avg: 0.380)\tLoss: 4.9548 (avg: 4.9922)\tTop1: 1.562 (avg: 2.656)\tTop5: 12.500 (avg: 10.406)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.370 (avg: 0.381)\tLoss: 4.9835 (avg: 4.9988)\tTop1: 3.125 (avg: 2.479)\tTop5: 7.812 (avg: 10.229)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.382 (avg: 0.382)\tLoss: 5.0041 (avg: 4.9991)\tTop1: 4.688 (avg: 2.594)\tTop5: 15.625 (avg: 10.328)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.371 (avg: 0.382)\tLoss: 4.9907 (avg: 4.9958)\tTop1: 4.688 (avg: 2.700)\tTop5: 17.188 (avg: 10.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9250\tTop 1 accuracy: 2.650\tTop 5 accuracy: 11.350\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.372 (avg: 0.375)\tLoss: 5.0077 (avg: 4.9412)\tTop1: 6.250 (avg: 2.312)\tTop5: 9.375 (avg: 11.312)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.372 (avg: 0.378)\tLoss: 4.9130 (avg: 4.9401)\tTop1: 0.000 (avg: 2.281)\tTop5: 12.500 (avg: 11.375)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.382 (avg: 0.379)\tLoss: 4.8022 (avg: 4.9387)\tTop1: 3.125 (avg: 2.250)\tTop5: 14.062 (avg: 10.917)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.376 (avg: 0.381)\tLoss: 5.0511 (avg: 4.9497)\tTop1: 1.562 (avg: 2.375)\tTop5: 9.375 (avg: 11.094)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.378 (avg: 0.381)\tLoss: 4.8030 (avg: 4.9526)\tTop1: 0.000 (avg: 2.350)\tTop5: 12.500 (avg: 11.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0821\tTop 1 accuracy: 1.900\tTop 5 accuracy: 10.450\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.374 (avg: 0.371)\tLoss: 4.8596 (avg: 4.8474)\tTop1: 1.562 (avg: 2.438)\tTop5: 12.500 (avg: 12.250)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.374 (avg: 0.376)\tLoss: 5.0705 (avg: 4.8782)\tTop1: 1.562 (avg: 2.594)\tTop5: 17.188 (avg: 12.062)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.373 (avg: 0.379)\tLoss: 4.7202 (avg: 4.8861)\tTop1: 3.125 (avg: 2.688)\tTop5: 17.188 (avg: 12.083)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.384 (avg: 0.380)\tLoss: 4.8920 (avg: 4.8847)\tTop1: 3.125 (avg: 2.766)\tTop5: 10.938 (avg: 12.172)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.376 (avg: 0.381)\tLoss: 4.9387 (avg: 4.8803)\tTop1: 1.562 (avg: 2.750)\tTop5: 10.938 (avg: 12.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9981\tTop 1 accuracy: 2.800\tTop 5 accuracy: 10.900\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.377 (avg: 0.374)\tLoss: 4.8156 (avg: 4.8450)\tTop1: 6.250 (avg: 3.500)\tTop5: 20.312 (avg: 13.250)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.377 (avg: 0.379)\tLoss: 4.6641 (avg: 4.8222)\tTop1: 6.250 (avg: 3.656)\tTop5: 15.625 (avg: 13.469)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.376 (avg: 0.380)\tLoss: 5.0593 (avg: 4.8279)\tTop1: 4.688 (avg: 3.646)\tTop5: 12.500 (avg: 13.104)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.378 (avg: 0.381)\tLoss: 4.7643 (avg: 4.8120)\tTop1: 1.562 (avg: 3.750)\tTop5: 12.500 (avg: 13.578)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.386 (avg: 0.382)\tLoss: 5.0138 (avg: 4.8184)\tTop1: 1.562 (avg: 3.713)\tTop5: 15.625 (avg: 13.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5577\tTop 1 accuracy: 3.650\tTop 5 accuracy: 13.700\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.387 (avg: 0.375)\tLoss: 4.7946 (avg: 4.8101)\tTop1: 4.688 (avg: 3.562)\tTop5: 14.062 (avg: 13.688)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.378 (avg: 0.378)\tLoss: 4.7981 (avg: 4.7907)\tTop1: 1.562 (avg: 3.781)\tTop5: 14.062 (avg: 14.156)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.374 (avg: 0.380)\tLoss: 4.6778 (avg: 4.7873)\tTop1: 3.125 (avg: 3.896)\tTop5: 14.062 (avg: 14.188)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.388 (avg: 0.381)\tLoss: 4.7815 (avg: 4.7905)\tTop1: 6.250 (avg: 4.016)\tTop5: 15.625 (avg: 14.688)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.376 (avg: 0.382)\tLoss: 4.8880 (avg: 4.7890)\tTop1: 1.562 (avg: 4.100)\tTop5: 15.625 (avg: 14.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7511\tTop 1 accuracy: 3.850\tTop 5 accuracy: 15.450\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.375 (avg: 0.374)\tLoss: 4.6423 (avg: 4.7427)\tTop1: 6.250 (avg: 4.250)\tTop5: 15.625 (avg: 15.188)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.374 (avg: 0.379)\tLoss: 4.7134 (avg: 4.7520)\tTop1: 6.250 (avg: 4.031)\tTop5: 17.188 (avg: 14.781)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.379 (avg: 0.381)\tLoss: 4.6689 (avg: 4.7409)\tTop1: 3.125 (avg: 3.854)\tTop5: 21.875 (avg: 15.125)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.376 (avg: 0.381)\tLoss: 5.0176 (avg: 4.7563)\tTop1: 0.000 (avg: 3.594)\tTop5: 7.812 (avg: 14.531)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.390 (avg: 0.382)\tLoss: 4.8742 (avg: 4.7545)\tTop1: 4.688 (avg: 3.775)\tTop5: 10.938 (avg: 15.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6755\tTop 1 accuracy: 3.600\tTop 5 accuracy: 15.050\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.381 (avg: 0.374)\tLoss: 4.7876 (avg: 4.6587)\tTop1: 0.000 (avg: 4.312)\tTop5: 17.188 (avg: 17.125)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.376 (avg: 0.379)\tLoss: 4.6358 (avg: 4.6757)\tTop1: 3.125 (avg: 4.031)\tTop5: 21.875 (avg: 16.938)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.381 (avg: 0.381)\tLoss: 4.3923 (avg: 4.6955)\tTop1: 10.938 (avg: 4.188)\tTop5: 20.312 (avg: 16.688)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.385 (avg: 0.381)\tLoss: 4.4762 (avg: 4.6936)\tTop1: 9.375 (avg: 4.391)\tTop5: 21.875 (avg: 16.719)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.374 (avg: 0.382)\tLoss: 4.6326 (avg: 4.6918)\tTop1: 1.562 (avg: 4.400)\tTop5: 14.062 (avg: 16.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6346\tTop 1 accuracy: 3.950\tTop 5 accuracy: 15.950\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.373 (avg: 0.374)\tLoss: 4.6215 (avg: 4.6541)\tTop1: 3.125 (avg: 5.062)\tTop5: 18.750 (avg: 18.688)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.376 (avg: 0.379)\tLoss: 4.7883 (avg: 4.6784)\tTop1: 3.125 (avg: 5.031)\tTop5: 7.812 (avg: 17.906)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.371 (avg: 0.380)\tLoss: 4.6744 (avg: 4.6885)\tTop1: 9.375 (avg: 4.812)\tTop5: 20.312 (avg: 17.479)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.376 (avg: 0.380)\tLoss: 4.7036 (avg: 4.6751)\tTop1: 4.688 (avg: 4.703)\tTop5: 21.875 (avg: 17.641)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.376 (avg: 0.380)\tLoss: 4.6032 (avg: 4.6664)\tTop1: 3.125 (avg: 4.738)\tTop5: 17.188 (avg: 17.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4581\tTop 1 accuracy: 3.600\tTop 5 accuracy: 15.750\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.382 (avg: 0.374)\tLoss: 4.3612 (avg: 4.5889)\tTop1: 7.812 (avg: 5.312)\tTop5: 17.188 (avg: 17.688)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.376 (avg: 0.379)\tLoss: 4.4045 (avg: 4.6175)\tTop1: 12.500 (avg: 4.969)\tTop5: 23.438 (avg: 17.906)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.377 (avg: 0.381)\tLoss: 4.4181 (avg: 4.6022)\tTop1: 4.688 (avg: 5.250)\tTop5: 20.312 (avg: 17.979)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.381 (avg: 0.381)\tLoss: 4.5207 (avg: 4.5964)\tTop1: 3.125 (avg: 5.203)\tTop5: 23.438 (avg: 18.172)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.376 (avg: 0.382)\tLoss: 4.4574 (avg: 4.5966)\tTop1: 7.812 (avg: 5.275)\tTop5: 26.562 (avg: 18.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8142\tTop 1 accuracy: 4.500\tTop 5 accuracy: 16.850\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.376 (avg: 0.375)\tLoss: 4.7255 (avg: 4.5078)\tTop1: 1.562 (avg: 5.688)\tTop5: 10.938 (avg: 20.625)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.371 (avg: 0.379)\tLoss: 4.8580 (avg: 4.5561)\tTop1: 1.562 (avg: 5.250)\tTop5: 10.938 (avg: 19.219)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.383 (avg: 0.381)\tLoss: 4.4123 (avg: 4.5646)\tTop1: 7.812 (avg: 5.250)\tTop5: 21.875 (avg: 18.979)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.380 (avg: 0.381)\tLoss: 4.4996 (avg: 4.5711)\tTop1: 1.562 (avg: 5.141)\tTop5: 18.750 (avg: 18.656)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.380 (avg: 0.381)\tLoss: 4.5047 (avg: 4.5747)\tTop1: 4.688 (avg: 5.263)\tTop5: 21.875 (avg: 18.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5232\tTop 1 accuracy: 4.800\tTop 5 accuracy: 17.300\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.384 (avg: 0.374)\tLoss: 4.7905 (avg: 4.5237)\tTop1: 3.125 (avg: 5.875)\tTop5: 9.375 (avg: 20.750)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.375 (avg: 0.379)\tLoss: 4.4212 (avg: 4.5185)\tTop1: 7.812 (avg: 5.969)\tTop5: 20.312 (avg: 20.250)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.376 (avg: 0.381)\tLoss: 4.5407 (avg: 4.5249)\tTop1: 4.688 (avg: 6.104)\tTop5: 17.188 (avg: 19.938)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.383 (avg: 0.382)\tLoss: 4.5373 (avg: 4.5255)\tTop1: 6.250 (avg: 6.141)\tTop5: 23.438 (avg: 20.031)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.375 (avg: 0.382)\tLoss: 4.4827 (avg: 4.5255)\tTop1: 7.812 (avg: 6.025)\tTop5: 20.312 (avg: 20.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6054\tTop 1 accuracy: 6.100\tTop 5 accuracy: 18.650\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.375 (avg: 0.374)\tLoss: 4.7247 (avg: 4.4586)\tTop1: 1.562 (avg: 6.750)\tTop5: 17.188 (avg: 21.625)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.371 (avg: 0.379)\tLoss: 4.6483 (avg: 4.4703)\tTop1: 7.812 (avg: 6.406)\tTop5: 15.625 (avg: 21.406)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.383 (avg: 0.381)\tLoss: 4.7815 (avg: 4.4622)\tTop1: 6.250 (avg: 6.333)\tTop5: 18.750 (avg: 21.688)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.377 (avg: 0.382)\tLoss: 4.7047 (avg: 4.4884)\tTop1: 9.375 (avg: 6.094)\tTop5: 20.312 (avg: 21.344)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.382 (avg: 0.382)\tLoss: 4.4221 (avg: 4.4924)\tTop1: 1.562 (avg: 6.125)\tTop5: 17.188 (avg: 20.813)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5110\tTop 1 accuracy: 5.000\tTop 5 accuracy: 18.550\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.379 (avg: 0.374)\tLoss: 4.3223 (avg: 4.4592)\tTop1: 7.812 (avg: 6.312)\tTop5: 26.562 (avg: 21.062)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.377 (avg: 0.379)\tLoss: 4.3896 (avg: 4.4883)\tTop1: 6.250 (avg: 6.094)\tTop5: 21.875 (avg: 20.188)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.375 (avg: 0.381)\tLoss: 4.5557 (avg: 4.4894)\tTop1: 4.688 (avg: 6.083)\tTop5: 20.312 (avg: 20.062)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.384 (avg: 0.381)\tLoss: 4.5270 (avg: 4.4765)\tTop1: 3.125 (avg: 6.234)\tTop5: 20.312 (avg: 20.500)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.374 (avg: 0.382)\tLoss: 4.6306 (avg: 4.4834)\tTop1: 9.375 (avg: 6.338)\tTop5: 14.062 (avg: 20.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5450\tTop 1 accuracy: 6.350\tTop 5 accuracy: 20.600\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.373 (avg: 0.372)\tLoss: 4.6468 (avg: 4.3534)\tTop1: 7.812 (avg: 8.875)\tTop5: 23.438 (avg: 25.812)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.375 (avg: 0.378)\tLoss: 4.3604 (avg: 4.4058)\tTop1: 7.812 (avg: 7.375)\tTop5: 25.000 (avg: 23.812)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.376 (avg: 0.380)\tLoss: 4.4172 (avg: 4.4079)\tTop1: 10.938 (avg: 7.062)\tTop5: 20.312 (avg: 23.521)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.376 (avg: 0.380)\tLoss: 4.4465 (avg: 4.4351)\tTop1: 6.250 (avg: 6.938)\tTop5: 18.750 (avg: 22.625)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.380 (avg: 0.381)\tLoss: 4.5209 (avg: 4.4326)\tTop1: 3.125 (avg: 6.913)\tTop5: 14.062 (avg: 22.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3072\tTop 1 accuracy: 6.450\tTop 5 accuracy: 21.550\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.383 (avg: 0.373)\tLoss: 4.4515 (avg: 4.4290)\tTop1: 9.375 (avg: 6.625)\tTop5: 23.438 (avg: 23.438)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.373 (avg: 0.378)\tLoss: 4.6970 (avg: 4.4292)\tTop1: 1.562 (avg: 6.406)\tTop5: 20.312 (avg: 23.406)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.376 (avg: 0.380)\tLoss: 4.5224 (avg: 4.4482)\tTop1: 1.562 (avg: 6.250)\tTop5: 14.062 (avg: 22.812)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.377 (avg: 0.381)\tLoss: 4.2824 (avg: 4.4323)\tTop1: 9.375 (avg: 6.562)\tTop5: 18.750 (avg: 23.312)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.376 (avg: 0.381)\tLoss: 4.1406 (avg: 4.4429)\tTop1: 7.812 (avg: 6.538)\tTop5: 37.500 (avg: 23.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4694\tTop 1 accuracy: 6.050\tTop 5 accuracy: 20.300\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.371 (avg: 0.373)\tLoss: 4.1726 (avg: 4.2734)\tTop1: 6.250 (avg: 7.250)\tTop5: 26.562 (avg: 25.625)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.370 (avg: 0.378)\tLoss: 4.1623 (avg: 4.3185)\tTop1: 7.812 (avg: 7.344)\tTop5: 26.562 (avg: 24.344)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.380 (avg: 0.380)\tLoss: 4.3852 (avg: 4.3252)\tTop1: 4.688 (avg: 7.250)\tTop5: 18.750 (avg: 24.708)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.377 (avg: 0.381)\tLoss: 4.6360 (avg: 4.3399)\tTop1: 4.688 (avg: 6.953)\tTop5: 12.500 (avg: 24.562)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.389 (avg: 0.382)\tLoss: 4.1245 (avg: 4.3408)\tTop1: 14.062 (avg: 7.150)\tTop5: 28.125 (avg: 24.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0450\tTop 1 accuracy: 6.400\tTop 5 accuracy: 22.450\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.381 (avg: 0.375)\tLoss: 4.2114 (avg: 4.2302)\tTop1: 12.500 (avg: 9.688)\tTop5: 28.125 (avg: 26.812)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.373 (avg: 0.379)\tLoss: 4.3159 (avg: 4.2431)\tTop1: 6.250 (avg: 8.938)\tTop5: 20.312 (avg: 26.531)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.379 (avg: 0.381)\tLoss: 4.3179 (avg: 4.2692)\tTop1: 1.562 (avg: 8.271)\tTop5: 23.438 (avg: 26.146)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.379 (avg: 0.381)\tLoss: 4.2565 (avg: 4.2974)\tTop1: 7.812 (avg: 8.000)\tTop5: 21.875 (avg: 25.703)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.373 (avg: 0.382)\tLoss: 4.3986 (avg: 4.3108)\tTop1: 6.250 (avg: 7.938)\tTop5: 21.875 (avg: 25.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2052\tTop 1 accuracy: 6.450\tTop 5 accuracy: 22.800\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.376 (avg: 0.375)\tLoss: 4.3421 (avg: 4.1796)\tTop1: 4.688 (avg: 9.562)\tTop5: 25.000 (avg: 28.688)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.370 (avg: 0.379)\tLoss: 3.7012 (avg: 4.1094)\tTop1: 17.188 (avg: 10.688)\tTop5: 43.750 (avg: 30.938)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.379 (avg: 0.381)\tLoss: 4.3011 (avg: 4.0879)\tTop1: 7.812 (avg: 11.292)\tTop5: 29.688 (avg: 31.167)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.374 (avg: 0.381)\tLoss: 3.8416 (avg: 4.0735)\tTop1: 17.188 (avg: 11.469)\tTop5: 42.188 (avg: 31.609)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.375 (avg: 0.382)\tLoss: 3.9480 (avg: 4.0736)\tTop1: 15.625 (avg: 11.450)\tTop5: 35.938 (avg: 31.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9478\tTop 1 accuracy: 9.350\tTop 5 accuracy: 26.650\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.386 (avg: 0.375)\tLoss: 3.7813 (avg: 3.9354)\tTop1: 10.938 (avg: 13.500)\tTop5: 29.688 (avg: 36.125)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.367 (avg: 0.377)\tLoss: 4.2943 (avg: 3.9511)\tTop1: 6.250 (avg: 13.125)\tTop5: 23.438 (avg: 35.312)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.374 (avg: 0.378)\tLoss: 3.9918 (avg: 3.9763)\tTop1: 14.062 (avg: 13.312)\tTop5: 32.812 (avg: 34.917)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.383 (avg: 0.379)\tLoss: 3.8949 (avg: 3.9787)\tTop1: 15.625 (avg: 13.234)\tTop5: 37.500 (avg: 34.828)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.374 (avg: 0.380)\tLoss: 4.1733 (avg: 3.9900)\tTop1: 9.375 (avg: 13.075)\tTop5: 34.375 (avg: 34.325)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9603\tTop 1 accuracy: 9.100\tTop 5 accuracy: 27.900\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.374 (avg: 0.375)\tLoss: 4.2175 (avg: 4.0223)\tTop1: 7.812 (avg: 12.688)\tTop5: 23.438 (avg: 32.688)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.372 (avg: 0.380)\tLoss: 3.9522 (avg: 3.9900)\tTop1: 12.500 (avg: 13.000)\tTop5: 37.500 (avg: 34.000)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.381 (avg: 0.381)\tLoss: 4.0022 (avg: 3.9897)\tTop1: 18.750 (avg: 13.167)\tTop5: 31.250 (avg: 34.562)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.378 (avg: 0.382)\tLoss: 3.9295 (avg: 3.9842)\tTop1: 14.062 (avg: 12.984)\tTop5: 39.062 (avg: 34.484)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.385 (avg: 0.382)\tLoss: 4.0005 (avg: 3.9727)\tTop1: 17.188 (avg: 13.188)\tTop5: 35.938 (avg: 34.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8380\tTop 1 accuracy: 10.100\tTop 5 accuracy: 28.150\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.385 (avg: 0.375)\tLoss: 3.9311 (avg: 3.9348)\tTop1: 9.375 (avg: 13.812)\tTop5: 32.812 (avg: 34.250)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.375 (avg: 0.378)\tLoss: 4.0858 (avg: 3.9500)\tTop1: 7.812 (avg: 13.312)\tTop5: 32.812 (avg: 34.656)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.372 (avg: 0.380)\tLoss: 3.7597 (avg: 3.9466)\tTop1: 12.500 (avg: 12.958)\tTop5: 40.625 (avg: 34.792)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.377 (avg: 0.381)\tLoss: 4.1880 (avg: 3.9653)\tTop1: 12.500 (avg: 13.281)\tTop5: 26.562 (avg: 34.828)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.372 (avg: 0.381)\tLoss: 3.9684 (avg: 3.9617)\tTop1: 14.062 (avg: 13.463)\tTop5: 37.500 (avg: 34.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8503\tTop 1 accuracy: 9.900\tTop 5 accuracy: 29.150\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.375 (avg: 0.374)\tLoss: 4.1605 (avg: 3.9449)\tTop1: 15.625 (avg: 13.375)\tTop5: 26.562 (avg: 36.625)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.378 (avg: 0.379)\tLoss: 4.1643 (avg: 3.9336)\tTop1: 17.188 (avg: 13.719)\tTop5: 28.125 (avg: 35.344)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.378 (avg: 0.380)\tLoss: 3.8936 (avg: 3.9256)\tTop1: 12.500 (avg: 14.500)\tTop5: 42.188 (avg: 36.271)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.377 (avg: 0.381)\tLoss: 4.4844 (avg: 3.9401)\tTop1: 9.375 (avg: 14.031)\tTop5: 29.688 (avg: 35.641)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.385 (avg: 0.382)\tLoss: 3.8044 (avg: 3.9468)\tTop1: 9.375 (avg: 13.625)\tTop5: 32.812 (avg: 35.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8996\tTop 1 accuracy: 9.350\tTop 5 accuracy: 27.400\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.383 (avg: 0.374)\tLoss: 3.6214 (avg: 3.8946)\tTop1: 20.312 (avg: 14.688)\tTop5: 42.188 (avg: 37.312)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.380 (avg: 0.379)\tLoss: 3.6835 (avg: 3.8995)\tTop1: 14.062 (avg: 14.062)\tTop5: 34.375 (avg: 36.562)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.373 (avg: 0.380)\tLoss: 3.8994 (avg: 3.9178)\tTop1: 14.062 (avg: 13.896)\tTop5: 34.375 (avg: 36.208)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.382 (avg: 0.381)\tLoss: 3.8413 (avg: 3.9235)\tTop1: 9.375 (avg: 13.812)\tTop5: 39.062 (avg: 36.016)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.381 (avg: 0.381)\tLoss: 3.7676 (avg: 3.9338)\tTop1: 17.188 (avg: 13.800)\tTop5: 40.625 (avg: 35.625)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8454\tTop 1 accuracy: 10.350\tTop 5 accuracy: 28.000\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.373 (avg: 0.374)\tLoss: 4.0697 (avg: 3.8904)\tTop1: 12.500 (avg: 14.438)\tTop5: 32.812 (avg: 36.812)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.380 (avg: 0.379)\tLoss: 3.5858 (avg: 3.8849)\tTop1: 21.875 (avg: 14.094)\tTop5: 40.625 (avg: 36.250)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.375 (avg: 0.381)\tLoss: 4.3953 (avg: 3.9196)\tTop1: 15.625 (avg: 13.729)\tTop5: 25.000 (avg: 35.646)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.374 (avg: 0.382)\tLoss: 3.8414 (avg: 3.9149)\tTop1: 15.625 (avg: 14.094)\tTop5: 37.500 (avg: 35.609)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.378 (avg: 0.382)\tLoss: 3.8588 (avg: 3.9252)\tTop1: 14.062 (avg: 14.100)\tTop5: 35.938 (avg: 35.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7852\tTop 1 accuracy: 9.900\tTop 5 accuracy: 28.100\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.379 (avg: 0.375)\tLoss: 3.9249 (avg: 3.8660)\tTop1: 14.062 (avg: 15.688)\tTop5: 31.250 (avg: 36.812)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.373 (avg: 0.379)\tLoss: 3.6949 (avg: 3.8910)\tTop1: 18.750 (avg: 14.875)\tTop5: 50.000 (avg: 36.312)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.372 (avg: 0.381)\tLoss: 4.0006 (avg: 3.9059)\tTop1: 18.750 (avg: 14.604)\tTop5: 29.688 (avg: 36.271)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.383 (avg: 0.382)\tLoss: 3.8563 (avg: 3.9023)\tTop1: 18.750 (avg: 14.594)\tTop5: 32.812 (avg: 36.125)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.374 (avg: 0.382)\tLoss: 3.9800 (avg: 3.9110)\tTop1: 10.938 (avg: 14.450)\tTop5: 28.125 (avg: 35.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7051\tTop 1 accuracy: 10.200\tTop 5 accuracy: 28.750\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.374 (avg: 0.374)\tLoss: 4.1820 (avg: 3.9215)\tTop1: 9.375 (avg: 13.312)\tTop5: 23.438 (avg: 37.062)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.379 (avg: 0.379)\tLoss: 3.9240 (avg: 3.8950)\tTop1: 17.188 (avg: 14.125)\tTop5: 40.625 (avg: 37.531)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.382 (avg: 0.380)\tLoss: 3.8583 (avg: 3.8945)\tTop1: 9.375 (avg: 14.146)\tTop5: 39.062 (avg: 36.604)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.375 (avg: 0.380)\tLoss: 3.6867 (avg: 3.8825)\tTop1: 26.562 (avg: 14.453)\tTop5: 46.875 (avg: 36.953)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.380 (avg: 0.381)\tLoss: 3.8857 (avg: 3.8962)\tTop1: 18.750 (avg: 14.363)\tTop5: 34.375 (avg: 36.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8404\tTop 1 accuracy: 10.450\tTop 5 accuracy: 27.950\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.380 (avg: 0.375)\tLoss: 3.8735 (avg: 3.8552)\tTop1: 15.625 (avg: 14.688)\tTop5: 39.062 (avg: 38.938)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.374 (avg: 0.380)\tLoss: 3.7939 (avg: 3.8730)\tTop1: 15.625 (avg: 14.375)\tTop5: 39.062 (avg: 37.719)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.377 (avg: 0.381)\tLoss: 3.8021 (avg: 3.8869)\tTop1: 15.625 (avg: 13.896)\tTop5: 43.750 (avg: 37.146)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.374 (avg: 0.382)\tLoss: 3.7810 (avg: 3.8788)\tTop1: 23.438 (avg: 14.250)\tTop5: 39.062 (avg: 36.984)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.375 (avg: 0.382)\tLoss: 3.7636 (avg: 3.8817)\tTop1: 15.625 (avg: 14.188)\tTop5: 40.625 (avg: 36.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7875\tTop 1 accuracy: 10.250\tTop 5 accuracy: 28.550\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.375 (avg: 0.375)\tLoss: 3.7087 (avg: 3.8756)\tTop1: 17.188 (avg: 14.438)\tTop5: 39.062 (avg: 36.312)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.380 (avg: 0.380)\tLoss: 4.1025 (avg: 3.8563)\tTop1: 12.500 (avg: 14.688)\tTop5: 34.375 (avg: 37.344)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.375 (avg: 0.381)\tLoss: 3.7115 (avg: 3.8514)\tTop1: 14.062 (avg: 15.042)\tTop5: 40.625 (avg: 37.479)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.373 (avg: 0.382)\tLoss: 4.2350 (avg: 3.8621)\tTop1: 21.875 (avg: 14.609)\tTop5: 37.500 (avg: 37.016)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.386 (avg: 0.382)\tLoss: 3.6823 (avg: 3.8699)\tTop1: 15.625 (avg: 14.488)\tTop5: 48.438 (avg: 36.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8227\tTop 1 accuracy: 10.050\tTop 5 accuracy: 28.300\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.381 (avg: 0.374)\tLoss: 3.4261 (avg: 3.8058)\tTop1: 17.188 (avg: 15.188)\tTop5: 43.750 (avg: 38.562)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.384 (avg: 0.379)\tLoss: 3.9516 (avg: 3.8384)\tTop1: 7.812 (avg: 14.781)\tTop5: 45.312 (avg: 38.125)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.369 (avg: 0.381)\tLoss: 3.8513 (avg: 3.8326)\tTop1: 14.062 (avg: 15.042)\tTop5: 39.062 (avg: 38.271)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.383 (avg: 0.382)\tLoss: 3.9994 (avg: 3.8599)\tTop1: 15.625 (avg: 14.859)\tTop5: 32.812 (avg: 37.328)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.381 (avg: 0.382)\tLoss: 4.1282 (avg: 3.8633)\tTop1: 12.500 (avg: 14.638)\tTop5: 37.500 (avg: 37.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8447\tTop 1 accuracy: 10.300\tTop 5 accuracy: 28.550\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.367 (avg: 0.375)\tLoss: 3.9067 (avg: 3.8160)\tTop1: 10.938 (avg: 16.688)\tTop5: 31.250 (avg: 38.875)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.372 (avg: 0.377)\tLoss: 3.9315 (avg: 3.8397)\tTop1: 14.062 (avg: 15.625)\tTop5: 37.500 (avg: 38.688)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.378 (avg: 0.379)\tLoss: 3.7241 (avg: 3.8294)\tTop1: 15.625 (avg: 15.354)\tTop5: 39.062 (avg: 38.938)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.377 (avg: 0.381)\tLoss: 3.8113 (avg: 3.8399)\tTop1: 20.312 (avg: 15.031)\tTop5: 42.188 (avg: 38.641)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.384 (avg: 0.381)\tLoss: 3.9444 (avg: 3.8509)\tTop1: 18.750 (avg: 14.975)\tTop5: 39.062 (avg: 38.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7939\tTop 1 accuracy: 11.050\tTop 5 accuracy: 28.800\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.382 (avg: 0.375)\tLoss: 3.5404 (avg: 3.7496)\tTop1: 21.875 (avg: 17.250)\tTop5: 46.875 (avg: 40.438)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.376 (avg: 0.379)\tLoss: 4.1732 (avg: 3.8130)\tTop1: 14.062 (avg: 16.344)\tTop5: 26.562 (avg: 39.375)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.382 (avg: 0.381)\tLoss: 3.9325 (avg: 3.8337)\tTop1: 12.500 (avg: 15.562)\tTop5: 32.812 (avg: 38.438)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.378 (avg: 0.382)\tLoss: 4.1280 (avg: 3.8344)\tTop1: 10.938 (avg: 15.188)\tTop5: 29.688 (avg: 38.406)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.375 (avg: 0.382)\tLoss: 3.9981 (avg: 3.8389)\tTop1: 14.062 (avg: 15.088)\tTop5: 37.500 (avg: 38.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9201\tTop 1 accuracy: 10.400\tTop 5 accuracy: 29.250\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.381 (avg: 0.375)\tLoss: 4.0019 (avg: 3.8197)\tTop1: 7.812 (avg: 14.688)\tTop5: 28.125 (avg: 39.375)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.372 (avg: 0.379)\tLoss: 4.0274 (avg: 3.7990)\tTop1: 15.625 (avg: 15.969)\tTop5: 32.812 (avg: 39.219)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.377 (avg: 0.381)\tLoss: 3.9241 (avg: 3.8076)\tTop1: 14.062 (avg: 15.771)\tTop5: 37.500 (avg: 38.896)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.374 (avg: 0.381)\tLoss: 4.0286 (avg: 3.8280)\tTop1: 17.188 (avg: 15.422)\tTop5: 35.938 (avg: 38.219)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.387 (avg: 0.382)\tLoss: 3.9779 (avg: 3.8281)\tTop1: 7.812 (avg: 15.325)\tTop5: 37.500 (avg: 38.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8902\tTop 1 accuracy: 10.750\tTop 5 accuracy: 28.600\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.377 (avg: 0.374)\tLoss: 3.7843 (avg: 3.8044)\tTop1: 9.375 (avg: 14.875)\tTop5: 35.938 (avg: 37.875)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.376 (avg: 0.379)\tLoss: 3.8750 (avg: 3.7992)\tTop1: 7.812 (avg: 15.031)\tTop5: 32.812 (avg: 37.844)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.375 (avg: 0.381)\tLoss: 3.9805 (avg: 3.7940)\tTop1: 12.500 (avg: 15.604)\tTop5: 40.625 (avg: 38.688)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.380 (avg: 0.382)\tLoss: 3.9727 (avg: 3.8194)\tTop1: 14.062 (avg: 15.672)\tTop5: 29.688 (avg: 38.125)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.376 (avg: 0.382)\tLoss: 4.0080 (avg: 3.8210)\tTop1: 15.625 (avg: 15.675)\tTop5: 35.938 (avg: 37.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8635\tTop 1 accuracy: 11.050\tTop 5 accuracy: 29.450\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.377 (avg: 0.375)\tLoss: 3.9129 (avg: 3.7627)\tTop1: 17.188 (avg: 16.250)\tTop5: 34.375 (avg: 39.688)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.370 (avg: 0.379)\tLoss: 3.6097 (avg: 3.7782)\tTop1: 10.938 (avg: 15.594)\tTop5: 46.875 (avg: 39.969)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.382 (avg: 0.381)\tLoss: 4.1229 (avg: 3.7727)\tTop1: 10.938 (avg: 15.771)\tTop5: 31.250 (avg: 39.479)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.377 (avg: 0.382)\tLoss: 3.8864 (avg: 3.7802)\tTop1: 12.500 (avg: 15.875)\tTop5: 45.312 (avg: 39.406)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.381 (avg: 0.382)\tLoss: 4.0892 (avg: 3.8019)\tTop1: 14.062 (avg: 15.538)\tTop5: 34.375 (avg: 38.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6424\tTop 1 accuracy: 10.400\tTop 5 accuracy: 29.950\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.378 (avg: 0.374)\tLoss: 3.6921 (avg: 3.7178)\tTop1: 26.562 (avg: 16.125)\tTop5: 40.625 (avg: 41.312)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.376 (avg: 0.378)\tLoss: 3.9967 (avg: 3.8003)\tTop1: 12.500 (avg: 15.156)\tTop5: 35.938 (avg: 39.188)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.382 (avg: 0.380)\tLoss: 3.8231 (avg: 3.7739)\tTop1: 12.500 (avg: 15.521)\tTop5: 37.500 (avg: 39.917)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.379 (avg: 0.381)\tLoss: 3.6931 (avg: 3.7897)\tTop1: 15.625 (avg: 15.734)\tTop5: 37.500 (avg: 39.578)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.383 (avg: 0.381)\tLoss: 3.6594 (avg: 3.7980)\tTop1: 14.062 (avg: 15.388)\tTop5: 42.188 (avg: 39.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8129\tTop 1 accuracy: 11.150\tTop 5 accuracy: 30.100\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.368 (avg: 0.373)\tLoss: 3.8281 (avg: 3.7939)\tTop1: 21.875 (avg: 16.312)\tTop5: 42.188 (avg: 38.688)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.380 (avg: 0.378)\tLoss: 4.0425 (avg: 3.8024)\tTop1: 10.938 (avg: 15.531)\tTop5: 34.375 (avg: 37.875)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.374 (avg: 0.380)\tLoss: 3.8199 (avg: 3.7840)\tTop1: 17.188 (avg: 15.625)\tTop5: 32.812 (avg: 38.667)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.374 (avg: 0.381)\tLoss: 3.9245 (avg: 3.7781)\tTop1: 10.938 (avg: 15.703)\tTop5: 32.812 (avg: 38.859)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.388 (avg: 0.382)\tLoss: 3.9195 (avg: 3.7902)\tTop1: 14.062 (avg: 15.488)\tTop5: 37.500 (avg: 38.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7496\tTop 1 accuracy: 10.550\tTop 5 accuracy: 28.700\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.382 (avg: 0.376)\tLoss: 3.4157 (avg: 3.7378)\tTop1: 20.312 (avg: 15.750)\tTop5: 53.125 (avg: 40.438)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.374 (avg: 0.378)\tLoss: 3.8585 (avg: 3.7557)\tTop1: 18.750 (avg: 16.250)\tTop5: 39.062 (avg: 40.219)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.377 (avg: 0.380)\tLoss: 3.9529 (avg: 3.7710)\tTop1: 14.062 (avg: 15.896)\tTop5: 39.062 (avg: 39.729)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.386 (avg: 0.381)\tLoss: 3.5363 (avg: 3.7706)\tTop1: 28.125 (avg: 15.812)\tTop5: 43.750 (avg: 39.469)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.381 (avg: 0.382)\tLoss: 3.5603 (avg: 3.7711)\tTop1: 18.750 (avg: 15.950)\tTop5: 45.312 (avg: 39.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6753\tTop 1 accuracy: 11.550\tTop 5 accuracy: 29.100\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.375 (avg: 0.374)\tLoss: 3.7761 (avg: 3.7256)\tTop1: 10.938 (avg: 15.312)\tTop5: 32.812 (avg: 41.375)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.376 (avg: 0.379)\tLoss: 4.0232 (avg: 3.7404)\tTop1: 15.625 (avg: 15.406)\tTop5: 42.188 (avg: 40.219)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.381 (avg: 0.381)\tLoss: 4.0456 (avg: 3.7526)\tTop1: 12.500 (avg: 15.354)\tTop5: 35.938 (avg: 39.854)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.372 (avg: 0.382)\tLoss: 3.8194 (avg: 3.7664)\tTop1: 10.938 (avg: 15.641)\tTop5: 39.062 (avg: 39.688)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.385 (avg: 0.382)\tLoss: 3.7972 (avg: 3.7629)\tTop1: 15.625 (avg: 15.713)\tTop5: 29.688 (avg: 39.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8029\tTop 1 accuracy: 11.100\tTop 5 accuracy: 29.950\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.380 (avg: 0.375)\tLoss: 3.4867 (avg: 3.7631)\tTop1: 25.000 (avg: 17.000)\tTop5: 42.188 (avg: 41.125)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.375 (avg: 0.380)\tLoss: 3.7462 (avg: 3.7685)\tTop1: 23.438 (avg: 17.188)\tTop5: 43.750 (avg: 40.656)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.377 (avg: 0.381)\tLoss: 3.9162 (avg: 3.7487)\tTop1: 20.312 (avg: 17.083)\tTop5: 32.812 (avg: 40.896)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.379 (avg: 0.382)\tLoss: 4.0151 (avg: 3.7462)\tTop1: 12.500 (avg: 16.906)\tTop5: 31.250 (avg: 40.844)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.378 (avg: 0.383)\tLoss: 3.8827 (avg: 3.7585)\tTop1: 15.625 (avg: 16.450)\tTop5: 37.500 (avg: 40.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6757\tTop 1 accuracy: 11.350\tTop 5 accuracy: 29.250\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.374 (avg: 0.375)\tLoss: 3.4689 (avg: 3.7317)\tTop1: 21.875 (avg: 17.875)\tTop5: 50.000 (avg: 41.438)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.372 (avg: 0.379)\tLoss: 3.5972 (avg: 3.7293)\tTop1: 17.188 (avg: 17.688)\tTop5: 42.188 (avg: 41.094)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.377 (avg: 0.380)\tLoss: 3.5436 (avg: 3.7383)\tTop1: 18.750 (avg: 17.167)\tTop5: 53.125 (avg: 41.083)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.374 (avg: 0.381)\tLoss: 3.8035 (avg: 3.7421)\tTop1: 28.125 (avg: 17.031)\tTop5: 43.750 (avg: 40.625)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.381 (avg: 0.382)\tLoss: 3.8416 (avg: 3.7370)\tTop1: 12.500 (avg: 17.038)\tTop5: 35.938 (avg: 40.813)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7219\tTop 1 accuracy: 10.650\tTop 5 accuracy: 30.050\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.378 (avg: 0.370)\tLoss: 3.7752 (avg: 3.7405)\tTop1: 23.438 (avg: 16.688)\tTop5: 45.312 (avg: 39.125)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.377 (avg: 0.377)\tLoss: 3.3610 (avg: 3.7214)\tTop1: 23.438 (avg: 17.562)\tTop5: 43.750 (avg: 39.688)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.378 (avg: 0.379)\tLoss: 3.6763 (avg: 3.7274)\tTop1: 17.188 (avg: 16.938)\tTop5: 46.875 (avg: 40.125)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.377 (avg: 0.380)\tLoss: 3.3600 (avg: 3.7152)\tTop1: 18.750 (avg: 17.000)\tTop5: 48.438 (avg: 40.266)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.381 (avg: 0.381)\tLoss: 3.4507 (avg: 3.7280)\tTop1: 18.750 (avg: 16.863)\tTop5: 45.312 (avg: 40.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5550\tTop 1 accuracy: 11.600\tTop 5 accuracy: 29.450\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.374 (avg: 0.374)\tLoss: 3.7332 (avg: 3.6962)\tTop1: 23.438 (avg: 16.625)\tTop5: 46.875 (avg: 41.875)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.370 (avg: 0.379)\tLoss: 3.7809 (avg: 3.6835)\tTop1: 15.625 (avg: 17.500)\tTop5: 32.812 (avg: 42.000)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.375 (avg: 0.381)\tLoss: 3.8998 (avg: 3.7076)\tTop1: 9.375 (avg: 17.250)\tTop5: 40.625 (avg: 41.542)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.378 (avg: 0.381)\tLoss: 3.6366 (avg: 3.7118)\tTop1: 17.188 (avg: 16.859)\tTop5: 35.938 (avg: 41.000)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.384 (avg: 0.382)\tLoss: 3.7804 (avg: 3.7168)\tTop1: 20.312 (avg: 16.888)\tTop5: 43.750 (avg: 40.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6992\tTop 1 accuracy: 11.350\tTop 5 accuracy: 29.350\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.387 (avg: 0.375)\tLoss: 3.8170 (avg: 3.6804)\tTop1: 14.062 (avg: 17.062)\tTop5: 40.625 (avg: 43.000)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.377 (avg: 0.380)\tLoss: 3.7812 (avg: 3.6333)\tTop1: 14.062 (avg: 17.812)\tTop5: 43.750 (avg: 42.906)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.376 (avg: 0.382)\tLoss: 3.4909 (avg: 3.6619)\tTop1: 18.750 (avg: 17.562)\tTop5: 43.750 (avg: 42.271)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.387 (avg: 0.382)\tLoss: 3.5846 (avg: 3.6922)\tTop1: 12.500 (avg: 16.953)\tTop5: 39.062 (avg: 41.266)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.377 (avg: 0.383)\tLoss: 3.4821 (avg: 3.6968)\tTop1: 21.875 (avg: 17.250)\tTop5: 50.000 (avg: 41.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5339\tTop 1 accuracy: 11.000\tTop 5 accuracy: 29.000\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.373 (avg: 0.375)\tLoss: 3.7918 (avg: 3.6497)\tTop1: 21.875 (avg: 19.312)\tTop5: 45.312 (avg: 42.938)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.379 (avg: 0.379)\tLoss: 3.5215 (avg: 3.6715)\tTop1: 23.438 (avg: 18.469)\tTop5: 46.875 (avg: 41.844)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.374 (avg: 0.381)\tLoss: 3.6933 (avg: 3.6573)\tTop1: 18.750 (avg: 18.312)\tTop5: 37.500 (avg: 41.604)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.375 (avg: 0.381)\tLoss: 3.5958 (avg: 3.6615)\tTop1: 20.312 (avg: 18.156)\tTop5: 37.500 (avg: 41.562)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.383 (avg: 0.382)\tLoss: 3.9072 (avg: 3.6819)\tTop1: 21.875 (avg: 17.812)\tTop5: 37.500 (avg: 41.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0124\tTop 1 accuracy: 11.150\tTop 5 accuracy: 28.950\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.383 (avg: 0.375)\tLoss: 3.6500 (avg: 3.6195)\tTop1: 9.375 (avg: 18.000)\tTop5: 43.750 (avg: 44.375)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.376 (avg: 0.380)\tLoss: 4.0945 (avg: 3.6474)\tTop1: 15.625 (avg: 17.469)\tTop5: 32.812 (avg: 42.906)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.377 (avg: 0.381)\tLoss: 3.9199 (avg: 3.6660)\tTop1: 15.625 (avg: 17.562)\tTop5: 39.062 (avg: 42.271)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.392 (avg: 0.382)\tLoss: 3.5303 (avg: 3.6706)\tTop1: 26.562 (avg: 17.422)\tTop5: 43.750 (avg: 42.000)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.373 (avg: 0.383)\tLoss: 3.6757 (avg: 3.6827)\tTop1: 17.188 (avg: 17.312)\tTop5: 37.500 (avg: 41.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6535\tTop 1 accuracy: 11.700\tTop 5 accuracy: 30.250\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.374 (avg: 0.375)\tLoss: 3.6046 (avg: 3.6093)\tTop1: 20.312 (avg: 19.375)\tTop5: 45.312 (avg: 43.562)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.383 (avg: 0.380)\tLoss: 3.2019 (avg: 3.6393)\tTop1: 29.688 (avg: 19.125)\tTop5: 51.562 (avg: 42.781)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.367 (avg: 0.380)\tLoss: 3.8487 (avg: 3.6229)\tTop1: 10.938 (avg: 18.688)\tTop5: 35.938 (avg: 43.188)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.379 (avg: 0.381)\tLoss: 3.8679 (avg: 3.6416)\tTop1: 15.625 (avg: 18.062)\tTop5: 35.938 (avg: 42.359)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.378 (avg: 0.381)\tLoss: 3.7629 (avg: 3.6631)\tTop1: 14.062 (avg: 17.613)\tTop5: 45.312 (avg: 42.063)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7546\tTop 1 accuracy: 11.250\tTop 5 accuracy: 30.300\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.379 (avg: 0.376)\tLoss: 3.4928 (avg: 3.6217)\tTop1: 28.125 (avg: 18.125)\tTop5: 53.125 (avg: 40.938)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.376 (avg: 0.381)\tLoss: 3.8079 (avg: 3.6408)\tTop1: 10.938 (avg: 18.562)\tTop5: 39.062 (avg: 41.594)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.378 (avg: 0.382)\tLoss: 3.5831 (avg: 3.6459)\tTop1: 26.562 (avg: 18.604)\tTop5: 46.875 (avg: 41.771)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.385 (avg: 0.382)\tLoss: 3.6260 (avg: 3.6557)\tTop1: 17.188 (avg: 18.297)\tTop5: 40.625 (avg: 41.453)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.372 (avg: 0.382)\tLoss: 3.5180 (avg: 3.6556)\tTop1: 17.188 (avg: 18.150)\tTop5: 46.875 (avg: 41.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6942\tTop 1 accuracy: 11.650\tTop 5 accuracy: 30.900\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.381 (avg: 0.376)\tLoss: 3.7918 (avg: 3.5971)\tTop1: 15.625 (avg: 18.562)\tTop5: 50.000 (avg: 43.875)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.379 (avg: 0.380)\tLoss: 3.4997 (avg: 3.5639)\tTop1: 17.188 (avg: 19.250)\tTop5: 39.062 (avg: 44.219)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.379 (avg: 0.381)\tLoss: 3.7155 (avg: 3.5604)\tTop1: 25.000 (avg: 19.667)\tTop5: 45.312 (avg: 44.833)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.376 (avg: 0.382)\tLoss: 3.4604 (avg: 3.5509)\tTop1: 21.875 (avg: 20.094)\tTop5: 48.438 (avg: 45.375)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.382 (avg: 0.382)\tLoss: 3.4435 (avg: 3.5527)\tTop1: 18.750 (avg: 20.038)\tTop5: 43.750 (avg: 45.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6280\tTop 1 accuracy: 12.350\tTop 5 accuracy: 31.200\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.385 (avg: 0.375)\tLoss: 3.3203 (avg: 3.4774)\tTop1: 29.688 (avg: 21.375)\tTop5: 46.875 (avg: 45.562)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.373 (avg: 0.380)\tLoss: 3.2004 (avg: 3.5209)\tTop1: 21.875 (avg: 20.438)\tTop5: 59.375 (avg: 45.062)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.378 (avg: 0.381)\tLoss: 3.5579 (avg: 3.5353)\tTop1: 12.500 (avg: 19.938)\tTop5: 46.875 (avg: 45.271)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.382 (avg: 0.382)\tLoss: 3.4687 (avg: 3.5331)\tTop1: 18.750 (avg: 19.922)\tTop5: 51.562 (avg: 45.359)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.377 (avg: 0.383)\tLoss: 3.5420 (avg: 3.5313)\tTop1: 20.312 (avg: 20.413)\tTop5: 42.188 (avg: 45.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6560\tTop 1 accuracy: 12.150\tTop 5 accuracy: 30.650\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.372 (avg: 0.375)\tLoss: 3.8977 (avg: 3.5252)\tTop1: 15.625 (avg: 20.875)\tTop5: 34.375 (avg: 44.250)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.373 (avg: 0.379)\tLoss: 3.8688 (avg: 3.5404)\tTop1: 18.750 (avg: 20.594)\tTop5: 34.375 (avg: 44.375)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.380 (avg: 0.381)\tLoss: 3.3287 (avg: 3.5229)\tTop1: 25.000 (avg: 20.729)\tTop5: 42.188 (avg: 44.896)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.375 (avg: 0.382)\tLoss: 3.7015 (avg: 3.5238)\tTop1: 18.750 (avg: 20.547)\tTop5: 46.875 (avg: 45.188)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.382 (avg: 0.382)\tLoss: 3.9303 (avg: 3.5266)\tTop1: 14.062 (avg: 20.263)\tTop5: 42.188 (avg: 45.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6495\tTop 1 accuracy: 12.500\tTop 5 accuracy: 31.350\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.387 (avg: 0.376)\tLoss: 3.6456 (avg: 3.4666)\tTop1: 17.188 (avg: 20.812)\tTop5: 40.625 (avg: 47.250)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.373 (avg: 0.380)\tLoss: 3.3431 (avg: 3.4837)\tTop1: 26.562 (avg: 20.812)\tTop5: 51.562 (avg: 46.406)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.374 (avg: 0.381)\tLoss: 3.4550 (avg: 3.5061)\tTop1: 23.438 (avg: 20.542)\tTop5: 54.688 (avg: 45.896)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.383 (avg: 0.382)\tLoss: 3.4730 (avg: 3.5189)\tTop1: 20.312 (avg: 20.578)\tTop5: 53.125 (avg: 45.750)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.365 (avg: 0.382)\tLoss: 3.2731 (avg: 3.5221)\tTop1: 25.000 (avg: 20.700)\tTop5: 54.688 (avg: 45.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6633\tTop 1 accuracy: 12.450\tTop 5 accuracy: 30.750\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.372 (avg: 0.375)\tLoss: 3.5357 (avg: 3.4803)\tTop1: 15.625 (avg: 20.875)\tTop5: 43.750 (avg: 46.250)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.374 (avg: 0.379)\tLoss: 3.5635 (avg: 3.4948)\tTop1: 18.750 (avg: 20.688)\tTop5: 42.188 (avg: 45.938)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.376 (avg: 0.380)\tLoss: 3.6311 (avg: 3.5129)\tTop1: 15.625 (avg: 20.458)\tTop5: 48.438 (avg: 45.854)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.374 (avg: 0.381)\tLoss: 3.5846 (avg: 3.5128)\tTop1: 17.188 (avg: 20.438)\tTop5: 35.938 (avg: 45.656)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.387 (avg: 0.382)\tLoss: 3.5760 (avg: 3.5216)\tTop1: 17.188 (avg: 20.238)\tTop5: 43.750 (avg: 45.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5833\tTop 1 accuracy: 12.250\tTop 5 accuracy: 30.750\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.387 (avg: 0.373)\tLoss: 3.7393 (avg: 3.5489)\tTop1: 21.875 (avg: 20.000)\tTop5: 45.312 (avg: 44.875)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.379 (avg: 0.377)\tLoss: 3.5010 (avg: 3.5016)\tTop1: 21.875 (avg: 20.219)\tTop5: 46.875 (avg: 45.750)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.377 (avg: 0.380)\tLoss: 3.2489 (avg: 3.4926)\tTop1: 25.000 (avg: 20.542)\tTop5: 53.125 (avg: 45.917)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.384 (avg: 0.381)\tLoss: 3.4465 (avg: 3.5010)\tTop1: 18.750 (avg: 21.000)\tTop5: 39.062 (avg: 45.734)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.375 (avg: 0.382)\tLoss: 3.4665 (avg: 3.5183)\tTop1: 21.875 (avg: 20.763)\tTop5: 43.750 (avg: 45.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6837\tTop 1 accuracy: 12.950\tTop 5 accuracy: 30.800\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.375 (avg: 0.374)\tLoss: 3.3880 (avg: 3.4688)\tTop1: 28.125 (avg: 22.125)\tTop5: 51.562 (avg: 47.562)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.379 (avg: 0.378)\tLoss: 3.4564 (avg: 3.5091)\tTop1: 23.438 (avg: 21.062)\tTop5: 43.750 (avg: 46.750)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.408 (avg: 0.380)\tLoss: 3.2884 (avg: 3.4997)\tTop1: 29.688 (avg: 21.354)\tTop5: 59.375 (avg: 46.479)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.375 (avg: 0.383)\tLoss: 3.6948 (avg: 3.5112)\tTop1: 17.188 (avg: 21.031)\tTop5: 39.062 (avg: 46.328)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.378 (avg: 0.383)\tLoss: 3.6024 (avg: 3.5089)\tTop1: 20.312 (avg: 20.913)\tTop5: 35.938 (avg: 46.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6925\tTop 1 accuracy: 12.750\tTop 5 accuracy: 31.000\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.388 (avg: 0.374)\tLoss: 3.4912 (avg: 3.5192)\tTop1: 21.875 (avg: 21.000)\tTop5: 40.625 (avg: 45.375)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.420 (avg: 0.392)\tLoss: 3.7167 (avg: 3.5173)\tTop1: 10.938 (avg: 21.094)\tTop5: 37.500 (avg: 45.375)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.393 (avg: 0.399)\tLoss: 3.9054 (avg: 3.5130)\tTop1: 15.625 (avg: 21.000)\tTop5: 35.938 (avg: 45.896)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.424 (avg: 0.403)\tLoss: 3.0268 (avg: 3.5115)\tTop1: 20.312 (avg: 20.766)\tTop5: 54.688 (avg: 45.734)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.375 (avg: 0.401)\tLoss: 3.4570 (avg: 3.5131)\tTop1: 20.312 (avg: 20.925)\tTop5: 51.562 (avg: 45.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6773\tTop 1 accuracy: 12.250\tTop 5 accuracy: 30.950\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.379 (avg: 0.375)\tLoss: 3.4801 (avg: 3.4292)\tTop1: 18.750 (avg: 22.500)\tTop5: 53.125 (avg: 48.062)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.376 (avg: 0.379)\tLoss: 3.5830 (avg: 3.4494)\tTop1: 18.750 (avg: 21.406)\tTop5: 46.875 (avg: 47.750)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.383 (avg: 0.381)\tLoss: 3.9224 (avg: 3.4832)\tTop1: 15.625 (avg: 21.188)\tTop5: 39.062 (avg: 46.250)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.370 (avg: 0.381)\tLoss: 3.6831 (avg: 3.5143)\tTop1: 15.625 (avg: 20.516)\tTop5: 35.938 (avg: 45.406)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.383 (avg: 0.382)\tLoss: 3.5752 (avg: 3.5082)\tTop1: 17.188 (avg: 20.538)\tTop5: 50.000 (avg: 45.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6354\tTop 1 accuracy: 12.350\tTop 5 accuracy: 30.700\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.385 (avg: 0.375)\tLoss: 3.5527 (avg: 3.5094)\tTop1: 20.312 (avg: 20.125)\tTop5: 48.438 (avg: 44.438)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.375 (avg: 0.377)\tLoss: 3.6264 (avg: 3.5076)\tTop1: 23.438 (avg: 20.781)\tTop5: 40.625 (avg: 45.344)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.377 (avg: 0.379)\tLoss: 3.5110 (avg: 3.5109)\tTop1: 21.875 (avg: 21.083)\tTop5: 48.438 (avg: 45.354)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.388 (avg: 0.380)\tLoss: 3.7228 (avg: 3.4877)\tTop1: 20.312 (avg: 21.422)\tTop5: 40.625 (avg: 46.047)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.373 (avg: 0.381)\tLoss: 3.8365 (avg: 3.5025)\tTop1: 10.938 (avg: 21.063)\tTop5: 35.938 (avg: 45.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6758\tTop 1 accuracy: 12.800\tTop 5 accuracy: 31.350\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.373 (avg: 0.374)\tLoss: 3.4640 (avg: 3.5054)\tTop1: 26.562 (avg: 20.562)\tTop5: 50.000 (avg: 46.938)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.378 (avg: 0.379)\tLoss: 3.3057 (avg: 3.4879)\tTop1: 28.125 (avg: 21.344)\tTop5: 46.875 (avg: 46.750)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.376 (avg: 0.380)\tLoss: 3.7076 (avg: 3.5054)\tTop1: 15.625 (avg: 21.167)\tTop5: 35.938 (avg: 46.021)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.381 (avg: 0.381)\tLoss: 3.7209 (avg: 3.5066)\tTop1: 20.312 (avg: 21.125)\tTop5: 43.750 (avg: 46.062)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.378 (avg: 0.381)\tLoss: 3.5334 (avg: 3.4990)\tTop1: 25.000 (avg: 21.163)\tTop5: 46.875 (avg: 46.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6318\tTop 1 accuracy: 12.450\tTop 5 accuracy: 30.650\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.378 (avg: 0.374)\tLoss: 4.0831 (avg: 3.5168)\tTop1: 14.062 (avg: 20.812)\tTop5: 32.812 (avg: 47.188)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.374 (avg: 0.379)\tLoss: 3.5904 (avg: 3.5238)\tTop1: 18.750 (avg: 20.594)\tTop5: 32.812 (avg: 45.875)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.376 (avg: 0.381)\tLoss: 3.5205 (avg: 3.5055)\tTop1: 17.188 (avg: 20.729)\tTop5: 43.750 (avg: 46.396)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.380 (avg: 0.382)\tLoss: 3.8019 (avg: 3.4924)\tTop1: 17.188 (avg: 20.812)\tTop5: 29.688 (avg: 46.578)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.374 (avg: 0.382)\tLoss: 3.3605 (avg: 3.4960)\tTop1: 20.312 (avg: 20.725)\tTop5: 48.438 (avg: 46.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6744\tTop 1 accuracy: 12.200\tTop 5 accuracy: 31.100\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.375 (avg: 0.374)\tLoss: 3.3215 (avg: 3.4698)\tTop1: 20.312 (avg: 20.625)\tTop5: 50.000 (avg: 46.625)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.374 (avg: 0.380)\tLoss: 3.7016 (avg: 3.4876)\tTop1: 14.062 (avg: 21.562)\tTop5: 34.375 (avg: 46.688)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.383 (avg: 0.381)\tLoss: 3.7575 (avg: 3.4869)\tTop1: 18.750 (avg: 21.354)\tTop5: 45.312 (avg: 46.417)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.379 (avg: 0.382)\tLoss: 3.5507 (avg: 3.4976)\tTop1: 25.000 (avg: 21.281)\tTop5: 53.125 (avg: 46.484)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.381 (avg: 0.383)\tLoss: 3.5330 (avg: 3.4973)\tTop1: 15.625 (avg: 20.838)\tTop5: 48.438 (avg: 46.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6558\tTop 1 accuracy: 12.400\tTop 5 accuracy: 30.950\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.383 (avg: 0.375)\tLoss: 3.8566 (avg: 3.4190)\tTop1: 17.188 (avg: 22.438)\tTop5: 34.375 (avg: 47.688)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.369 (avg: 0.380)\tLoss: 3.5189 (avg: 3.4795)\tTop1: 17.188 (avg: 21.219)\tTop5: 45.312 (avg: 46.469)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.375 (avg: 0.380)\tLoss: 3.5151 (avg: 3.4992)\tTop1: 26.562 (avg: 21.354)\tTop5: 51.562 (avg: 46.062)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.387 (avg: 0.381)\tLoss: 3.6715 (avg: 3.4943)\tTop1: 15.625 (avg: 20.953)\tTop5: 40.625 (avg: 45.969)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.378 (avg: 0.382)\tLoss: 3.5952 (avg: 3.4928)\tTop1: 15.625 (avg: 20.800)\tTop5: 45.312 (avg: 45.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6845\tTop 1 accuracy: 12.750\tTop 5 accuracy: 31.200\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.638 (avg: 0.626)\tLoss: 3.3909 (avg: 3.4401)\tTop1: 25.000 (avg: 21.438)\tTop5: 53.125 (avg: 47.375)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.626 (avg: 0.632)\tLoss: 3.8886 (avg: 3.5016)\tTop1: 20.312 (avg: 21.281)\tTop5: 43.750 (avg: 45.969)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.418 (avg: 0.605)\tLoss: 3.4680 (avg: 3.4844)\tTop1: 25.000 (avg: 21.333)\tTop5: 45.312 (avg: 46.583)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.632 (avg: 0.577)\tLoss: 3.6665 (avg: 3.4890)\tTop1: 26.562 (avg: 21.156)\tTop5: 50.000 (avg: 46.125)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.631 (avg: 0.586)\tLoss: 3.8533 (avg: 3.4907)\tTop1: 17.188 (avg: 21.188)\tTop5: 39.062 (avg: 46.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6505\tTop 1 accuracy: 12.300\tTop 5 accuracy: 31.150\n",
            "\n",
            "pct_3x3 = 0.375: top1 = 12.500000953674316 \t top5 = 31.35000228881836 \t batch time = 0.29384005814790726\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.470 (avg: 0.608)\tLoss: 5.2963 (avg: 5.3062)\tTop1: 1.562 (avg: 0.188)\tTop5: 4.688 (avg: 2.312)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.627 (avg: 0.602)\tLoss: 5.2970 (avg: 5.3025)\tTop1: 0.000 (avg: 0.375)\tTop5: 1.562 (avg: 2.344)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.685 (avg: 0.626)\tLoss: 5.2991 (avg: 5.3012)\tTop1: 0.000 (avg: 0.417)\tTop5: 0.000 (avg: 2.104)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.476 (avg: 0.628)\tLoss: 5.2992 (avg: 5.3006)\tTop1: 0.000 (avg: 0.453)\tTop5: 1.562 (avg: 2.109)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.673 (avg: 0.606)\tLoss: 5.2987 (avg: 5.3002)\tTop1: 0.000 (avg: 0.463)\tTop5: 0.000 (avg: 2.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2965\tTop 1 accuracy: 0.250\tTop 5 accuracy: 1.950\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.668 (avg: 0.658)\tLoss: 5.2979 (avg: 5.2981)\tTop1: 0.000 (avg: 0.875)\tTop5: 1.562 (avg: 2.688)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.473 (avg: 0.592)\tLoss: 5.2951 (avg: 5.2979)\tTop1: 1.562 (avg: 0.719)\tTop5: 4.688 (avg: 2.719)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.598 (avg: 0.598)\tLoss: 5.2969 (avg: 5.2978)\tTop1: 1.562 (avg: 0.688)\tTop5: 3.125 (avg: 2.625)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.683 (avg: 0.617)\tLoss: 5.2997 (avg: 5.2977)\tTop1: 0.000 (avg: 0.625)\tTop5: 1.562 (avg: 2.609)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.441 (avg: 0.618)\tLoss: 5.2992 (avg: 5.2980)\tTop1: 1.562 (avg: 0.562)\tTop5: 3.125 (avg: 2.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2936\tTop 1 accuracy: 0.250\tTop 5 accuracy: 1.950\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.707 (avg: 0.650)\tLoss: 5.2943 (avg: 5.2954)\tTop1: 3.125 (avg: 1.000)\tTop5: 4.688 (avg: 3.938)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.662 (avg: 0.665)\tLoss: 5.2782 (avg: 5.2951)\tTop1: 0.000 (avg: 0.750)\tTop5: 1.562 (avg: 3.094)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.410 (avg: 0.601)\tLoss: 5.2938 (avg: 5.2952)\tTop1: 0.000 (avg: 0.688)\tTop5: 1.562 (avg: 2.812)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.657 (avg: 0.608)\tLoss: 5.2998 (avg: 5.2945)\tTop1: 0.000 (avg: 0.625)\tTop5: 4.688 (avg: 2.750)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.662 (avg: 0.622)\tLoss: 5.2605 (avg: 5.2920)\tTop1: 0.000 (avg: 0.638)\tTop5: 6.250 (avg: 2.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2097\tTop 1 accuracy: 0.350\tTop 5 accuracy: 2.450\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.706 (avg: 0.511)\tLoss: 5.2936 (avg: 5.2685)\tTop1: 0.000 (avg: 0.562)\tTop5: 0.000 (avg: 3.188)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.678 (avg: 0.582)\tLoss: 5.2271 (avg: 5.2680)\tTop1: 0.000 (avg: 0.688)\tTop5: 4.688 (avg: 3.250)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.674 (avg: 0.613)\tLoss: 5.2719 (avg: 5.2675)\tTop1: 0.000 (avg: 0.854)\tTop5: 1.562 (avg: 3.438)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.441 (avg: 0.588)\tLoss: 5.2643 (avg: 5.2651)\tTop1: 1.562 (avg: 0.875)\tTop5: 1.562 (avg: 3.578)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.636 (avg: 0.586)\tLoss: 5.2492 (avg: 5.2642)\tTop1: 1.562 (avg: 0.863)\tTop5: 4.688 (avg: 3.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1382\tTop 1 accuracy: 0.500\tTop 5 accuracy: 2.500\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.444 (avg: 0.645)\tLoss: 5.2716 (avg: 5.2424)\tTop1: 0.000 (avg: 0.750)\tTop5: 3.125 (avg: 3.750)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.411 (avg: 0.555)\tLoss: 5.2389 (avg: 5.2462)\tTop1: 0.000 (avg: 0.875)\tTop5: 7.812 (avg: 4.219)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.706 (avg: 0.585)\tLoss: 5.3053 (avg: 5.2518)\tTop1: 0.000 (avg: 0.771)\tTop5: 1.562 (avg: 4.167)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.669 (avg: 0.610)\tLoss: 5.2832 (avg: 5.2524)\tTop1: 1.562 (avg: 0.875)\tTop5: 9.375 (avg: 4.406)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.443 (avg: 0.604)\tLoss: 5.2254 (avg: 5.2510)\tTop1: 0.000 (avg: 0.900)\tTop5: 1.562 (avg: 4.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1494\tTop 1 accuracy: 0.800\tTop 5 accuracy: 3.600\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.660 (avg: 0.640)\tLoss: 5.1933 (avg: 5.2283)\tTop1: 1.562 (avg: 1.188)\tTop5: 7.812 (avg: 5.250)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.665 (avg: 0.657)\tLoss: 5.2725 (avg: 5.2305)\tTop1: 0.000 (avg: 0.906)\tTop5: 4.688 (avg: 4.906)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.503 (avg: 0.601)\tLoss: 5.2436 (avg: 5.2417)\tTop1: 0.000 (avg: 1.000)\tTop5: 7.812 (avg: 4.667)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.401 (avg: 0.599)\tLoss: 5.2696 (avg: 5.2467)\tTop1: 0.000 (avg: 0.969)\tTop5: 1.562 (avg: 4.281)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.400 (avg: 0.561)\tLoss: 5.2112 (avg: 5.2489)\tTop1: 0.000 (avg: 0.925)\tTop5: 7.812 (avg: 4.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2727\tTop 1 accuracy: 0.550\tTop 5 accuracy: 3.150\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.402 (avg: 0.396)\tLoss: 5.2101 (avg: 5.2444)\tTop1: 1.562 (avg: 1.062)\tTop5: 6.250 (avg: 4.500)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.398 (avg: 0.401)\tLoss: 5.2543 (avg: 5.2379)\tTop1: 0.000 (avg: 1.406)\tTop5: 4.688 (avg: 4.750)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.399 (avg: 0.403)\tLoss: 5.2310 (avg: 5.2376)\tTop1: 0.000 (avg: 1.250)\tTop5: 4.688 (avg: 4.542)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.395 (avg: 0.403)\tLoss: 5.2504 (avg: 5.2365)\tTop1: 1.562 (avg: 1.250)\tTop5: 1.562 (avg: 4.453)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.401 (avg: 0.403)\tLoss: 5.3328 (avg: 5.2345)\tTop1: 1.562 (avg: 1.213)\tTop5: 4.688 (avg: 4.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1225\tTop 1 accuracy: 0.900\tTop 5 accuracy: 4.100\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.394 (avg: 0.396)\tLoss: 5.2032 (avg: 5.2328)\tTop1: 1.562 (avg: 1.062)\tTop5: 6.250 (avg: 5.062)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.392 (avg: 0.401)\tLoss: 5.1859 (avg: 5.2201)\tTop1: 0.000 (avg: 1.062)\tTop5: 3.125 (avg: 5.219)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.402 (avg: 0.404)\tLoss: 5.2784 (avg: 5.2283)\tTop1: 0.000 (avg: 0.979)\tTop5: 1.562 (avg: 5.021)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.398 (avg: 0.404)\tLoss: 5.2754 (avg: 5.2297)\tTop1: 0.000 (avg: 0.891)\tTop5: 1.562 (avg: 5.000)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.404 (avg: 0.405)\tLoss: 5.2959 (avg: 5.2349)\tTop1: 0.000 (avg: 0.900)\tTop5: 0.000 (avg: 4.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2547\tTop 1 accuracy: 0.600\tTop 5 accuracy: 3.750\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.401 (avg: 0.396)\tLoss: 5.2492 (avg: 5.2397)\tTop1: 1.562 (avg: 1.125)\tTop5: 6.250 (avg: 5.500)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.406 (avg: 0.403)\tLoss: 5.2641 (avg: 5.2365)\tTop1: 0.000 (avg: 1.031)\tTop5: 1.562 (avg: 4.906)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.402 (avg: 0.405)\tLoss: 5.2256 (avg: 5.2286)\tTop1: 3.125 (avg: 1.104)\tTop5: 6.250 (avg: 5.333)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.410 (avg: 0.406)\tLoss: 5.2552 (avg: 5.2330)\tTop1: 1.562 (avg: 1.078)\tTop5: 6.250 (avg: 5.188)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.400 (avg: 0.407)\tLoss: 5.2581 (avg: 5.2303)\tTop1: 0.000 (avg: 1.100)\tTop5: 0.000 (avg: 5.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1298\tTop 1 accuracy: 0.550\tTop 5 accuracy: 3.700\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.399 (avg: 0.399)\tLoss: 5.1725 (avg: 5.2306)\tTop1: 1.562 (avg: 1.125)\tTop5: 7.812 (avg: 5.938)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.404 (avg: 0.404)\tLoss: 5.1062 (avg: 5.2178)\tTop1: 0.000 (avg: 0.969)\tTop5: 7.812 (avg: 5.688)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.398 (avg: 0.406)\tLoss: 5.1995 (avg: 5.2212)\tTop1: 1.562 (avg: 0.979)\tTop5: 3.125 (avg: 5.479)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.405 (avg: 0.407)\tLoss: 5.2732 (avg: 5.2181)\tTop1: 0.000 (avg: 0.984)\tTop5: 6.250 (avg: 5.656)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.401 (avg: 0.408)\tLoss: 5.2086 (avg: 5.2196)\tTop1: 0.000 (avg: 0.975)\tTop5: 3.125 (avg: 5.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1615\tTop 1 accuracy: 0.650\tTop 5 accuracy: 3.700\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.403 (avg: 0.397)\tLoss: 5.2134 (avg: 5.2098)\tTop1: 0.000 (avg: 0.750)\tTop5: 3.125 (avg: 5.188)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.398 (avg: 0.403)\tLoss: 5.2082 (avg: 5.1996)\tTop1: 0.000 (avg: 1.000)\tTop5: 6.250 (avg: 5.375)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.413 (avg: 0.407)\tLoss: 5.1799 (avg: 5.1963)\tTop1: 0.000 (avg: 0.979)\tTop5: 9.375 (avg: 5.792)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.406 (avg: 0.411)\tLoss: 5.2932 (avg: 5.1954)\tTop1: 0.000 (avg: 1.031)\tTop5: 3.125 (avg: 5.859)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.419 (avg: 0.413)\tLoss: 5.1161 (avg: 5.2036)\tTop1: 0.000 (avg: 1.025)\tTop5: 6.250 (avg: 5.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1957\tTop 1 accuracy: 1.400\tTop 5 accuracy: 4.550\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.402 (avg: 0.397)\tLoss: 5.2634 (avg: 5.1658)\tTop1: 0.000 (avg: 0.938)\tTop5: 4.688 (avg: 6.250)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.402 (avg: 0.402)\tLoss: 5.2319 (avg: 5.1885)\tTop1: 1.562 (avg: 1.062)\tTop5: 4.688 (avg: 6.094)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.405 (avg: 0.404)\tLoss: 5.1370 (avg: 5.1942)\tTop1: 7.812 (avg: 1.271)\tTop5: 7.812 (avg: 5.979)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.396 (avg: 0.405)\tLoss: 5.1999 (avg: 5.1898)\tTop1: 0.000 (avg: 1.391)\tTop5: 7.812 (avg: 6.094)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.402 (avg: 0.405)\tLoss: 5.1922 (avg: 5.1904)\tTop1: 0.000 (avg: 1.438)\tTop5: 6.250 (avg: 6.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0809\tTop 1 accuracy: 1.350\tTop 5 accuracy: 5.750\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.392 (avg: 0.397)\tLoss: 5.1856 (avg: 5.1937)\tTop1: 0.000 (avg: 1.375)\tTop5: 3.125 (avg: 6.125)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.403 (avg: 0.402)\tLoss: 5.0980 (avg: 5.1753)\tTop1: 1.562 (avg: 1.344)\tTop5: 10.938 (avg: 6.344)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.396 (avg: 0.403)\tLoss: 5.2182 (avg: 5.1772)\tTop1: 1.562 (avg: 1.333)\tTop5: 7.812 (avg: 6.458)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.398 (avg: 0.404)\tLoss: 5.0458 (avg: 5.1743)\tTop1: 1.562 (avg: 1.266)\tTop5: 6.250 (avg: 6.469)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.401 (avg: 0.405)\tLoss: 5.2015 (avg: 5.1710)\tTop1: 4.688 (avg: 1.388)\tTop5: 7.812 (avg: 6.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1435\tTop 1 accuracy: 2.000\tTop 5 accuracy: 5.900\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.663 (avg: 0.640)\tLoss: 5.2848 (avg: 5.1538)\tTop1: 0.000 (avg: 1.750)\tTop5: 1.562 (avg: 7.000)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.680 (avg: 0.658)\tLoss: 5.2174 (avg: 5.1612)\tTop1: 0.000 (avg: 1.688)\tTop5: 6.250 (avg: 6.656)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.436 (avg: 0.648)\tLoss: 5.1487 (avg: 5.1639)\tTop1: 0.000 (avg: 1.625)\tTop5: 4.688 (avg: 6.667)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.710 (avg: 0.611)\tLoss: 5.1572 (avg: 5.1637)\tTop1: 0.000 (avg: 1.531)\tTop5: 3.125 (avg: 6.641)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.556 (avg: 0.619)\tLoss: 5.1777 (avg: 5.1617)\tTop1: 1.562 (avg: 1.500)\tTop5: 12.500 (avg: 6.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0913\tTop 1 accuracy: 1.300\tTop 5 accuracy: 6.650\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.476 (avg: 0.567)\tLoss: 5.0285 (avg: 5.1327)\tTop1: 1.562 (avg: 1.438)\tTop5: 10.938 (avg: 6.812)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.661 (avg: 0.562)\tLoss: 5.0726 (avg: 5.1382)\tTop1: 0.000 (avg: 1.438)\tTop5: 6.250 (avg: 6.500)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.681 (avg: 0.595)\tLoss: 5.0662 (avg: 5.1318)\tTop1: 1.562 (avg: 1.479)\tTop5: 7.812 (avg: 6.625)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.669 (avg: 0.616)\tLoss: 5.1147 (avg: 5.1327)\tTop1: 1.562 (avg: 1.516)\tTop5: 7.812 (avg: 6.609)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.469 (avg: 0.588)\tLoss: 5.1899 (avg: 5.1364)\tTop1: 0.000 (avg: 1.525)\tTop5: 7.812 (avg: 6.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1201\tTop 1 accuracy: 1.400\tTop 5 accuracy: 6.350\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.695 (avg: 0.656)\tLoss: 5.0249 (avg: 5.1041)\tTop1: 1.562 (avg: 1.938)\tTop5: 9.375 (avg: 7.875)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.439 (avg: 0.616)\tLoss: 5.2621 (avg: 5.1216)\tTop1: 3.125 (avg: 1.969)\tTop5: 7.812 (avg: 7.219)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.556 (avg: 0.602)\tLoss: 5.1914 (avg: 5.1309)\tTop1: 3.125 (avg: 1.938)\tTop5: 6.250 (avg: 7.104)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.543 (avg: 0.617)\tLoss: 5.1935 (avg: 5.1339)\tTop1: 1.562 (avg: 1.734)\tTop5: 4.688 (avg: 7.250)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.442 (avg: 0.628)\tLoss: 5.1416 (avg: 5.1345)\tTop1: 1.562 (avg: 1.750)\tTop5: 7.812 (avg: 7.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0093\tTop 1 accuracy: 1.800\tTop 5 accuracy: 6.400\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.662 (avg: 0.637)\tLoss: 5.0788 (avg: 5.0965)\tTop1: 3.125 (avg: 2.250)\tTop5: 9.375 (avg: 8.250)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.663 (avg: 0.654)\tLoss: 5.1215 (avg: 5.1090)\tTop1: 0.000 (avg: 2.031)\tTop5: 9.375 (avg: 8.031)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.448 (avg: 0.613)\tLoss: 5.1322 (avg: 5.1110)\tTop1: 1.562 (avg: 2.062)\tTop5: 3.125 (avg: 7.750)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.618 (avg: 0.613)\tLoss: 5.1320 (avg: 5.1216)\tTop1: 0.000 (avg: 1.797)\tTop5: 12.500 (avg: 7.359)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.657 (avg: 0.624)\tLoss: 5.3006 (avg: 5.1172)\tTop1: 0.000 (avg: 1.875)\tTop5: 1.562 (avg: 7.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1199\tTop 1 accuracy: 1.550\tTop 5 accuracy: 6.550\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.677 (avg: 0.467)\tLoss: 5.1793 (avg: 5.0787)\tTop1: 1.562 (avg: 1.625)\tTop5: 4.688 (avg: 7.500)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.616 (avg: 0.562)\tLoss: 5.0312 (avg: 5.0894)\tTop1: 4.688 (avg: 1.750)\tTop5: 9.375 (avg: 7.562)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.661 (avg: 0.599)\tLoss: 5.0865 (avg: 5.0996)\tTop1: 3.125 (avg: 1.667)\tTop5: 10.938 (avg: 7.479)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.448 (avg: 0.589)\tLoss: 5.0227 (avg: 5.1009)\tTop1: 6.250 (avg: 1.672)\tTop5: 12.500 (avg: 7.734)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.671 (avg: 0.582)\tLoss: 5.1271 (avg: 5.1067)\tTop1: 1.562 (avg: 1.725)\tTop5: 9.375 (avg: 7.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9827\tTop 1 accuracy: 1.650\tTop 5 accuracy: 7.300\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.668 (avg: 0.654)\tLoss: 5.0869 (avg: 5.0959)\tTop1: 0.000 (avg: 2.000)\tTop5: 6.250 (avg: 7.625)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.456 (avg: 0.572)\tLoss: 5.1226 (avg: 5.1017)\tTop1: 4.688 (avg: 1.906)\tTop5: 12.500 (avg: 7.438)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.648 (avg: 0.588)\tLoss: 5.1188 (avg: 5.1071)\tTop1: 3.125 (avg: 1.938)\tTop5: 4.688 (avg: 7.479)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.687 (avg: 0.610)\tLoss: 5.1264 (avg: 5.1084)\tTop1: 1.562 (avg: 1.812)\tTop5: 4.688 (avg: 7.469)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.455 (avg: 0.610)\tLoss: 5.0819 (avg: 5.0989)\tTop1: 3.125 (avg: 1.850)\tTop5: 7.812 (avg: 7.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9750\tTop 1 accuracy: 1.750\tTop 5 accuracy: 7.450\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.676 (avg: 0.627)\tLoss: 5.0212 (avg: 5.1001)\tTop1: 3.125 (avg: 1.812)\tTop5: 10.938 (avg: 8.312)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.684 (avg: 0.652)\tLoss: 5.0508 (avg: 5.0917)\tTop1: 1.562 (avg: 1.844)\tTop5: 4.688 (avg: 8.562)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.473 (avg: 0.608)\tLoss: 5.0723 (avg: 5.0852)\tTop1: 1.562 (avg: 1.958)\tTop5: 7.812 (avg: 8.604)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.529 (avg: 0.603)\tLoss: 5.0880 (avg: 5.0804)\tTop1: 1.562 (avg: 2.000)\tTop5: 7.812 (avg: 8.484)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.663 (avg: 0.619)\tLoss: 5.0714 (avg: 5.0828)\tTop1: 3.125 (avg: 2.062)\tTop5: 7.812 (avg: 8.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0382\tTop 1 accuracy: 1.750\tTop 5 accuracy: 7.400\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.625 (avg: 0.455)\tLoss: 5.0261 (avg: 5.0721)\tTop1: 0.000 (avg: 1.625)\tTop5: 7.812 (avg: 7.562)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.666 (avg: 0.557)\tLoss: 5.1247 (avg: 5.0784)\tTop1: 3.125 (avg: 1.906)\tTop5: 9.375 (avg: 7.688)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.672 (avg: 0.594)\tLoss: 5.2032 (avg: 5.0875)\tTop1: 0.000 (avg: 2.042)\tTop5: 3.125 (avg: 7.917)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.480 (avg: 0.589)\tLoss: 4.8659 (avg: 5.0847)\tTop1: 6.250 (avg: 2.047)\tTop5: 10.938 (avg: 8.094)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.666 (avg: 0.582)\tLoss: 5.2820 (avg: 5.0788)\tTop1: 0.000 (avg: 2.175)\tTop5: 4.688 (avg: 8.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0946\tTop 1 accuracy: 1.450\tTop 5 accuracy: 7.750\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.684 (avg: 0.658)\tLoss: 5.0928 (avg: 5.0586)\tTop1: 4.688 (avg: 2.562)\tTop5: 12.500 (avg: 9.250)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.453 (avg: 0.578)\tLoss: 5.2058 (avg: 5.0618)\tTop1: 1.562 (avg: 2.406)\tTop5: 7.812 (avg: 9.219)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.674 (avg: 0.585)\tLoss: 4.8724 (avg: 5.0567)\tTop1: 3.125 (avg: 2.479)\tTop5: 14.062 (avg: 9.604)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.675 (avg: 0.608)\tLoss: 5.0475 (avg: 5.0512)\tTop1: 1.562 (avg: 2.438)\tTop5: 9.375 (avg: 9.500)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.445 (avg: 0.612)\tLoss: 5.1559 (avg: 5.0594)\tTop1: 0.000 (avg: 2.413)\tTop5: 4.688 (avg: 9.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0692\tTop 1 accuracy: 2.150\tTop 5 accuracy: 8.050\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.685 (avg: 0.633)\tLoss: 4.9029 (avg: 5.0253)\tTop1: 4.688 (avg: 2.375)\tTop5: 18.750 (avg: 10.125)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.666 (avg: 0.654)\tLoss: 4.9077 (avg: 5.0297)\tTop1: 1.562 (avg: 2.406)\tTop5: 7.812 (avg: 9.562)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.439 (avg: 0.612)\tLoss: 5.0872 (avg: 5.0510)\tTop1: 1.562 (avg: 2.292)\tTop5: 4.688 (avg: 9.167)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.626 (avg: 0.615)\tLoss: 5.1409 (avg: 5.0474)\tTop1: 1.562 (avg: 2.391)\tTop5: 12.500 (avg: 9.172)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.670 (avg: 0.627)\tLoss: 5.1346 (avg: 5.0508)\tTop1: 1.562 (avg: 2.425)\tTop5: 9.375 (avg: 9.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0881\tTop 1 accuracy: 1.950\tTop 5 accuracy: 8.850\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.681 (avg: 0.494)\tLoss: 5.0437 (avg: 5.0487)\tTop1: 1.562 (avg: 2.250)\tTop5: 9.375 (avg: 9.938)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.692 (avg: 0.570)\tLoss: 5.1045 (avg: 5.0229)\tTop1: 1.562 (avg: 2.188)\tTop5: 7.812 (avg: 9.688)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.684 (avg: 0.608)\tLoss: 4.8559 (avg: 5.0289)\tTop1: 6.250 (avg: 2.146)\tTop5: 15.625 (avg: 9.625)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.471 (avg: 0.592)\tLoss: 5.0287 (avg: 5.0273)\tTop1: 1.562 (avg: 2.172)\tTop5: 9.375 (avg: 9.625)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.599 (avg: 0.594)\tLoss: 5.0101 (avg: 5.0265)\tTop1: 1.562 (avg: 2.225)\tTop5: 9.375 (avg: 9.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0627\tTop 1 accuracy: 2.500\tTop 5 accuracy: 9.050\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.462 (avg: 0.649)\tLoss: 5.1340 (avg: 4.9915)\tTop1: 3.125 (avg: 2.500)\tTop5: 6.250 (avg: 10.562)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.402 (avg: 0.556)\tLoss: 5.0408 (avg: 4.9974)\tTop1: 3.125 (avg: 2.531)\tTop5: 7.812 (avg: 10.406)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.664 (avg: 0.586)\tLoss: 5.1197 (avg: 5.0152)\tTop1: 3.125 (avg: 2.542)\tTop5: 12.500 (avg: 9.875)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.695 (avg: 0.609)\tLoss: 4.8547 (avg: 5.0051)\tTop1: 3.125 (avg: 2.547)\tTop5: 10.938 (avg: 9.734)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.485 (avg: 0.605)\tLoss: 4.9699 (avg: 4.9984)\tTop1: 6.250 (avg: 2.588)\tTop5: 15.625 (avg: 10.063)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1568\tTop 1 accuracy: 1.850\tTop 5 accuracy: 9.050\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.680 (avg: 0.658)\tLoss: 5.0526 (avg: 4.9375)\tTop1: 0.000 (avg: 3.000)\tTop5: 4.688 (avg: 10.812)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.690 (avg: 0.668)\tLoss: 5.0918 (avg: 4.9505)\tTop1: 0.000 (avg: 3.000)\tTop5: 3.125 (avg: 10.469)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.487 (avg: 0.607)\tLoss: 4.9164 (avg: 4.9402)\tTop1: 0.000 (avg: 2.896)\tTop5: 12.500 (avg: 10.625)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.684 (avg: 0.616)\tLoss: 5.0048 (avg: 4.9449)\tTop1: 0.000 (avg: 2.828)\tTop5: 6.250 (avg: 10.359)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.657 (avg: 0.628)\tLoss: 5.0446 (avg: 4.9470)\tTop1: 0.000 (avg: 2.788)\tTop5: 9.375 (avg: 10.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9801\tTop 1 accuracy: 1.950\tTop 5 accuracy: 8.450\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.680 (avg: 0.510)\tLoss: 4.8506 (avg: 4.8811)\tTop1: 4.688 (avg: 2.750)\tTop5: 14.062 (avg: 11.375)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.696 (avg: 0.582)\tLoss: 4.8240 (avg: 4.8908)\tTop1: 3.125 (avg: 2.781)\tTop5: 12.500 (avg: 11.312)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.697 (avg: 0.615)\tLoss: 4.9294 (avg: 4.8819)\tTop1: 4.688 (avg: 2.833)\tTop5: 10.938 (avg: 11.833)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.478 (avg: 0.592)\tLoss: 4.7098 (avg: 4.8787)\tTop1: 1.562 (avg: 2.828)\tTop5: 10.938 (avg: 11.656)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.553 (avg: 0.595)\tLoss: 4.9893 (avg: 4.8877)\tTop1: 1.562 (avg: 2.825)\tTop5: 6.250 (avg: 11.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6355\tTop 1 accuracy: 2.600\tTop 5 accuracy: 12.200\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.471 (avg: 0.647)\tLoss: 4.9825 (avg: 4.8345)\tTop1: 0.000 (avg: 3.375)\tTop5: 15.625 (avg: 12.938)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.669 (avg: 0.577)\tLoss: 4.6966 (avg: 4.8375)\tTop1: 3.125 (avg: 3.438)\tTop5: 10.938 (avg: 12.562)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.675 (avg: 0.608)\tLoss: 4.9346 (avg: 4.8295)\tTop1: 0.000 (avg: 3.375)\tTop5: 9.375 (avg: 12.625)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.713 (avg: 0.625)\tLoss: 4.9084 (avg: 4.8353)\tTop1: 3.125 (avg: 3.484)\tTop5: 12.500 (avg: 12.672)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.473 (avg: 0.607)\tLoss: 4.5853 (avg: 4.8316)\tTop1: 4.688 (avg: 3.413)\tTop5: 23.438 (avg: 12.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5799\tTop 1 accuracy: 3.050\tTop 5 accuracy: 12.950\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.674 (avg: 0.655)\tLoss: 4.7124 (avg: 4.7625)\tTop1: 6.250 (avg: 2.938)\tTop5: 15.625 (avg: 13.000)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.447 (avg: 0.656)\tLoss: 4.7634 (avg: 4.7858)\tTop1: 4.688 (avg: 3.375)\tTop5: 9.375 (avg: 12.875)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.540 (avg: 0.596)\tLoss: 4.9584 (avg: 4.7871)\tTop1: 1.562 (avg: 3.667)\tTop5: 15.625 (avg: 12.875)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.680 (avg: 0.613)\tLoss: 4.5878 (avg: 4.7849)\tTop1: 9.375 (avg: 3.609)\tTop5: 17.188 (avg: 12.969)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.661 (avg: 0.626)\tLoss: 4.7302 (avg: 4.7822)\tTop1: 1.562 (avg: 3.675)\tTop5: 20.312 (avg: 13.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6447\tTop 1 accuracy: 3.350\tTop 5 accuracy: 12.550\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.675 (avg: 0.559)\tLoss: 4.6331 (avg: 4.7034)\tTop1: 3.125 (avg: 4.875)\tTop5: 17.188 (avg: 16.125)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.710 (avg: 0.617)\tLoss: 4.6246 (avg: 4.6849)\tTop1: 3.125 (avg: 4.625)\tTop5: 18.750 (avg: 16.531)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.435 (avg: 0.636)\tLoss: 4.6209 (avg: 4.6951)\tTop1: 3.125 (avg: 4.646)\tTop5: 25.000 (avg: 16.000)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.699 (avg: 0.599)\tLoss: 4.7258 (avg: 4.7058)\tTop1: 4.688 (avg: 4.500)\tTop5: 10.938 (avg: 15.828)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.677 (avg: 0.612)\tLoss: 4.6191 (avg: 4.7105)\tTop1: 4.688 (avg: 4.350)\tTop5: 17.188 (avg: 15.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5544\tTop 1 accuracy: 3.850\tTop 5 accuracy: 14.800\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.445 (avg: 0.553)\tLoss: 4.5615 (avg: 4.5672)\tTop1: 4.688 (avg: 4.500)\tTop5: 21.875 (avg: 17.875)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.557 (avg: 0.573)\tLoss: 4.5621 (avg: 4.5341)\tTop1: 4.688 (avg: 5.188)\tTop5: 12.500 (avg: 19.000)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.671 (avg: 0.607)\tLoss: 4.3565 (avg: 4.5275)\tTop1: 7.812 (avg: 5.542)\tTop5: 21.875 (avg: 19.667)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.440 (avg: 0.618)\tLoss: 4.6509 (avg: 4.5115)\tTop1: 4.688 (avg: 6.203)\tTop5: 17.188 (avg: 20.172)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.666 (avg: 0.595)\tLoss: 4.1857 (avg: 4.5031)\tTop1: 10.938 (avg: 6.388)\tTop5: 34.375 (avg: 20.563)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2821\tTop 1 accuracy: 5.250\tTop 5 accuracy: 18.600\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.672 (avg: 0.666)\tLoss: 4.5773 (avg: 4.4339)\tTop1: 3.125 (avg: 8.125)\tTop5: 23.438 (avg: 25.000)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.466 (avg: 0.608)\tLoss: 4.6560 (avg: 4.4290)\tTop1: 6.250 (avg: 8.125)\tTop5: 18.750 (avg: 23.938)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.536 (avg: 0.594)\tLoss: 4.2421 (avg: 4.4253)\tTop1: 9.375 (avg: 7.542)\tTop5: 25.000 (avg: 23.083)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.688 (avg: 0.613)\tLoss: 4.3789 (avg: 4.4281)\tTop1: 10.938 (avg: 7.531)\tTop5: 25.000 (avg: 23.047)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.563 (avg: 0.626)\tLoss: 4.5147 (avg: 4.4238)\tTop1: 6.250 (avg: 7.538)\tTop5: 15.625 (avg: 22.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2455\tTop 1 accuracy: 6.800\tTop 5 accuracy: 19.900\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.669 (avg: 0.657)\tLoss: 4.4091 (avg: 4.4085)\tTop1: 10.938 (avg: 7.750)\tTop5: 18.750 (avg: 22.812)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.716 (avg: 0.670)\tLoss: 4.4204 (avg: 4.4020)\tTop1: 7.812 (avg: 7.750)\tTop5: 17.188 (avg: 22.719)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.484 (avg: 0.622)\tLoss: 4.0882 (avg: 4.3925)\tTop1: 15.625 (avg: 7.542)\tTop5: 29.688 (avg: 23.146)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.627 (avg: 0.613)\tLoss: 4.4879 (avg: 4.3864)\tTop1: 6.250 (avg: 7.922)\tTop5: 18.750 (avg: 23.578)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.671 (avg: 0.626)\tLoss: 4.3429 (avg: 4.3925)\tTop1: 10.938 (avg: 8.175)\tTop5: 23.438 (avg: 23.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2661\tTop 1 accuracy: 6.400\tTop 5 accuracy: 20.350\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.682 (avg: 0.482)\tLoss: 4.3887 (avg: 4.3501)\tTop1: 7.812 (avg: 8.938)\tTop5: 25.000 (avg: 26.062)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.668 (avg: 0.573)\tLoss: 4.1812 (avg: 4.3568)\tTop1: 10.938 (avg: 8.500)\tTop5: 29.688 (avg: 25.281)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.680 (avg: 0.610)\tLoss: 4.2356 (avg: 4.3731)\tTop1: 14.062 (avg: 8.354)\tTop5: 28.125 (avg: 25.083)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.446 (avg: 0.594)\tLoss: 4.2006 (avg: 4.3785)\tTop1: 12.500 (avg: 8.031)\tTop5: 37.500 (avg: 24.938)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.671 (avg: 0.597)\tLoss: 4.2873 (avg: 4.3789)\tTop1: 12.500 (avg: 8.062)\tTop5: 31.250 (avg: 24.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0899\tTop 1 accuracy: 6.900\tTop 5 accuracy: 20.400\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.460 (avg: 0.642)\tLoss: 4.2846 (avg: 4.2939)\tTop1: 7.812 (avg: 9.625)\tTop5: 28.125 (avg: 27.688)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.662 (avg: 0.578)\tLoss: 4.5032 (avg: 4.3500)\tTop1: 9.375 (avg: 8.750)\tTop5: 20.312 (avg: 25.438)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.704 (avg: 0.606)\tLoss: 4.2176 (avg: 4.3415)\tTop1: 10.938 (avg: 8.604)\tTop5: 34.375 (avg: 25.417)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.664 (avg: 0.625)\tLoss: 4.5551 (avg: 4.3395)\tTop1: 4.688 (avg: 8.578)\tTop5: 14.062 (avg: 25.297)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.485 (avg: 0.606)\tLoss: 4.4393 (avg: 4.3540)\tTop1: 6.250 (avg: 8.525)\tTop5: 25.000 (avg: 24.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1457\tTop 1 accuracy: 7.000\tTop 5 accuracy: 20.650\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.705 (avg: 0.663)\tLoss: 4.0817 (avg: 4.2543)\tTop1: 18.750 (avg: 10.188)\tTop5: 37.500 (avg: 28.625)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.496 (avg: 0.646)\tLoss: 4.3445 (avg: 4.3234)\tTop1: 7.812 (avg: 9.125)\tTop5: 18.750 (avg: 26.125)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.696 (avg: 0.609)\tLoss: 4.4288 (avg: 4.3474)\tTop1: 6.250 (avg: 8.750)\tTop5: 20.312 (avg: 25.375)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.714 (avg: 0.625)\tLoss: 4.1472 (avg: 4.3316)\tTop1: 10.938 (avg: 8.609)\tTop5: 29.688 (avg: 25.531)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.712 (avg: 0.637)\tLoss: 4.3266 (avg: 4.3390)\tTop1: 7.812 (avg: 8.475)\tTop5: 26.562 (avg: 25.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2425\tTop 1 accuracy: 7.300\tTop 5 accuracy: 20.750\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.687 (avg: 0.653)\tLoss: 3.9976 (avg: 4.2844)\tTop1: 7.812 (avg: 8.750)\tTop5: 29.688 (avg: 27.125)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.700 (avg: 0.670)\tLoss: 4.2383 (avg: 4.3052)\tTop1: 9.375 (avg: 8.562)\tTop5: 21.875 (avg: 25.688)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.480 (avg: 0.628)\tLoss: 4.3868 (avg: 4.3008)\tTop1: 4.688 (avg: 8.354)\tTop5: 23.438 (avg: 26.083)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.670 (avg: 0.629)\tLoss: 4.2898 (avg: 4.3194)\tTop1: 12.500 (avg: 8.312)\tTop5: 26.562 (avg: 25.609)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.669 (avg: 0.638)\tLoss: 4.3179 (avg: 4.3270)\tTop1: 4.688 (avg: 8.150)\tTop5: 18.750 (avg: 25.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0848\tTop 1 accuracy: 7.150\tTop 5 accuracy: 22.700\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.668 (avg: 0.522)\tLoss: 4.1650 (avg: 4.2815)\tTop1: 15.625 (avg: 10.625)\tTop5: 32.812 (avg: 27.750)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.668 (avg: 0.599)\tLoss: 4.1207 (avg: 4.2936)\tTop1: 6.250 (avg: 10.188)\tTop5: 32.812 (avg: 27.688)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.690 (avg: 0.629)\tLoss: 4.0223 (avg: 4.2991)\tTop1: 14.062 (avg: 9.771)\tTop5: 34.375 (avg: 27.000)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.454 (avg: 0.596)\tLoss: 4.3017 (avg: 4.3004)\tTop1: 7.812 (avg: 9.250)\tTop5: 28.125 (avg: 26.484)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.689 (avg: 0.609)\tLoss: 4.4379 (avg: 4.3022)\tTop1: 4.688 (avg: 9.138)\tTop5: 14.062 (avg: 26.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1160\tTop 1 accuracy: 6.750\tTop 5 accuracy: 21.900\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.448 (avg: 0.578)\tLoss: 4.2448 (avg: 4.2242)\tTop1: 12.500 (avg: 9.062)\tTop5: 29.688 (avg: 28.812)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.570 (avg: 0.580)\tLoss: 4.4618 (avg: 4.2273)\tTop1: 6.250 (avg: 9.438)\tTop5: 26.562 (avg: 28.531)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.679 (avg: 0.607)\tLoss: 4.7199 (avg: 4.2697)\tTop1: 4.688 (avg: 9.375)\tTop5: 23.438 (avg: 27.396)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.638 (avg: 0.625)\tLoss: 4.5457 (avg: 4.3015)\tTop1: 7.812 (avg: 9.062)\tTop5: 21.875 (avg: 26.734)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.674 (avg: 0.595)\tLoss: 4.1551 (avg: 4.3013)\tTop1: 9.375 (avg: 8.800)\tTop5: 32.812 (avg: 26.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0532\tTop 1 accuracy: 7.200\tTop 5 accuracy: 22.550\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.670 (avg: 0.669)\tLoss: 4.1770 (avg: 4.2537)\tTop1: 7.812 (avg: 9.625)\tTop5: 31.250 (avg: 27.188)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.481 (avg: 0.620)\tLoss: 4.3766 (avg: 4.2634)\tTop1: 6.250 (avg: 9.312)\tTop5: 21.875 (avg: 26.812)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.665 (avg: 0.614)\tLoss: 4.1113 (avg: 4.2610)\tTop1: 10.938 (avg: 9.500)\tTop5: 28.125 (avg: 27.583)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.684 (avg: 0.628)\tLoss: 4.4643 (avg: 4.2724)\tTop1: 9.375 (avg: 9.297)\tTop5: 25.000 (avg: 27.375)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.449 (avg: 0.632)\tLoss: 4.4103 (avg: 4.2751)\tTop1: 4.688 (avg: 8.988)\tTop5: 18.750 (avg: 27.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2125\tTop 1 accuracy: 7.200\tTop 5 accuracy: 22.450\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.679 (avg: 0.648)\tLoss: 4.0281 (avg: 4.2242)\tTop1: 14.062 (avg: 9.875)\tTop5: 35.938 (avg: 28.812)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.669 (avg: 0.665)\tLoss: 4.6894 (avg: 4.2329)\tTop1: 4.688 (avg: 10.062)\tTop5: 20.312 (avg: 27.781)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.455 (avg: 0.619)\tLoss: 4.4202 (avg: 4.2577)\tTop1: 7.812 (avg: 9.854)\tTop5: 26.562 (avg: 27.354)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.658 (avg: 0.614)\tLoss: 4.4236 (avg: 4.2729)\tTop1: 4.688 (avg: 9.312)\tTop5: 18.750 (avg: 26.812)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.695 (avg: 0.627)\tLoss: 4.4922 (avg: 4.2677)\tTop1: 4.688 (avg: 9.312)\tTop5: 25.000 (avg: 26.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1094\tTop 1 accuracy: 7.350\tTop 5 accuracy: 21.800\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.679 (avg: 0.517)\tLoss: 4.4710 (avg: 4.2339)\tTop1: 9.375 (avg: 9.750)\tTop5: 21.875 (avg: 27.438)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.692 (avg: 0.597)\tLoss: 4.6790 (avg: 4.2249)\tTop1: 6.250 (avg: 9.438)\tTop5: 21.875 (avg: 28.000)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.700 (avg: 0.629)\tLoss: 4.1618 (avg: 4.2428)\tTop1: 12.500 (avg: 9.292)\tTop5: 28.125 (avg: 27.625)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.416 (avg: 0.597)\tLoss: 3.9955 (avg: 4.2332)\tTop1: 14.062 (avg: 9.156)\tTop5: 34.375 (avg: 28.188)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.674 (avg: 0.608)\tLoss: 4.1370 (avg: 4.2449)\tTop1: 9.375 (avg: 8.925)\tTop5: 31.250 (avg: 27.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0475\tTop 1 accuracy: 7.800\tTop 5 accuracy: 22.350\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.448 (avg: 0.586)\tLoss: 3.9169 (avg: 4.2013)\tTop1: 10.938 (avg: 9.938)\tTop5: 23.438 (avg: 27.500)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.680 (avg: 0.574)\tLoss: 4.2176 (avg: 4.2347)\tTop1: 9.375 (avg: 9.938)\tTop5: 23.438 (avg: 27.344)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.660 (avg: 0.606)\tLoss: 4.3472 (avg: 4.2323)\tTop1: 7.812 (avg: 10.396)\tTop5: 25.000 (avg: 27.958)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.682 (avg: 0.624)\tLoss: 4.0441 (avg: 4.2238)\tTop1: 18.750 (avg: 10.391)\tTop5: 42.188 (avg: 28.125)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.420 (avg: 0.595)\tLoss: 4.2188 (avg: 4.2318)\tTop1: 12.500 (avg: 10.088)\tTop5: 26.562 (avg: 27.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1283\tTop 1 accuracy: 7.450\tTop 5 accuracy: 22.700\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.701 (avg: 0.662)\tLoss: 4.1334 (avg: 4.1924)\tTop1: 14.062 (avg: 9.500)\tTop5: 34.375 (avg: 26.812)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.473 (avg: 0.625)\tLoss: 4.2173 (avg: 4.2146)\tTop1: 17.188 (avg: 10.438)\tTop5: 29.688 (avg: 28.219)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.676 (avg: 0.611)\tLoss: 4.0211 (avg: 4.2039)\tTop1: 15.625 (avg: 10.125)\tTop5: 42.188 (avg: 28.708)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.706 (avg: 0.627)\tLoss: 4.1985 (avg: 4.2050)\tTop1: 12.500 (avg: 10.047)\tTop5: 35.938 (avg: 28.734)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.486 (avg: 0.635)\tLoss: 4.0787 (avg: 4.2032)\tTop1: 12.500 (avg: 10.013)\tTop5: 32.812 (avg: 28.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9543\tTop 1 accuracy: 7.650\tTop 5 accuracy: 23.500\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.701 (avg: 0.655)\tLoss: 4.2492 (avg: 4.1619)\tTop1: 12.500 (avg: 10.375)\tTop5: 29.688 (avg: 29.625)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.724 (avg: 0.672)\tLoss: 4.1765 (avg: 4.1579)\tTop1: 10.938 (avg: 9.906)\tTop5: 25.000 (avg: 29.094)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.459 (avg: 0.616)\tLoss: 4.2959 (avg: 4.1896)\tTop1: 12.500 (avg: 9.917)\tTop5: 31.250 (avg: 28.521)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.669 (avg: 0.627)\tLoss: 4.2831 (avg: 4.2066)\tTop1: 15.625 (avg: 9.984)\tTop5: 25.000 (avg: 28.562)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.675 (avg: 0.639)\tLoss: 4.1152 (avg: 4.2072)\tTop1: 9.375 (avg: 9.850)\tTop5: 28.125 (avg: 28.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0204\tTop 1 accuracy: 8.000\tTop 5 accuracy: 23.000\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.537 (avg: 0.566)\tLoss: 4.0225 (avg: 4.2161)\tTop1: 9.375 (avg: 10.812)\tTop5: 37.500 (avg: 29.188)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.681 (avg: 0.626)\tLoss: 4.4038 (avg: 4.2098)\tTop1: 12.500 (avg: 10.219)\tTop5: 34.375 (avg: 28.750)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.467 (avg: 0.639)\tLoss: 4.2152 (avg: 4.2059)\tTop1: 12.500 (avg: 9.938)\tTop5: 37.500 (avg: 28.729)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.704 (avg: 0.609)\tLoss: 4.2184 (avg: 4.1905)\tTop1: 12.500 (avg: 10.141)\tTop5: 28.125 (avg: 28.922)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.672 (avg: 0.621)\tLoss: 4.3427 (avg: 4.1998)\tTop1: 10.938 (avg: 10.300)\tTop5: 25.000 (avg: 28.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0831\tTop 1 accuracy: 8.050\tTop 5 accuracy: 23.650\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.478 (avg: 0.530)\tLoss: 4.1848 (avg: 4.1640)\tTop1: 4.688 (avg: 10.125)\tTop5: 29.688 (avg: 28.750)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.624 (avg: 0.572)\tLoss: 4.2243 (avg: 4.1632)\tTop1: 9.375 (avg: 10.500)\tTop5: 28.125 (avg: 29.719)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.664 (avg: 0.606)\tLoss: 4.0430 (avg: 4.1680)\tTop1: 12.500 (avg: 10.333)\tTop5: 31.250 (avg: 29.104)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.440 (avg: 0.612)\tLoss: 4.2958 (avg: 4.1686)\tTop1: 10.938 (avg: 10.344)\tTop5: 28.125 (avg: 29.016)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.687 (avg: 0.597)\tLoss: 4.2657 (avg: 4.1708)\tTop1: 9.375 (avg: 10.125)\tTop5: 21.875 (avg: 29.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9851\tTop 1 accuracy: 7.750\tTop 5 accuracy: 23.850\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.673 (avg: 0.664)\tLoss: 4.1116 (avg: 4.1040)\tTop1: 4.688 (avg: 11.375)\tTop5: 26.562 (avg: 30.938)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.444 (avg: 0.590)\tLoss: 4.1662 (avg: 4.1277)\tTop1: 12.500 (avg: 11.000)\tTop5: 31.250 (avg: 30.781)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.405 (avg: 0.586)\tLoss: 4.2538 (avg: 4.1592)\tTop1: 9.375 (avg: 10.792)\tTop5: 28.125 (avg: 29.583)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.397 (avg: 0.543)\tLoss: 4.5323 (avg: 4.1580)\tTop1: 6.250 (avg: 10.828)\tTop5: 15.625 (avg: 29.625)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.405 (avg: 0.516)\tLoss: 4.3288 (avg: 4.1580)\tTop1: 9.375 (avg: 10.588)\tTop5: 26.562 (avg: 29.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1516\tTop 1 accuracy: 8.600\tTop 5 accuracy: 23.750\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.403 (avg: 0.397)\tLoss: 4.4571 (avg: 4.1503)\tTop1: 7.812 (avg: 10.188)\tTop5: 23.438 (avg: 29.375)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.405 (avg: 0.403)\tLoss: 4.0968 (avg: 4.1513)\tTop1: 6.250 (avg: 10.250)\tTop5: 25.000 (avg: 29.938)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.402 (avg: 0.405)\tLoss: 3.9637 (avg: 4.1531)\tTop1: 10.938 (avg: 10.458)\tTop5: 34.375 (avg: 29.812)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.406 (avg: 0.406)\tLoss: 3.8564 (avg: 4.1415)\tTop1: 23.438 (avg: 10.609)\tTop5: 46.875 (avg: 29.797)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.399 (avg: 0.407)\tLoss: 4.5028 (avg: 4.1444)\tTop1: 9.375 (avg: 10.763)\tTop5: 23.438 (avg: 29.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9354\tTop 1 accuracy: 7.450\tTop 5 accuracy: 24.600\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.395 (avg: 0.398)\tLoss: 4.0181 (avg: 4.1181)\tTop1: 14.062 (avg: 11.500)\tTop5: 40.625 (avg: 31.250)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.404 (avg: 0.404)\tLoss: 4.1638 (avg: 4.1326)\tTop1: 15.625 (avg: 11.312)\tTop5: 35.938 (avg: 30.719)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.399 (avg: 0.405)\tLoss: 3.9287 (avg: 4.1273)\tTop1: 17.188 (avg: 11.604)\tTop5: 32.812 (avg: 30.917)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.403 (avg: 0.406)\tLoss: 4.1113 (avg: 4.1345)\tTop1: 7.812 (avg: 11.312)\tTop5: 26.562 (avg: 30.703)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.400 (avg: 0.407)\tLoss: 4.1521 (avg: 4.1269)\tTop1: 14.062 (avg: 11.388)\tTop5: 21.875 (avg: 30.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0474\tTop 1 accuracy: 8.450\tTop 5 accuracy: 25.350\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.402 (avg: 0.399)\tLoss: 4.1612 (avg: 4.0743)\tTop1: 14.062 (avg: 11.938)\tTop5: 29.688 (avg: 31.500)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.389 (avg: 0.404)\tLoss: 3.8963 (avg: 4.1069)\tTop1: 12.500 (avg: 11.438)\tTop5: 31.250 (avg: 30.844)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.401 (avg: 0.406)\tLoss: 4.1088 (avg: 4.1184)\tTop1: 12.500 (avg: 11.125)\tTop5: 39.062 (avg: 30.688)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.398 (avg: 0.407)\tLoss: 4.1669 (avg: 4.1222)\tTop1: 9.375 (avg: 10.828)\tTop5: 34.375 (avg: 30.281)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.403 (avg: 0.407)\tLoss: 4.1031 (avg: 4.1168)\tTop1: 9.375 (avg: 11.250)\tTop5: 34.375 (avg: 30.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0453\tTop 1 accuracy: 8.950\tTop 5 accuracy: 23.800\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.407 (avg: 0.399)\tLoss: 4.0070 (avg: 4.0789)\tTop1: 10.938 (avg: 11.875)\tTop5: 34.375 (avg: 32.000)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.402 (avg: 0.404)\tLoss: 4.4493 (avg: 4.0977)\tTop1: 10.938 (avg: 11.781)\tTop5: 25.000 (avg: 31.312)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.403 (avg: 0.406)\tLoss: 4.0022 (avg: 4.0997)\tTop1: 15.625 (avg: 11.292)\tTop5: 31.250 (avg: 30.875)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.400 (avg: 0.407)\tLoss: 3.9411 (avg: 4.1043)\tTop1: 10.938 (avg: 11.141)\tTop5: 29.688 (avg: 30.469)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.400 (avg: 0.407)\tLoss: 4.3788 (avg: 4.1038)\tTop1: 7.812 (avg: 11.488)\tTop5: 23.438 (avg: 30.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8946\tTop 1 accuracy: 9.150\tTop 5 accuracy: 24.250\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.398 (avg: 0.397)\tLoss: 3.9655 (avg: 4.0803)\tTop1: 10.938 (avg: 12.000)\tTop5: 35.938 (avg: 32.250)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.403 (avg: 0.403)\tLoss: 3.9914 (avg: 4.0869)\tTop1: 9.375 (avg: 11.531)\tTop5: 28.125 (avg: 31.562)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.401 (avg: 0.405)\tLoss: 3.9513 (avg: 4.0770)\tTop1: 10.938 (avg: 12.062)\tTop5: 34.375 (avg: 31.979)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.403 (avg: 0.406)\tLoss: 4.2954 (avg: 4.0888)\tTop1: 6.250 (avg: 11.844)\tTop5: 28.125 (avg: 31.641)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.394 (avg: 0.407)\tLoss: 4.3982 (avg: 4.0904)\tTop1: 6.250 (avg: 11.650)\tTop5: 21.875 (avg: 31.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9352\tTop 1 accuracy: 7.350\tTop 5 accuracy: 24.850\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.401 (avg: 0.400)\tLoss: 4.0095 (avg: 4.1092)\tTop1: 10.938 (avg: 12.125)\tTop5: 31.250 (avg: 30.812)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.404 (avg: 0.405)\tLoss: 3.8727 (avg: 4.0772)\tTop1: 10.938 (avg: 12.375)\tTop5: 34.375 (avg: 32.031)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.400 (avg: 0.406)\tLoss: 4.2055 (avg: 4.0798)\tTop1: 7.812 (avg: 12.312)\tTop5: 21.875 (avg: 31.354)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.404 (avg: 0.407)\tLoss: 3.9647 (avg: 4.0805)\tTop1: 10.938 (avg: 11.984)\tTop5: 32.812 (avg: 31.609)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.399 (avg: 0.408)\tLoss: 4.0780 (avg: 4.0805)\tTop1: 17.188 (avg: 11.700)\tTop5: 29.688 (avg: 31.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9165\tTop 1 accuracy: 8.550\tTop 5 accuracy: 25.200\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.412 (avg: 0.400)\tLoss: 4.2529 (avg: 4.0567)\tTop1: 14.062 (avg: 11.375)\tTop5: 29.688 (avg: 31.062)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.401 (avg: 0.405)\tLoss: 3.8383 (avg: 4.0501)\tTop1: 12.500 (avg: 11.969)\tTop5: 42.188 (avg: 31.938)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.404 (avg: 0.406)\tLoss: 4.2491 (avg: 4.0469)\tTop1: 12.500 (avg: 12.208)\tTop5: 31.250 (avg: 32.312)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.403 (avg: 0.407)\tLoss: 4.1669 (avg: 4.0578)\tTop1: 10.938 (avg: 11.812)\tTop5: 23.438 (avg: 31.984)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.407 (avg: 0.408)\tLoss: 4.0452 (avg: 4.0612)\tTop1: 10.938 (avg: 11.688)\tTop5: 28.125 (avg: 32.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9482\tTop 1 accuracy: 8.800\tTop 5 accuracy: 25.100\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.400 (avg: 0.398)\tLoss: 3.8865 (avg: 3.9821)\tTop1: 14.062 (avg: 13.000)\tTop5: 32.812 (avg: 33.250)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.400 (avg: 0.404)\tLoss: 4.3275 (avg: 4.0315)\tTop1: 7.812 (avg: 12.156)\tTop5: 23.438 (avg: 32.281)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.404 (avg: 0.406)\tLoss: 4.2578 (avg: 4.0681)\tTop1: 6.250 (avg: 11.625)\tTop5: 34.375 (avg: 31.292)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.402 (avg: 0.407)\tLoss: 3.9424 (avg: 4.0612)\tTop1: 10.938 (avg: 11.594)\tTop5: 37.500 (avg: 31.359)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.404 (avg: 0.407)\tLoss: 4.3864 (avg: 4.0597)\tTop1: 9.375 (avg: 11.838)\tTop5: 25.000 (avg: 31.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0696\tTop 1 accuracy: 8.100\tTop 5 accuracy: 25.950\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.401 (avg: 0.395)\tLoss: 4.2904 (avg: 3.9810)\tTop1: 9.375 (avg: 13.562)\tTop5: 29.688 (avg: 32.938)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.406 (avg: 0.402)\tLoss: 4.1470 (avg: 3.9871)\tTop1: 6.250 (avg: 13.219)\tTop5: 23.438 (avg: 33.000)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.402 (avg: 0.404)\tLoss: 4.1090 (avg: 3.9940)\tTop1: 12.500 (avg: 13.188)\tTop5: 26.562 (avg: 33.292)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.407 (avg: 0.406)\tLoss: 3.9304 (avg: 4.0154)\tTop1: 10.938 (avg: 12.734)\tTop5: 34.375 (avg: 32.875)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.409 (avg: 0.406)\tLoss: 4.0216 (avg: 4.0359)\tTop1: 12.500 (avg: 12.550)\tTop5: 32.812 (avg: 32.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9456\tTop 1 accuracy: 8.900\tTop 5 accuracy: 25.850\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.402 (avg: 0.401)\tLoss: 3.9868 (avg: 4.0088)\tTop1: 12.500 (avg: 13.500)\tTop5: 29.688 (avg: 32.500)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.404 (avg: 0.405)\tLoss: 4.2345 (avg: 4.0191)\tTop1: 14.062 (avg: 13.000)\tTop5: 34.375 (avg: 32.938)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.399 (avg: 0.406)\tLoss: 4.0773 (avg: 4.0232)\tTop1: 17.188 (avg: 12.583)\tTop5: 42.188 (avg: 32.875)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.403 (avg: 0.407)\tLoss: 3.9415 (avg: 4.0116)\tTop1: 4.688 (avg: 12.719)\tTop5: 31.250 (avg: 32.953)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.396 (avg: 0.408)\tLoss: 3.5212 (avg: 4.0193)\tTop1: 25.000 (avg: 12.688)\tTop5: 50.000 (avg: 33.013)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9154\tTop 1 accuracy: 9.450\tTop 5 accuracy: 26.750\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.406 (avg: 0.398)\tLoss: 3.9470 (avg: 4.0247)\tTop1: 18.750 (avg: 12.688)\tTop5: 37.500 (avg: 32.188)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.403 (avg: 0.404)\tLoss: 4.0183 (avg: 3.9836)\tTop1: 7.812 (avg: 13.125)\tTop5: 31.250 (avg: 32.812)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.405 (avg: 0.406)\tLoss: 3.8856 (avg: 3.9798)\tTop1: 12.500 (avg: 12.625)\tTop5: 37.500 (avg: 34.271)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.399 (avg: 0.407)\tLoss: 4.1184 (avg: 3.9973)\tTop1: 7.812 (avg: 12.484)\tTop5: 29.688 (avg: 33.641)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.401 (avg: 0.407)\tLoss: 4.0921 (avg: 4.0018)\tTop1: 9.375 (avg: 12.200)\tTop5: 32.812 (avg: 33.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8767\tTop 1 accuracy: 9.250\tTop 5 accuracy: 26.350\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.405 (avg: 0.400)\tLoss: 3.9031 (avg: 4.0492)\tTop1: 20.312 (avg: 12.125)\tTop5: 39.062 (avg: 33.438)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.401 (avg: 0.405)\tLoss: 3.7472 (avg: 4.0156)\tTop1: 21.875 (avg: 12.625)\tTop5: 43.750 (avg: 33.469)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.407 (avg: 0.407)\tLoss: 4.1581 (avg: 4.0053)\tTop1: 18.750 (avg: 12.833)\tTop5: 34.375 (avg: 33.729)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.400 (avg: 0.407)\tLoss: 3.7811 (avg: 3.9845)\tTop1: 14.062 (avg: 13.016)\tTop5: 39.062 (avg: 33.797)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.408 (avg: 0.408)\tLoss: 3.9200 (avg: 3.9853)\tTop1: 9.375 (avg: 12.813)\tTop5: 28.125 (avg: 33.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9348\tTop 1 accuracy: 9.000\tTop 5 accuracy: 26.800\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.396 (avg: 0.397)\tLoss: 3.9875 (avg: 3.8842)\tTop1: 12.500 (avg: 14.375)\tTop5: 35.938 (avg: 36.875)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.407 (avg: 0.403)\tLoss: 3.9710 (avg: 3.8642)\tTop1: 12.500 (avg: 14.781)\tTop5: 29.688 (avg: 36.594)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.402 (avg: 0.405)\tLoss: 3.8575 (avg: 3.8776)\tTop1: 15.625 (avg: 14.479)\tTop5: 46.875 (avg: 36.667)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.399 (avg: 0.406)\tLoss: 3.9981 (avg: 3.8788)\tTop1: 15.625 (avg: 14.672)\tTop5: 35.938 (avg: 36.594)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.401 (avg: 0.407)\tLoss: 4.2016 (avg: 3.8746)\tTop1: 14.062 (avg: 14.800)\tTop5: 29.688 (avg: 36.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8419\tTop 1 accuracy: 10.500\tTop 5 accuracy: 27.600\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.398 (avg: 0.396)\tLoss: 3.8860 (avg: 3.7909)\tTop1: 17.188 (avg: 16.000)\tTop5: 37.500 (avg: 38.562)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.404 (avg: 0.401)\tLoss: 3.8958 (avg: 3.8117)\tTop1: 18.750 (avg: 16.188)\tTop5: 35.938 (avg: 37.656)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.401 (avg: 0.404)\tLoss: 3.7949 (avg: 3.8257)\tTop1: 14.062 (avg: 15.146)\tTop5: 53.125 (avg: 38.104)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.411 (avg: 0.406)\tLoss: 3.6477 (avg: 3.8309)\tTop1: 14.062 (avg: 15.547)\tTop5: 35.938 (avg: 38.031)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.403 (avg: 0.407)\tLoss: 4.1093 (avg: 3.8442)\tTop1: 9.375 (avg: 15.363)\tTop5: 23.438 (avg: 37.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8800\tTop 1 accuracy: 10.350\tTop 5 accuracy: 28.900\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.405 (avg: 0.399)\tLoss: 4.1743 (avg: 3.8534)\tTop1: 14.062 (avg: 14.938)\tTop5: 28.125 (avg: 37.062)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.400 (avg: 0.404)\tLoss: 3.7875 (avg: 3.8132)\tTop1: 20.312 (avg: 15.562)\tTop5: 35.938 (avg: 39.031)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.403 (avg: 0.406)\tLoss: 3.7637 (avg: 3.8411)\tTop1: 23.438 (avg: 15.292)\tTop5: 42.188 (avg: 37.958)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.401 (avg: 0.407)\tLoss: 3.8388 (avg: 3.8400)\tTop1: 17.188 (avg: 15.516)\tTop5: 39.062 (avg: 38.078)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.404 (avg: 0.407)\tLoss: 3.7859 (avg: 3.8348)\tTop1: 15.625 (avg: 15.538)\tTop5: 37.500 (avg: 38.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9236\tTop 1 accuracy: 10.100\tTop 5 accuracy: 28.900\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.405 (avg: 0.401)\tLoss: 3.5346 (avg: 3.8684)\tTop1: 28.125 (avg: 16.062)\tTop5: 46.875 (avg: 36.625)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.393 (avg: 0.405)\tLoss: 3.6033 (avg: 3.8551)\tTop1: 21.875 (avg: 15.344)\tTop5: 39.062 (avg: 37.094)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.401 (avg: 0.407)\tLoss: 3.6054 (avg: 3.8394)\tTop1: 14.062 (avg: 15.458)\tTop5: 40.625 (avg: 37.458)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.402 (avg: 0.407)\tLoss: 3.7624 (avg: 3.8327)\tTop1: 21.875 (avg: 15.484)\tTop5: 45.312 (avg: 37.781)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.409 (avg: 0.408)\tLoss: 4.1107 (avg: 3.8307)\tTop1: 12.500 (avg: 15.825)\tTop5: 40.625 (avg: 38.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9064\tTop 1 accuracy: 10.100\tTop 5 accuracy: 28.400\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.400 (avg: 0.397)\tLoss: 3.9584 (avg: 3.8660)\tTop1: 14.062 (avg: 17.062)\tTop5: 34.375 (avg: 37.250)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.405 (avg: 0.403)\tLoss: 3.8983 (avg: 3.8553)\tTop1: 12.500 (avg: 16.469)\tTop5: 37.500 (avg: 37.438)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.401 (avg: 0.405)\tLoss: 4.2191 (avg: 3.8425)\tTop1: 9.375 (avg: 16.000)\tTop5: 25.000 (avg: 37.375)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.405 (avg: 0.406)\tLoss: 3.7217 (avg: 3.8452)\tTop1: 15.625 (avg: 15.828)\tTop5: 34.375 (avg: 37.312)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.396 (avg: 0.407)\tLoss: 3.8602 (avg: 3.8308)\tTop1: 15.625 (avg: 15.875)\tTop5: 37.500 (avg: 37.950)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9020\tTop 1 accuracy: 10.350\tTop 5 accuracy: 28.750\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.399 (avg: 0.398)\tLoss: 4.0528 (avg: 3.8413)\tTop1: 14.062 (avg: 15.438)\tTop5: 32.812 (avg: 38.000)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.406 (avg: 0.403)\tLoss: 3.8235 (avg: 3.8478)\tTop1: 17.188 (avg: 15.781)\tTop5: 32.812 (avg: 38.219)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.403 (avg: 0.405)\tLoss: 3.9035 (avg: 3.8268)\tTop1: 10.938 (avg: 15.604)\tTop5: 34.375 (avg: 38.667)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.406 (avg: 0.406)\tLoss: 3.6970 (avg: 3.8163)\tTop1: 10.938 (avg: 15.719)\tTop5: 42.188 (avg: 38.859)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.399 (avg: 0.407)\tLoss: 3.9729 (avg: 3.8278)\tTop1: 9.375 (avg: 15.750)\tTop5: 32.812 (avg: 38.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8399\tTop 1 accuracy: 10.100\tTop 5 accuracy: 28.700\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.406 (avg: 0.398)\tLoss: 3.7031 (avg: 3.7579)\tTop1: 14.062 (avg: 17.938)\tTop5: 43.750 (avg: 40.250)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.395 (avg: 0.402)\tLoss: 3.7425 (avg: 3.8014)\tTop1: 15.625 (avg: 17.156)\tTop5: 40.625 (avg: 38.875)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.403 (avg: 0.404)\tLoss: 3.6241 (avg: 3.7979)\tTop1: 14.062 (avg: 16.708)\tTop5: 43.750 (avg: 38.438)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.397 (avg: 0.405)\tLoss: 4.0849 (avg: 3.8038)\tTop1: 12.500 (avg: 16.562)\tTop5: 35.938 (avg: 38.438)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.404 (avg: 0.406)\tLoss: 4.0101 (avg: 3.8219)\tTop1: 12.500 (avg: 16.038)\tTop5: 34.375 (avg: 37.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9315\tTop 1 accuracy: 10.200\tTop 5 accuracy: 28.650\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.402 (avg: 0.400)\tLoss: 3.3693 (avg: 3.7407)\tTop1: 15.625 (avg: 15.562)\tTop5: 54.688 (avg: 39.188)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.403 (avg: 0.405)\tLoss: 3.7556 (avg: 3.7845)\tTop1: 17.188 (avg: 15.750)\tTop5: 43.750 (avg: 38.281)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.408 (avg: 0.407)\tLoss: 3.7161 (avg: 3.7982)\tTop1: 18.750 (avg: 16.208)\tTop5: 34.375 (avg: 38.521)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.400 (avg: 0.407)\tLoss: 3.7316 (avg: 3.8144)\tTop1: 7.812 (avg: 16.109)\tTop5: 42.188 (avg: 38.141)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.403 (avg: 0.407)\tLoss: 4.2410 (avg: 3.8167)\tTop1: 7.812 (avg: 15.950)\tTop5: 26.562 (avg: 38.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8883\tTop 1 accuracy: 10.250\tTop 5 accuracy: 28.600\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.398 (avg: 0.397)\tLoss: 4.0776 (avg: 3.8446)\tTop1: 12.500 (avg: 16.062)\tTop5: 37.500 (avg: 38.875)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.391 (avg: 0.403)\tLoss: 3.8552 (avg: 3.8175)\tTop1: 7.812 (avg: 16.156)\tTop5: 29.688 (avg: 37.938)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.398 (avg: 0.405)\tLoss: 3.7875 (avg: 3.8260)\tTop1: 10.938 (avg: 16.000)\tTop5: 37.500 (avg: 38.271)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.403 (avg: 0.406)\tLoss: 3.8062 (avg: 3.8118)\tTop1: 7.812 (avg: 16.141)\tTop5: 35.938 (avg: 38.703)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.400 (avg: 0.407)\tLoss: 3.8039 (avg: 3.8143)\tTop1: 25.000 (avg: 16.025)\tTop5: 39.062 (avg: 38.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8802\tTop 1 accuracy: 10.250\tTop 5 accuracy: 28.700\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.401 (avg: 0.399)\tLoss: 3.7209 (avg: 3.7300)\tTop1: 18.750 (avg: 16.562)\tTop5: 32.812 (avg: 40.562)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.404 (avg: 0.405)\tLoss: 4.0548 (avg: 3.7815)\tTop1: 17.188 (avg: 15.969)\tTop5: 35.938 (avg: 39.375)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.401 (avg: 0.407)\tLoss: 3.9445 (avg: 3.7809)\tTop1: 18.750 (avg: 16.167)\tTop5: 39.062 (avg: 39.250)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.411 (avg: 0.408)\tLoss: 4.1434 (avg: 3.8071)\tTop1: 7.812 (avg: 16.094)\tTop5: 26.562 (avg: 38.656)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.400 (avg: 0.408)\tLoss: 3.8230 (avg: 3.8083)\tTop1: 17.188 (avg: 16.300)\tTop5: 39.062 (avg: 38.562)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9500\tTop 1 accuracy: 9.750\tTop 5 accuracy: 28.700\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.400 (avg: 0.398)\tLoss: 3.5542 (avg: 3.7638)\tTop1: 15.625 (avg: 17.062)\tTop5: 39.062 (avg: 39.312)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.395 (avg: 0.404)\tLoss: 4.0621 (avg: 3.7768)\tTop1: 9.375 (avg: 16.688)\tTop5: 31.250 (avg: 39.344)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.402 (avg: 0.405)\tLoss: 3.7876 (avg: 3.7938)\tTop1: 18.750 (avg: 16.667)\tTop5: 37.500 (avg: 39.083)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.399 (avg: 0.406)\tLoss: 3.8728 (avg: 3.8001)\tTop1: 10.938 (avg: 16.562)\tTop5: 34.375 (avg: 38.391)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.409 (avg: 0.407)\tLoss: 3.7794 (avg: 3.8052)\tTop1: 14.062 (avg: 16.388)\tTop5: 35.938 (avg: 38.562)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9449\tTop 1 accuracy: 9.900\tTop 5 accuracy: 29.050\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.410 (avg: 0.399)\tLoss: 3.4636 (avg: 3.8448)\tTop1: 21.875 (avg: 15.812)\tTop5: 40.625 (avg: 37.562)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.396 (avg: 0.404)\tLoss: 3.7644 (avg: 3.8340)\tTop1: 10.938 (avg: 15.625)\tTop5: 32.812 (avg: 38.062)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.409 (avg: 0.406)\tLoss: 3.8617 (avg: 3.8208)\tTop1: 17.188 (avg: 16.083)\tTop5: 34.375 (avg: 38.458)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.404 (avg: 0.407)\tLoss: 3.8356 (avg: 3.8089)\tTop1: 12.500 (avg: 16.047)\tTop5: 39.062 (avg: 38.922)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.404 (avg: 0.408)\tLoss: 4.0117 (avg: 3.8138)\tTop1: 12.500 (avg: 16.062)\tTop5: 29.688 (avg: 38.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8991\tTop 1 accuracy: 10.150\tTop 5 accuracy: 28.200\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.394 (avg: 0.397)\tLoss: 3.7745 (avg: 3.7939)\tTop1: 14.062 (avg: 17.125)\tTop5: 45.312 (avg: 39.562)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.403 (avg: 0.403)\tLoss: 3.9304 (avg: 3.7862)\tTop1: 15.625 (avg: 16.719)\tTop5: 34.375 (avg: 38.750)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.397 (avg: 0.405)\tLoss: 4.0194 (avg: 3.7997)\tTop1: 12.500 (avg: 16.625)\tTop5: 35.938 (avg: 38.812)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.405 (avg: 0.406)\tLoss: 3.9350 (avg: 3.8004)\tTop1: 14.062 (avg: 16.312)\tTop5: 40.625 (avg: 38.797)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.406 (avg: 0.407)\tLoss: 3.8030 (avg: 3.8044)\tTop1: 15.625 (avg: 16.088)\tTop5: 42.188 (avg: 38.562)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9244\tTop 1 accuracy: 10.100\tTop 5 accuracy: 28.800\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.402 (avg: 0.400)\tLoss: 3.8208 (avg: 3.7412)\tTop1: 20.312 (avg: 16.562)\tTop5: 43.750 (avg: 41.375)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.410 (avg: 0.405)\tLoss: 3.2636 (avg: 3.7528)\tTop1: 32.812 (avg: 16.844)\tTop5: 53.125 (avg: 40.094)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.408 (avg: 0.407)\tLoss: 3.8608 (avg: 3.7736)\tTop1: 18.750 (avg: 16.396)\tTop5: 40.625 (avg: 39.458)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.408 (avg: 0.408)\tLoss: 3.8449 (avg: 3.7883)\tTop1: 12.500 (avg: 16.188)\tTop5: 35.938 (avg: 39.109)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.397 (avg: 0.408)\tLoss: 3.7786 (avg: 3.7991)\tTop1: 17.188 (avg: 16.150)\tTop5: 37.500 (avg: 38.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0082\tTop 1 accuracy: 9.850\tTop 5 accuracy: 28.150\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.403 (avg: 0.400)\tLoss: 3.8879 (avg: 3.8371)\tTop1: 17.188 (avg: 16.062)\tTop5: 40.625 (avg: 36.562)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.402 (avg: 0.405)\tLoss: 3.8353 (avg: 3.8136)\tTop1: 14.062 (avg: 16.688)\tTop5: 35.938 (avg: 37.969)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.406 (avg: 0.406)\tLoss: 3.5022 (avg: 3.7939)\tTop1: 21.875 (avg: 16.667)\tTop5: 42.188 (avg: 38.396)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.402 (avg: 0.407)\tLoss: 3.4937 (avg: 3.8066)\tTop1: 7.812 (avg: 16.391)\tTop5: 42.188 (avg: 38.312)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.405 (avg: 0.408)\tLoss: 3.7131 (avg: 3.7940)\tTop1: 10.938 (avg: 16.400)\tTop5: 39.062 (avg: 38.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9237\tTop 1 accuracy: 10.350\tTop 5 accuracy: 28.800\n",
            "\n",
            "pct_3x3 = 0.5: top1 = 9.90000057220459 \t top5 = 29.05000114440918 \t batch time = 0.2948407232761383\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.414 (avg: 0.491)\tLoss: 5.3030 (avg: 5.3044)\tTop1: 0.000 (avg: 0.500)\tTop5: 1.562 (avg: 2.812)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.405 (avg: 0.451)\tLoss: 5.2996 (avg: 5.3019)\tTop1: 0.000 (avg: 0.375)\tTop5: 0.000 (avg: 2.438)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.401 (avg: 0.438)\tLoss: 5.2978 (avg: 5.3009)\tTop1: 0.000 (avg: 0.375)\tTop5: 1.562 (avg: 2.208)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.405 (avg: 0.432)\tLoss: 5.2982 (avg: 5.3004)\tTop1: 1.562 (avg: 0.359)\tTop5: 3.125 (avg: 2.125)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.411 (avg: 0.428)\tLoss: 5.2971 (avg: 5.3000)\tTop1: 0.000 (avg: 0.338)\tTop5: 1.562 (avg: 2.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2952\tTop 1 accuracy: 0.800\tTop 5 accuracy: 2.400\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.410 (avg: 0.399)\tLoss: 5.2973 (avg: 5.2973)\tTop1: 0.000 (avg: 0.625)\tTop5: 3.125 (avg: 3.062)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.397 (avg: 0.405)\tLoss: 5.2926 (avg: 5.2971)\tTop1: 0.000 (avg: 0.469)\tTop5: 3.125 (avg: 2.750)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.403 (avg: 0.407)\tLoss: 5.2354 (avg: 5.2952)\tTop1: 3.125 (avg: 0.542)\tTop5: 9.375 (avg: 2.667)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.410 (avg: 0.407)\tLoss: 5.3101 (avg: 5.2931)\tTop1: 0.000 (avg: 0.453)\tTop5: 1.562 (avg: 2.609)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.394 (avg: 0.408)\tLoss: 5.2836 (avg: 5.2909)\tTop1: 0.000 (avg: 0.488)\tTop5: 1.562 (avg: 2.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1651\tTop 1 accuracy: 0.500\tTop 5 accuracy: 3.050\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.404 (avg: 0.400)\tLoss: 5.2896 (avg: 5.2701)\tTop1: 3.125 (avg: 0.812)\tTop5: 6.250 (avg: 3.375)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.403 (avg: 0.406)\tLoss: 5.3006 (avg: 5.2808)\tTop1: 0.000 (avg: 0.656)\tTop5: 4.688 (avg: 3.156)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.404 (avg: 0.408)\tLoss: 5.2424 (avg: 5.2747)\tTop1: 0.000 (avg: 0.688)\tTop5: 6.250 (avg: 3.125)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.401 (avg: 0.409)\tLoss: 5.2898 (avg: 5.2716)\tTop1: 0.000 (avg: 0.734)\tTop5: 0.000 (avg: 3.188)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 5.3101 (avg: 5.2702)\tTop1: 0.000 (avg: 0.713)\tTop5: 1.562 (avg: 3.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1875\tTop 1 accuracy: 0.700\tTop 5 accuracy: 3.600\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.401 (avg: 0.401)\tLoss: 5.2612 (avg: 5.2538)\tTop1: 0.000 (avg: 0.812)\tTop5: 7.812 (avg: 4.625)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.403 (avg: 0.406)\tLoss: 5.2367 (avg: 5.2600)\tTop1: 3.125 (avg: 0.969)\tTop5: 4.688 (avg: 4.281)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.402 (avg: 0.408)\tLoss: 5.2220 (avg: 5.2616)\tTop1: 0.000 (avg: 0.938)\tTop5: 9.375 (avg: 4.229)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.404 (avg: 0.409)\tLoss: 5.2615 (avg: 5.2629)\tTop1: 0.000 (avg: 0.859)\tTop5: 7.812 (avg: 4.172)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.403 (avg: 0.409)\tLoss: 5.3537 (avg: 5.2594)\tTop1: 0.000 (avg: 0.825)\tTop5: 1.562 (avg: 4.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2124\tTop 1 accuracy: 0.550\tTop 5 accuracy: 3.600\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.403 (avg: 0.399)\tLoss: 5.1519 (avg: 5.2338)\tTop1: 0.000 (avg: 0.812)\tTop5: 6.250 (avg: 4.688)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.400 (avg: 0.404)\tLoss: 5.2299 (avg: 5.2325)\tTop1: 3.125 (avg: 0.719)\tTop5: 9.375 (avg: 4.438)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.397 (avg: 0.407)\tLoss: 5.2735 (avg: 5.2416)\tTop1: 0.000 (avg: 0.771)\tTop5: 1.562 (avg: 4.292)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.401 (avg: 0.408)\tLoss: 5.2862 (avg: 5.2450)\tTop1: 1.562 (avg: 0.859)\tTop5: 3.125 (avg: 4.297)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.404 (avg: 0.408)\tLoss: 5.2604 (avg: 5.2430)\tTop1: 0.000 (avg: 0.925)\tTop5: 0.000 (avg: 4.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1695\tTop 1 accuracy: 1.100\tTop 5 accuracy: 4.300\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.396 (avg: 0.401)\tLoss: 5.1985 (avg: 5.2253)\tTop1: 0.000 (avg: 0.938)\tTop5: 6.250 (avg: 5.688)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.404 (avg: 0.406)\tLoss: 5.1964 (avg: 5.2227)\tTop1: 1.562 (avg: 1.188)\tTop5: 9.375 (avg: 5.719)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.400 (avg: 0.408)\tLoss: 5.2360 (avg: 5.2169)\tTop1: 1.562 (avg: 1.229)\tTop5: 7.812 (avg: 5.708)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.401 (avg: 0.409)\tLoss: 5.2583 (avg: 5.2195)\tTop1: 0.000 (avg: 1.156)\tTop5: 4.688 (avg: 5.312)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.404 (avg: 0.409)\tLoss: 5.1398 (avg: 5.2171)\tTop1: 0.000 (avg: 1.088)\tTop5: 6.250 (avg: 5.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1529\tTop 1 accuracy: 0.850\tTop 5 accuracy: 3.850\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.406 (avg: 0.399)\tLoss: 5.1584 (avg: 5.1895)\tTop1: 0.000 (avg: 1.125)\tTop5: 6.250 (avg: 6.188)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.397 (avg: 0.404)\tLoss: 5.2173 (avg: 5.1904)\tTop1: 3.125 (avg: 1.156)\tTop5: 9.375 (avg: 6.062)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.402 (avg: 0.406)\tLoss: 5.2141 (avg: 5.1885)\tTop1: 0.000 (avg: 1.271)\tTop5: 7.812 (avg: 6.062)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.413 (avg: 0.407)\tLoss: 5.1500 (avg: 5.1889)\tTop1: 0.000 (avg: 1.234)\tTop5: 4.688 (avg: 5.891)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.399 (avg: 0.407)\tLoss: 5.2668 (avg: 5.1896)\tTop1: 0.000 (avg: 1.150)\tTop5: 6.250 (avg: 5.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0432\tTop 1 accuracy: 1.250\tTop 5 accuracy: 5.700\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.407 (avg: 0.402)\tLoss: 5.1077 (avg: 5.1403)\tTop1: 4.688 (avg: 1.375)\tTop5: 9.375 (avg: 6.562)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.413 (avg: 0.407)\tLoss: 5.0908 (avg: 5.1457)\tTop1: 0.000 (avg: 1.344)\tTop5: 3.125 (avg: 6.062)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.400 (avg: 0.409)\tLoss: 5.0654 (avg: 5.1438)\tTop1: 1.562 (avg: 1.312)\tTop5: 10.938 (avg: 5.958)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.414 (avg: 0.410)\tLoss: 5.0109 (avg: 5.1390)\tTop1: 0.000 (avg: 1.391)\tTop5: 12.500 (avg: 6.234)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.405 (avg: 0.410)\tLoss: 5.1879 (avg: 5.1410)\tTop1: 0.000 (avg: 1.338)\tTop5: 6.250 (avg: 6.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1527\tTop 1 accuracy: 1.850\tTop 5 accuracy: 7.350\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.403 (avg: 0.402)\tLoss: 4.9654 (avg: 5.1012)\tTop1: 1.562 (avg: 2.125)\tTop5: 12.500 (avg: 7.375)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.398 (avg: 0.407)\tLoss: 5.1097 (avg: 5.1036)\tTop1: 3.125 (avg: 1.812)\tTop5: 7.812 (avg: 7.125)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.411 (avg: 0.409)\tLoss: 5.0498 (avg: 5.1172)\tTop1: 1.562 (avg: 1.625)\tTop5: 6.250 (avg: 6.750)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.404 (avg: 0.410)\tLoss: 4.9960 (avg: 5.1150)\tTop1: 3.125 (avg: 1.688)\tTop5: 6.250 (avg: 6.500)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.410 (avg: 0.411)\tLoss: 5.1885 (avg: 5.1143)\tTop1: 0.000 (avg: 1.663)\tTop5: 9.375 (avg: 6.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0795\tTop 1 accuracy: 1.400\tTop 5 accuracy: 6.500\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.408 (avg: 0.401)\tLoss: 4.9991 (avg: 5.0834)\tTop1: 3.125 (avg: 1.875)\tTop5: 7.812 (avg: 6.500)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.404 (avg: 0.407)\tLoss: 5.0357 (avg: 5.0889)\tTop1: 3.125 (avg: 1.656)\tTop5: 10.938 (avg: 6.688)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.407 (avg: 0.409)\tLoss: 5.0889 (avg: 5.0953)\tTop1: 1.562 (avg: 1.542)\tTop5: 7.812 (avg: 6.625)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.415 (avg: 0.410)\tLoss: 5.0834 (avg: 5.0911)\tTop1: 3.125 (avg: 1.594)\tTop5: 9.375 (avg: 6.625)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 5.1872 (avg: 5.0896)\tTop1: 1.562 (avg: 1.688)\tTop5: 4.688 (avg: 6.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0959\tTop 1 accuracy: 1.950\tTop 5 accuracy: 7.550\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.408 (avg: 0.403)\tLoss: 5.1398 (avg: 5.0333)\tTop1: 1.562 (avg: 2.375)\tTop5: 7.812 (avg: 8.812)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.411 (avg: 0.408)\tLoss: 4.9812 (avg: 5.0441)\tTop1: 3.125 (avg: 2.000)\tTop5: 14.062 (avg: 8.344)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.410 (avg: 0.409)\tLoss: 5.0000 (avg: 5.0548)\tTop1: 1.562 (avg: 1.854)\tTop5: 6.250 (avg: 7.729)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 5.0152 (avg: 5.0561)\tTop1: 1.562 (avg: 1.766)\tTop5: 9.375 (avg: 7.906)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.413 (avg: 0.411)\tLoss: 4.9448 (avg: 5.0451)\tTop1: 1.562 (avg: 1.813)\tTop5: 6.250 (avg: 8.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0419\tTop 1 accuracy: 2.550\tTop 5 accuracy: 9.200\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.413 (avg: 0.400)\tLoss: 5.0114 (avg: 4.9840)\tTop1: 3.125 (avg: 1.875)\tTop5: 10.938 (avg: 8.688)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.400 (avg: 0.406)\tLoss: 4.9964 (avg: 4.9964)\tTop1: 3.125 (avg: 2.000)\tTop5: 17.188 (avg: 8.812)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.409 (avg: 0.409)\tLoss: 5.0242 (avg: 4.9896)\tTop1: 1.562 (avg: 2.083)\tTop5: 6.250 (avg: 8.729)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.400 (avg: 0.409)\tLoss: 4.8721 (avg: 4.9882)\tTop1: 1.562 (avg: 2.109)\tTop5: 15.625 (avg: 8.906)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.402 (avg: 0.409)\tLoss: 5.1043 (avg: 4.9958)\tTop1: 0.000 (avg: 1.963)\tTop5: 6.250 (avg: 8.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0240\tTop 1 accuracy: 1.700\tTop 5 accuracy: 8.900\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.411 (avg: 0.402)\tLoss: 5.1287 (avg: 4.9566)\tTop1: 0.000 (avg: 2.000)\tTop5: 1.562 (avg: 9.188)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.410 (avg: 0.407)\tLoss: 5.0782 (avg: 4.9782)\tTop1: 1.562 (avg: 1.844)\tTop5: 7.812 (avg: 8.562)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.401 (avg: 0.409)\tLoss: 5.0350 (avg: 4.9949)\tTop1: 4.688 (avg: 1.771)\tTop5: 12.500 (avg: 8.354)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.410 (avg: 0.410)\tLoss: 4.8854 (avg: 4.9953)\tTop1: 3.125 (avg: 1.844)\tTop5: 15.625 (avg: 8.672)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.402 (avg: 0.410)\tLoss: 5.1023 (avg: 4.9888)\tTop1: 3.125 (avg: 1.913)\tTop5: 6.250 (avg: 8.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0499\tTop 1 accuracy: 1.850\tTop 5 accuracy: 9.150\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.404 (avg: 0.402)\tLoss: 4.9029 (avg: 4.9597)\tTop1: 3.125 (avg: 2.812)\tTop5: 6.250 (avg: 9.688)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.408 (avg: 0.408)\tLoss: 4.8085 (avg: 4.9563)\tTop1: 3.125 (avg: 2.531)\tTop5: 12.500 (avg: 9.844)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.409 (avg: 0.409)\tLoss: 5.1955 (avg: 4.9703)\tTop1: 1.562 (avg: 2.312)\tTop5: 3.125 (avg: 9.396)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.401 (avg: 0.410)\tLoss: 5.1095 (avg: 4.9639)\tTop1: 1.562 (avg: 2.312)\tTop5: 9.375 (avg: 9.188)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.409 (avg: 0.410)\tLoss: 4.9916 (avg: 4.9600)\tTop1: 1.562 (avg: 2.388)\tTop5: 10.938 (avg: 9.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8753\tTop 1 accuracy: 2.600\tTop 5 accuracy: 10.650\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.415 (avg: 0.403)\tLoss: 4.8272 (avg: 4.9170)\tTop1: 4.688 (avg: 3.188)\tTop5: 14.062 (avg: 11.438)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.404 (avg: 0.408)\tLoss: 4.7765 (avg: 4.8990)\tTop1: 1.562 (avg: 3.500)\tTop5: 14.062 (avg: 11.844)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.403 (avg: 0.409)\tLoss: 4.8903 (avg: 4.9089)\tTop1: 1.562 (avg: 3.167)\tTop5: 12.500 (avg: 11.229)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 4.9445 (avg: 4.9149)\tTop1: 4.688 (avg: 3.031)\tTop5: 9.375 (avg: 10.969)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.399 (avg: 0.411)\tLoss: 4.9405 (avg: 4.9132)\tTop1: 0.000 (avg: 3.000)\tTop5: 6.250 (avg: 10.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8727\tTop 1 accuracy: 2.600\tTop 5 accuracy: 10.550\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.405 (avg: 0.402)\tLoss: 4.8911 (avg: 4.8556)\tTop1: 0.000 (avg: 2.875)\tTop5: 7.812 (avg: 11.688)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.413 (avg: 0.407)\tLoss: 4.9448 (avg: 4.8661)\tTop1: 1.562 (avg: 2.594)\tTop5: 7.812 (avg: 11.500)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.402 (avg: 0.409)\tLoss: 4.7661 (avg: 4.8785)\tTop1: 4.688 (avg: 2.771)\tTop5: 12.500 (avg: 11.271)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.406 (avg: 0.410)\tLoss: 4.8081 (avg: 4.8671)\tTop1: 1.562 (avg: 2.875)\tTop5: 17.188 (avg: 11.906)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.409 (avg: 0.410)\tLoss: 4.9214 (avg: 4.8631)\tTop1: 1.562 (avg: 3.025)\tTop5: 9.375 (avg: 11.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7186\tTop 1 accuracy: 2.950\tTop 5 accuracy: 10.900\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.402 (avg: 0.400)\tLoss: 4.6748 (avg: 4.7919)\tTop1: 3.125 (avg: 3.875)\tTop5: 14.062 (avg: 14.438)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.404 (avg: 0.407)\tLoss: 4.8633 (avg: 4.7837)\tTop1: 1.562 (avg: 3.125)\tTop5: 10.938 (avg: 13.688)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.407 (avg: 0.409)\tLoss: 4.8965 (avg: 4.7938)\tTop1: 4.688 (avg: 3.167)\tTop5: 17.188 (avg: 13.417)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.401 (avg: 0.410)\tLoss: 4.6267 (avg: 4.7965)\tTop1: 7.812 (avg: 3.328)\tTop5: 14.062 (avg: 13.406)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.409 (avg: 0.410)\tLoss: 4.7243 (avg: 4.7929)\tTop1: 3.125 (avg: 3.363)\tTop5: 15.625 (avg: 13.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7998\tTop 1 accuracy: 4.350\tTop 5 accuracy: 14.800\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.408 (avg: 0.403)\tLoss: 4.6132 (avg: 4.7039)\tTop1: 1.562 (avg: 3.625)\tTop5: 18.750 (avg: 15.375)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.402 (avg: 0.407)\tLoss: 4.6983 (avg: 4.7249)\tTop1: 1.562 (avg: 3.344)\tTop5: 20.312 (avg: 15.188)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.406 (avg: 0.409)\tLoss: 4.7077 (avg: 4.7186)\tTop1: 6.250 (avg: 3.542)\tTop5: 25.000 (avg: 15.438)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.412 (avg: 0.410)\tLoss: 4.8620 (avg: 4.7467)\tTop1: 6.250 (avg: 3.484)\tTop5: 17.188 (avg: 14.750)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.403 (avg: 0.411)\tLoss: 4.8229 (avg: 4.7439)\tTop1: 4.688 (avg: 3.588)\tTop5: 12.500 (avg: 14.813)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8362\tTop 1 accuracy: 3.250\tTop 5 accuracy: 13.200\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.396 (avg: 0.403)\tLoss: 4.5660 (avg: 4.7107)\tTop1: 4.688 (avg: 3.750)\tTop5: 28.125 (avg: 15.438)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.407 (avg: 0.408)\tLoss: 4.8392 (avg: 4.6947)\tTop1: 6.250 (avg: 3.688)\tTop5: 14.062 (avg: 15.844)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.402 (avg: 0.409)\tLoss: 4.9950 (avg: 4.7038)\tTop1: 1.562 (avg: 3.562)\tTop5: 10.938 (avg: 15.354)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.407 (avg: 0.411)\tLoss: 4.7321 (avg: 4.6922)\tTop1: 3.125 (avg: 3.750)\tTop5: 15.625 (avg: 15.641)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.414 (avg: 0.411)\tLoss: 4.5446 (avg: 4.6906)\tTop1: 10.938 (avg: 3.988)\tTop5: 18.750 (avg: 15.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6245\tTop 1 accuracy: 3.800\tTop 5 accuracy: 15.400\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.415 (avg: 0.403)\tLoss: 4.7915 (avg: 4.6520)\tTop1: 1.562 (avg: 4.250)\tTop5: 18.750 (avg: 17.375)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.402 (avg: 0.408)\tLoss: 4.7838 (avg: 4.6205)\tTop1: 6.250 (avg: 4.531)\tTop5: 12.500 (avg: 17.656)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.407 (avg: 0.409)\tLoss: 4.7216 (avg: 4.6162)\tTop1: 4.688 (avg: 4.396)\tTop5: 17.188 (avg: 17.188)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.406 (avg: 0.410)\tLoss: 4.8059 (avg: 4.6123)\tTop1: 4.688 (avg: 4.578)\tTop5: 7.812 (avg: 17.328)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.399 (avg: 0.411)\tLoss: 4.6643 (avg: 4.6185)\tTop1: 4.688 (avg: 4.738)\tTop5: 14.062 (avg: 17.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6499\tTop 1 accuracy: 4.400\tTop 5 accuracy: 15.650\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.411 (avg: 0.403)\tLoss: 4.5628 (avg: 4.5695)\tTop1: 3.125 (avg: 5.750)\tTop5: 17.188 (avg: 18.875)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.415 (avg: 0.408)\tLoss: 4.3330 (avg: 4.5840)\tTop1: 6.250 (avg: 5.625)\tTop5: 25.000 (avg: 18.375)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 4.5782 (avg: 4.5921)\tTop1: 3.125 (avg: 5.708)\tTop5: 17.188 (avg: 18.250)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.407 (avg: 0.411)\tLoss: 4.5489 (avg: 4.5789)\tTop1: 6.250 (avg: 5.641)\tTop5: 23.438 (avg: 18.750)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.404 (avg: 0.411)\tLoss: 4.6253 (avg: 4.5908)\tTop1: 4.688 (avg: 5.425)\tTop5: 20.312 (avg: 18.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6668\tTop 1 accuracy: 4.850\tTop 5 accuracy: 16.200\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.402 (avg: 0.400)\tLoss: 4.5463 (avg: 4.6094)\tTop1: 4.688 (avg: 5.125)\tTop5: 17.188 (avg: 18.562)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.412 (avg: 0.406)\tLoss: 4.6556 (avg: 4.5822)\tTop1: 1.562 (avg: 4.656)\tTop5: 15.625 (avg: 18.594)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.411 (avg: 0.409)\tLoss: 4.6820 (avg: 4.5825)\tTop1: 3.125 (avg: 4.979)\tTop5: 17.188 (avg: 18.521)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.405 (avg: 0.410)\tLoss: 4.3722 (avg: 4.5819)\tTop1: 9.375 (avg: 5.078)\tTop5: 21.875 (avg: 18.547)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.401 (avg: 0.410)\tLoss: 4.3696 (avg: 4.5867)\tTop1: 6.250 (avg: 5.063)\tTop5: 21.875 (avg: 18.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6476\tTop 1 accuracy: 4.850\tTop 5 accuracy: 18.300\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.414 (avg: 0.403)\tLoss: 4.4227 (avg: 4.4693)\tTop1: 12.500 (avg: 6.938)\tTop5: 26.562 (avg: 20.188)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.405 (avg: 0.408)\tLoss: 4.3579 (avg: 4.4906)\tTop1: 6.250 (avg: 6.938)\tTop5: 23.438 (avg: 20.438)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.401 (avg: 0.410)\tLoss: 4.6240 (avg: 4.5050)\tTop1: 7.812 (avg: 6.396)\tTop5: 20.312 (avg: 20.229)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.410 (avg: 0.411)\tLoss: 4.5724 (avg: 4.5130)\tTop1: 6.250 (avg: 6.109)\tTop5: 18.750 (avg: 19.844)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.394 (avg: 0.412)\tLoss: 4.7308 (avg: 4.5223)\tTop1: 4.688 (avg: 6.038)\tTop5: 12.500 (avg: 19.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6747\tTop 1 accuracy: 5.000\tTop 5 accuracy: 17.600\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.399 (avg: 0.401)\tLoss: 4.6443 (avg: 4.4260)\tTop1: 1.562 (avg: 6.000)\tTop5: 15.625 (avg: 22.562)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.399 (avg: 0.408)\tLoss: 4.2915 (avg: 4.4523)\tTop1: 9.375 (avg: 6.344)\tTop5: 26.562 (avg: 21.875)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.407 (avg: 0.409)\tLoss: 4.1172 (avg: 4.4730)\tTop1: 9.375 (avg: 5.917)\tTop5: 31.250 (avg: 21.104)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 4.5219 (avg: 4.4737)\tTop1: 3.125 (avg: 5.828)\tTop5: 29.688 (avg: 21.234)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.409 (avg: 0.411)\tLoss: 4.5199 (avg: 4.4931)\tTop1: 6.250 (avg: 5.725)\tTop5: 17.188 (avg: 20.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3501\tTop 1 accuracy: 6.600\tTop 5 accuracy: 19.600\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.407 (avg: 0.403)\tLoss: 4.4144 (avg: 4.4076)\tTop1: 4.688 (avg: 6.500)\tTop5: 25.000 (avg: 20.500)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.400 (avg: 0.407)\tLoss: 4.4427 (avg: 4.4365)\tTop1: 4.688 (avg: 6.250)\tTop5: 18.750 (avg: 21.125)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.413 (avg: 0.409)\tLoss: 4.5441 (avg: 4.4502)\tTop1: 4.688 (avg: 6.271)\tTop5: 23.438 (avg: 21.146)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 4.5743 (avg: 4.4494)\tTop1: 6.250 (avg: 6.453)\tTop5: 23.438 (avg: 21.047)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.403 (avg: 0.410)\tLoss: 4.6696 (avg: 4.4582)\tTop1: 4.688 (avg: 6.463)\tTop5: 15.625 (avg: 20.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5424\tTop 1 accuracy: 5.450\tTop 5 accuracy: 18.000\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.407 (avg: 0.402)\tLoss: 4.2804 (avg: 4.4390)\tTop1: 6.250 (avg: 5.812)\tTop5: 23.438 (avg: 21.562)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.403 (avg: 0.407)\tLoss: 4.4171 (avg: 4.4573)\tTop1: 7.812 (avg: 6.281)\tTop5: 25.000 (avg: 21.469)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.405 (avg: 0.410)\tLoss: 4.3018 (avg: 4.4344)\tTop1: 4.688 (avg: 6.479)\tTop5: 23.438 (avg: 21.979)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.418 (avg: 0.411)\tLoss: 4.6443 (avg: 4.4128)\tTop1: 1.562 (avg: 6.625)\tTop5: 10.938 (avg: 22.500)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.398 (avg: 0.411)\tLoss: 4.3254 (avg: 4.4254)\tTop1: 6.250 (avg: 6.538)\tTop5: 25.000 (avg: 22.313)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4499\tTop 1 accuracy: 5.050\tTop 5 accuracy: 20.850\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.409 (avg: 0.400)\tLoss: 4.4338 (avg: 4.3904)\tTop1: 12.500 (avg: 7.062)\tTop5: 20.312 (avg: 22.312)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.409 (avg: 0.407)\tLoss: 4.2753 (avg: 4.3472)\tTop1: 9.375 (avg: 7.625)\tTop5: 23.438 (avg: 24.125)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.405 (avg: 0.409)\tLoss: 4.2506 (avg: 4.3747)\tTop1: 12.500 (avg: 7.042)\tTop5: 25.000 (avg: 23.104)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.405 (avg: 0.410)\tLoss: 4.3711 (avg: 4.3679)\tTop1: 3.125 (avg: 7.094)\tTop5: 21.875 (avg: 23.703)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.405 (avg: 0.411)\tLoss: 4.4100 (avg: 4.3726)\tTop1: 14.062 (avg: 7.188)\tTop5: 20.312 (avg: 23.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1212\tTop 1 accuracy: 6.550\tTop 5 accuracy: 23.000\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.407 (avg: 0.402)\tLoss: 4.1591 (avg: 4.3167)\tTop1: 7.812 (avg: 7.562)\tTop5: 23.438 (avg: 24.438)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.400 (avg: 0.407)\tLoss: 4.3182 (avg: 4.2835)\tTop1: 7.812 (avg: 8.031)\tTop5: 29.688 (avg: 25.719)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.411 (avg: 0.409)\tLoss: 4.2498 (avg: 4.2952)\tTop1: 12.500 (avg: 8.333)\tTop5: 37.500 (avg: 25.646)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 4.5317 (avg: 4.3097)\tTop1: 10.938 (avg: 7.906)\tTop5: 23.438 (avg: 25.172)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.405 (avg: 0.411)\tLoss: 4.4325 (avg: 4.3193)\tTop1: 10.938 (avg: 7.725)\tTop5: 21.875 (avg: 24.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4893\tTop 1 accuracy: 5.900\tTop 5 accuracy: 20.800\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.401 (avg: 0.402)\tLoss: 4.2834 (avg: 4.2661)\tTop1: 9.375 (avg: 9.125)\tTop5: 29.688 (avg: 27.188)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.405 (avg: 0.407)\tLoss: 4.3475 (avg: 4.2610)\tTop1: 17.188 (avg: 8.969)\tTop5: 25.000 (avg: 26.531)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.402 (avg: 0.409)\tLoss: 4.3006 (avg: 4.2686)\tTop1: 7.812 (avg: 8.479)\tTop5: 29.688 (avg: 26.521)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.410 (avg: 0.410)\tLoss: 4.0968 (avg: 4.2717)\tTop1: 9.375 (avg: 8.547)\tTop5: 28.125 (avg: 26.562)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.406 (avg: 0.411)\tLoss: 4.7832 (avg: 4.2781)\tTop1: 6.250 (avg: 8.425)\tTop5: 21.875 (avg: 26.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2184\tTop 1 accuracy: 6.350\tTop 5 accuracy: 21.900\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.398 (avg: 0.402)\tLoss: 3.8869 (avg: 4.2445)\tTop1: 17.188 (avg: 8.438)\tTop5: 39.062 (avg: 25.500)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.412 (avg: 0.407)\tLoss: 4.3647 (avg: 4.2315)\tTop1: 9.375 (avg: 8.531)\tTop5: 26.562 (avg: 26.062)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.414 (avg: 0.409)\tLoss: 4.1705 (avg: 4.2528)\tTop1: 9.375 (avg: 7.917)\tTop5: 29.688 (avg: 25.958)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.401 (avg: 0.410)\tLoss: 4.1113 (avg: 4.2654)\tTop1: 6.250 (avg: 7.953)\tTop5: 32.812 (avg: 25.984)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.408 (avg: 0.411)\tLoss: 4.1730 (avg: 4.2563)\tTop1: 6.250 (avg: 8.088)\tTop5: 26.562 (avg: 26.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8407\tTop 1 accuracy: 8.450\tTop 5 accuracy: 23.900\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.406 (avg: 0.403)\tLoss: 4.0491 (avg: 4.1104)\tTop1: 12.500 (avg: 10.000)\tTop5: 29.688 (avg: 31.812)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.407 (avg: 0.408)\tLoss: 3.8004 (avg: 4.0555)\tTop1: 14.062 (avg: 10.875)\tTop5: 42.188 (avg: 32.531)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.404 (avg: 0.409)\tLoss: 4.0214 (avg: 4.0233)\tTop1: 12.500 (avg: 11.938)\tTop5: 31.250 (avg: 33.562)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.411 (avg: 0.410)\tLoss: 4.0134 (avg: 3.9923)\tTop1: 15.625 (avg: 12.594)\tTop5: 29.688 (avg: 34.234)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.403 (avg: 0.410)\tLoss: 3.8191 (avg: 3.9871)\tTop1: 17.188 (avg: 12.813)\tTop5: 35.938 (avg: 34.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7864\tTop 1 accuracy: 10.000\tTop 5 accuracy: 28.300\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.409 (avg: 0.401)\tLoss: 3.9233 (avg: 3.9488)\tTop1: 10.938 (avg: 14.000)\tTop5: 31.250 (avg: 36.125)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.408 (avg: 0.406)\tLoss: 3.9682 (avg: 3.9241)\tTop1: 12.500 (avg: 14.219)\tTop5: 42.188 (avg: 36.688)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.399 (avg: 0.408)\tLoss: 3.9178 (avg: 3.9236)\tTop1: 7.812 (avg: 14.062)\tTop5: 34.375 (avg: 36.271)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.410 (avg: 0.409)\tLoss: 3.9676 (avg: 3.9203)\tTop1: 9.375 (avg: 14.172)\tTop5: 34.375 (avg: 35.812)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.410 (avg: 0.410)\tLoss: 3.6798 (avg: 3.9102)\tTop1: 14.062 (avg: 14.100)\tTop5: 40.625 (avg: 36.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6633\tTop 1 accuracy: 10.250\tTop 5 accuracy: 29.100\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.407 (avg: 0.400)\tLoss: 3.8001 (avg: 3.8880)\tTop1: 10.938 (avg: 13.688)\tTop5: 37.500 (avg: 36.688)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.407 (avg: 0.407)\tLoss: 3.9489 (avg: 3.9009)\tTop1: 14.062 (avg: 13.781)\tTop5: 34.375 (avg: 35.844)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.403 (avg: 0.408)\tLoss: 3.8663 (avg: 3.9202)\tTop1: 12.500 (avg: 13.708)\tTop5: 34.375 (avg: 35.375)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.399 (avg: 0.410)\tLoss: 3.9228 (avg: 3.9078)\tTop1: 14.062 (avg: 14.016)\tTop5: 29.688 (avg: 35.797)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 3.8844 (avg: 3.8858)\tTop1: 14.062 (avg: 14.525)\tTop5: 35.938 (avg: 36.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7034\tTop 1 accuracy: 10.100\tTop 5 accuracy: 29.250\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.405 (avg: 0.401)\tLoss: 3.9122 (avg: 3.7792)\tTop1: 14.062 (avg: 15.812)\tTop5: 31.250 (avg: 40.688)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.407 (avg: 0.407)\tLoss: 3.9673 (avg: 3.8563)\tTop1: 15.625 (avg: 15.250)\tTop5: 34.375 (avg: 38.750)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.403 (avg: 0.408)\tLoss: 4.1251 (avg: 3.8566)\tTop1: 9.375 (avg: 14.875)\tTop5: 29.688 (avg: 37.896)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.413 (avg: 0.409)\tLoss: 3.7892 (avg: 3.8504)\tTop1: 10.938 (avg: 14.422)\tTop5: 29.688 (avg: 37.906)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.403 (avg: 0.410)\tLoss: 3.6792 (avg: 3.8660)\tTop1: 17.188 (avg: 14.225)\tTop5: 42.188 (avg: 37.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6317\tTop 1 accuracy: 11.250\tTop 5 accuracy: 29.350\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.406 (avg: 0.402)\tLoss: 3.5228 (avg: 3.7872)\tTop1: 29.688 (avg: 15.812)\tTop5: 50.000 (avg: 39.188)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.409 (avg: 0.407)\tLoss: 4.2144 (avg: 3.7934)\tTop1: 4.688 (avg: 16.469)\tTop5: 29.688 (avg: 39.594)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.402 (avg: 0.409)\tLoss: 3.9691 (avg: 3.8144)\tTop1: 17.188 (avg: 16.021)\tTop5: 32.812 (avg: 38.521)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 3.8084 (avg: 3.8372)\tTop1: 20.312 (avg: 15.734)\tTop5: 43.750 (avg: 37.422)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.415 (avg: 0.410)\tLoss: 3.9809 (avg: 3.8455)\tTop1: 10.938 (avg: 15.463)\tTop5: 34.375 (avg: 37.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7250\tTop 1 accuracy: 10.400\tTop 5 accuracy: 29.700\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.415 (avg: 0.402)\tLoss: 3.7503 (avg: 3.7975)\tTop1: 15.625 (avg: 14.562)\tTop5: 42.188 (avg: 37.812)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.410 (avg: 0.408)\tLoss: 3.9426 (avg: 3.8053)\tTop1: 10.938 (avg: 15.219)\tTop5: 26.562 (avg: 38.062)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.411 (avg: 0.409)\tLoss: 3.7764 (avg: 3.8050)\tTop1: 14.062 (avg: 15.917)\tTop5: 40.625 (avg: 38.312)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.404 (avg: 0.410)\tLoss: 4.1731 (avg: 3.8275)\tTop1: 12.500 (avg: 15.359)\tTop5: 26.562 (avg: 38.219)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.401 (avg: 0.411)\tLoss: 3.8889 (avg: 3.8340)\tTop1: 9.375 (avg: 15.275)\tTop5: 34.375 (avg: 37.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5929\tTop 1 accuracy: 10.850\tTop 5 accuracy: 29.600\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.408 (avg: 0.400)\tLoss: 3.8959 (avg: 3.7669)\tTop1: 12.500 (avg: 15.500)\tTop5: 32.812 (avg: 39.688)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.412 (avg: 0.406)\tLoss: 3.6003 (avg: 3.7955)\tTop1: 20.312 (avg: 15.594)\tTop5: 42.188 (avg: 38.906)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.400 (avg: 0.408)\tLoss: 3.7037 (avg: 3.7861)\tTop1: 10.938 (avg: 15.479)\tTop5: 35.938 (avg: 39.354)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.408 (avg: 0.409)\tLoss: 4.2292 (avg: 3.7998)\tTop1: 17.188 (avg: 15.578)\tTop5: 21.875 (avg: 38.922)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.406 (avg: 0.410)\tLoss: 3.6768 (avg: 3.8171)\tTop1: 18.750 (avg: 15.350)\tTop5: 34.375 (avg: 38.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6478\tTop 1 accuracy: 11.100\tTop 5 accuracy: 29.500\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.400 (avg: 0.398)\tLoss: 3.9486 (avg: 3.7779)\tTop1: 14.062 (avg: 15.375)\tTop5: 31.250 (avg: 37.438)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.409 (avg: 0.405)\tLoss: 3.6104 (avg: 3.7915)\tTop1: 14.062 (avg: 15.469)\tTop5: 42.188 (avg: 37.750)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.407 (avg: 0.408)\tLoss: 3.6555 (avg: 3.7993)\tTop1: 20.312 (avg: 15.500)\tTop5: 40.625 (avg: 38.083)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.401 (avg: 0.409)\tLoss: 3.8953 (avg: 3.8016)\tTop1: 15.625 (avg: 15.578)\tTop5: 35.938 (avg: 38.281)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 4.1017 (avg: 3.8015)\tTop1: 9.375 (avg: 15.513)\tTop5: 29.688 (avg: 38.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5603\tTop 1 accuracy: 11.500\tTop 5 accuracy: 28.900\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.414 (avg: 0.403)\tLoss: 3.8471 (avg: 3.7945)\tTop1: 15.625 (avg: 16.625)\tTop5: 32.812 (avg: 41.062)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.405 (avg: 0.408)\tLoss: 3.5989 (avg: 3.8201)\tTop1: 15.625 (avg: 15.344)\tTop5: 42.188 (avg: 39.312)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.411 (avg: 0.410)\tLoss: 3.5255 (avg: 3.7982)\tTop1: 18.750 (avg: 15.354)\tTop5: 45.312 (avg: 39.479)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.412 (avg: 0.410)\tLoss: 3.7252 (avg: 3.7930)\tTop1: 15.625 (avg: 15.266)\tTop5: 37.500 (avg: 38.891)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.403 (avg: 0.411)\tLoss: 3.8163 (avg: 3.7862)\tTop1: 7.812 (avg: 15.400)\tTop5: 40.625 (avg: 38.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7291\tTop 1 accuracy: 11.300\tTop 5 accuracy: 29.800\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.404 (avg: 0.402)\tLoss: 3.3856 (avg: 3.7852)\tTop1: 17.188 (avg: 15.375)\tTop5: 50.000 (avg: 38.500)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.409 (avg: 0.408)\tLoss: 3.4849 (avg: 3.7517)\tTop1: 23.438 (avg: 16.000)\tTop5: 45.312 (avg: 39.469)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.398 (avg: 0.409)\tLoss: 3.5320 (avg: 3.7693)\tTop1: 23.438 (avg: 16.354)\tTop5: 40.625 (avg: 39.625)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.404 (avg: 0.410)\tLoss: 3.5371 (avg: 3.7773)\tTop1: 18.750 (avg: 16.000)\tTop5: 50.000 (avg: 39.438)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.403 (avg: 0.410)\tLoss: 3.6064 (avg: 3.7769)\tTop1: 17.188 (avg: 15.975)\tTop5: 35.938 (avg: 39.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4610\tTop 1 accuracy: 10.850\tTop 5 accuracy: 28.700\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.400 (avg: 0.402)\tLoss: 3.7486 (avg: 3.7612)\tTop1: 15.625 (avg: 15.625)\tTop5: 42.188 (avg: 39.438)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.405 (avg: 0.407)\tLoss: 3.9716 (avg: 3.7656)\tTop1: 12.500 (avg: 15.969)\tTop5: 37.500 (avg: 40.500)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.413 (avg: 0.409)\tLoss: 3.4542 (avg: 3.7679)\tTop1: 20.312 (avg: 15.667)\tTop5: 53.125 (avg: 40.188)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.406 (avg: 0.410)\tLoss: 3.8840 (avg: 3.7605)\tTop1: 18.750 (avg: 16.250)\tTop5: 34.375 (avg: 40.078)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.402 (avg: 0.410)\tLoss: 3.6316 (avg: 3.7616)\tTop1: 26.562 (avg: 15.950)\tTop5: 43.750 (avg: 40.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5601\tTop 1 accuracy: 11.500\tTop 5 accuracy: 31.450\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.405 (avg: 0.399)\tLoss: 3.8631 (avg: 3.7729)\tTop1: 14.062 (avg: 15.875)\tTop5: 40.625 (avg: 39.375)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.404 (avg: 0.406)\tLoss: 3.4981 (avg: 3.7574)\tTop1: 18.750 (avg: 16.125)\tTop5: 48.438 (avg: 39.719)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.408 (avg: 0.408)\tLoss: 3.8853 (avg: 3.7569)\tTop1: 12.500 (avg: 16.021)\tTop5: 35.938 (avg: 40.125)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.422 (avg: 0.409)\tLoss: 3.8889 (avg: 3.7493)\tTop1: 17.188 (avg: 16.234)\tTop5: 37.500 (avg: 40.547)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.410 (avg: 0.410)\tLoss: 3.7218 (avg: 3.7418)\tTop1: 15.625 (avg: 16.588)\tTop5: 40.625 (avg: 40.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5661\tTop 1 accuracy: 12.000\tTop 5 accuracy: 30.650\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.399 (avg: 0.400)\tLoss: 3.7598 (avg: 3.7025)\tTop1: 15.625 (avg: 16.125)\tTop5: 40.625 (avg: 42.188)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.403 (avg: 0.405)\tLoss: 3.6947 (avg: 3.7013)\tTop1: 14.062 (avg: 17.062)\tTop5: 37.500 (avg: 42.125)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.406 (avg: 0.408)\tLoss: 3.6788 (avg: 3.7240)\tTop1: 15.625 (avg: 17.062)\tTop5: 48.438 (avg: 41.417)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.410 (avg: 0.409)\tLoss: 3.9155 (avg: 3.7289)\tTop1: 14.062 (avg: 16.625)\tTop5: 32.812 (avg: 40.969)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.416 (avg: 0.410)\tLoss: 3.8922 (avg: 3.7308)\tTop1: 18.750 (avg: 16.700)\tTop5: 32.812 (avg: 40.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4811\tTop 1 accuracy: 11.700\tTop 5 accuracy: 30.450\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.405 (avg: 0.403)\tLoss: 3.8149 (avg: 3.7176)\tTop1: 10.938 (avg: 17.250)\tTop5: 32.812 (avg: 39.812)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.402 (avg: 0.407)\tLoss: 3.7845 (avg: 3.6950)\tTop1: 18.750 (avg: 17.000)\tTop5: 37.500 (avg: 40.688)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.412 (avg: 0.409)\tLoss: 3.6350 (avg: 3.6979)\tTop1: 17.188 (avg: 16.708)\tTop5: 46.875 (avg: 40.917)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 3.5368 (avg: 3.7130)\tTop1: 14.062 (avg: 16.547)\tTop5: 45.312 (avg: 41.109)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.407 (avg: 0.411)\tLoss: 3.8949 (avg: 3.7155)\tTop1: 18.750 (avg: 16.650)\tTop5: 40.625 (avg: 41.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6128\tTop 1 accuracy: 11.350\tTop 5 accuracy: 30.700\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.410 (avg: 0.404)\tLoss: 3.5679 (avg: 3.6985)\tTop1: 20.312 (avg: 17.562)\tTop5: 43.750 (avg: 41.250)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.408 (avg: 0.408)\tLoss: 3.2909 (avg: 3.6692)\tTop1: 25.000 (avg: 17.625)\tTop5: 42.188 (avg: 41.125)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.404 (avg: 0.410)\tLoss: 3.7673 (avg: 3.6899)\tTop1: 18.750 (avg: 17.292)\tTop5: 48.438 (avg: 41.417)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.410 (avg: 0.411)\tLoss: 3.7292 (avg: 3.7067)\tTop1: 12.500 (avg: 17.016)\tTop5: 40.625 (avg: 41.297)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.406 (avg: 0.411)\tLoss: 3.6459 (avg: 3.7062)\tTop1: 15.625 (avg: 17.263)\tTop5: 40.625 (avg: 41.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4685\tTop 1 accuracy: 11.900\tTop 5 accuracy: 30.900\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.403 (avg: 0.403)\tLoss: 3.7227 (avg: 3.6434)\tTop1: 17.188 (avg: 17.688)\tTop5: 43.750 (avg: 43.000)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.400 (avg: 0.408)\tLoss: 3.7443 (avg: 3.6828)\tTop1: 15.625 (avg: 16.531)\tTop5: 39.062 (avg: 41.969)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.412 (avg: 0.409)\tLoss: 3.5485 (avg: 3.6747)\tTop1: 25.000 (avg: 17.042)\tTop5: 45.312 (avg: 42.417)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 4.0007 (avg: 3.6920)\tTop1: 14.062 (avg: 16.656)\tTop5: 34.375 (avg: 41.625)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.409 (avg: 0.411)\tLoss: 3.3562 (avg: 3.6845)\tTop1: 23.438 (avg: 16.650)\tTop5: 48.438 (avg: 41.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5015\tTop 1 accuracy: 11.800\tTop 5 accuracy: 31.350\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.409 (avg: 0.401)\tLoss: 3.8691 (avg: 3.6708)\tTop1: 20.312 (avg: 16.812)\tTop5: 39.062 (avg: 41.625)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.401 (avg: 0.406)\tLoss: 3.6992 (avg: 3.6648)\tTop1: 18.750 (avg: 16.906)\tTop5: 37.500 (avg: 41.625)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.411 (avg: 0.409)\tLoss: 4.2393 (avg: 3.6609)\tTop1: 12.500 (avg: 16.979)\tTop5: 35.938 (avg: 42.271)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 3.4048 (avg: 3.6658)\tTop1: 21.875 (avg: 17.047)\tTop5: 50.000 (avg: 42.141)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.405 (avg: 0.411)\tLoss: 3.7445 (avg: 3.6702)\tTop1: 14.062 (avg: 16.825)\tTop5: 45.312 (avg: 41.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4139\tTop 1 accuracy: 11.900\tTop 5 accuracy: 31.300\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.408 (avg: 0.403)\tLoss: 3.8255 (avg: 3.6529)\tTop1: 18.750 (avg: 19.000)\tTop5: 43.750 (avg: 42.438)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.406 (avg: 0.405)\tLoss: 3.6046 (avg: 3.6373)\tTop1: 15.625 (avg: 18.688)\tTop5: 37.500 (avg: 42.750)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.404 (avg: 0.408)\tLoss: 3.7343 (avg: 3.6360)\tTop1: 9.375 (avg: 18.271)\tTop5: 32.812 (avg: 42.271)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.411 (avg: 0.409)\tLoss: 3.7943 (avg: 3.6607)\tTop1: 15.625 (avg: 18.062)\tTop5: 39.062 (avg: 41.922)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 3.7979 (avg: 3.6594)\tTop1: 17.188 (avg: 17.775)\tTop5: 34.375 (avg: 41.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6205\tTop 1 accuracy: 12.400\tTop 5 accuracy: 31.600\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.397 (avg: 0.403)\tLoss: 3.6822 (avg: 3.6985)\tTop1: 14.062 (avg: 16.875)\tTop5: 32.812 (avg: 39.750)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.405 (avg: 0.408)\tLoss: 3.8203 (avg: 3.6432)\tTop1: 12.500 (avg: 17.531)\tTop5: 39.062 (avg: 41.938)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.417 (avg: 0.410)\tLoss: 3.9019 (avg: 3.6406)\tTop1: 12.500 (avg: 17.771)\tTop5: 37.500 (avg: 42.229)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.401 (avg: 0.411)\tLoss: 3.8699 (avg: 3.6426)\tTop1: 14.062 (avg: 17.562)\tTop5: 37.500 (avg: 42.422)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.409 (avg: 0.411)\tLoss: 3.3617 (avg: 3.6452)\tTop1: 18.750 (avg: 17.550)\tTop5: 46.875 (avg: 42.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8170\tTop 1 accuracy: 9.850\tTop 5 accuracy: 28.900\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.409 (avg: 0.404)\tLoss: 3.6520 (avg: 3.5690)\tTop1: 23.438 (avg: 18.812)\tTop5: 42.188 (avg: 44.312)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.405 (avg: 0.408)\tLoss: 3.4554 (avg: 3.5709)\tTop1: 18.750 (avg: 19.031)\tTop5: 42.188 (avg: 44.062)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.403 (avg: 0.410)\tLoss: 3.5456 (avg: 3.6060)\tTop1: 15.625 (avg: 18.333)\tTop5: 48.438 (avg: 43.167)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.415 (avg: 0.411)\tLoss: 3.3030 (avg: 3.6155)\tTop1: 17.188 (avg: 18.062)\tTop5: 50.000 (avg: 42.859)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.405 (avg: 0.411)\tLoss: 3.7597 (avg: 3.6141)\tTop1: 14.062 (avg: 18.263)\tTop5: 42.188 (avg: 43.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5609\tTop 1 accuracy: 12.700\tTop 5 accuracy: 32.100\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.406 (avg: 0.404)\tLoss: 3.4916 (avg: 3.5342)\tTop1: 28.125 (avg: 19.625)\tTop5: 46.875 (avg: 45.062)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.407 (avg: 0.409)\tLoss: 3.5815 (avg: 3.5465)\tTop1: 18.750 (avg: 18.625)\tTop5: 37.500 (avg: 44.469)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.399 (avg: 0.410)\tLoss: 3.9431 (avg: 3.5987)\tTop1: 18.750 (avg: 18.292)\tTop5: 37.500 (avg: 43.417)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.403 (avg: 0.411)\tLoss: 3.7078 (avg: 3.6011)\tTop1: 18.750 (avg: 18.125)\tTop5: 45.312 (avg: 43.125)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.412 (avg: 0.412)\tLoss: 3.8490 (avg: 3.6013)\tTop1: 7.812 (avg: 18.113)\tTop5: 31.250 (avg: 43.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5034\tTop 1 accuracy: 11.550\tTop 5 accuracy: 31.150\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.410 (avg: 0.401)\tLoss: 3.4512 (avg: 3.5370)\tTop1: 18.750 (avg: 19.812)\tTop5: 42.188 (avg: 45.500)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.405 (avg: 0.407)\tLoss: 3.7250 (avg: 3.5639)\tTop1: 12.500 (avg: 18.531)\tTop5: 42.188 (avg: 44.500)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.411 (avg: 0.409)\tLoss: 3.8528 (avg: 3.5666)\tTop1: 15.625 (avg: 19.083)\tTop5: 37.500 (avg: 44.521)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.402 (avg: 0.410)\tLoss: 3.8591 (avg: 3.5809)\tTop1: 10.938 (avg: 18.797)\tTop5: 39.062 (avg: 44.000)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.399 (avg: 0.411)\tLoss: 4.0876 (avg: 3.5979)\tTop1: 14.062 (avg: 18.600)\tTop5: 29.688 (avg: 43.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4286\tTop 1 accuracy: 12.350\tTop 5 accuracy: 32.150\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.414 (avg: 0.403)\tLoss: 3.7027 (avg: 3.5207)\tTop1: 14.062 (avg: 19.938)\tTop5: 37.500 (avg: 46.062)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.404 (avg: 0.407)\tLoss: 3.5989 (avg: 3.5627)\tTop1: 18.750 (avg: 19.312)\tTop5: 45.312 (avg: 44.125)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.402 (avg: 0.408)\tLoss: 3.3467 (avg: 3.5883)\tTop1: 21.875 (avg: 18.833)\tTop5: 45.312 (avg: 43.188)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.404 (avg: 0.409)\tLoss: 3.7404 (avg: 3.5890)\tTop1: 18.750 (avg: 18.641)\tTop5: 45.312 (avg: 43.438)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.399 (avg: 0.410)\tLoss: 3.4457 (avg: 3.5737)\tTop1: 18.750 (avg: 18.900)\tTop5: 50.000 (avg: 43.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4753\tTop 1 accuracy: 12.050\tTop 5 accuracy: 32.150\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.399 (avg: 0.402)\tLoss: 3.5652 (avg: 3.5062)\tTop1: 17.188 (avg: 19.438)\tTop5: 40.625 (avg: 45.938)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.409 (avg: 0.407)\tLoss: 3.6446 (avg: 3.5488)\tTop1: 20.312 (avg: 19.375)\tTop5: 39.062 (avg: 45.094)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.412 (avg: 0.409)\tLoss: 3.4951 (avg: 3.5472)\tTop1: 25.000 (avg: 19.083)\tTop5: 39.062 (avg: 45.125)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.399 (avg: 0.410)\tLoss: 3.6815 (avg: 3.5672)\tTop1: 14.062 (avg: 18.688)\tTop5: 45.312 (avg: 44.562)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.410 (avg: 0.411)\tLoss: 3.4427 (avg: 3.5506)\tTop1: 23.438 (avg: 18.888)\tTop5: 42.188 (avg: 44.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4107\tTop 1 accuracy: 13.150\tTop 5 accuracy: 32.550\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.414 (avg: 0.404)\tLoss: 3.4328 (avg: 3.5534)\tTop1: 25.000 (avg: 19.250)\tTop5: 46.875 (avg: 43.438)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.406 (avg: 0.408)\tLoss: 3.4521 (avg: 3.5265)\tTop1: 21.875 (avg: 19.906)\tTop5: 45.312 (avg: 45.656)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.406 (avg: 0.409)\tLoss: 3.6568 (avg: 3.5318)\tTop1: 18.750 (avg: 19.688)\tTop5: 37.500 (avg: 45.021)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.409 (avg: 0.410)\tLoss: 3.5408 (avg: 3.5278)\tTop1: 21.875 (avg: 19.734)\tTop5: 43.750 (avg: 44.719)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 3.6149 (avg: 3.5410)\tTop1: 21.875 (avg: 19.613)\tTop5: 43.750 (avg: 44.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6305\tTop 1 accuracy: 12.400\tTop 5 accuracy: 32.500\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.404 (avg: 0.401)\tLoss: 3.3236 (avg: 3.4673)\tTop1: 21.875 (avg: 20.375)\tTop5: 48.438 (avg: 46.188)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.418 (avg: 0.408)\tLoss: 3.6509 (avg: 3.4728)\tTop1: 18.750 (avg: 19.719)\tTop5: 45.312 (avg: 46.125)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.407 (avg: 0.409)\tLoss: 3.4046 (avg: 3.4923)\tTop1: 20.312 (avg: 19.688)\tTop5: 56.250 (avg: 46.208)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 3.5479 (avg: 3.5039)\tTop1: 23.438 (avg: 19.391)\tTop5: 43.750 (avg: 45.797)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.411 (avg: 0.411)\tLoss: 3.6779 (avg: 3.5239)\tTop1: 18.750 (avg: 19.250)\tTop5: 48.438 (avg: 45.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3973\tTop 1 accuracy: 12.850\tTop 5 accuracy: 32.300\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.399 (avg: 0.400)\tLoss: 3.7620 (avg: 3.5642)\tTop1: 14.062 (avg: 18.750)\tTop5: 40.625 (avg: 43.500)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.407 (avg: 0.406)\tLoss: 3.4602 (avg: 3.5047)\tTop1: 20.312 (avg: 20.000)\tTop5: 45.312 (avg: 44.875)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.414 (avg: 0.409)\tLoss: 3.7797 (avg: 3.5105)\tTop1: 15.625 (avg: 19.833)\tTop5: 42.188 (avg: 45.125)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.400 (avg: 0.410)\tLoss: 3.6005 (avg: 3.5121)\tTop1: 17.188 (avg: 19.531)\tTop5: 46.875 (avg: 45.125)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.413 (avg: 0.410)\tLoss: 3.3594 (avg: 3.5004)\tTop1: 21.875 (avg: 19.900)\tTop5: 43.750 (avg: 45.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5008\tTop 1 accuracy: 12.350\tTop 5 accuracy: 32.650\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.408 (avg: 0.403)\tLoss: 3.5086 (avg: 3.4369)\tTop1: 21.875 (avg: 21.250)\tTop5: 40.625 (avg: 46.500)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.404 (avg: 0.408)\tLoss: 3.4487 (avg: 3.4525)\tTop1: 25.000 (avg: 21.156)\tTop5: 45.312 (avg: 45.969)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.403 (avg: 0.408)\tLoss: 3.2172 (avg: 3.4851)\tTop1: 23.438 (avg: 20.583)\tTop5: 45.312 (avg: 45.438)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.411 (avg: 0.409)\tLoss: 3.3984 (avg: 3.4974)\tTop1: 21.875 (avg: 20.297)\tTop5: 54.688 (avg: 45.672)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 3.5194 (avg: 3.4830)\tTop1: 20.312 (avg: 20.450)\tTop5: 45.312 (avg: 45.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6589\tTop 1 accuracy: 12.900\tTop 5 accuracy: 31.650\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.405 (avg: 0.403)\tLoss: 3.1208 (avg: 3.4508)\tTop1: 28.125 (avg: 20.625)\tTop5: 56.250 (avg: 47.438)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.409 (avg: 0.408)\tLoss: 3.5479 (avg: 3.4204)\tTop1: 21.875 (avg: 20.781)\tTop5: 48.438 (avg: 47.500)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.401 (avg: 0.410)\tLoss: 3.4111 (avg: 3.4458)\tTop1: 18.750 (avg: 20.125)\tTop5: 40.625 (avg: 46.646)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.405 (avg: 0.411)\tLoss: 3.6143 (avg: 3.4483)\tTop1: 28.125 (avg: 20.375)\tTop5: 42.188 (avg: 46.719)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.410 (avg: 0.411)\tLoss: 3.8718 (avg: 3.4562)\tTop1: 17.188 (avg: 20.363)\tTop5: 40.625 (avg: 46.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5361\tTop 1 accuracy: 12.700\tTop 5 accuracy: 32.900\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.413 (avg: 0.402)\tLoss: 3.3581 (avg: 3.3989)\tTop1: 26.562 (avg: 22.188)\tTop5: 48.438 (avg: 46.812)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.402 (avg: 0.408)\tLoss: 3.2917 (avg: 3.4057)\tTop1: 28.125 (avg: 22.469)\tTop5: 51.562 (avg: 47.188)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.401 (avg: 0.409)\tLoss: 3.4424 (avg: 3.4087)\tTop1: 18.750 (avg: 21.521)\tTop5: 45.312 (avg: 47.083)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 3.3972 (avg: 3.4124)\tTop1: 31.250 (avg: 21.703)\tTop5: 54.688 (avg: 47.094)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.404 (avg: 0.411)\tLoss: 3.4317 (avg: 3.4361)\tTop1: 20.312 (avg: 21.163)\tTop5: 51.562 (avg: 46.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4286\tTop 1 accuracy: 12.250\tTop 5 accuracy: 33.250\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.408 (avg: 0.403)\tLoss: 3.0807 (avg: 3.3317)\tTop1: 26.562 (avg: 22.750)\tTop5: 53.125 (avg: 48.938)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.415 (avg: 0.408)\tLoss: 3.2718 (avg: 3.3046)\tTop1: 25.000 (avg: 24.219)\tTop5: 53.125 (avg: 50.906)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.404 (avg: 0.410)\tLoss: 3.4657 (avg: 3.3112)\tTop1: 20.312 (avg: 23.729)\tTop5: 43.750 (avg: 50.500)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.410 (avg: 0.411)\tLoss: 3.2449 (avg: 3.3186)\tTop1: 20.312 (avg: 23.375)\tTop5: 53.125 (avg: 50.266)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.407 (avg: 0.411)\tLoss: 3.0708 (avg: 3.3043)\tTop1: 25.000 (avg: 23.725)\tTop5: 60.938 (avg: 50.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3398\tTop 1 accuracy: 12.900\tTop 5 accuracy: 34.000\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.400 (avg: 0.399)\tLoss: 3.3158 (avg: 3.2993)\tTop1: 25.000 (avg: 24.688)\tTop5: 53.125 (avg: 50.625)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.409 (avg: 0.406)\tLoss: 3.3678 (avg: 3.2747)\tTop1: 31.250 (avg: 25.188)\tTop5: 54.688 (avg: 51.344)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.411 (avg: 0.409)\tLoss: 3.0692 (avg: 3.2885)\tTop1: 25.000 (avg: 24.562)\tTop5: 48.438 (avg: 50.479)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.403 (avg: 0.410)\tLoss: 3.4912 (avg: 3.2778)\tTop1: 21.875 (avg: 24.828)\tTop5: 46.875 (avg: 50.531)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 3.0156 (avg: 3.2754)\tTop1: 31.250 (avg: 24.650)\tTop5: 48.438 (avg: 50.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3324\tTop 1 accuracy: 13.750\tTop 5 accuracy: 33.800\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.411 (avg: 0.403)\tLoss: 2.8101 (avg: 3.2360)\tTop1: 37.500 (avg: 26.125)\tTop5: 56.250 (avg: 51.875)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.402 (avg: 0.408)\tLoss: 3.0553 (avg: 3.2119)\tTop1: 23.438 (avg: 26.438)\tTop5: 48.438 (avg: 51.688)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.400 (avg: 0.408)\tLoss: 3.4191 (avg: 3.2467)\tTop1: 17.188 (avg: 25.604)\tTop5: 51.562 (avg: 51.333)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.411 (avg: 0.409)\tLoss: 3.4757 (avg: 3.2634)\tTop1: 23.438 (avg: 25.219)\tTop5: 46.875 (avg: 51.031)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.400 (avg: 0.410)\tLoss: 3.2260 (avg: 3.2556)\tTop1: 29.688 (avg: 25.450)\tTop5: 51.562 (avg: 51.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3096\tTop 1 accuracy: 13.600\tTop 5 accuracy: 33.950\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.405 (avg: 0.403)\tLoss: 3.3877 (avg: 3.2364)\tTop1: 21.875 (avg: 26.188)\tTop5: 48.438 (avg: 52.062)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.409 (avg: 0.408)\tLoss: 3.4399 (avg: 3.2440)\tTop1: 18.750 (avg: 25.500)\tTop5: 46.875 (avg: 52.281)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.406 (avg: 0.409)\tLoss: 3.4221 (avg: 3.2528)\tTop1: 26.562 (avg: 25.062)\tTop5: 48.438 (avg: 51.250)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 3.1260 (avg: 3.2608)\tTop1: 29.688 (avg: 25.031)\tTop5: 59.375 (avg: 51.156)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.408 (avg: 0.411)\tLoss: 3.7341 (avg: 3.2541)\tTop1: 12.500 (avg: 25.163)\tTop5: 42.188 (avg: 51.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3629\tTop 1 accuracy: 14.600\tTop 5 accuracy: 33.400\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.404 (avg: 0.402)\tLoss: 2.7433 (avg: 3.2412)\tTop1: 39.062 (avg: 25.625)\tTop5: 59.375 (avg: 50.688)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.408 (avg: 0.408)\tLoss: 3.0873 (avg: 3.2094)\tTop1: 21.875 (avg: 26.250)\tTop5: 56.250 (avg: 51.656)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.411 (avg: 0.409)\tLoss: 3.1559 (avg: 3.2132)\tTop1: 25.000 (avg: 26.146)\tTop5: 51.562 (avg: 52.208)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.401 (avg: 0.410)\tLoss: 3.2688 (avg: 3.2290)\tTop1: 29.688 (avg: 25.750)\tTop5: 51.562 (avg: 51.828)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.412 (avg: 0.411)\tLoss: 3.5973 (avg: 3.2483)\tTop1: 21.875 (avg: 25.588)\tTop5: 42.188 (avg: 51.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3224\tTop 1 accuracy: 13.850\tTop 5 accuracy: 33.400\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.410 (avg: 0.403)\tLoss: 3.1786 (avg: 3.2061)\tTop1: 32.812 (avg: 25.938)\tTop5: 60.938 (avg: 52.750)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.405 (avg: 0.408)\tLoss: 3.3405 (avg: 3.2327)\tTop1: 18.750 (avg: 25.062)\tTop5: 39.062 (avg: 52.281)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 3.3369 (avg: 3.2387)\tTop1: 20.312 (avg: 25.229)\tTop5: 56.250 (avg: 51.875)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.414 (avg: 0.411)\tLoss: 3.2097 (avg: 3.2409)\tTop1: 25.000 (avg: 25.234)\tTop5: 50.000 (avg: 51.750)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.403 (avg: 0.411)\tLoss: 3.3054 (avg: 3.2484)\tTop1: 18.750 (avg: 25.050)\tTop5: 50.000 (avg: 51.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3540\tTop 1 accuracy: 13.800\tTop 5 accuracy: 33.550\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.400 (avg: 0.401)\tLoss: 2.9008 (avg: 3.2227)\tTop1: 35.938 (avg: 25.500)\tTop5: 57.812 (avg: 52.688)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.408 (avg: 0.406)\tLoss: 3.3825 (avg: 3.2266)\tTop1: 25.000 (avg: 25.625)\tTop5: 51.562 (avg: 52.781)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.403 (avg: 0.408)\tLoss: 3.3165 (avg: 3.2346)\tTop1: 18.750 (avg: 25.667)\tTop5: 43.750 (avg: 52.042)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.407 (avg: 0.409)\tLoss: 2.6968 (avg: 3.2536)\tTop1: 34.375 (avg: 25.219)\tTop5: 65.625 (avg: 51.703)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.414 (avg: 0.413)\tLoss: 3.0767 (avg: 3.2391)\tTop1: 32.812 (avg: 25.563)\tTop5: 53.125 (avg: 51.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3764\tTop 1 accuracy: 14.450\tTop 5 accuracy: 33.550\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.406 (avg: 0.403)\tLoss: 3.2503 (avg: 3.1838)\tTop1: 25.000 (avg: 26.000)\tTop5: 48.438 (avg: 52.938)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.402 (avg: 0.408)\tLoss: 3.1191 (avg: 3.2005)\tTop1: 23.438 (avg: 25.125)\tTop5: 59.375 (avg: 52.719)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.408 (avg: 0.409)\tLoss: 3.3438 (avg: 3.2316)\tTop1: 21.875 (avg: 25.208)\tTop5: 48.438 (avg: 52.396)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.401 (avg: 0.409)\tLoss: 3.0794 (avg: 3.2229)\tTop1: 21.875 (avg: 25.406)\tTop5: 56.250 (avg: 52.453)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 3.1124 (avg: 3.2349)\tTop1: 23.438 (avg: 25.563)\tTop5: 53.125 (avg: 51.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3948\tTop 1 accuracy: 13.500\tTop 5 accuracy: 33.850\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.410 (avg: 0.402)\tLoss: 3.4005 (avg: 3.1762)\tTop1: 20.312 (avg: 26.438)\tTop5: 43.750 (avg: 51.375)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.411 (avg: 0.408)\tLoss: 2.9352 (avg: 3.1653)\tTop1: 28.125 (avg: 26.031)\tTop5: 57.812 (avg: 52.812)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.409 (avg: 0.409)\tLoss: 2.8486 (avg: 3.1920)\tTop1: 29.688 (avg: 25.688)\tTop5: 59.375 (avg: 52.500)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 3.2661 (avg: 3.2003)\tTop1: 18.750 (avg: 25.484)\tTop5: 48.438 (avg: 52.141)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.404 (avg: 0.411)\tLoss: 3.3066 (avg: 3.2323)\tTop1: 32.812 (avg: 25.363)\tTop5: 48.438 (avg: 51.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3731\tTop 1 accuracy: 14.000\tTop 5 accuracy: 33.700\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.410 (avg: 0.402)\tLoss: 3.3542 (avg: 3.2368)\tTop1: 25.000 (avg: 25.562)\tTop5: 46.875 (avg: 52.375)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.412 (avg: 0.407)\tLoss: 3.5054 (avg: 3.2433)\tTop1: 21.875 (avg: 25.938)\tTop5: 48.438 (avg: 52.094)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.414 (avg: 0.409)\tLoss: 3.2500 (avg: 3.2177)\tTop1: 23.438 (avg: 26.000)\tTop5: 51.562 (avg: 52.375)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.405 (avg: 0.410)\tLoss: 3.5713 (avg: 3.2168)\tTop1: 17.188 (avg: 25.859)\tTop5: 45.312 (avg: 52.391)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.405 (avg: 0.410)\tLoss: 3.1037 (avg: 3.2239)\tTop1: 23.438 (avg: 25.638)\tTop5: 62.500 (avg: 52.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4253\tTop 1 accuracy: 13.700\tTop 5 accuracy: 33.550\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.416 (avg: 0.402)\tLoss: 3.2529 (avg: 3.1893)\tTop1: 29.688 (avg: 24.875)\tTop5: 51.562 (avg: 53.062)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.406 (avg: 0.407)\tLoss: 2.9401 (avg: 3.2221)\tTop1: 25.000 (avg: 24.906)\tTop5: 57.812 (avg: 51.531)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.409 (avg: 0.409)\tLoss: 3.2357 (avg: 3.2073)\tTop1: 25.000 (avg: 25.292)\tTop5: 51.562 (avg: 52.604)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.414 (avg: 0.410)\tLoss: 3.2853 (avg: 3.2073)\tTop1: 15.625 (avg: 25.453)\tTop5: 53.125 (avg: 52.672)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.405 (avg: 0.411)\tLoss: 3.0604 (avg: 3.2225)\tTop1: 25.000 (avg: 25.300)\tTop5: 51.562 (avg: 52.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3483\tTop 1 accuracy: 14.300\tTop 5 accuracy: 33.650\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.398 (avg: 0.399)\tLoss: 2.8958 (avg: 3.1177)\tTop1: 32.812 (avg: 26.312)\tTop5: 65.625 (avg: 55.438)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.410 (avg: 0.406)\tLoss: 3.2866 (avg: 3.1587)\tTop1: 23.438 (avg: 26.344)\tTop5: 50.000 (avg: 53.938)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.403 (avg: 0.408)\tLoss: 3.1573 (avg: 3.1831)\tTop1: 28.125 (avg: 26.438)\tTop5: 50.000 (avg: 53.396)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.404 (avg: 0.409)\tLoss: 3.1114 (avg: 3.1975)\tTop1: 21.875 (avg: 26.234)\tTop5: 53.125 (avg: 52.859)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.409 (avg: 0.410)\tLoss: 4.0150 (avg: 3.2129)\tTop1: 17.188 (avg: 25.750)\tTop5: 35.938 (avg: 52.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3804\tTop 1 accuracy: 14.000\tTop 5 accuracy: 33.700\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.402 (avg: 0.403)\tLoss: 3.0223 (avg: 3.1445)\tTop1: 31.250 (avg: 26.750)\tTop5: 62.500 (avg: 54.375)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.406 (avg: 0.408)\tLoss: 3.3207 (avg: 3.1470)\tTop1: 28.125 (avg: 26.625)\tTop5: 46.875 (avg: 53.656)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 3.3171 (avg: 3.2073)\tTop1: 21.875 (avg: 25.854)\tTop5: 48.438 (avg: 51.979)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.400 (avg: 0.410)\tLoss: 3.6754 (avg: 3.2171)\tTop1: 15.625 (avg: 25.453)\tTop5: 40.625 (avg: 52.047)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.417 (avg: 0.410)\tLoss: 3.0367 (avg: 3.2135)\tTop1: 23.438 (avg: 25.500)\tTop5: 56.250 (avg: 52.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3807\tTop 1 accuracy: 13.500\tTop 5 accuracy: 33.500\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.408 (avg: 0.402)\tLoss: 2.9544 (avg: 3.2005)\tTop1: 32.812 (avg: 25.750)\tTop5: 60.938 (avg: 53.500)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.401 (avg: 0.407)\tLoss: 3.4348 (avg: 3.2013)\tTop1: 18.750 (avg: 25.875)\tTop5: 53.125 (avg: 53.125)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.407 (avg: 0.409)\tLoss: 3.3103 (avg: 3.2217)\tTop1: 18.750 (avg: 25.604)\tTop5: 53.125 (avg: 52.417)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.414 (avg: 0.410)\tLoss: 3.0662 (avg: 3.2111)\tTop1: 23.438 (avg: 25.344)\tTop5: 56.250 (avg: 52.625)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.401 (avg: 0.411)\tLoss: 3.0214 (avg: 3.2107)\tTop1: 25.000 (avg: 25.600)\tTop5: 57.812 (avg: 52.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3811\tTop 1 accuracy: 14.200\tTop 5 accuracy: 33.900\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.402 (avg: 0.403)\tLoss: 3.1566 (avg: 3.1847)\tTop1: 23.438 (avg: 25.750)\tTop5: 53.125 (avg: 51.750)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.408 (avg: 0.408)\tLoss: 3.1332 (avg: 3.1963)\tTop1: 29.688 (avg: 26.031)\tTop5: 48.438 (avg: 52.250)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.404 (avg: 0.410)\tLoss: 3.0305 (avg: 3.1818)\tTop1: 31.250 (avg: 26.083)\tTop5: 60.938 (avg: 52.688)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.403 (avg: 0.411)\tLoss: 3.4423 (avg: 3.2024)\tTop1: 23.438 (avg: 25.531)\tTop5: 45.312 (avg: 52.391)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.410 (avg: 0.411)\tLoss: 3.0151 (avg: 3.1960)\tTop1: 28.125 (avg: 25.638)\tTop5: 54.688 (avg: 52.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3973\tTop 1 accuracy: 14.350\tTop 5 accuracy: 33.650\n",
            "\n",
            "pct_3x3 = 0.625: top1 = 12.90000057220459 \t top5 = 34.0 \t batch time = 0.2951161190867424\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.408 (avg: 0.500)\tLoss: 5.3109 (avg: 5.2999)\tTop1: 0.000 (avg: 0.750)\tTop5: 0.000 (avg: 3.000)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.412 (avg: 0.458)\tLoss: 5.2991 (avg: 5.2997)\tTop1: 0.000 (avg: 0.469)\tTop5: 1.562 (avg: 2.781)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.407 (avg: 0.444)\tLoss: 5.2017 (avg: 5.2955)\tTop1: 1.562 (avg: 0.562)\tTop5: 6.250 (avg: 2.833)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.417 (avg: 0.437)\tLoss: 5.2405 (avg: 5.2894)\tTop1: 0.000 (avg: 0.500)\tTop5: 1.562 (avg: 2.766)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.414 (avg: 0.433)\tLoss: 5.2926 (avg: 5.2850)\tTop1: 1.562 (avg: 0.500)\tTop5: 3.125 (avg: 2.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3083\tTop 1 accuracy: 0.400\tTop 5 accuracy: 2.750\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.406 (avg: 0.403)\tLoss: 5.2918 (avg: 5.2702)\tTop1: 0.000 (avg: 0.500)\tTop5: 0.000 (avg: 2.500)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.413 (avg: 0.410)\tLoss: 5.2665 (avg: 5.2582)\tTop1: 1.562 (avg: 0.594)\tTop5: 4.688 (avg: 3.000)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.411 (avg: 0.412)\tLoss: 5.2975 (avg: 5.2539)\tTop1: 1.562 (avg: 0.688)\tTop5: 3.125 (avg: 3.396)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 5.1937 (avg: 5.2521)\tTop1: 0.000 (avg: 0.688)\tTop5: 9.375 (avg: 3.531)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.411 (avg: 0.414)\tLoss: 5.2720 (avg: 5.2524)\tTop1: 1.562 (avg: 0.750)\tTop5: 4.688 (avg: 3.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2904\tTop 1 accuracy: 0.700\tTop 5 accuracy: 3.150\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.408 (avg: 0.406)\tLoss: 5.1994 (avg: 5.2286)\tTop1: 0.000 (avg: 1.250)\tTop5: 3.125 (avg: 4.500)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.406 (avg: 0.411)\tLoss: 5.2361 (avg: 5.2355)\tTop1: 0.000 (avg: 1.125)\tTop5: 3.125 (avg: 4.438)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.406 (avg: 0.413)\tLoss: 5.2769 (avg: 5.2339)\tTop1: 0.000 (avg: 1.167)\tTop5: 0.000 (avg: 4.562)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.406 (avg: 0.413)\tLoss: 5.2388 (avg: 5.2327)\tTop1: 0.000 (avg: 1.172)\tTop5: 4.688 (avg: 4.562)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.410 (avg: 0.413)\tLoss: 5.2517 (avg: 5.2345)\tTop1: 1.562 (avg: 1.150)\tTop5: 3.125 (avg: 4.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3120\tTop 1 accuracy: 0.700\tTop 5 accuracy: 3.450\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.411 (avg: 0.405)\tLoss: 5.2443 (avg: 5.2262)\tTop1: 3.125 (avg: 1.500)\tTop5: 3.125 (avg: 5.000)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.416 (avg: 0.410)\tLoss: 5.1426 (avg: 5.2187)\tTop1: 0.000 (avg: 1.094)\tTop5: 4.688 (avg: 4.969)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.413 (avg: 0.412)\tLoss: 5.2277 (avg: 5.2248)\tTop1: 0.000 (avg: 1.062)\tTop5: 3.125 (avg: 4.750)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.409 (avg: 0.412)\tLoss: 5.1889 (avg: 5.2258)\tTop1: 0.000 (avg: 1.031)\tTop5: 1.562 (avg: 4.688)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 5.1813 (avg: 5.2265)\tTop1: 1.562 (avg: 1.025)\tTop5: 6.250 (avg: 4.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3048\tTop 1 accuracy: 0.650\tTop 5 accuracy: 3.500\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.410 (avg: 0.404)\tLoss: 5.2555 (avg: 5.2010)\tTop1: 0.000 (avg: 0.938)\tTop5: 4.688 (avg: 5.562)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.415 (avg: 0.410)\tLoss: 5.1318 (avg: 5.2120)\tTop1: 3.125 (avg: 1.031)\tTop5: 6.250 (avg: 5.250)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.409 (avg: 0.412)\tLoss: 5.3099 (avg: 5.2148)\tTop1: 0.000 (avg: 0.979)\tTop5: 3.125 (avg: 5.000)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.409 (avg: 0.412)\tLoss: 5.1887 (avg: 5.2137)\tTop1: 1.562 (avg: 1.062)\tTop5: 6.250 (avg: 5.141)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.409 (avg: 0.413)\tLoss: 5.1998 (avg: 5.2119)\tTop1: 0.000 (avg: 1.075)\tTop5: 6.250 (avg: 5.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2275\tTop 1 accuracy: 1.150\tTop 5 accuracy: 5.900\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.412 (avg: 0.405)\tLoss: 5.1251 (avg: 5.1873)\tTop1: 3.125 (avg: 1.438)\tTop5: 14.062 (avg: 6.188)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.406 (avg: 0.410)\tLoss: 5.1343 (avg: 5.1879)\tTop1: 1.562 (avg: 1.375)\tTop5: 4.688 (avg: 5.750)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.409 (avg: 0.412)\tLoss: 4.9756 (avg: 5.1883)\tTop1: 4.688 (avg: 1.292)\tTop5: 15.625 (avg: 5.979)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.414 (avg: 0.413)\tLoss: 5.1900 (avg: 5.1859)\tTop1: 1.562 (avg: 1.250)\tTop5: 3.125 (avg: 6.203)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.402 (avg: 0.413)\tLoss: 5.2302 (avg: 5.1851)\tTop1: 0.000 (avg: 1.325)\tTop5: 4.688 (avg: 6.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1613\tTop 1 accuracy: 1.650\tTop 5 accuracy: 5.950\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.411 (avg: 0.402)\tLoss: 5.2540 (avg: 5.1459)\tTop1: 6.250 (avg: 2.500)\tTop5: 7.812 (avg: 8.250)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.406 (avg: 0.409)\tLoss: 5.0783 (avg: 5.1589)\tTop1: 3.125 (avg: 1.875)\tTop5: 3.125 (avg: 6.906)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.418 (avg: 0.411)\tLoss: 5.2471 (avg: 5.1608)\tTop1: 0.000 (avg: 1.875)\tTop5: 4.688 (avg: 7.021)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.402 (avg: 0.412)\tLoss: 5.2555 (avg: 5.1657)\tTop1: 0.000 (avg: 1.781)\tTop5: 3.125 (avg: 6.828)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.401 (avg: 0.413)\tLoss: 5.2425 (avg: 5.1656)\tTop1: 0.000 (avg: 1.750)\tTop5: 3.125 (avg: 6.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2732\tTop 1 accuracy: 1.250\tTop 5 accuracy: 6.800\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.408 (avg: 0.405)\tLoss: 5.2276 (avg: 5.2007)\tTop1: 0.000 (avg: 1.625)\tTop5: 3.125 (avg: 6.062)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.415 (avg: 0.410)\tLoss: 5.1973 (avg: 5.1928)\tTop1: 1.562 (avg: 1.438)\tTop5: 3.125 (avg: 6.031)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.409 (avg: 0.411)\tLoss: 5.1656 (avg: 5.1794)\tTop1: 3.125 (avg: 1.729)\tTop5: 6.250 (avg: 6.812)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.405 (avg: 0.412)\tLoss: 5.1085 (avg: 5.1742)\tTop1: 3.125 (avg: 1.672)\tTop5: 6.250 (avg: 6.875)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.404 (avg: 0.412)\tLoss: 5.2163 (avg: 5.1590)\tTop1: 0.000 (avg: 1.688)\tTop5: 1.562 (avg: 7.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2225\tTop 1 accuracy: 1.450\tTop 5 accuracy: 7.400\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.413 (avg: 0.404)\tLoss: 5.0991 (avg: 5.1626)\tTop1: 1.562 (avg: 1.562)\tTop5: 9.375 (avg: 6.938)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.407 (avg: 0.409)\tLoss: 5.1388 (avg: 5.1606)\tTop1: 3.125 (avg: 1.844)\tTop5: 4.688 (avg: 6.406)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.407 (avg: 0.411)\tLoss: 4.9696 (avg: 5.1513)\tTop1: 1.562 (avg: 1.792)\tTop5: 12.500 (avg: 6.438)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.405 (avg: 0.412)\tLoss: 5.2158 (avg: 5.1441)\tTop1: 1.562 (avg: 1.828)\tTop5: 4.688 (avg: 6.984)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.403 (avg: 0.412)\tLoss: 5.2010 (avg: 5.1390)\tTop1: 1.562 (avg: 1.738)\tTop5: 6.250 (avg: 7.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1787\tTop 1 accuracy: 2.000\tTop 5 accuracy: 7.850\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.403 (avg: 0.405)\tLoss: 5.1435 (avg: 5.0576)\tTop1: 3.125 (avg: 1.750)\tTop5: 6.250 (avg: 8.438)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.410 (avg: 0.410)\tLoss: 5.1502 (avg: 5.0711)\tTop1: 3.125 (avg: 1.875)\tTop5: 4.688 (avg: 8.000)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.414 (avg: 0.411)\tLoss: 5.1098 (avg: 5.0766)\tTop1: 3.125 (avg: 1.979)\tTop5: 4.688 (avg: 7.979)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.409 (avg: 0.412)\tLoss: 5.0857 (avg: 5.0825)\tTop1: 3.125 (avg: 2.062)\tTop5: 10.938 (avg: 8.047)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.417 (avg: 0.413)\tLoss: 5.1114 (avg: 5.0771)\tTop1: 1.562 (avg: 2.150)\tTop5: 7.812 (avg: 8.312)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1867\tTop 1 accuracy: 2.750\tTop 5 accuracy: 8.600\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.406 (avg: 0.404)\tLoss: 5.0024 (avg: 5.0049)\tTop1: 1.562 (avg: 2.375)\tTop5: 7.812 (avg: 10.188)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 5.1480 (avg: 5.0203)\tTop1: 0.000 (avg: 2.219)\tTop5: 6.250 (avg: 9.781)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.410 (avg: 0.412)\tLoss: 5.1321 (avg: 5.0232)\tTop1: 0.000 (avg: 2.375)\tTop5: 9.375 (avg: 9.604)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.414 (avg: 0.413)\tLoss: 5.0215 (avg: 5.0208)\tTop1: 1.562 (avg: 2.297)\tTop5: 9.375 (avg: 9.453)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.405 (avg: 0.414)\tLoss: 5.0743 (avg: 5.0173)\tTop1: 0.000 (avg: 2.325)\tTop5: 3.125 (avg: 9.325)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9589\tTop 1 accuracy: 2.700\tTop 5 accuracy: 10.050\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.413 (avg: 0.403)\tLoss: 5.0173 (avg: 5.0083)\tTop1: 1.562 (avg: 2.125)\tTop5: 7.812 (avg: 8.750)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.406 (avg: 0.409)\tLoss: 4.9107 (avg: 4.9960)\tTop1: 0.000 (avg: 2.312)\tTop5: 10.938 (avg: 9.312)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.416 (avg: 0.411)\tLoss: 4.9872 (avg: 5.0022)\tTop1: 3.125 (avg: 2.375)\tTop5: 10.938 (avg: 9.438)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.403 (avg: 0.412)\tLoss: 4.8010 (avg: 4.9978)\tTop1: 3.125 (avg: 2.516)\tTop5: 15.625 (avg: 9.734)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 4.8648 (avg: 4.9932)\tTop1: 1.562 (avg: 2.588)\tTop5: 9.375 (avg: 10.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6688\tTop 1 accuracy: 3.100\tTop 5 accuracy: 10.800\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.404 (avg: 0.405)\tLoss: 4.8550 (avg: 4.9058)\tTop1: 6.250 (avg: 2.938)\tTop5: 14.062 (avg: 11.125)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.416 (avg: 0.410)\tLoss: 4.9757 (avg: 4.9356)\tTop1: 1.562 (avg: 3.000)\tTop5: 10.938 (avg: 11.312)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.410 (avg: 0.412)\tLoss: 4.9333 (avg: 4.9482)\tTop1: 3.125 (avg: 2.938)\tTop5: 10.938 (avg: 10.938)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.403 (avg: 0.413)\tLoss: 4.8447 (avg: 4.9370)\tTop1: 0.000 (avg: 2.781)\tTop5: 15.625 (avg: 10.797)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.405 (avg: 0.412)\tLoss: 4.8471 (avg: 4.9370)\tTop1: 4.688 (avg: 2.913)\tTop5: 12.500 (avg: 10.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9605\tTop 1 accuracy: 3.750\tTop 5 accuracy: 13.300\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.410 (avg: 0.406)\tLoss: 4.8435 (avg: 4.9105)\tTop1: 3.125 (avg: 2.688)\tTop5: 18.750 (avg: 11.438)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.407 (avg: 0.411)\tLoss: 5.0670 (avg: 4.8961)\tTop1: 0.000 (avg: 2.875)\tTop5: 12.500 (avg: 12.062)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.403 (avg: 0.412)\tLoss: 5.0117 (avg: 4.8959)\tTop1: 3.125 (avg: 2.896)\tTop5: 9.375 (avg: 11.688)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.413 (avg: 0.413)\tLoss: 4.9271 (avg: 4.9110)\tTop1: 1.562 (avg: 2.984)\tTop5: 4.688 (avg: 11.516)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.401 (avg: 0.414)\tLoss: 4.9902 (avg: 4.9109)\tTop1: 6.250 (avg: 3.025)\tTop5: 7.812 (avg: 11.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7530\tTop 1 accuracy: 4.000\tTop 5 accuracy: 12.350\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.406 (avg: 0.405)\tLoss: 4.9589 (avg: 4.8521)\tTop1: 1.562 (avg: 3.188)\tTop5: 14.062 (avg: 12.875)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.404 (avg: 0.410)\tLoss: 4.9417 (avg: 4.8810)\tTop1: 0.000 (avg: 2.969)\tTop5: 12.500 (avg: 11.969)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.415 (avg: 0.412)\tLoss: 5.0582 (avg: 4.8629)\tTop1: 4.688 (avg: 3.458)\tTop5: 9.375 (avg: 12.479)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.407 (avg: 0.413)\tLoss: 4.9293 (avg: 4.8570)\tTop1: 6.250 (avg: 3.469)\tTop5: 12.500 (avg: 12.547)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.407 (avg: 0.414)\tLoss: 4.9688 (avg: 4.8617)\tTop1: 1.562 (avg: 3.250)\tTop5: 7.812 (avg: 12.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9044\tTop 1 accuracy: 3.900\tTop 5 accuracy: 12.600\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.408 (avg: 0.405)\tLoss: 4.8683 (avg: 4.8396)\tTop1: 4.688 (avg: 3.500)\tTop5: 14.062 (avg: 12.688)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.419 (avg: 0.411)\tLoss: 5.0533 (avg: 4.8084)\tTop1: 0.000 (avg: 3.344)\tTop5: 6.250 (avg: 13.031)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 4.7846 (avg: 4.7941)\tTop1: 4.688 (avg: 3.771)\tTop5: 12.500 (avg: 13.375)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 4.9496 (avg: 4.8128)\tTop1: 3.125 (avg: 3.484)\tTop5: 9.375 (avg: 13.062)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.410 (avg: 0.414)\tLoss: 4.7043 (avg: 4.8100)\tTop1: 4.688 (avg: 3.450)\tTop5: 15.625 (avg: 13.063)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3119\tTop 1 accuracy: 3.650\tTop 5 accuracy: 10.600\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.414 (avg: 0.403)\tLoss: 4.7541 (avg: 4.7579)\tTop1: 1.562 (avg: 3.875)\tTop5: 10.938 (avg: 14.625)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.410 (avg: 0.409)\tLoss: 4.7761 (avg: 4.7516)\tTop1: 4.688 (avg: 3.500)\tTop5: 20.312 (avg: 14.156)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.410 (avg: 0.411)\tLoss: 4.8000 (avg: 4.7449)\tTop1: 3.125 (avg: 3.667)\tTop5: 10.938 (avg: 14.792)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.411 (avg: 0.412)\tLoss: 4.9907 (avg: 4.7579)\tTop1: 1.562 (avg: 3.828)\tTop5: 6.250 (avg: 14.594)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.412 (avg: 0.413)\tLoss: 4.5847 (avg: 4.7590)\tTop1: 4.688 (avg: 3.788)\tTop5: 18.750 (avg: 14.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5436\tTop 1 accuracy: 3.350\tTop 5 accuracy: 14.250\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.406 (avg: 0.405)\tLoss: 4.6920 (avg: 4.6666)\tTop1: 1.562 (avg: 4.062)\tTop5: 15.625 (avg: 15.562)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 4.6020 (avg: 4.6867)\tTop1: 7.812 (avg: 4.000)\tTop5: 15.625 (avg: 15.188)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.412 (avg: 0.412)\tLoss: 4.9183 (avg: 4.7189)\tTop1: 3.125 (avg: 3.812)\tTop5: 9.375 (avg: 15.042)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.410 (avg: 0.413)\tLoss: 4.7408 (avg: 4.7531)\tTop1: 7.812 (avg: 3.719)\tTop5: 15.625 (avg: 14.609)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 4.7474 (avg: 4.7561)\tTop1: 6.250 (avg: 3.888)\tTop5: 14.062 (avg: 14.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7992\tTop 1 accuracy: 3.400\tTop 5 accuracy: 13.950\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.408 (avg: 0.405)\tLoss: 4.5569 (avg: 4.6307)\tTop1: 6.250 (avg: 4.625)\tTop5: 17.188 (avg: 17.250)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.411 (avg: 0.410)\tLoss: 4.4127 (avg: 4.6635)\tTop1: 7.812 (avg: 4.750)\tTop5: 29.688 (avg: 17.062)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 4.7328 (avg: 4.6676)\tTop1: 6.250 (avg: 4.688)\tTop5: 17.188 (avg: 16.583)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.415 (avg: 0.413)\tLoss: 4.7140 (avg: 4.6759)\tTop1: 0.000 (avg: 4.266)\tTop5: 12.500 (avg: 16.172)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.404 (avg: 0.413)\tLoss: 4.4710 (avg: 4.6761)\tTop1: 9.375 (avg: 4.525)\tTop5: 25.000 (avg: 16.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4441\tTop 1 accuracy: 4.200\tTop 5 accuracy: 16.200\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.411 (avg: 0.405)\tLoss: 4.5226 (avg: 4.5670)\tTop1: 6.250 (avg: 6.250)\tTop5: 18.750 (avg: 19.625)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 4.5190 (avg: 4.5912)\tTop1: 3.125 (avg: 5.844)\tTop5: 18.750 (avg: 19.281)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.412 (avg: 0.412)\tLoss: 4.8247 (avg: 4.6257)\tTop1: 1.562 (avg: 5.292)\tTop5: 15.625 (avg: 18.688)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 4.4834 (avg: 4.6326)\tTop1: 1.562 (avg: 5.094)\tTop5: 20.312 (avg: 18.484)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.404 (avg: 0.413)\tLoss: 4.3555 (avg: 4.6206)\tTop1: 6.250 (avg: 5.475)\tTop5: 23.438 (avg: 18.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6241\tTop 1 accuracy: 4.550\tTop 5 accuracy: 16.750\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.403 (avg: 0.405)\tLoss: 4.3809 (avg: 4.5873)\tTop1: 9.375 (avg: 6.250)\tTop5: 20.312 (avg: 19.562)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.415 (avg: 0.411)\tLoss: 4.3609 (avg: 4.5643)\tTop1: 7.812 (avg: 5.969)\tTop5: 20.312 (avg: 19.938)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.409 (avg: 0.412)\tLoss: 4.4027 (avg: 4.5567)\tTop1: 4.688 (avg: 5.917)\tTop5: 21.875 (avg: 20.146)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.403 (avg: 0.413)\tLoss: 4.6169 (avg: 4.5461)\tTop1: 4.688 (avg: 5.891)\tTop5: 18.750 (avg: 19.938)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.416 (avg: 0.414)\tLoss: 4.8393 (avg: 4.5523)\tTop1: 1.562 (avg: 5.788)\tTop5: 9.375 (avg: 19.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5735\tTop 1 accuracy: 6.050\tTop 5 accuracy: 18.150\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.413 (avg: 0.405)\tLoss: 4.4655 (avg: 4.4815)\tTop1: 6.250 (avg: 7.375)\tTop5: 17.188 (avg: 22.062)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 4.6091 (avg: 4.5093)\tTop1: 1.562 (avg: 6.156)\tTop5: 18.750 (avg: 20.406)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.402 (avg: 0.412)\tLoss: 4.7383 (avg: 4.4934)\tTop1: 1.562 (avg: 6.292)\tTop5: 15.625 (avg: 20.812)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.415 (avg: 0.413)\tLoss: 4.3843 (avg: 4.4916)\tTop1: 14.062 (avg: 6.469)\tTop5: 26.562 (avg: 20.875)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.401 (avg: 0.413)\tLoss: 4.6778 (avg: 4.4947)\tTop1: 4.688 (avg: 6.438)\tTop5: 21.875 (avg: 20.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2399\tTop 1 accuracy: 6.150\tTop 5 accuracy: 20.100\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.412 (avg: 0.406)\tLoss: 4.4683 (avg: 4.4499)\tTop1: 6.250 (avg: 7.000)\tTop5: 21.875 (avg: 22.062)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.406 (avg: 0.411)\tLoss: 4.3557 (avg: 4.4510)\tTop1: 7.812 (avg: 6.750)\tTop5: 21.875 (avg: 22.312)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.413 (avg: 0.413)\tLoss: 4.3080 (avg: 4.4638)\tTop1: 6.250 (avg: 6.667)\tTop5: 29.688 (avg: 21.917)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.406 (avg: 0.413)\tLoss: 4.4528 (avg: 4.4677)\tTop1: 6.250 (avg: 6.719)\tTop5: 21.875 (avg: 21.734)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.402 (avg: 0.414)\tLoss: 4.6792 (avg: 4.4773)\tTop1: 6.250 (avg: 6.575)\tTop5: 15.625 (avg: 21.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3712\tTop 1 accuracy: 6.100\tTop 5 accuracy: 21.100\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.410 (avg: 0.406)\tLoss: 4.3251 (avg: 4.3907)\tTop1: 7.812 (avg: 7.250)\tTop5: 32.812 (avg: 22.688)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.417 (avg: 0.411)\tLoss: 4.1319 (avg: 4.3929)\tTop1: 9.375 (avg: 7.500)\tTop5: 23.438 (avg: 22.781)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.403 (avg: 0.412)\tLoss: 4.4536 (avg: 4.4101)\tTop1: 3.125 (avg: 7.104)\tTop5: 29.688 (avg: 22.896)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.409 (avg: 0.413)\tLoss: 4.2802 (avg: 4.4230)\tTop1: 9.375 (avg: 6.906)\tTop5: 21.875 (avg: 22.500)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.406 (avg: 0.414)\tLoss: 4.4774 (avg: 4.4326)\tTop1: 3.125 (avg: 6.588)\tTop5: 14.062 (avg: 22.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2903\tTop 1 accuracy: 6.450\tTop 5 accuracy: 22.350\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.417 (avg: 0.406)\tLoss: 4.5765 (avg: 4.3029)\tTop1: 6.250 (avg: 8.938)\tTop5: 18.750 (avg: 26.562)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.406 (avg: 0.410)\tLoss: 4.5287 (avg: 4.3146)\tTop1: 7.812 (avg: 8.062)\tTop5: 20.312 (avg: 26.094)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 4.1483 (avg: 4.3411)\tTop1: 10.938 (avg: 7.958)\tTop5: 34.375 (avg: 25.062)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.413 (avg: 0.413)\tLoss: 4.0670 (avg: 4.3504)\tTop1: 15.625 (avg: 7.984)\tTop5: 32.812 (avg: 24.906)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.409 (avg: 0.413)\tLoss: 4.8910 (avg: 4.3525)\tTop1: 4.688 (avg: 7.788)\tTop5: 17.188 (avg: 24.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1514\tTop 1 accuracy: 6.200\tTop 5 accuracy: 21.750\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.407 (avg: 0.406)\tLoss: 4.3542 (avg: 4.2445)\tTop1: 9.375 (avg: 8.875)\tTop5: 25.000 (avg: 28.125)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.408 (avg: 0.411)\tLoss: 4.2810 (avg: 4.2770)\tTop1: 10.938 (avg: 8.156)\tTop5: 25.000 (avg: 26.875)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.413 (avg: 0.413)\tLoss: 4.2235 (avg: 4.3084)\tTop1: 7.812 (avg: 8.062)\tTop5: 29.688 (avg: 25.729)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.412 (avg: 0.413)\tLoss: 4.3378 (avg: 4.3285)\tTop1: 10.938 (avg: 7.859)\tTop5: 26.562 (avg: 25.031)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.417 (avg: 0.414)\tLoss: 4.3882 (avg: 4.3298)\tTop1: 7.812 (avg: 7.700)\tTop5: 28.125 (avg: 25.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2574\tTop 1 accuracy: 6.450\tTop 5 accuracy: 20.100\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.409 (avg: 0.405)\tLoss: 4.6640 (avg: 4.3446)\tTop1: 6.250 (avg: 8.000)\tTop5: 23.438 (avg: 24.500)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.409 (avg: 0.411)\tLoss: 4.3214 (avg: 4.2854)\tTop1: 6.250 (avg: 8.750)\tTop5: 26.562 (avg: 25.906)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 3.8933 (avg: 4.2651)\tTop1: 6.250 (avg: 8.875)\tTop5: 35.938 (avg: 26.521)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.413 (avg: 0.413)\tLoss: 4.0215 (avg: 4.2754)\tTop1: 14.062 (avg: 8.906)\tTop5: 26.562 (avg: 26.156)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.410 (avg: 0.414)\tLoss: 4.2461 (avg: 4.2730)\tTop1: 10.938 (avg: 8.875)\tTop5: 28.125 (avg: 26.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1935\tTop 1 accuracy: 8.550\tTop 5 accuracy: 23.350\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.400 (avg: 0.405)\tLoss: 4.2294 (avg: 4.1719)\tTop1: 3.125 (avg: 9.062)\tTop5: 21.875 (avg: 28.375)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.404 (avg: 0.410)\tLoss: 3.9420 (avg: 4.1844)\tTop1: 10.938 (avg: 8.969)\tTop5: 32.812 (avg: 28.375)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.408 (avg: 0.412)\tLoss: 4.0220 (avg: 4.2134)\tTop1: 10.938 (avg: 8.917)\tTop5: 28.125 (avg: 27.667)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.405 (avg: 0.412)\tLoss: 4.1056 (avg: 4.2280)\tTop1: 14.062 (avg: 8.875)\tTop5: 29.688 (avg: 27.438)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.405 (avg: 0.413)\tLoss: 4.1756 (avg: 4.2377)\tTop1: 14.062 (avg: 8.700)\tTop5: 40.625 (avg: 27.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3801\tTop 1 accuracy: 8.100\tTop 5 accuracy: 22.900\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.408 (avg: 0.404)\tLoss: 3.9872 (avg: 4.1365)\tTop1: 9.375 (avg: 10.750)\tTop5: 37.500 (avg: 30.750)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.417 (avg: 0.410)\tLoss: 4.2133 (avg: 4.1955)\tTop1: 7.812 (avg: 9.875)\tTop5: 28.125 (avg: 29.469)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.411 (avg: 0.412)\tLoss: 4.3209 (avg: 4.1918)\tTop1: 14.062 (avg: 10.333)\tTop5: 35.938 (avg: 29.667)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 4.1981 (avg: 4.1926)\tTop1: 10.938 (avg: 10.031)\tTop5: 28.125 (avg: 29.141)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.409 (avg: 0.413)\tLoss: 4.2655 (avg: 4.1949)\tTop1: 12.500 (avg: 9.963)\tTop5: 20.312 (avg: 29.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4792\tTop 1 accuracy: 8.500\tTop 5 accuracy: 25.050\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.415 (avg: 0.406)\tLoss: 4.2770 (avg: 4.1084)\tTop1: 4.688 (avg: 10.438)\tTop5: 23.438 (avg: 31.250)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.413 (avg: 0.411)\tLoss: 4.2084 (avg: 4.1337)\tTop1: 10.938 (avg: 10.500)\tTop5: 25.000 (avg: 30.562)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.410 (avg: 0.413)\tLoss: 4.1256 (avg: 4.1818)\tTop1: 6.250 (avg: 10.104)\tTop5: 34.375 (avg: 29.583)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.414 (avg: 0.414)\tLoss: 4.0745 (avg: 4.1813)\tTop1: 4.688 (avg: 10.078)\tTop5: 23.438 (avg: 29.109)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.404 (avg: 0.414)\tLoss: 4.1135 (avg: 4.1894)\tTop1: 14.062 (avg: 9.863)\tTop5: 31.250 (avg: 28.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4314\tTop 1 accuracy: 9.050\tTop 5 accuracy: 26.300\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.409 (avg: 0.405)\tLoss: 3.8562 (avg: 3.9592)\tTop1: 9.375 (avg: 13.500)\tTop5: 32.812 (avg: 35.375)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.406 (avg: 0.410)\tLoss: 3.5992 (avg: 3.9080)\tTop1: 17.188 (avg: 14.312)\tTop5: 45.312 (avg: 36.250)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.411 (avg: 0.412)\tLoss: 3.5576 (avg: 3.8820)\tTop1: 10.938 (avg: 14.521)\tTop5: 43.750 (avg: 36.833)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 4.0118 (avg: 3.8714)\tTop1: 12.500 (avg: 14.969)\tTop5: 34.375 (avg: 37.203)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.411 (avg: 0.413)\tLoss: 4.1503 (avg: 3.8680)\tTop1: 20.312 (avg: 15.025)\tTop5: 31.250 (avg: 37.312)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6680\tTop 1 accuracy: 12.350\tTop 5 accuracy: 30.250\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.408 (avg: 0.405)\tLoss: 3.6812 (avg: 3.7301)\tTop1: 15.625 (avg: 16.938)\tTop5: 35.938 (avg: 39.750)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.413 (avg: 0.411)\tLoss: 4.2339 (avg: 3.7961)\tTop1: 9.375 (avg: 15.688)\tTop5: 29.688 (avg: 38.562)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.408 (avg: 0.412)\tLoss: 3.3166 (avg: 3.7715)\tTop1: 28.125 (avg: 16.125)\tTop5: 54.688 (avg: 39.292)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.406 (avg: 0.413)\tLoss: 3.9463 (avg: 3.7731)\tTop1: 10.938 (avg: 16.016)\tTop5: 34.375 (avg: 39.188)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.409 (avg: 0.414)\tLoss: 3.6182 (avg: 3.7855)\tTop1: 14.062 (avg: 16.000)\tTop5: 34.375 (avg: 39.013)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7355\tTop 1 accuracy: 12.100\tTop 5 accuracy: 29.600\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.412 (avg: 0.406)\tLoss: 3.9038 (avg: 3.7265)\tTop1: 17.188 (avg: 15.500)\tTop5: 42.188 (avg: 39.750)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.404 (avg: 0.411)\tLoss: 3.8547 (avg: 3.7419)\tTop1: 12.500 (avg: 16.281)\tTop5: 32.812 (avg: 40.500)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.409 (avg: 0.413)\tLoss: 3.8846 (avg: 3.7404)\tTop1: 18.750 (avg: 16.354)\tTop5: 34.375 (avg: 40.542)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.414 (avg: 0.414)\tLoss: 3.9320 (avg: 3.7435)\tTop1: 10.938 (avg: 16.500)\tTop5: 34.375 (avg: 40.078)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.411 (avg: 0.414)\tLoss: 3.5968 (avg: 3.7499)\tTop1: 23.438 (avg: 16.550)\tTop5: 45.312 (avg: 40.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7577\tTop 1 accuracy: 11.650\tTop 5 accuracy: 29.950\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.404 (avg: 0.402)\tLoss: 3.4607 (avg: 3.6771)\tTop1: 9.375 (avg: 17.938)\tTop5: 42.188 (avg: 40.938)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.410 (avg: 0.409)\tLoss: 3.3472 (avg: 3.7166)\tTop1: 26.562 (avg: 17.406)\tTop5: 48.438 (avg: 40.844)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.412 (avg: 0.411)\tLoss: 3.7890 (avg: 3.6940)\tTop1: 14.062 (avg: 17.875)\tTop5: 35.938 (avg: 41.021)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.408 (avg: 0.412)\tLoss: 3.5989 (avg: 3.7088)\tTop1: 20.312 (avg: 17.531)\tTop5: 37.500 (avg: 40.688)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.417 (avg: 0.413)\tLoss: 4.2889 (avg: 3.7249)\tTop1: 17.188 (avg: 17.338)\tTop5: 29.688 (avg: 40.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7119\tTop 1 accuracy: 11.850\tTop 5 accuracy: 30.550\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.410 (avg: 0.404)\tLoss: 3.4555 (avg: 3.6789)\tTop1: 21.875 (avg: 18.438)\tTop5: 51.562 (avg: 41.750)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.410 (avg: 0.410)\tLoss: 3.7415 (avg: 3.6851)\tTop1: 18.750 (avg: 18.344)\tTop5: 34.375 (avg: 41.469)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.410 (avg: 0.412)\tLoss: 3.9930 (avg: 3.7103)\tTop1: 15.625 (avg: 17.583)\tTop5: 31.250 (avg: 40.854)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.415 (avg: 0.413)\tLoss: 3.7105 (avg: 3.7051)\tTop1: 15.625 (avg: 17.500)\tTop5: 35.938 (avg: 41.062)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.413 (avg: 0.414)\tLoss: 3.5307 (avg: 3.7059)\tTop1: 21.875 (avg: 17.438)\tTop5: 40.625 (avg: 41.063)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6952\tTop 1 accuracy: 12.700\tTop 5 accuracy: 31.700\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.409 (avg: 0.405)\tLoss: 4.1590 (avg: 3.6557)\tTop1: 12.500 (avg: 18.312)\tTop5: 31.250 (avg: 41.750)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.403 (avg: 0.410)\tLoss: 4.1037 (avg: 3.6934)\tTop1: 9.375 (avg: 17.938)\tTop5: 29.688 (avg: 41.094)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.415 (avg: 0.412)\tLoss: 3.3600 (avg: 3.6877)\tTop1: 20.312 (avg: 17.771)\tTop5: 42.188 (avg: 40.938)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.403 (avg: 0.413)\tLoss: 3.7298 (avg: 3.6952)\tTop1: 14.062 (avg: 17.703)\tTop5: 37.500 (avg: 40.875)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.408 (avg: 0.414)\tLoss: 3.6116 (avg: 3.6878)\tTop1: 21.875 (avg: 17.750)\tTop5: 50.000 (avg: 40.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6603\tTop 1 accuracy: 11.950\tTop 5 accuracy: 32.050\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.403 (avg: 0.406)\tLoss: 3.8704 (avg: 3.6329)\tTop1: 15.625 (avg: 17.188)\tTop5: 40.625 (avg: 42.688)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.413 (avg: 0.411)\tLoss: 3.5298 (avg: 3.6524)\tTop1: 17.188 (avg: 17.719)\tTop5: 43.750 (avg: 41.906)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.409 (avg: 0.413)\tLoss: 3.3420 (avg: 3.6413)\tTop1: 25.000 (avg: 18.208)\tTop5: 48.438 (avg: 41.625)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.411 (avg: 0.414)\tLoss: 3.7295 (avg: 3.6578)\tTop1: 18.750 (avg: 18.078)\tTop5: 39.062 (avg: 41.469)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.410 (avg: 0.414)\tLoss: 3.5825 (avg: 3.6617)\tTop1: 14.062 (avg: 17.812)\tTop5: 45.312 (avg: 41.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7541\tTop 1 accuracy: 12.250\tTop 5 accuracy: 30.800\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.417 (avg: 0.407)\tLoss: 3.8183 (avg: 3.5978)\tTop1: 12.500 (avg: 19.312)\tTop5: 37.500 (avg: 42.625)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.411 (avg: 0.412)\tLoss: 3.5721 (avg: 3.6333)\tTop1: 15.625 (avg: 18.188)\tTop5: 39.062 (avg: 42.500)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.409 (avg: 0.413)\tLoss: 3.6653 (avg: 3.6404)\tTop1: 17.188 (avg: 18.667)\tTop5: 45.312 (avg: 42.146)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.418 (avg: 0.414)\tLoss: 3.8404 (avg: 3.6447)\tTop1: 25.000 (avg: 18.547)\tTop5: 42.188 (avg: 42.109)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.407 (avg: 0.415)\tLoss: 3.8901 (avg: 3.6542)\tTop1: 15.625 (avg: 18.113)\tTop5: 39.062 (avg: 41.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7683\tTop 1 accuracy: 12.650\tTop 5 accuracy: 31.250\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.410 (avg: 0.401)\tLoss: 2.9299 (avg: 3.5658)\tTop1: 28.125 (avg: 18.688)\tTop5: 65.625 (avg: 45.125)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.404 (avg: 0.408)\tLoss: 3.8347 (avg: 3.6090)\tTop1: 20.312 (avg: 18.344)\tTop5: 34.375 (avg: 43.750)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.420 (avg: 0.411)\tLoss: 3.6315 (avg: 3.6213)\tTop1: 15.625 (avg: 18.208)\tTop5: 46.875 (avg: 43.271)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.413 (avg: 0.413)\tLoss: 3.5451 (avg: 3.6347)\tTop1: 18.750 (avg: 17.984)\tTop5: 46.875 (avg: 42.734)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.410 (avg: 0.414)\tLoss: 3.5689 (avg: 3.6201)\tTop1: 26.562 (avg: 18.188)\tTop5: 43.750 (avg: 43.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6060\tTop 1 accuracy: 12.700\tTop 5 accuracy: 32.200\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.407 (avg: 0.404)\tLoss: 3.7544 (avg: 3.6863)\tTop1: 18.750 (avg: 17.500)\tTop5: 42.188 (avg: 42.312)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.418 (avg: 0.411)\tLoss: 3.2107 (avg: 3.6279)\tTop1: 21.875 (avg: 18.281)\tTop5: 54.688 (avg: 43.156)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.410 (avg: 0.412)\tLoss: 3.3928 (avg: 3.6243)\tTop1: 20.312 (avg: 18.312)\tTop5: 46.875 (avg: 43.042)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.406 (avg: 0.413)\tLoss: 3.7472 (avg: 3.6124)\tTop1: 21.875 (avg: 18.594)\tTop5: 40.625 (avg: 43.188)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.414 (avg: 0.414)\tLoss: 3.3328 (avg: 3.6154)\tTop1: 18.750 (avg: 18.663)\tTop5: 50.000 (avg: 43.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8088\tTop 1 accuracy: 12.850\tTop 5 accuracy: 31.000\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.407 (avg: 0.406)\tLoss: 3.8339 (avg: 3.5784)\tTop1: 12.500 (avg: 17.875)\tTop5: 40.625 (avg: 44.125)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.408 (avg: 0.411)\tLoss: 3.6635 (avg: 3.6182)\tTop1: 10.938 (avg: 17.594)\tTop5: 37.500 (avg: 43.438)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.409 (avg: 0.413)\tLoss: 3.5513 (avg: 3.6051)\tTop1: 10.938 (avg: 17.688)\tTop5: 45.312 (avg: 43.438)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.412 (avg: 0.414)\tLoss: 3.5238 (avg: 3.5884)\tTop1: 18.750 (avg: 18.406)\tTop5: 37.500 (avg: 43.922)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.397 (avg: 0.414)\tLoss: 3.7047 (avg: 3.5971)\tTop1: 20.312 (avg: 18.275)\tTop5: 42.188 (avg: 43.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9165\tTop 1 accuracy: 12.750\tTop 5 accuracy: 30.900\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.408 (avg: 0.407)\tLoss: 3.5143 (avg: 3.5295)\tTop1: 20.312 (avg: 19.875)\tTop5: 40.625 (avg: 44.688)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.405 (avg: 0.411)\tLoss: 3.9764 (avg: 3.5756)\tTop1: 14.062 (avg: 19.500)\tTop5: 37.500 (avg: 44.031)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.410 (avg: 0.413)\tLoss: 3.2901 (avg: 3.5653)\tTop1: 20.312 (avg: 18.938)\tTop5: 57.812 (avg: 44.229)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.405 (avg: 0.414)\tLoss: 3.7623 (avg: 3.5812)\tTop1: 18.750 (avg: 18.609)\tTop5: 40.625 (avg: 43.766)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.415 (avg: 0.415)\tLoss: 3.5443 (avg: 3.5779)\tTop1: 17.188 (avg: 18.775)\tTop5: 51.562 (avg: 43.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6935\tTop 1 accuracy: 12.650\tTop 5 accuracy: 31.350\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.411 (avg: 0.405)\tLoss: 3.5670 (avg: 3.5058)\tTop1: 17.188 (avg: 20.062)\tTop5: 40.625 (avg: 45.750)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.414 (avg: 0.411)\tLoss: 3.3569 (avg: 3.5345)\tTop1: 25.000 (avg: 19.781)\tTop5: 48.438 (avg: 45.031)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.418 (avg: 0.413)\tLoss: 3.4152 (avg: 3.5567)\tTop1: 25.000 (avg: 18.979)\tTop5: 48.438 (avg: 44.938)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.415 (avg: 0.414)\tLoss: 3.8015 (avg: 3.5584)\tTop1: 10.938 (avg: 18.797)\tTop5: 35.938 (avg: 44.656)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.406 (avg: 0.415)\tLoss: 3.4975 (avg: 3.5581)\tTop1: 21.875 (avg: 18.975)\tTop5: 48.438 (avg: 44.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7963\tTop 1 accuracy: 13.050\tTop 5 accuracy: 31.500\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.404 (avg: 0.400)\tLoss: 3.5463 (avg: 3.5483)\tTop1: 15.625 (avg: 19.188)\tTop5: 45.312 (avg: 45.250)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.412 (avg: 0.408)\tLoss: 3.5770 (avg: 3.5598)\tTop1: 20.312 (avg: 19.094)\tTop5: 42.188 (avg: 44.375)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.414 (avg: 0.411)\tLoss: 3.3116 (avg: 3.5438)\tTop1: 21.875 (avg: 19.375)\tTop5: 51.562 (avg: 44.875)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.410 (avg: 0.412)\tLoss: 3.4443 (avg: 3.5273)\tTop1: 31.250 (avg: 19.641)\tTop5: 48.438 (avg: 44.625)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.404 (avg: 0.413)\tLoss: 3.2279 (avg: 3.5391)\tTop1: 28.125 (avg: 19.363)\tTop5: 48.438 (avg: 44.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6806\tTop 1 accuracy: 12.700\tTop 5 accuracy: 32.250\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.399 (avg: 0.406)\tLoss: 3.3013 (avg: 3.4879)\tTop1: 21.875 (avg: 20.812)\tTop5: 50.000 (avg: 45.875)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.416 (avg: 0.411)\tLoss: 3.3069 (avg: 3.5063)\tTop1: 21.875 (avg: 20.250)\tTop5: 50.000 (avg: 45.469)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.405 (avg: 0.413)\tLoss: 3.4070 (avg: 3.5194)\tTop1: 28.125 (avg: 19.958)\tTop5: 48.438 (avg: 45.479)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.411 (avg: 0.414)\tLoss: 3.8494 (avg: 3.5147)\tTop1: 9.375 (avg: 19.719)\tTop5: 42.188 (avg: 45.328)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.418 (avg: 0.414)\tLoss: 3.5779 (avg: 3.5298)\tTop1: 17.188 (avg: 19.588)\tTop5: 39.062 (avg: 45.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8362\tTop 1 accuracy: 12.850\tTop 5 accuracy: 31.650\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.414 (avg: 0.406)\tLoss: 3.8234 (avg: 3.4909)\tTop1: 17.188 (avg: 21.062)\tTop5: 37.500 (avg: 46.750)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.404 (avg: 0.411)\tLoss: 3.7610 (avg: 3.5182)\tTop1: 17.188 (avg: 19.938)\tTop5: 40.625 (avg: 45.500)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.407 (avg: 0.413)\tLoss: 3.6379 (avg: 3.5035)\tTop1: 15.625 (avg: 20.125)\tTop5: 50.000 (avg: 46.292)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.412 (avg: 0.414)\tLoss: 3.5781 (avg: 3.5086)\tTop1: 17.188 (avg: 20.047)\tTop5: 42.188 (avg: 46.031)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.403 (avg: 0.414)\tLoss: 3.3915 (avg: 3.5078)\tTop1: 23.438 (avg: 20.250)\tTop5: 51.562 (avg: 45.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5557\tTop 1 accuracy: 13.250\tTop 5 accuracy: 31.350\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.410 (avg: 0.405)\tLoss: 3.5352 (avg: 3.5494)\tTop1: 20.312 (avg: 19.562)\tTop5: 43.750 (avg: 45.000)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.408 (avg: 0.411)\tLoss: 3.3657 (avg: 3.5101)\tTop1: 18.750 (avg: 20.500)\tTop5: 50.000 (avg: 45.969)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.418 (avg: 0.412)\tLoss: 3.2272 (avg: 3.4859)\tTop1: 26.562 (avg: 20.458)\tTop5: 54.688 (avg: 46.229)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.411 (avg: 0.413)\tLoss: 3.6621 (avg: 3.4762)\tTop1: 9.375 (avg: 20.453)\tTop5: 43.750 (avg: 46.016)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.410 (avg: 0.414)\tLoss: 3.3082 (avg: 3.4881)\tTop1: 20.312 (avg: 20.150)\tTop5: 51.562 (avg: 45.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9994\tTop 1 accuracy: 12.700\tTop 5 accuracy: 31.850\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.403 (avg: 0.406)\tLoss: 3.1507 (avg: 3.4504)\tTop1: 25.000 (avg: 21.875)\tTop5: 51.562 (avg: 46.000)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.412 (avg: 0.411)\tLoss: 3.4848 (avg: 3.4764)\tTop1: 23.438 (avg: 21.625)\tTop5: 48.438 (avg: 45.781)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.402 (avg: 0.413)\tLoss: 3.4732 (avg: 3.4882)\tTop1: 21.875 (avg: 21.583)\tTop5: 48.438 (avg: 46.000)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.402 (avg: 0.414)\tLoss: 3.7172 (avg: 3.4796)\tTop1: 12.500 (avg: 21.016)\tTop5: 39.062 (avg: 46.281)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.409 (avg: 0.414)\tLoss: 3.5497 (avg: 3.4744)\tTop1: 14.062 (avg: 21.138)\tTop5: 45.312 (avg: 46.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7446\tTop 1 accuracy: 12.650\tTop 5 accuracy: 32.550\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.408 (avg: 0.403)\tLoss: 3.1717 (avg: 3.4042)\tTop1: 29.688 (avg: 22.688)\tTop5: 57.812 (avg: 47.625)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.410 (avg: 0.408)\tLoss: 3.7090 (avg: 3.4348)\tTop1: 23.438 (avg: 21.250)\tTop5: 37.500 (avg: 46.781)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.408 (avg: 0.411)\tLoss: 3.1768 (avg: 3.4207)\tTop1: 21.875 (avg: 21.562)\tTop5: 54.688 (avg: 47.229)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.411 (avg: 0.412)\tLoss: 3.4420 (avg: 3.4418)\tTop1: 25.000 (avg: 21.609)\tTop5: 46.875 (avg: 46.750)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 3.6183 (avg: 3.4558)\tTop1: 18.750 (avg: 21.188)\tTop5: 43.750 (avg: 46.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8371\tTop 1 accuracy: 13.750\tTop 5 accuracy: 32.950\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.410 (avg: 0.406)\tLoss: 3.3834 (avg: 3.3828)\tTop1: 18.750 (avg: 22.375)\tTop5: 51.562 (avg: 50.125)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.411 (avg: 0.412)\tLoss: 3.1776 (avg: 3.3768)\tTop1: 32.812 (avg: 22.625)\tTop5: 53.125 (avg: 49.219)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.412 (avg: 0.413)\tLoss: 3.5059 (avg: 3.3863)\tTop1: 15.625 (avg: 22.833)\tTop5: 54.688 (avg: 48.833)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.417 (avg: 0.414)\tLoss: 3.6215 (avg: 3.4235)\tTop1: 18.750 (avg: 21.797)\tTop5: 48.438 (avg: 47.797)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.414 (avg: 0.415)\tLoss: 3.8490 (avg: 3.4312)\tTop1: 17.188 (avg: 21.525)\tTop5: 37.500 (avg: 47.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9717\tTop 1 accuracy: 12.700\tTop 5 accuracy: 31.750\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.411 (avg: 0.406)\tLoss: 3.6860 (avg: 3.3921)\tTop1: 20.312 (avg: 21.375)\tTop5: 45.312 (avg: 49.875)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.414 (avg: 0.411)\tLoss: 3.6543 (avg: 3.3970)\tTop1: 18.750 (avg: 21.938)\tTop5: 42.188 (avg: 48.375)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.409 (avg: 0.413)\tLoss: 3.3142 (avg: 3.4095)\tTop1: 26.562 (avg: 21.792)\tTop5: 46.875 (avg: 48.167)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.414 (avg: 0.414)\tLoss: 3.7109 (avg: 3.4221)\tTop1: 10.938 (avg: 21.562)\tTop5: 35.938 (avg: 48.062)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.407 (avg: 0.413)\tLoss: 3.3414 (avg: 3.4230)\tTop1: 29.688 (avg: 21.538)\tTop5: 45.312 (avg: 47.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8179\tTop 1 accuracy: 13.450\tTop 5 accuracy: 32.150\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.412 (avg: 0.406)\tLoss: 3.3964 (avg: 3.3375)\tTop1: 20.312 (avg: 23.000)\tTop5: 42.188 (avg: 50.125)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.405 (avg: 0.412)\tLoss: 3.3596 (avg: 3.3867)\tTop1: 25.000 (avg: 21.812)\tTop5: 50.000 (avg: 48.469)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.415 (avg: 0.413)\tLoss: 3.5298 (avg: 3.3968)\tTop1: 18.750 (avg: 21.312)\tTop5: 51.562 (avg: 47.875)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.409 (avg: 0.414)\tLoss: 3.3544 (avg: 3.3936)\tTop1: 23.438 (avg: 21.469)\tTop5: 46.875 (avg: 48.125)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.410 (avg: 0.415)\tLoss: 3.5449 (avg: 3.4068)\tTop1: 21.875 (avg: 21.363)\tTop5: 46.875 (avg: 47.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0155\tTop 1 accuracy: 12.550\tTop 5 accuracy: 32.300\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.409 (avg: 0.406)\tLoss: 3.2890 (avg: 3.3260)\tTop1: 15.625 (avg: 23.312)\tTop5: 54.688 (avg: 50.438)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.414 (avg: 0.411)\tLoss: 3.3138 (avg: 3.3664)\tTop1: 23.438 (avg: 23.000)\tTop5: 53.125 (avg: 49.125)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.407 (avg: 0.413)\tLoss: 3.5036 (avg: 3.3662)\tTop1: 21.875 (avg: 22.667)\tTop5: 45.312 (avg: 48.917)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.406 (avg: 0.414)\tLoss: 3.3696 (avg: 3.3847)\tTop1: 21.875 (avg: 22.219)\tTop5: 54.688 (avg: 48.250)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.414 (avg: 0.414)\tLoss: 3.3154 (avg: 3.3930)\tTop1: 21.875 (avg: 21.813)\tTop5: 43.750 (avg: 47.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1011\tTop 1 accuracy: 12.200\tTop 5 accuracy: 32.250\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.406 (avg: 0.402)\tLoss: 3.2444 (avg: 3.2977)\tTop1: 23.438 (avg: 23.750)\tTop5: 56.250 (avg: 49.875)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.408 (avg: 0.407)\tLoss: 3.2313 (avg: 3.2987)\tTop1: 26.562 (avg: 22.875)\tTop5: 46.875 (avg: 49.625)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.405 (avg: 0.408)\tLoss: 3.6717 (avg: 3.3285)\tTop1: 18.750 (avg: 22.833)\tTop5: 42.188 (avg: 49.250)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.404 (avg: 0.410)\tLoss: 3.4050 (avg: 3.3593)\tTop1: 18.750 (avg: 22.516)\tTop5: 48.438 (avg: 48.594)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.400 (avg: 0.410)\tLoss: 3.5268 (avg: 3.3585)\tTop1: 18.750 (avg: 22.350)\tTop5: 39.062 (avg: 48.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9429\tTop 1 accuracy: 12.850\tTop 5 accuracy: 32.350\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.404 (avg: 0.403)\tLoss: 3.1671 (avg: 3.2931)\tTop1: 26.562 (avg: 22.750)\tTop5: 51.562 (avg: 49.812)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.402 (avg: 0.408)\tLoss: 3.2461 (avg: 3.2823)\tTop1: 29.688 (avg: 22.781)\tTop5: 51.562 (avg: 49.125)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.415 (avg: 0.411)\tLoss: 3.7021 (avg: 3.3169)\tTop1: 17.188 (avg: 22.292)\tTop5: 39.062 (avg: 48.479)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.411 (avg: 0.412)\tLoss: 3.3874 (avg: 3.3373)\tTop1: 21.875 (avg: 22.672)\tTop5: 59.375 (avg: 48.641)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.407 (avg: 0.413)\tLoss: 3.4631 (avg: 3.3501)\tTop1: 20.312 (avg: 22.525)\tTop5: 45.312 (avg: 48.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7889\tTop 1 accuracy: 12.900\tTop 5 accuracy: 32.700\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.406 (avg: 0.404)\tLoss: 3.2445 (avg: 3.2619)\tTop1: 21.875 (avg: 24.375)\tTop5: 51.562 (avg: 50.562)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.416 (avg: 0.409)\tLoss: 3.1566 (avg: 3.2876)\tTop1: 23.438 (avg: 23.062)\tTop5: 57.812 (avg: 50.406)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.403 (avg: 0.412)\tLoss: 3.4003 (avg: 3.2846)\tTop1: 21.875 (avg: 23.438)\tTop5: 56.250 (avg: 50.583)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.408 (avg: 0.412)\tLoss: 3.2247 (avg: 3.2947)\tTop1: 25.000 (avg: 23.297)\tTop5: 53.125 (avg: 50.234)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.412 (avg: 0.412)\tLoss: 3.4195 (avg: 3.3059)\tTop1: 18.750 (avg: 23.113)\tTop5: 45.312 (avg: 49.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1587\tTop 1 accuracy: 12.500\tTop 5 accuracy: 32.450\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.416 (avg: 0.404)\tLoss: 3.4452 (avg: 3.2561)\tTop1: 23.438 (avg: 24.375)\tTop5: 50.000 (avg: 51.062)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 3.2020 (avg: 3.2646)\tTop1: 23.438 (avg: 24.281)\tTop5: 53.125 (avg: 50.781)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.409 (avg: 0.412)\tLoss: 3.0899 (avg: 3.2877)\tTop1: 25.000 (avg: 23.312)\tTop5: 59.375 (avg: 50.646)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.411 (avg: 0.413)\tLoss: 3.6754 (avg: 3.3075)\tTop1: 18.750 (avg: 22.859)\tTop5: 45.312 (avg: 49.844)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.410 (avg: 0.413)\tLoss: 2.8173 (avg: 3.2972)\tTop1: 31.250 (avg: 23.275)\tTop5: 60.938 (avg: 50.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0740\tTop 1 accuracy: 13.250\tTop 5 accuracy: 33.400\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.408 (avg: 0.406)\tLoss: 3.5251 (avg: 3.1884)\tTop1: 26.562 (avg: 25.562)\tTop5: 43.750 (avg: 52.750)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.406 (avg: 0.410)\tLoss: 3.4789 (avg: 3.2099)\tTop1: 17.188 (avg: 24.750)\tTop5: 48.438 (avg: 52.750)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.399 (avg: 0.412)\tLoss: 3.3991 (avg: 3.2443)\tTop1: 17.188 (avg: 24.104)\tTop5: 50.000 (avg: 51.708)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.399 (avg: 0.413)\tLoss: 2.9402 (avg: 3.2707)\tTop1: 29.688 (avg: 23.578)\tTop5: 64.062 (avg: 50.891)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.408 (avg: 0.413)\tLoss: 3.5577 (avg: 3.2821)\tTop1: 18.750 (avg: 23.900)\tTop5: 42.188 (avg: 50.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8641\tTop 1 accuracy: 13.750\tTop 5 accuracy: 33.150\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.403 (avg: 0.403)\tLoss: 2.9391 (avg: 3.1480)\tTop1: 26.562 (avg: 25.062)\tTop5: 64.062 (avg: 54.188)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.403 (avg: 0.406)\tLoss: 3.5497 (avg: 3.2008)\tTop1: 21.875 (avg: 23.875)\tTop5: 40.625 (avg: 53.188)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.403 (avg: 0.409)\tLoss: 3.2064 (avg: 3.2171)\tTop1: 26.562 (avg: 24.021)\tTop5: 51.562 (avg: 52.667)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.412 (avg: 0.409)\tLoss: 3.3018 (avg: 3.2338)\tTop1: 28.125 (avg: 24.078)\tTop5: 51.562 (avg: 52.344)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.409 (avg: 0.410)\tLoss: 3.2365 (avg: 3.2451)\tTop1: 26.562 (avg: 24.050)\tTop5: 53.125 (avg: 52.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7453\tTop 1 accuracy: 13.400\tTop 5 accuracy: 33.100\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.403 (avg: 0.402)\tLoss: 2.9663 (avg: 3.1530)\tTop1: 26.562 (avg: 25.062)\tTop5: 54.688 (avg: 53.625)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.405 (avg: 0.406)\tLoss: 3.4910 (avg: 3.1687)\tTop1: 18.750 (avg: 25.156)\tTop5: 51.562 (avg: 53.406)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.409 (avg: 0.408)\tLoss: 3.3014 (avg: 3.2041)\tTop1: 17.188 (avg: 24.979)\tTop5: 53.125 (avg: 52.812)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.405 (avg: 0.409)\tLoss: 2.9152 (avg: 3.2269)\tTop1: 29.688 (avg: 24.828)\tTop5: 54.688 (avg: 51.969)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.403 (avg: 0.409)\tLoss: 3.1150 (avg: 3.2265)\tTop1: 29.688 (avg: 24.738)\tTop5: 54.688 (avg: 52.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0877\tTop 1 accuracy: 13.550\tTop 5 accuracy: 33.300\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.394 (avg: 0.398)\tLoss: 2.9046 (avg: 3.0576)\tTop1: 29.688 (avg: 26.500)\tTop5: 60.938 (avg: 56.625)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.409 (avg: 0.404)\tLoss: 2.9980 (avg: 3.0503)\tTop1: 31.250 (avg: 27.438)\tTop5: 53.125 (avg: 56.344)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.404 (avg: 0.407)\tLoss: 2.7647 (avg: 3.0408)\tTop1: 32.812 (avg: 28.021)\tTop5: 62.500 (avg: 56.375)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.404 (avg: 0.408)\tLoss: 2.8113 (avg: 3.0451)\tTop1: 31.250 (avg: 28.094)\tTop5: 57.812 (avg: 56.438)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.406 (avg: 0.408)\tLoss: 2.9506 (avg: 3.0471)\tTop1: 32.812 (avg: 28.350)\tTop5: 64.062 (avg: 56.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1498\tTop 1 accuracy: 14.600\tTop 5 accuracy: 34.200\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.410 (avg: 0.403)\tLoss: 2.8746 (avg: 3.0355)\tTop1: 26.562 (avg: 27.500)\tTop5: 62.500 (avg: 55.812)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.407 (avg: 0.407)\tLoss: 2.6984 (avg: 2.9958)\tTop1: 34.375 (avg: 28.688)\tTop5: 65.625 (avg: 57.562)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.405 (avg: 0.409)\tLoss: 2.8232 (avg: 2.9923)\tTop1: 35.938 (avg: 28.646)\tTop5: 54.688 (avg: 57.062)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 2.9079 (avg: 2.9903)\tTop1: 32.812 (avg: 28.938)\tTop5: 64.062 (avg: 57.250)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.399 (avg: 0.410)\tLoss: 2.9538 (avg: 2.9955)\tTop1: 26.562 (avg: 28.900)\tTop5: 57.812 (avg: 57.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0805\tTop 1 accuracy: 15.000\tTop 5 accuracy: 34.650\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.405 (avg: 0.402)\tLoss: 3.4714 (avg: 3.0284)\tTop1: 26.562 (avg: 31.000)\tTop5: 48.438 (avg: 56.750)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.407 (avg: 0.406)\tLoss: 2.9305 (avg: 3.0124)\tTop1: 25.000 (avg: 29.844)\tTop5: 64.062 (avg: 57.250)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.419 (avg: 0.408)\tLoss: 2.7436 (avg: 2.9930)\tTop1: 32.812 (avg: 29.917)\tTop5: 67.188 (avg: 57.521)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.402 (avg: 0.409)\tLoss: 2.9940 (avg: 2.9892)\tTop1: 29.688 (avg: 29.797)\tTop5: 53.125 (avg: 57.328)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.404 (avg: 0.409)\tLoss: 2.9865 (avg: 2.9863)\tTop1: 31.250 (avg: 30.125)\tTop5: 54.688 (avg: 57.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2401\tTop 1 accuracy: 14.400\tTop 5 accuracy: 34.750\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.410 (avg: 0.403)\tLoss: 2.8220 (avg: 2.9112)\tTop1: 31.250 (avg: 30.688)\tTop5: 64.062 (avg: 58.500)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.407 (avg: 0.408)\tLoss: 2.8001 (avg: 2.9594)\tTop1: 39.062 (avg: 29.625)\tTop5: 62.500 (avg: 57.625)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.405 (avg: 0.409)\tLoss: 3.2241 (avg: 2.9596)\tTop1: 28.125 (avg: 29.188)\tTop5: 46.875 (avg: 57.854)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 3.3775 (avg: 2.9812)\tTop1: 21.875 (avg: 29.391)\tTop5: 50.000 (avg: 57.375)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.412 (avg: 0.411)\tLoss: 3.1534 (avg: 2.9844)\tTop1: 35.938 (avg: 29.650)\tTop5: 51.562 (avg: 57.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1640\tTop 1 accuracy: 14.700\tTop 5 accuracy: 35.250\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.416 (avg: 0.405)\tLoss: 2.6742 (avg: 2.9637)\tTop1: 29.688 (avg: 30.250)\tTop5: 62.500 (avg: 57.688)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.412 (avg: 0.410)\tLoss: 2.9187 (avg: 2.9481)\tTop1: 29.688 (avg: 30.625)\tTop5: 57.812 (avg: 58.156)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.407 (avg: 0.411)\tLoss: 3.2403 (avg: 2.9674)\tTop1: 20.312 (avg: 30.562)\tTop5: 51.562 (avg: 57.125)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.414 (avg: 0.412)\tLoss: 3.0104 (avg: 2.9597)\tTop1: 29.688 (avg: 30.578)\tTop5: 59.375 (avg: 57.391)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 3.1368 (avg: 2.9725)\tTop1: 32.812 (avg: 30.225)\tTop5: 62.500 (avg: 57.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0711\tTop 1 accuracy: 14.800\tTop 5 accuracy: 34.650\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.409 (avg: 0.405)\tLoss: 2.7652 (avg: 2.8926)\tTop1: 31.250 (avg: 31.500)\tTop5: 62.500 (avg: 59.688)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.406 (avg: 0.410)\tLoss: 3.0360 (avg: 2.9366)\tTop1: 35.938 (avg: 30.500)\tTop5: 56.250 (avg: 58.531)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.411 (avg: 0.412)\tLoss: 3.1338 (avg: 2.9286)\tTop1: 29.688 (avg: 30.917)\tTop5: 53.125 (avg: 58.500)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.403 (avg: 0.412)\tLoss: 3.1682 (avg: 2.9491)\tTop1: 25.000 (avg: 30.703)\tTop5: 56.250 (avg: 58.297)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.419 (avg: 0.412)\tLoss: 2.9731 (avg: 2.9637)\tTop1: 37.500 (avg: 30.400)\tTop5: 54.688 (avg: 57.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1478\tTop 1 accuracy: 14.800\tTop 5 accuracy: 34.800\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.408 (avg: 0.405)\tLoss: 3.0820 (avg: 2.9540)\tTop1: 25.000 (avg: 31.188)\tTop5: 59.375 (avg: 57.250)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.405 (avg: 0.410)\tLoss: 3.2033 (avg: 2.9744)\tTop1: 26.562 (avg: 30.656)\tTop5: 51.562 (avg: 56.812)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.405 (avg: 0.411)\tLoss: 3.0513 (avg: 2.9736)\tTop1: 26.562 (avg: 30.646)\tTop5: 56.250 (avg: 57.104)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.415 (avg: 0.412)\tLoss: 3.0087 (avg: 2.9471)\tTop1: 29.688 (avg: 30.828)\tTop5: 54.688 (avg: 57.859)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.406 (avg: 0.413)\tLoss: 3.2984 (avg: 2.9562)\tTop1: 25.000 (avg: 30.488)\tTop5: 50.000 (avg: 57.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2120\tTop 1 accuracy: 14.300\tTop 5 accuracy: 35.350\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.412 (avg: 0.405)\tLoss: 2.9696 (avg: 2.9729)\tTop1: 26.562 (avg: 30.250)\tTop5: 59.375 (avg: 57.562)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.408 (avg: 0.410)\tLoss: 2.8954 (avg: 2.9307)\tTop1: 29.688 (avg: 30.656)\tTop5: 64.062 (avg: 58.406)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.404 (avg: 0.412)\tLoss: 3.1289 (avg: 2.9568)\tTop1: 29.688 (avg: 30.271)\tTop5: 54.688 (avg: 57.396)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 2.6861 (avg: 2.9504)\tTop1: 45.312 (avg: 30.703)\tTop5: 64.062 (avg: 57.719)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.400 (avg: 0.413)\tLoss: 2.4800 (avg: 2.9561)\tTop1: 42.188 (avg: 30.450)\tTop5: 65.625 (avg: 57.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1319\tTop 1 accuracy: 14.700\tTop 5 accuracy: 34.950\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.407 (avg: 0.404)\tLoss: 2.6985 (avg: 2.9892)\tTop1: 37.500 (avg: 30.688)\tTop5: 62.500 (avg: 59.125)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.409 (avg: 0.409)\tLoss: 2.9040 (avg: 2.9419)\tTop1: 28.125 (avg: 30.969)\tTop5: 54.688 (avg: 58.688)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.403 (avg: 0.409)\tLoss: 2.9640 (avg: 2.9515)\tTop1: 25.000 (avg: 30.458)\tTop5: 53.125 (avg: 58.292)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.404 (avg: 0.410)\tLoss: 3.1620 (avg: 2.9574)\tTop1: 23.438 (avg: 30.578)\tTop5: 53.125 (avg: 57.797)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.412 (avg: 0.411)\tLoss: 3.1902 (avg: 2.9507)\tTop1: 26.562 (avg: 30.513)\tTop5: 56.250 (avg: 58.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2033\tTop 1 accuracy: 14.850\tTop 5 accuracy: 34.750\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.413 (avg: 0.405)\tLoss: 2.8887 (avg: 2.9273)\tTop1: 21.875 (avg: 32.125)\tTop5: 59.375 (avg: 58.500)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.402 (avg: 0.410)\tLoss: 3.2727 (avg: 2.9454)\tTop1: 15.625 (avg: 30.812)\tTop5: 48.438 (avg: 58.500)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.404 (avg: 0.411)\tLoss: 2.9238 (avg: 2.9272)\tTop1: 31.250 (avg: 30.979)\tTop5: 59.375 (avg: 59.167)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.414 (avg: 0.412)\tLoss: 3.0214 (avg: 2.9468)\tTop1: 26.562 (avg: 30.562)\tTop5: 50.000 (avg: 58.281)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.408 (avg: 0.412)\tLoss: 3.0050 (avg: 2.9422)\tTop1: 29.688 (avg: 30.813)\tTop5: 56.250 (avg: 58.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1045\tTop 1 accuracy: 14.200\tTop 5 accuracy: 34.750\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.406 (avg: 0.403)\tLoss: 2.7486 (avg: 2.9642)\tTop1: 34.375 (avg: 30.562)\tTop5: 65.625 (avg: 57.688)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.407 (avg: 0.409)\tLoss: 2.9697 (avg: 2.9301)\tTop1: 32.812 (avg: 30.938)\tTop5: 59.375 (avg: 58.219)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.412 (avg: 0.411)\tLoss: 3.2367 (avg: 2.9405)\tTop1: 20.312 (avg: 30.688)\tTop5: 53.125 (avg: 58.333)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.401 (avg: 0.412)\tLoss: 3.0538 (avg: 2.9460)\tTop1: 31.250 (avg: 30.891)\tTop5: 57.812 (avg: 58.406)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.408 (avg: 0.411)\tLoss: 2.8223 (avg: 2.9364)\tTop1: 32.812 (avg: 30.950)\tTop5: 59.375 (avg: 58.563)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2626\tTop 1 accuracy: 14.750\tTop 5 accuracy: 34.700\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.406 (avg: 0.403)\tLoss: 2.9195 (avg: 2.9090)\tTop1: 25.000 (avg: 31.312)\tTop5: 60.938 (avg: 59.750)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.416 (avg: 0.409)\tLoss: 2.8176 (avg: 2.9176)\tTop1: 37.500 (avg: 30.875)\tTop5: 57.812 (avg: 58.844)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.403 (avg: 0.411)\tLoss: 3.1621 (avg: 2.9143)\tTop1: 29.688 (avg: 31.125)\tTop5: 51.562 (avg: 59.062)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 3.1324 (avg: 2.9280)\tTop1: 31.250 (avg: 30.797)\tTop5: 53.125 (avg: 58.734)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.406 (avg: 0.412)\tLoss: 3.2353 (avg: 2.9299)\tTop1: 28.125 (avg: 30.650)\tTop5: 53.125 (avg: 58.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1587\tTop 1 accuracy: 14.700\tTop 5 accuracy: 34.750\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.409 (avg: 0.403)\tLoss: 3.1774 (avg: 2.8536)\tTop1: 23.438 (avg: 32.688)\tTop5: 56.250 (avg: 59.750)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.405 (avg: 0.409)\tLoss: 2.7885 (avg: 2.8906)\tTop1: 35.938 (avg: 32.281)\tTop5: 57.812 (avg: 59.781)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.409 (avg: 0.411)\tLoss: 2.7632 (avg: 2.8868)\tTop1: 35.938 (avg: 32.333)\tTop5: 62.500 (avg: 59.917)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.409 (avg: 0.412)\tLoss: 3.0874 (avg: 2.9111)\tTop1: 18.750 (avg: 31.469)\tTop5: 50.000 (avg: 58.953)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.407 (avg: 0.412)\tLoss: 3.1763 (avg: 2.9259)\tTop1: 28.125 (avg: 31.163)\tTop5: 53.125 (avg: 58.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2752\tTop 1 accuracy: 14.650\tTop 5 accuracy: 34.850\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.403 (avg: 0.403)\tLoss: 2.5960 (avg: 2.9018)\tTop1: 32.812 (avg: 31.625)\tTop5: 65.625 (avg: 57.688)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.408 (avg: 0.409)\tLoss: 2.5386 (avg: 2.8942)\tTop1: 39.062 (avg: 30.781)\tTop5: 65.625 (avg: 58.531)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.402 (avg: 0.410)\tLoss: 2.6263 (avg: 2.9000)\tTop1: 42.188 (avg: 31.000)\tTop5: 67.188 (avg: 58.604)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.407 (avg: 0.410)\tLoss: 2.6281 (avg: 2.9016)\tTop1: 31.250 (avg: 31.297)\tTop5: 68.750 (avg: 58.984)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.408 (avg: 0.411)\tLoss: 3.2103 (avg: 2.9147)\tTop1: 17.188 (avg: 31.275)\tTop5: 59.375 (avg: 58.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2089\tTop 1 accuracy: 14.600\tTop 5 accuracy: 35.100\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.402 (avg: 0.403)\tLoss: 2.7309 (avg: 2.8757)\tTop1: 35.938 (avg: 32.562)\tTop5: 65.625 (avg: 60.938)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.409 (avg: 0.409)\tLoss: 3.0303 (avg: 2.8948)\tTop1: 23.438 (avg: 31.906)\tTop5: 57.812 (avg: 60.281)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.408 (avg: 0.411)\tLoss: 3.1160 (avg: 2.9156)\tTop1: 28.125 (avg: 30.958)\tTop5: 54.688 (avg: 59.625)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.411 (avg: 0.412)\tLoss: 2.5639 (avg: 2.9185)\tTop1: 34.375 (avg: 31.047)\tTop5: 73.438 (avg: 59.344)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.405 (avg: 0.412)\tLoss: 2.6984 (avg: 2.9120)\tTop1: 32.812 (avg: 31.013)\tTop5: 59.375 (avg: 59.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2254\tTop 1 accuracy: 14.250\tTop 5 accuracy: 34.950\n",
            "\n",
            "pct_3x3 = 0.75: top1 = 14.30000114440918 \t top5 = 35.35000228881836 \t batch time = 0.2981904670596123\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.418 (avg: 0.514)\tLoss: 5.2923 (avg: 5.3162)\tTop1: 1.562 (avg: 0.438)\tTop5: 4.688 (avg: 2.438)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.415 (avg: 0.471)\tLoss: 5.3014 (avg: 5.3074)\tTop1: 0.000 (avg: 0.438)\tTop5: 1.562 (avg: 2.250)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.429 (avg: 0.457)\tLoss: 5.2995 (avg: 5.3046)\tTop1: 1.562 (avg: 0.542)\tTop5: 3.125 (avg: 2.354)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.413 (avg: 0.449)\tLoss: 5.2991 (avg: 5.3033)\tTop1: 0.000 (avg: 0.422)\tTop5: 1.562 (avg: 2.141)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.421 (avg: 0.444)\tLoss: 5.2991 (avg: 5.3024)\tTop1: 0.000 (avg: 0.400)\tTop5: 0.000 (avg: 2.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2937\tTop 1 accuracy: 0.650\tTop 5 accuracy: 2.500\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.419 (avg: 0.416)\tLoss: 5.2958 (avg: 5.2979)\tTop1: 1.562 (avg: 0.562)\tTop5: 3.125 (avg: 2.750)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.421 (avg: 0.422)\tLoss: 5.2992 (avg: 5.2978)\tTop1: 0.000 (avg: 0.500)\tTop5: 3.125 (avg: 2.594)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.417 (avg: 0.423)\tLoss: 5.3026 (avg: 5.2977)\tTop1: 0.000 (avg: 0.542)\tTop5: 0.000 (avg: 2.604)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.415 (avg: 0.424)\tLoss: 5.2940 (avg: 5.2977)\tTop1: 1.562 (avg: 0.516)\tTop5: 6.250 (avg: 2.547)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.428 (avg: 0.425)\tLoss: 5.2983 (avg: 5.2978)\tTop1: 0.000 (avg: 0.500)\tTop5: 3.125 (avg: 2.563)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2864\tTop 1 accuracy: 0.400\tTop 5 accuracy: 2.250\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.424 (avg: 0.417)\tLoss: 5.2978 (avg: 5.2966)\tTop1: 0.000 (avg: 0.312)\tTop5: 1.562 (avg: 2.562)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.431 (avg: 0.422)\tLoss: 5.2948 (avg: 5.2961)\tTop1: 0.000 (avg: 0.438)\tTop5: 3.125 (avg: 2.531)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.419 (avg: 0.424)\tLoss: 5.3128 (avg: 5.2956)\tTop1: 0.000 (avg: 0.417)\tTop5: 1.562 (avg: 2.562)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.419 (avg: 0.424)\tLoss: 5.2890 (avg: 5.2947)\tTop1: 1.562 (avg: 0.453)\tTop5: 3.125 (avg: 2.609)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.426 (avg: 0.425)\tLoss: 5.2906 (avg: 5.2914)\tTop1: 0.000 (avg: 0.463)\tTop5: 3.125 (avg: 2.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2969\tTop 1 accuracy: 0.450\tTop 5 accuracy: 2.250\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.420 (avg: 0.417)\tLoss: 5.2917 (avg: 5.2775)\tTop1: 0.000 (avg: 0.375)\tTop5: 1.562 (avg: 2.625)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.424 (avg: 0.422)\tLoss: 5.2681 (avg: 5.2752)\tTop1: 0.000 (avg: 0.500)\tTop5: 1.562 (avg: 2.594)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.421 (avg: 0.422)\tLoss: 5.2807 (avg: 5.2685)\tTop1: 0.000 (avg: 0.500)\tTop5: 3.125 (avg: 2.771)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.417 (avg: 0.423)\tLoss: 5.3104 (avg: 5.2656)\tTop1: 1.562 (avg: 0.531)\tTop5: 1.562 (avg: 2.797)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.427 (avg: 0.424)\tLoss: 5.2306 (avg: 5.2629)\tTop1: 0.000 (avg: 0.650)\tTop5: 7.812 (avg: 3.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2338\tTop 1 accuracy: 0.700\tTop 5 accuracy: 3.300\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.422 (avg: 0.417)\tLoss: 5.2704 (avg: 5.2610)\tTop1: 0.000 (avg: 0.438)\tTop5: 1.562 (avg: 3.438)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.422 (avg: 0.422)\tLoss: 5.1971 (avg: 5.2483)\tTop1: 1.562 (avg: 0.750)\tTop5: 1.562 (avg: 3.656)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.420 (avg: 0.424)\tLoss: 5.2743 (avg: 5.2516)\tTop1: 1.562 (avg: 0.792)\tTop5: 1.562 (avg: 3.729)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.421 (avg: 0.424)\tLoss: 5.2870 (avg: 5.2487)\tTop1: 0.000 (avg: 0.766)\tTop5: 6.250 (avg: 3.781)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.424 (avg: 0.425)\tLoss: 5.2473 (avg: 5.2473)\tTop1: 0.000 (avg: 0.700)\tTop5: 3.125 (avg: 3.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2538\tTop 1 accuracy: 0.600\tTop 5 accuracy: 2.750\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.419 (avg: 0.416)\tLoss: 5.2769 (avg: 5.2329)\tTop1: 1.562 (avg: 0.750)\tTop5: 3.125 (avg: 3.938)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.423 (avg: 0.421)\tLoss: 5.2875 (avg: 5.2308)\tTop1: 0.000 (avg: 0.812)\tTop5: 4.688 (avg: 4.031)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.409 (avg: 0.423)\tLoss: 5.2670 (avg: 5.2338)\tTop1: 0.000 (avg: 0.708)\tTop5: 4.688 (avg: 4.021)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.420 (avg: 0.423)\tLoss: 5.2840 (avg: 5.2378)\tTop1: 3.125 (avg: 0.797)\tTop5: 3.125 (avg: 4.109)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.425 (avg: 0.424)\tLoss: 5.1962 (avg: 5.2288)\tTop1: 0.000 (avg: 1.025)\tTop5: 3.125 (avg: 4.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2298\tTop 1 accuracy: 0.650\tTop 5 accuracy: 3.800\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.417 (avg: 0.416)\tLoss: 5.2488 (avg: 5.2203)\tTop1: 0.000 (avg: 1.375)\tTop5: 3.125 (avg: 5.000)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.425 (avg: 0.421)\tLoss: 5.1942 (avg: 5.2148)\tTop1: 0.000 (avg: 1.125)\tTop5: 4.688 (avg: 5.375)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.425 (avg: 0.423)\tLoss: 5.1148 (avg: 5.2093)\tTop1: 4.688 (avg: 1.000)\tTop5: 7.812 (avg: 5.333)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.417 (avg: 0.424)\tLoss: 5.2768 (avg: 5.2058)\tTop1: 0.000 (avg: 0.953)\tTop5: 1.562 (avg: 5.266)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.427 (avg: 0.425)\tLoss: 5.1719 (avg: 5.2080)\tTop1: 3.125 (avg: 1.000)\tTop5: 4.688 (avg: 5.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1358\tTop 1 accuracy: 1.300\tTop 5 accuracy: 5.500\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.418 (avg: 0.416)\tLoss: 5.2997 (avg: 5.1634)\tTop1: 3.125 (avg: 1.812)\tTop5: 7.812 (avg: 6.875)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.423 (avg: 0.422)\tLoss: 5.1135 (avg: 5.1762)\tTop1: 0.000 (avg: 1.500)\tTop5: 1.562 (avg: 6.531)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.418 (avg: 0.423)\tLoss: 5.2244 (avg: 5.1855)\tTop1: 3.125 (avg: 1.438)\tTop5: 6.250 (avg: 6.292)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.416 (avg: 0.424)\tLoss: 5.1294 (avg: 5.1875)\tTop1: 3.125 (avg: 1.297)\tTop5: 10.938 (avg: 6.266)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.427 (avg: 0.424)\tLoss: 5.2652 (avg: 5.1897)\tTop1: 3.125 (avg: 1.313)\tTop5: 7.812 (avg: 6.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0612\tTop 1 accuracy: 1.000\tTop 5 accuracy: 6.100\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.420 (avg: 0.416)\tLoss: 5.0585 (avg: 5.1380)\tTop1: 3.125 (avg: 1.938)\tTop5: 9.375 (avg: 8.438)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.416 (avg: 0.420)\tLoss: 5.2417 (avg: 5.1596)\tTop1: 1.562 (avg: 1.750)\tTop5: 3.125 (avg: 7.406)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.418 (avg: 0.421)\tLoss: 5.0242 (avg: 5.1633)\tTop1: 1.562 (avg: 1.625)\tTop5: 10.938 (avg: 7.042)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.413 (avg: 0.422)\tLoss: 5.1718 (avg: 5.1692)\tTop1: 0.000 (avg: 1.453)\tTop5: 4.688 (avg: 6.766)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.428 (avg: 0.423)\tLoss: 5.2043 (avg: 5.1726)\tTop1: 0.000 (avg: 1.413)\tTop5: 7.812 (avg: 6.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0784\tTop 1 accuracy: 1.400\tTop 5 accuracy: 6.800\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.410 (avg: 0.415)\tLoss: 5.1833 (avg: 5.1511)\tTop1: 1.562 (avg: 2.062)\tTop5: 1.562 (avg: 7.688)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.426 (avg: 0.421)\tLoss: 5.2586 (avg: 5.1464)\tTop1: 1.562 (avg: 1.781)\tTop5: 4.688 (avg: 7.281)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.421 (avg: 0.423)\tLoss: 5.1986 (avg: 5.1476)\tTop1: 0.000 (avg: 1.688)\tTop5: 0.000 (avg: 7.208)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.412 (avg: 0.424)\tLoss: 5.1450 (avg: 5.1478)\tTop1: 3.125 (avg: 1.750)\tTop5: 7.812 (avg: 7.359)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.428 (avg: 0.424)\tLoss: 5.1899 (avg: 5.1527)\tTop1: 3.125 (avg: 1.638)\tTop5: 7.812 (avg: 7.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1089\tTop 1 accuracy: 1.250\tTop 5 accuracy: 7.250\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.415 (avg: 0.416)\tLoss: 5.2473 (avg: 5.1549)\tTop1: 0.000 (avg: 1.250)\tTop5: 6.250 (avg: 8.875)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.422 (avg: 0.421)\tLoss: 5.1529 (avg: 5.1473)\tTop1: 0.000 (avg: 1.250)\tTop5: 3.125 (avg: 7.656)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.418 (avg: 0.422)\tLoss: 4.9257 (avg: 5.1436)\tTop1: 1.562 (avg: 1.500)\tTop5: 7.812 (avg: 7.688)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.417 (avg: 0.423)\tLoss: 5.1744 (avg: 5.1292)\tTop1: 0.000 (avg: 1.672)\tTop5: 3.125 (avg: 7.812)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.426 (avg: 0.423)\tLoss: 5.2030 (avg: 5.1362)\tTop1: 0.000 (avg: 1.575)\tTop5: 6.250 (avg: 7.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0159\tTop 1 accuracy: 2.400\tTop 5 accuracy: 7.850\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.416 (avg: 0.415)\tLoss: 4.9864 (avg: 5.1355)\tTop1: 7.812 (avg: 1.500)\tTop5: 15.625 (avg: 7.688)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.419 (avg: 0.421)\tLoss: 4.9608 (avg: 5.1219)\tTop1: 7.812 (avg: 1.562)\tTop5: 15.625 (avg: 7.969)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.417 (avg: 0.422)\tLoss: 5.1624 (avg: 5.1230)\tTop1: 0.000 (avg: 1.688)\tTop5: 6.250 (avg: 7.625)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.418 (avg: 0.423)\tLoss: 4.8895 (avg: 5.1239)\tTop1: 3.125 (avg: 1.922)\tTop5: 10.938 (avg: 7.688)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.423 (avg: 0.424)\tLoss: 5.0266 (avg: 5.1202)\tTop1: 0.000 (avg: 1.850)\tTop5: 6.250 (avg: 7.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0185\tTop 1 accuracy: 2.000\tTop 5 accuracy: 8.600\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.417 (avg: 0.415)\tLoss: 5.0646 (avg: 5.0753)\tTop1: 1.562 (avg: 1.938)\tTop5: 10.938 (avg: 9.438)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.422 (avg: 0.420)\tLoss: 5.0915 (avg: 5.0775)\tTop1: 3.125 (avg: 2.031)\tTop5: 6.250 (avg: 8.750)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.417 (avg: 0.422)\tLoss: 4.8328 (avg: 5.0756)\tTop1: 7.812 (avg: 2.083)\tTop5: 15.625 (avg: 8.958)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.420 (avg: 0.423)\tLoss: 5.0930 (avg: 5.0870)\tTop1: 4.688 (avg: 2.125)\tTop5: 12.500 (avg: 8.812)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.429 (avg: 0.424)\tLoss: 5.0613 (avg: 5.0832)\tTop1: 3.125 (avg: 2.075)\tTop5: 9.375 (avg: 8.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9773\tTop 1 accuracy: 1.600\tTop 5 accuracy: 9.200\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.418 (avg: 0.416)\tLoss: 4.8941 (avg: 5.0191)\tTop1: 6.250 (avg: 3.000)\tTop5: 14.062 (avg: 11.500)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.414 (avg: 0.419)\tLoss: 5.1090 (avg: 5.0507)\tTop1: 3.125 (avg: 2.625)\tTop5: 7.812 (avg: 10.312)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.416 (avg: 0.421)\tLoss: 5.0316 (avg: 5.0533)\tTop1: 3.125 (avg: 2.625)\tTop5: 10.938 (avg: 10.021)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.419 (avg: 0.422)\tLoss: 4.9620 (avg: 5.0446)\tTop1: 3.125 (avg: 2.594)\tTop5: 9.375 (avg: 10.031)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.429 (avg: 0.423)\tLoss: 5.1254 (avg: 5.0515)\tTop1: 3.125 (avg: 2.513)\tTop5: 9.375 (avg: 9.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9278\tTop 1 accuracy: 2.900\tTop 5 accuracy: 10.100\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.420 (avg: 0.415)\tLoss: 5.0397 (avg: 5.0034)\tTop1: 1.562 (avg: 2.688)\tTop5: 9.375 (avg: 11.500)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.426 (avg: 0.421)\tLoss: 5.1066 (avg: 5.0322)\tTop1: 3.125 (avg: 2.562)\tTop5: 15.625 (avg: 10.781)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.418 (avg: 0.423)\tLoss: 5.0272 (avg: 5.0309)\tTop1: 1.562 (avg: 2.625)\tTop5: 9.375 (avg: 10.896)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.418 (avg: 0.423)\tLoss: 5.1406 (avg: 5.0370)\tTop1: 1.562 (avg: 2.531)\tTop5: 7.812 (avg: 10.516)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.424 (avg: 0.424)\tLoss: 5.1444 (avg: 5.0348)\tTop1: 4.688 (avg: 2.563)\tTop5: 9.375 (avg: 10.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1230\tTop 1 accuracy: 3.250\tTop 5 accuracy: 10.750\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.412 (avg: 0.415)\tLoss: 5.0539 (avg: 4.9702)\tTop1: 1.562 (avg: 3.375)\tTop5: 7.812 (avg: 12.000)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.425 (avg: 0.419)\tLoss: 5.0340 (avg: 4.9819)\tTop1: 0.000 (avg: 3.250)\tTop5: 10.938 (avg: 11.312)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.415 (avg: 0.422)\tLoss: 5.0627 (avg: 4.9972)\tTop1: 1.562 (avg: 2.938)\tTop5: 7.812 (avg: 10.938)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.412 (avg: 0.423)\tLoss: 4.9558 (avg: 4.9922)\tTop1: 6.250 (avg: 2.953)\tTop5: 10.938 (avg: 11.141)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.419 (avg: 0.423)\tLoss: 5.0835 (avg: 4.9975)\tTop1: 1.562 (avg: 2.913)\tTop5: 6.250 (avg: 10.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0394\tTop 1 accuracy: 2.450\tTop 5 accuracy: 10.100\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.419 (avg: 0.416)\tLoss: 5.0806 (avg: 4.9515)\tTop1: 1.562 (avg: 2.688)\tTop5: 12.500 (avg: 12.875)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.420 (avg: 0.421)\tLoss: 4.9660 (avg: 4.9533)\tTop1: 3.125 (avg: 2.875)\tTop5: 17.188 (avg: 13.219)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.418 (avg: 0.423)\tLoss: 4.8340 (avg: 4.9721)\tTop1: 4.688 (avg: 2.854)\tTop5: 17.188 (avg: 12.521)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.419 (avg: 0.424)\tLoss: 4.9658 (avg: 4.9615)\tTop1: 0.000 (avg: 2.906)\tTop5: 7.812 (avg: 12.500)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.424 (avg: 0.424)\tLoss: 5.0108 (avg: 4.9712)\tTop1: 6.250 (avg: 2.863)\tTop5: 14.062 (avg: 12.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8494\tTop 1 accuracy: 3.500\tTop 5 accuracy: 10.700\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.416 (avg: 0.415)\tLoss: 4.8317 (avg: 4.9468)\tTop1: 4.688 (avg: 3.750)\tTop5: 9.375 (avg: 12.938)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.422 (avg: 0.421)\tLoss: 4.9328 (avg: 4.9327)\tTop1: 0.000 (avg: 3.219)\tTop5: 12.500 (avg: 12.750)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.415 (avg: 0.422)\tLoss: 4.9476 (avg: 4.9394)\tTop1: 3.125 (avg: 3.354)\tTop5: 9.375 (avg: 12.562)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.411 (avg: 0.424)\tLoss: 5.1519 (avg: 4.9266)\tTop1: 1.562 (avg: 3.453)\tTop5: 9.375 (avg: 12.734)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.424 (avg: 0.424)\tLoss: 4.9543 (avg: 4.9248)\tTop1: 1.562 (avg: 3.388)\tTop5: 14.062 (avg: 12.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9647\tTop 1 accuracy: 3.050\tTop 5 accuracy: 10.850\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.412 (avg: 0.415)\tLoss: 4.6439 (avg: 4.9273)\tTop1: 4.688 (avg: 3.375)\tTop5: 20.312 (avg: 12.875)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.422 (avg: 0.419)\tLoss: 4.9398 (avg: 4.9118)\tTop1: 4.688 (avg: 3.375)\tTop5: 12.500 (avg: 12.812)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.421 (avg: 0.421)\tLoss: 4.9480 (avg: 4.9082)\tTop1: 4.688 (avg: 3.250)\tTop5: 10.938 (avg: 12.521)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.420 (avg: 0.422)\tLoss: 4.8483 (avg: 4.8993)\tTop1: 1.562 (avg: 3.266)\tTop5: 17.188 (avg: 12.422)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.424 (avg: 0.423)\tLoss: 4.8392 (avg: 4.8947)\tTop1: 4.688 (avg: 3.400)\tTop5: 10.938 (avg: 12.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8835\tTop 1 accuracy: 2.950\tTop 5 accuracy: 11.650\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.424 (avg: 0.416)\tLoss: 4.8324 (avg: 4.8817)\tTop1: 4.688 (avg: 4.188)\tTop5: 15.625 (avg: 14.438)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.422 (avg: 0.421)\tLoss: 4.7325 (avg: 4.8559)\tTop1: 3.125 (avg: 3.875)\tTop5: 20.312 (avg: 14.406)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.417 (avg: 0.423)\tLoss: 4.6951 (avg: 4.8353)\tTop1: 4.688 (avg: 4.333)\tTop5: 18.750 (avg: 14.583)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.419 (avg: 0.424)\tLoss: 4.6441 (avg: 4.8344)\tTop1: 6.250 (avg: 4.250)\tTop5: 23.438 (avg: 14.516)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.423 (avg: 0.424)\tLoss: 4.7363 (avg: 4.8376)\tTop1: 1.562 (avg: 4.038)\tTop5: 15.625 (avg: 14.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9830\tTop 1 accuracy: 3.000\tTop 5 accuracy: 12.050\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.419 (avg: 0.413)\tLoss: 4.7802 (avg: 4.7682)\tTop1: 3.125 (avg: 3.875)\tTop5: 15.625 (avg: 15.875)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.425 (avg: 0.420)\tLoss: 4.8918 (avg: 4.7812)\tTop1: 4.688 (avg: 4.688)\tTop5: 17.188 (avg: 16.094)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.413 (avg: 0.422)\tLoss: 4.7674 (avg: 4.7912)\tTop1: 1.562 (avg: 4.479)\tTop5: 18.750 (avg: 16.000)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.421 (avg: 0.423)\tLoss: 4.8559 (avg: 4.7992)\tTop1: 3.125 (avg: 4.406)\tTop5: 10.938 (avg: 15.828)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.426 (avg: 0.424)\tLoss: 4.8264 (avg: 4.8046)\tTop1: 6.250 (avg: 4.375)\tTop5: 10.938 (avg: 15.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7821\tTop 1 accuracy: 3.700\tTop 5 accuracy: 13.250\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.419 (avg: 0.415)\tLoss: 4.7311 (avg: 4.7438)\tTop1: 4.688 (avg: 5.438)\tTop5: 21.875 (avg: 17.438)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.424 (avg: 0.421)\tLoss: 4.7229 (avg: 4.7737)\tTop1: 6.250 (avg: 5.031)\tTop5: 15.625 (avg: 16.406)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.429 (avg: 0.423)\tLoss: 4.8439 (avg: 4.7699)\tTop1: 3.125 (avg: 4.771)\tTop5: 7.812 (avg: 16.375)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.417 (avg: 0.423)\tLoss: 4.8265 (avg: 4.7646)\tTop1: 0.000 (avg: 4.688)\tTop5: 7.812 (avg: 16.406)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.427 (avg: 0.424)\tLoss: 4.7247 (avg: 4.7639)\tTop1: 3.125 (avg: 4.750)\tTop5: 14.062 (avg: 16.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7472\tTop 1 accuracy: 3.650\tTop 5 accuracy: 12.200\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.417 (avg: 0.415)\tLoss: 4.5862 (avg: 4.6704)\tTop1: 3.125 (avg: 4.875)\tTop5: 20.312 (avg: 16.688)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.426 (avg: 0.421)\tLoss: 4.9428 (avg: 4.6847)\tTop1: 4.688 (avg: 5.062)\tTop5: 12.500 (avg: 16.781)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.422 (avg: 0.423)\tLoss: 4.6764 (avg: 4.6976)\tTop1: 3.125 (avg: 5.062)\tTop5: 25.000 (avg: 17.062)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.416 (avg: 0.424)\tLoss: 5.1775 (avg: 4.6942)\tTop1: 1.562 (avg: 5.297)\tTop5: 7.812 (avg: 17.391)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.429 (avg: 0.424)\tLoss: 4.7338 (avg: 4.6925)\tTop1: 1.562 (avg: 5.100)\tTop5: 12.500 (avg: 17.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5052\tTop 1 accuracy: 5.100\tTop 5 accuracy: 16.950\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.418 (avg: 0.414)\tLoss: 4.6137 (avg: 4.5811)\tTop1: 4.688 (avg: 6.062)\tTop5: 21.875 (avg: 20.750)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.426 (avg: 0.419)\tLoss: 4.7154 (avg: 4.6262)\tTop1: 4.688 (avg: 5.719)\tTop5: 10.938 (avg: 19.250)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.417 (avg: 0.422)\tLoss: 4.7668 (avg: 4.6386)\tTop1: 4.688 (avg: 5.625)\tTop5: 9.375 (avg: 19.083)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.420 (avg: 0.423)\tLoss: 4.2662 (avg: 4.6357)\tTop1: 17.188 (avg: 5.500)\tTop5: 31.250 (avg: 19.344)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.425 (avg: 0.424)\tLoss: 4.7229 (avg: 4.6333)\tTop1: 3.125 (avg: 5.613)\tTop5: 14.062 (avg: 19.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2507\tTop 1 accuracy: 4.400\tTop 5 accuracy: 16.950\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.420 (avg: 0.416)\tLoss: 4.5859 (avg: 4.5795)\tTop1: 4.688 (avg: 5.500)\tTop5: 18.750 (avg: 20.062)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.426 (avg: 0.421)\tLoss: 4.6518 (avg: 4.5766)\tTop1: 1.562 (avg: 5.531)\tTop5: 12.500 (avg: 19.594)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.418 (avg: 0.423)\tLoss: 4.6102 (avg: 4.5762)\tTop1: 14.062 (avg: 6.125)\tTop5: 20.312 (avg: 19.750)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.417 (avg: 0.424)\tLoss: 4.4925 (avg: 4.5718)\tTop1: 10.938 (avg: 6.375)\tTop5: 25.000 (avg: 20.266)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.431 (avg: 0.424)\tLoss: 4.5600 (avg: 4.5760)\tTop1: 7.812 (avg: 6.275)\tTop5: 17.188 (avg: 20.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3970\tTop 1 accuracy: 5.250\tTop 5 accuracy: 17.700\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.419 (avg: 0.415)\tLoss: 4.3343 (avg: 4.5064)\tTop1: 12.500 (avg: 7.062)\tTop5: 23.438 (avg: 21.312)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.424 (avg: 0.421)\tLoss: 4.4719 (avg: 4.5370)\tTop1: 4.688 (avg: 6.562)\tTop5: 23.438 (avg: 21.062)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.419 (avg: 0.423)\tLoss: 4.3369 (avg: 4.5044)\tTop1: 12.500 (avg: 6.938)\tTop5: 31.250 (avg: 22.000)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.417 (avg: 0.424)\tLoss: 4.5238 (avg: 4.4926)\tTop1: 6.250 (avg: 7.062)\tTop5: 21.875 (avg: 22.359)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.430 (avg: 0.425)\tLoss: 4.7926 (avg: 4.5191)\tTop1: 1.562 (avg: 6.725)\tTop5: 12.500 (avg: 21.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6012\tTop 1 accuracy: 4.950\tTop 5 accuracy: 17.800\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.418 (avg: 0.416)\tLoss: 4.5794 (avg: 4.4929)\tTop1: 7.812 (avg: 7.000)\tTop5: 21.875 (avg: 21.375)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.424 (avg: 0.422)\tLoss: 4.4000 (avg: 4.5019)\tTop1: 6.250 (avg: 6.594)\tTop5: 15.625 (avg: 20.875)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.420 (avg: 0.424)\tLoss: 4.5110 (avg: 4.4915)\tTop1: 3.125 (avg: 6.625)\tTop5: 15.625 (avg: 20.875)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.419 (avg: 0.425)\tLoss: 4.4366 (avg: 4.5016)\tTop1: 4.688 (avg: 6.344)\tTop5: 15.625 (avg: 20.906)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.426 (avg: 0.425)\tLoss: 4.2840 (avg: 4.4903)\tTop1: 7.812 (avg: 6.525)\tTop5: 25.000 (avg: 21.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4891\tTop 1 accuracy: 5.200\tTop 5 accuracy: 16.300\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.422 (avg: 0.417)\tLoss: 4.2436 (avg: 4.4513)\tTop1: 4.688 (avg: 6.938)\tTop5: 29.688 (avg: 22.938)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.424 (avg: 0.422)\tLoss: 4.5066 (avg: 4.4242)\tTop1: 7.812 (avg: 7.781)\tTop5: 15.625 (avg: 24.719)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.415 (avg: 0.423)\tLoss: 4.3441 (avg: 4.4389)\tTop1: 10.938 (avg: 7.354)\tTop5: 26.562 (avg: 23.896)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.418 (avg: 0.424)\tLoss: 4.3841 (avg: 4.4571)\tTop1: 3.125 (avg: 7.234)\tTop5: 21.875 (avg: 23.188)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.430 (avg: 0.425)\tLoss: 4.1625 (avg: 4.4393)\tTop1: 10.938 (avg: 7.425)\tTop5: 31.250 (avg: 23.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5330\tTop 1 accuracy: 6.400\tTop 5 accuracy: 20.950\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.415 (avg: 0.411)\tLoss: 4.3282 (avg: 4.3756)\tTop1: 7.812 (avg: 7.375)\tTop5: 25.000 (avg: 25.500)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.424 (avg: 0.419)\tLoss: 4.6901 (avg: 4.3635)\tTop1: 9.375 (avg: 7.469)\tTop5: 25.000 (avg: 25.125)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.419 (avg: 0.421)\tLoss: 4.3146 (avg: 4.3713)\tTop1: 14.062 (avg: 7.688)\tTop5: 29.688 (avg: 24.875)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.420 (avg: 0.423)\tLoss: 4.4811 (avg: 4.3716)\tTop1: 6.250 (avg: 7.797)\tTop5: 23.438 (avg: 24.547)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.426 (avg: 0.424)\tLoss: 4.4103 (avg: 4.3999)\tTop1: 12.500 (avg: 7.625)\tTop5: 28.125 (avg: 24.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4644\tTop 1 accuracy: 6.550\tTop 5 accuracy: 19.850\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.421 (avg: 0.416)\tLoss: 4.4795 (avg: 4.2966)\tTop1: 6.250 (avg: 9.625)\tTop5: 20.312 (avg: 26.438)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.426 (avg: 0.421)\tLoss: 4.4643 (avg: 4.3039)\tTop1: 4.688 (avg: 8.500)\tTop5: 12.500 (avg: 25.531)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.422 (avg: 0.423)\tLoss: 4.4347 (avg: 4.3332)\tTop1: 6.250 (avg: 7.938)\tTop5: 23.438 (avg: 24.542)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.421 (avg: 0.424)\tLoss: 4.3663 (avg: 4.3466)\tTop1: 9.375 (avg: 7.922)\tTop5: 28.125 (avg: 24.250)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.422 (avg: 0.424)\tLoss: 4.4981 (avg: 4.3427)\tTop1: 7.812 (avg: 8.275)\tTop5: 15.625 (avg: 24.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4317\tTop 1 accuracy: 7.300\tTop 5 accuracy: 22.950\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.423 (avg: 0.416)\tLoss: 3.7996 (avg: 4.1278)\tTop1: 17.188 (avg: 10.125)\tTop5: 35.938 (avg: 30.562)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.424 (avg: 0.422)\tLoss: 3.7699 (avg: 4.0768)\tTop1: 9.375 (avg: 11.281)\tTop5: 40.625 (avg: 32.438)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.420 (avg: 0.423)\tLoss: 3.9144 (avg: 4.0548)\tTop1: 17.188 (avg: 11.979)\tTop5: 35.938 (avg: 33.021)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.418 (avg: 0.424)\tLoss: 3.9744 (avg: 4.0588)\tTop1: 18.750 (avg: 12.250)\tTop5: 37.500 (avg: 32.922)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.427 (avg: 0.425)\tLoss: 4.2355 (avg: 4.0707)\tTop1: 10.938 (avg: 12.388)\tTop5: 25.000 (avg: 32.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0880\tTop 1 accuracy: 9.600\tTop 5 accuracy: 26.250\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.420 (avg: 0.417)\tLoss: 3.9419 (avg: 3.9735)\tTop1: 14.062 (avg: 13.688)\tTop5: 32.812 (avg: 34.438)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.428 (avg: 0.422)\tLoss: 4.1247 (avg: 3.9845)\tTop1: 9.375 (avg: 13.625)\tTop5: 29.688 (avg: 34.906)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.413 (avg: 0.423)\tLoss: 3.7797 (avg: 3.9856)\tTop1: 14.062 (avg: 13.854)\tTop5: 40.625 (avg: 34.833)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.417 (avg: 0.424)\tLoss: 4.0598 (avg: 3.9866)\tTop1: 15.625 (avg: 13.859)\tTop5: 35.938 (avg: 34.859)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.426 (avg: 0.425)\tLoss: 3.8334 (avg: 3.9898)\tTop1: 18.750 (avg: 13.775)\tTop5: 40.625 (avg: 34.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9595\tTop 1 accuracy: 9.350\tTop 5 accuracy: 27.700\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.421 (avg: 0.417)\tLoss: 3.7318 (avg: 3.9239)\tTop1: 12.500 (avg: 13.750)\tTop5: 39.062 (avg: 35.812)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.426 (avg: 0.422)\tLoss: 3.6461 (avg: 3.9711)\tTop1: 20.312 (avg: 13.562)\tTop5: 34.375 (avg: 35.281)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.418 (avg: 0.424)\tLoss: 3.7511 (avg: 3.9843)\tTop1: 15.625 (avg: 13.396)\tTop5: 34.375 (avg: 35.104)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.418 (avg: 0.425)\tLoss: 3.5658 (avg: 3.9761)\tTop1: 21.875 (avg: 13.625)\tTop5: 43.750 (avg: 35.188)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.425 (avg: 0.425)\tLoss: 4.0234 (avg: 3.9646)\tTop1: 20.312 (avg: 14.088)\tTop5: 35.938 (avg: 35.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0824\tTop 1 accuracy: 9.350\tTop 5 accuracy: 27.400\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.415 (avg: 0.414)\tLoss: 3.7092 (avg: 3.8591)\tTop1: 14.062 (avg: 15.875)\tTop5: 39.062 (avg: 37.000)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.424 (avg: 0.420)\tLoss: 4.0954 (avg: 3.8959)\tTop1: 7.812 (avg: 15.938)\tTop5: 29.688 (avg: 36.344)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.421 (avg: 0.423)\tLoss: 3.7213 (avg: 3.9215)\tTop1: 10.938 (avg: 15.229)\tTop5: 35.938 (avg: 36.146)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.414 (avg: 0.424)\tLoss: 3.9027 (avg: 3.9349)\tTop1: 18.750 (avg: 14.938)\tTop5: 34.375 (avg: 35.984)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.429 (avg: 0.424)\tLoss: 4.1171 (avg: 3.9350)\tTop1: 9.375 (avg: 14.688)\tTop5: 29.688 (avg: 35.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9436\tTop 1 accuracy: 10.300\tTop 5 accuracy: 28.100\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.418 (avg: 0.416)\tLoss: 3.5763 (avg: 3.9009)\tTop1: 18.750 (avg: 15.625)\tTop5: 42.188 (avg: 36.312)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.420 (avg: 0.422)\tLoss: 3.8425 (avg: 3.8979)\tTop1: 20.312 (avg: 15.969)\tTop5: 40.625 (avg: 36.656)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.420 (avg: 0.424)\tLoss: 4.0106 (avg: 3.9147)\tTop1: 18.750 (avg: 15.646)\tTop5: 31.250 (avg: 36.208)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.411 (avg: 0.424)\tLoss: 4.0714 (avg: 3.9241)\tTop1: 17.188 (avg: 15.516)\tTop5: 32.812 (avg: 36.141)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.425 (avg: 0.425)\tLoss: 3.6092 (avg: 3.9109)\tTop1: 25.000 (avg: 15.275)\tTop5: 48.438 (avg: 36.625)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9488\tTop 1 accuracy: 9.400\tTop 5 accuracy: 28.800\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.419 (avg: 0.417)\tLoss: 3.8923 (avg: 3.8544)\tTop1: 18.750 (avg: 15.438)\tTop5: 39.062 (avg: 38.250)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.424 (avg: 0.422)\tLoss: 3.8463 (avg: 3.8878)\tTop1: 9.375 (avg: 14.969)\tTop5: 43.750 (avg: 37.094)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.419 (avg: 0.424)\tLoss: 4.0504 (avg: 3.8733)\tTop1: 12.500 (avg: 15.000)\tTop5: 29.688 (avg: 37.000)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.418 (avg: 0.424)\tLoss: 3.6866 (avg: 3.8948)\tTop1: 14.062 (avg: 14.844)\tTop5: 50.000 (avg: 36.906)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.429 (avg: 0.425)\tLoss: 3.9175 (avg: 3.8953)\tTop1: 10.938 (avg: 15.025)\tTop5: 31.250 (avg: 36.950)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8714\tTop 1 accuracy: 10.600\tTop 5 accuracy: 28.150\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.418 (avg: 0.416)\tLoss: 3.5774 (avg: 3.8622)\tTop1: 15.625 (avg: 15.000)\tTop5: 51.562 (avg: 37.438)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.425 (avg: 0.421)\tLoss: 3.7076 (avg: 3.8650)\tTop1: 18.750 (avg: 14.719)\tTop5: 37.500 (avg: 37.406)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.420 (avg: 0.423)\tLoss: 3.6123 (avg: 3.8441)\tTop1: 20.312 (avg: 15.000)\tTop5: 46.875 (avg: 37.938)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.414 (avg: 0.424)\tLoss: 3.7349 (avg: 3.8632)\tTop1: 20.312 (avg: 14.953)\tTop5: 40.625 (avg: 37.672)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.425 (avg: 0.425)\tLoss: 4.2309 (avg: 3.8814)\tTop1: 14.062 (avg: 15.188)\tTop5: 32.812 (avg: 37.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9529\tTop 1 accuracy: 10.150\tTop 5 accuracy: 28.700\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.417 (avg: 0.415)\tLoss: 3.9712 (avg: 3.7976)\tTop1: 15.625 (avg: 17.500)\tTop5: 32.812 (avg: 39.375)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.424 (avg: 0.420)\tLoss: 4.2601 (avg: 3.8350)\tTop1: 7.812 (avg: 16.656)\tTop5: 29.688 (avg: 38.875)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.412 (avg: 0.422)\tLoss: 3.7500 (avg: 3.8431)\tTop1: 21.875 (avg: 16.333)\tTop5: 37.500 (avg: 39.146)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.419 (avg: 0.423)\tLoss: 3.4213 (avg: 3.8323)\tTop1: 17.188 (avg: 16.203)\tTop5: 37.500 (avg: 38.922)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.426 (avg: 0.424)\tLoss: 3.9589 (avg: 3.8581)\tTop1: 14.062 (avg: 15.850)\tTop5: 35.938 (avg: 38.325)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8954\tTop 1 accuracy: 11.200\tTop 5 accuracy: 29.850\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.417 (avg: 0.416)\tLoss: 3.9133 (avg: 3.7962)\tTop1: 17.188 (avg: 16.188)\tTop5: 37.500 (avg: 39.938)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.425 (avg: 0.421)\tLoss: 3.5103 (avg: 3.7946)\tTop1: 17.188 (avg: 16.188)\tTop5: 46.875 (avg: 39.875)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.419 (avg: 0.423)\tLoss: 3.7436 (avg: 3.8264)\tTop1: 26.562 (avg: 15.854)\tTop5: 34.375 (avg: 38.958)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.414 (avg: 0.424)\tLoss: 3.8242 (avg: 3.8424)\tTop1: 20.312 (avg: 15.922)\tTop5: 42.188 (avg: 38.328)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.425 (avg: 0.424)\tLoss: 3.7436 (avg: 3.8367)\tTop1: 20.312 (avg: 16.038)\tTop5: 39.062 (avg: 38.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8088\tTop 1 accuracy: 11.100\tTop 5 accuracy: 29.550\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.422 (avg: 0.417)\tLoss: 3.8792 (avg: 3.7811)\tTop1: 18.750 (avg: 17.000)\tTop5: 35.938 (avg: 39.625)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.425 (avg: 0.422)\tLoss: 3.4888 (avg: 3.8081)\tTop1: 12.500 (avg: 16.719)\tTop5: 48.438 (avg: 39.812)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.410 (avg: 0.423)\tLoss: 4.0088 (avg: 3.8154)\tTop1: 10.938 (avg: 16.229)\tTop5: 35.938 (avg: 39.000)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.417 (avg: 0.424)\tLoss: 4.0510 (avg: 3.8110)\tTop1: 7.812 (avg: 16.234)\tTop5: 32.812 (avg: 39.078)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.431 (avg: 0.425)\tLoss: 4.1346 (avg: 3.8235)\tTop1: 10.938 (avg: 15.963)\tTop5: 29.688 (avg: 38.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7311\tTop 1 accuracy: 10.350\tTop 5 accuracy: 29.000\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.418 (avg: 0.416)\tLoss: 3.7585 (avg: 3.7127)\tTop1: 12.500 (avg: 17.062)\tTop5: 37.500 (avg: 42.812)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.423 (avg: 0.422)\tLoss: 3.3739 (avg: 3.7349)\tTop1: 14.062 (avg: 17.094)\tTop5: 54.688 (avg: 42.125)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.422 (avg: 0.424)\tLoss: 3.8817 (avg: 3.7816)\tTop1: 10.938 (avg: 16.625)\tTop5: 34.375 (avg: 40.229)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.418 (avg: 0.424)\tLoss: 3.3920 (avg: 3.7938)\tTop1: 18.750 (avg: 16.562)\tTop5: 45.312 (avg: 39.750)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.424 (avg: 0.425)\tLoss: 3.6666 (avg: 3.8040)\tTop1: 14.062 (avg: 16.425)\tTop5: 40.625 (avg: 39.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8302\tTop 1 accuracy: 10.900\tTop 5 accuracy: 29.900\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.416 (avg: 0.416)\tLoss: 3.6321 (avg: 3.7385)\tTop1: 18.750 (avg: 17.875)\tTop5: 40.625 (avg: 40.500)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.424 (avg: 0.421)\tLoss: 4.1400 (avg: 3.7695)\tTop1: 12.500 (avg: 16.750)\tTop5: 34.375 (avg: 39.781)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.419 (avg: 0.423)\tLoss: 3.8680 (avg: 3.7935)\tTop1: 17.188 (avg: 16.625)\tTop5: 32.812 (avg: 39.000)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.418 (avg: 0.424)\tLoss: 4.3267 (avg: 3.7883)\tTop1: 10.938 (avg: 16.750)\tTop5: 28.125 (avg: 39.391)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.428 (avg: 0.424)\tLoss: 3.4574 (avg: 3.7796)\tTop1: 25.000 (avg: 16.800)\tTop5: 46.875 (avg: 39.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8232\tTop 1 accuracy: 10.800\tTop 5 accuracy: 29.100\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.419 (avg: 0.417)\tLoss: 3.8330 (avg: 3.7842)\tTop1: 21.875 (avg: 17.188)\tTop5: 40.625 (avg: 40.562)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.424 (avg: 0.422)\tLoss: 3.6492 (avg: 3.7392)\tTop1: 17.188 (avg: 17.312)\tTop5: 48.438 (avg: 40.781)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.420 (avg: 0.423)\tLoss: 3.5949 (avg: 3.7423)\tTop1: 21.875 (avg: 17.396)\tTop5: 45.312 (avg: 40.271)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.417 (avg: 0.424)\tLoss: 3.9785 (avg: 3.7439)\tTop1: 15.625 (avg: 17.094)\tTop5: 37.500 (avg: 40.422)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.420 (avg: 0.425)\tLoss: 4.1249 (avg: 3.7561)\tTop1: 9.375 (avg: 16.925)\tTop5: 34.375 (avg: 40.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7837\tTop 1 accuracy: 10.250\tTop 5 accuracy: 29.400\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.417 (avg: 0.415)\tLoss: 3.5446 (avg: 3.7088)\tTop1: 23.438 (avg: 18.688)\tTop5: 45.312 (avg: 40.938)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.431 (avg: 0.421)\tLoss: 3.6770 (avg: 3.7538)\tTop1: 20.312 (avg: 17.344)\tTop5: 43.750 (avg: 39.969)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.420 (avg: 0.423)\tLoss: 3.4808 (avg: 3.7465)\tTop1: 21.875 (avg: 16.896)\tTop5: 50.000 (avg: 40.208)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.416 (avg: 0.424)\tLoss: 3.8535 (avg: 3.7501)\tTop1: 12.500 (avg: 17.016)\tTop5: 35.938 (avg: 40.047)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.432 (avg: 0.425)\tLoss: 3.8651 (avg: 3.7488)\tTop1: 14.062 (avg: 17.188)\tTop5: 35.938 (avg: 40.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0102\tTop 1 accuracy: 10.950\tTop 5 accuracy: 29.200\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.418 (avg: 0.416)\tLoss: 3.6233 (avg: 3.7138)\tTop1: 20.312 (avg: 17.250)\tTop5: 43.750 (avg: 41.438)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.419 (avg: 0.421)\tLoss: 3.8247 (avg: 3.7127)\tTop1: 14.062 (avg: 17.438)\tTop5: 43.750 (avg: 41.281)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.421 (avg: 0.422)\tLoss: 3.6998 (avg: 3.7014)\tTop1: 17.188 (avg: 17.250)\tTop5: 39.062 (avg: 41.208)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.423 (avg: 0.424)\tLoss: 3.8114 (avg: 3.7079)\tTop1: 25.000 (avg: 17.469)\tTop5: 45.312 (avg: 41.391)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.424 (avg: 0.424)\tLoss: 3.9597 (avg: 3.7160)\tTop1: 15.625 (avg: 17.538)\tTop5: 39.062 (avg: 41.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7825\tTop 1 accuracy: 11.750\tTop 5 accuracy: 31.000\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.420 (avg: 0.416)\tLoss: 3.4574 (avg: 3.6123)\tTop1: 26.562 (avg: 19.625)\tTop5: 45.312 (avg: 44.250)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.425 (avg: 0.422)\tLoss: 3.1617 (avg: 3.6736)\tTop1: 28.125 (avg: 19.188)\tTop5: 46.875 (avg: 42.188)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.419 (avg: 0.423)\tLoss: 3.9136 (avg: 3.6880)\tTop1: 14.062 (avg: 18.729)\tTop5: 34.375 (avg: 41.708)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.416 (avg: 0.424)\tLoss: 3.4021 (avg: 3.6924)\tTop1: 21.875 (avg: 18.312)\tTop5: 53.125 (avg: 41.750)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.427 (avg: 0.425)\tLoss: 3.2858 (avg: 3.6890)\tTop1: 29.688 (avg: 18.125)\tTop5: 51.562 (avg: 41.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6765\tTop 1 accuracy: 11.000\tTop 5 accuracy: 30.200\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.418 (avg: 0.416)\tLoss: 3.6240 (avg: 3.6310)\tTop1: 18.750 (avg: 17.562)\tTop5: 42.188 (avg: 42.312)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.425 (avg: 0.422)\tLoss: 3.5796 (avg: 3.6521)\tTop1: 23.438 (avg: 18.062)\tTop5: 46.875 (avg: 41.562)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.420 (avg: 0.423)\tLoss: 3.5804 (avg: 3.6544)\tTop1: 26.562 (avg: 18.354)\tTop5: 45.312 (avg: 42.042)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.417 (avg: 0.424)\tLoss: 3.7544 (avg: 3.6473)\tTop1: 25.000 (avg: 18.344)\tTop5: 42.188 (avg: 42.328)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.428 (avg: 0.425)\tLoss: 3.3205 (avg: 3.6594)\tTop1: 21.875 (avg: 18.363)\tTop5: 51.562 (avg: 42.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7527\tTop 1 accuracy: 11.850\tTop 5 accuracy: 29.700\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.416 (avg: 0.416)\tLoss: 3.2960 (avg: 3.5965)\tTop1: 20.312 (avg: 18.562)\tTop5: 46.875 (avg: 43.875)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.424 (avg: 0.422)\tLoss: 3.6351 (avg: 3.6229)\tTop1: 23.438 (avg: 18.562)\tTop5: 45.312 (avg: 43.188)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.425 (avg: 0.423)\tLoss: 3.4527 (avg: 3.6346)\tTop1: 23.438 (avg: 18.333)\tTop5: 45.312 (avg: 42.688)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.418 (avg: 0.424)\tLoss: 3.7479 (avg: 3.6397)\tTop1: 10.938 (avg: 18.297)\tTop5: 39.062 (avg: 42.781)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.420 (avg: 0.424)\tLoss: 3.8198 (avg: 3.6465)\tTop1: 6.250 (avg: 18.388)\tTop5: 39.062 (avg: 42.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8414\tTop 1 accuracy: 11.400\tTop 5 accuracy: 30.500\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.418 (avg: 0.416)\tLoss: 3.6834 (avg: 3.6078)\tTop1: 21.875 (avg: 20.750)\tTop5: 40.625 (avg: 43.188)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.422 (avg: 0.422)\tLoss: 3.2135 (avg: 3.5723)\tTop1: 23.438 (avg: 20.562)\tTop5: 48.438 (avg: 43.750)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.420 (avg: 0.423)\tLoss: 3.6608 (avg: 3.5913)\tTop1: 18.750 (avg: 19.812)\tTop5: 40.625 (avg: 43.812)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.414 (avg: 0.424)\tLoss: 3.5928 (avg: 3.5964)\tTop1: 14.062 (avg: 19.453)\tTop5: 39.062 (avg: 43.453)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.426 (avg: 0.425)\tLoss: 3.6860 (avg: 3.6117)\tTop1: 18.750 (avg: 19.038)\tTop5: 40.625 (avg: 43.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1896\tTop 1 accuracy: 11.500\tTop 5 accuracy: 30.500\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.419 (avg: 0.416)\tLoss: 3.4963 (avg: 3.5929)\tTop1: 25.000 (avg: 20.062)\tTop5: 45.312 (avg: 43.688)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.425 (avg: 0.420)\tLoss: 3.7420 (avg: 3.5877)\tTop1: 17.188 (avg: 19.969)\tTop5: 42.188 (avg: 43.938)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.421 (avg: 0.422)\tLoss: 3.7303 (avg: 3.5984)\tTop1: 12.500 (avg: 18.979)\tTop5: 43.750 (avg: 43.104)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.417 (avg: 0.424)\tLoss: 3.1858 (avg: 3.5872)\tTop1: 23.438 (avg: 19.344)\tTop5: 45.312 (avg: 43.594)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.426 (avg: 0.424)\tLoss: 3.6571 (avg: 3.5987)\tTop1: 21.875 (avg: 19.288)\tTop5: 42.188 (avg: 43.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8411\tTop 1 accuracy: 11.450\tTop 5 accuracy: 30.450\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.418 (avg: 0.416)\tLoss: 3.5909 (avg: 3.5670)\tTop1: 23.438 (avg: 19.062)\tTop5: 46.875 (avg: 44.438)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.424 (avg: 0.421)\tLoss: 3.9709 (avg: 3.5560)\tTop1: 25.000 (avg: 19.094)\tTop5: 40.625 (avg: 43.750)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.416 (avg: 0.423)\tLoss: 3.3254 (avg: 3.5630)\tTop1: 18.750 (avg: 19.167)\tTop5: 50.000 (avg: 44.021)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.421 (avg: 0.424)\tLoss: 4.0604 (avg: 3.5786)\tTop1: 12.500 (avg: 19.203)\tTop5: 37.500 (avg: 43.781)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.424 (avg: 0.424)\tLoss: 3.6731 (avg: 3.5862)\tTop1: 31.250 (avg: 19.338)\tTop5: 46.875 (avg: 43.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9605\tTop 1 accuracy: 12.400\tTop 5 accuracy: 31.400\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.419 (avg: 0.416)\tLoss: 3.1143 (avg: 3.5220)\tTop1: 25.000 (avg: 19.875)\tTop5: 56.250 (avg: 45.688)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.427 (avg: 0.422)\tLoss: 3.3630 (avg: 3.5309)\tTop1: 26.562 (avg: 20.781)\tTop5: 46.875 (avg: 45.000)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.420 (avg: 0.423)\tLoss: 3.2523 (avg: 3.5538)\tTop1: 14.062 (avg: 19.979)\tTop5: 54.688 (avg: 44.583)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.413 (avg: 0.424)\tLoss: 3.6758 (avg: 3.5606)\tTop1: 15.625 (avg: 19.734)\tTop5: 39.062 (avg: 44.656)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.423 (avg: 0.424)\tLoss: 3.4296 (avg: 3.5564)\tTop1: 28.125 (avg: 19.863)\tTop5: 48.438 (avg: 44.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8762\tTop 1 accuracy: 12.300\tTop 5 accuracy: 31.750\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.423 (avg: 0.417)\tLoss: 3.4378 (avg: 3.5008)\tTop1: 20.312 (avg: 22.188)\tTop5: 46.875 (avg: 46.188)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.425 (avg: 0.422)\tLoss: 3.2875 (avg: 3.5281)\tTop1: 20.312 (avg: 21.719)\tTop5: 50.000 (avg: 45.094)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.419 (avg: 0.424)\tLoss: 3.3020 (avg: 3.5265)\tTop1: 25.000 (avg: 20.812)\tTop5: 50.000 (avg: 45.062)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.416 (avg: 0.424)\tLoss: 3.5174 (avg: 3.5228)\tTop1: 20.312 (avg: 20.266)\tTop5: 42.188 (avg: 44.875)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.431 (avg: 0.424)\tLoss: 3.7549 (avg: 3.5415)\tTop1: 20.312 (avg: 20.188)\tTop5: 46.875 (avg: 44.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7612\tTop 1 accuracy: 13.350\tTop 5 accuracy: 32.350\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.413 (avg: 0.416)\tLoss: 3.3402 (avg: 3.3838)\tTop1: 18.750 (avg: 22.438)\tTop5: 51.562 (avg: 48.688)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.423 (avg: 0.421)\tLoss: 3.4927 (avg: 3.4561)\tTop1: 21.875 (avg: 21.844)\tTop5: 46.875 (avg: 47.750)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.417 (avg: 0.423)\tLoss: 3.4147 (avg: 3.4676)\tTop1: 17.188 (avg: 21.333)\tTop5: 46.875 (avg: 47.146)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.411 (avg: 0.423)\tLoss: 3.4854 (avg: 3.4959)\tTop1: 20.312 (avg: 21.000)\tTop5: 46.875 (avg: 46.062)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.426 (avg: 0.424)\tLoss: 3.4196 (avg: 3.4962)\tTop1: 21.875 (avg: 21.063)\tTop5: 43.750 (avg: 45.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8526\tTop 1 accuracy: 12.500\tTop 5 accuracy: 32.100\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.414 (avg: 0.414)\tLoss: 3.4131 (avg: 3.3974)\tTop1: 20.312 (avg: 23.562)\tTop5: 53.125 (avg: 48.375)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.424 (avg: 0.420)\tLoss: 3.3825 (avg: 3.4508)\tTop1: 23.438 (avg: 21.938)\tTop5: 45.312 (avg: 46.406)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.421 (avg: 0.422)\tLoss: 3.4613 (avg: 3.4825)\tTop1: 18.750 (avg: 21.354)\tTop5: 39.062 (avg: 45.833)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.422 (avg: 0.423)\tLoss: 3.3915 (avg: 3.4832)\tTop1: 25.000 (avg: 21.297)\tTop5: 46.875 (avg: 45.734)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.427 (avg: 0.424)\tLoss: 3.5620 (avg: 3.4886)\tTop1: 20.312 (avg: 21.100)\tTop5: 43.750 (avg: 45.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8678\tTop 1 accuracy: 13.150\tTop 5 accuracy: 32.200\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.416 (avg: 0.416)\tLoss: 3.4123 (avg: 3.3927)\tTop1: 21.875 (avg: 22.625)\tTop5: 50.000 (avg: 48.938)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.426 (avg: 0.421)\tLoss: 3.2882 (avg: 3.4442)\tTop1: 26.562 (avg: 21.250)\tTop5: 48.438 (avg: 46.781)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.414 (avg: 0.423)\tLoss: 3.0538 (avg: 3.4544)\tTop1: 26.562 (avg: 21.312)\tTop5: 62.500 (avg: 46.708)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.418 (avg: 0.424)\tLoss: 3.4753 (avg: 3.4633)\tTop1: 25.000 (avg: 20.938)\tTop5: 43.750 (avg: 46.672)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.429 (avg: 0.425)\tLoss: 3.2039 (avg: 3.4575)\tTop1: 25.000 (avg: 21.113)\tTop5: 54.688 (avg: 46.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8195\tTop 1 accuracy: 11.750\tTop 5 accuracy: 31.250\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.418 (avg: 0.416)\tLoss: 3.4163 (avg: 3.3199)\tTop1: 14.062 (avg: 24.500)\tTop5: 45.312 (avg: 50.062)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.426 (avg: 0.421)\tLoss: 3.2058 (avg: 3.3721)\tTop1: 26.562 (avg: 22.875)\tTop5: 51.562 (avg: 48.688)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.418 (avg: 0.423)\tLoss: 3.4211 (avg: 3.4279)\tTop1: 20.312 (avg: 21.792)\tTop5: 43.750 (avg: 47.479)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.414 (avg: 0.424)\tLoss: 3.4069 (avg: 3.4168)\tTop1: 21.875 (avg: 22.219)\tTop5: 48.438 (avg: 47.688)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.426 (avg: 0.424)\tLoss: 3.3560 (avg: 3.4304)\tTop1: 26.562 (avg: 21.975)\tTop5: 53.125 (avg: 47.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7373\tTop 1 accuracy: 13.700\tTop 5 accuracy: 33.500\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.418 (avg: 0.416)\tLoss: 3.7883 (avg: 3.4144)\tTop1: 10.938 (avg: 21.375)\tTop5: 37.500 (avg: 46.875)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.424 (avg: 0.421)\tLoss: 3.4273 (avg: 3.4044)\tTop1: 18.750 (avg: 21.531)\tTop5: 40.625 (avg: 47.062)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.418 (avg: 0.422)\tLoss: 3.6108 (avg: 3.3889)\tTop1: 25.000 (avg: 22.146)\tTop5: 39.062 (avg: 47.562)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.422 (avg: 0.423)\tLoss: 3.3807 (avg: 3.3842)\tTop1: 20.312 (avg: 22.609)\tTop5: 45.312 (avg: 47.594)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.426 (avg: 0.423)\tLoss: 3.4844 (avg: 3.4035)\tTop1: 25.000 (avg: 22.163)\tTop5: 43.750 (avg: 47.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9101\tTop 1 accuracy: 12.250\tTop 5 accuracy: 31.750\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.420 (avg: 0.416)\tLoss: 3.3317 (avg: 3.2895)\tTop1: 23.438 (avg: 23.312)\tTop5: 56.250 (avg: 49.750)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.426 (avg: 0.422)\tLoss: 3.2732 (avg: 3.3747)\tTop1: 26.562 (avg: 21.531)\tTop5: 51.562 (avg: 48.219)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.417 (avg: 0.424)\tLoss: 2.8882 (avg: 3.3513)\tTop1: 32.812 (avg: 22.500)\tTop5: 54.688 (avg: 48.875)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.417 (avg: 0.424)\tLoss: 3.2137 (avg: 3.3786)\tTop1: 28.125 (avg: 22.438)\tTop5: 53.125 (avg: 48.172)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.431 (avg: 0.425)\tLoss: 3.3575 (avg: 3.3825)\tTop1: 21.875 (avg: 22.088)\tTop5: 48.438 (avg: 48.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9785\tTop 1 accuracy: 12.350\tTop 5 accuracy: 32.800\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.422 (avg: 0.416)\tLoss: 3.1778 (avg: 3.3040)\tTop1: 32.812 (avg: 23.938)\tTop5: 54.688 (avg: 50.500)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.422 (avg: 0.422)\tLoss: 3.3005 (avg: 3.3475)\tTop1: 18.750 (avg: 23.188)\tTop5: 51.562 (avg: 49.344)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.419 (avg: 0.423)\tLoss: 3.3111 (avg: 3.3728)\tTop1: 21.875 (avg: 22.896)\tTop5: 46.875 (avg: 48.979)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.414 (avg: 0.424)\tLoss: 3.6796 (avg: 3.3577)\tTop1: 17.188 (avg: 23.250)\tTop5: 34.375 (avg: 49.203)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.425 (avg: 0.425)\tLoss: 3.5033 (avg: 3.3778)\tTop1: 14.062 (avg: 22.388)\tTop5: 45.312 (avg: 48.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1907\tTop 1 accuracy: 11.650\tTop 5 accuracy: 31.250\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.421 (avg: 0.416)\tLoss: 3.4330 (avg: 3.3436)\tTop1: 21.875 (avg: 24.000)\tTop5: 40.625 (avg: 49.562)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.423 (avg: 0.422)\tLoss: 3.2561 (avg: 3.2699)\tTop1: 17.188 (avg: 24.812)\tTop5: 50.000 (avg: 51.125)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.416 (avg: 0.424)\tLoss: 3.1446 (avg: 3.2332)\tTop1: 34.375 (avg: 26.167)\tTop5: 51.562 (avg: 52.021)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.417 (avg: 0.424)\tLoss: 3.5282 (avg: 3.1981)\tTop1: 26.562 (avg: 26.547)\tTop5: 50.000 (avg: 52.609)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.416 (avg: 0.425)\tLoss: 3.3326 (avg: 3.1908)\tTop1: 15.625 (avg: 26.613)\tTop5: 45.312 (avg: 52.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8871\tTop 1 accuracy: 14.000\tTop 5 accuracy: 33.650\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.418 (avg: 0.416)\tLoss: 3.0548 (avg: 3.0535)\tTop1: 25.000 (avg: 28.812)\tTop5: 53.125 (avg: 55.812)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.425 (avg: 0.421)\tLoss: 2.9266 (avg: 3.1119)\tTop1: 32.812 (avg: 28.156)\tTop5: 56.250 (avg: 54.312)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.418 (avg: 0.423)\tLoss: 3.5072 (avg: 3.1097)\tTop1: 18.750 (avg: 28.271)\tTop5: 50.000 (avg: 54.292)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.419 (avg: 0.424)\tLoss: 2.9335 (avg: 3.1319)\tTop1: 26.562 (avg: 27.641)\tTop5: 59.375 (avg: 53.828)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.427 (avg: 0.424)\tLoss: 2.7734 (avg: 3.1202)\tTop1: 31.250 (avg: 27.913)\tTop5: 60.938 (avg: 54.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0150\tTop 1 accuracy: 14.600\tTop 5 accuracy: 34.250\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.415 (avg: 0.417)\tLoss: 3.1410 (avg: 3.0515)\tTop1: 29.688 (avg: 29.750)\tTop5: 46.875 (avg: 54.625)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.422 (avg: 0.422)\tLoss: 2.6421 (avg: 3.0591)\tTop1: 35.938 (avg: 29.469)\tTop5: 65.625 (avg: 55.312)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.415 (avg: 0.423)\tLoss: 2.9689 (avg: 3.1076)\tTop1: 28.125 (avg: 28.938)\tTop5: 56.250 (avg: 54.104)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.415 (avg: 0.423)\tLoss: 3.0016 (avg: 3.0893)\tTop1: 26.562 (avg: 29.125)\tTop5: 57.812 (avg: 54.719)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.423 (avg: 0.424)\tLoss: 3.2391 (avg: 3.1071)\tTop1: 28.125 (avg: 28.888)\tTop5: 46.875 (avg: 54.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9622\tTop 1 accuracy: 13.900\tTop 5 accuracy: 33.600\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.419 (avg: 0.417)\tLoss: 3.0581 (avg: 3.1288)\tTop1: 26.562 (avg: 28.250)\tTop5: 54.688 (avg: 53.750)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.426 (avg: 0.422)\tLoss: 2.8615 (avg: 3.1280)\tTop1: 35.938 (avg: 28.281)\tTop5: 59.375 (avg: 54.281)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.419 (avg: 0.423)\tLoss: 2.8255 (avg: 3.1092)\tTop1: 29.688 (avg: 28.396)\tTop5: 62.500 (avg: 54.854)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.417 (avg: 0.424)\tLoss: 3.1332 (avg: 3.1062)\tTop1: 25.000 (avg: 28.375)\tTop5: 45.312 (avg: 54.797)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.423 (avg: 0.424)\tLoss: 3.1273 (avg: 3.1022)\tTop1: 31.250 (avg: 28.413)\tTop5: 51.562 (avg: 54.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9070\tTop 1 accuracy: 14.450\tTop 5 accuracy: 34.000\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.423 (avg: 0.415)\tLoss: 3.5197 (avg: 3.0727)\tTop1: 23.438 (avg: 29.062)\tTop5: 40.625 (avg: 55.438)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.422 (avg: 0.421)\tLoss: 2.9922 (avg: 3.0886)\tTop1: 35.938 (avg: 29.094)\tTop5: 53.125 (avg: 55.531)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.422 (avg: 0.423)\tLoss: 3.1709 (avg: 3.0907)\tTop1: 25.000 (avg: 29.146)\tTop5: 56.250 (avg: 55.438)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.418 (avg: 0.424)\tLoss: 2.9786 (avg: 3.0928)\tTop1: 23.438 (avg: 28.656)\tTop5: 54.688 (avg: 55.344)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.427 (avg: 0.425)\tLoss: 3.0133 (avg: 3.0877)\tTop1: 29.688 (avg: 28.700)\tTop5: 60.938 (avg: 55.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0943\tTop 1 accuracy: 13.800\tTop 5 accuracy: 34.650\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.418 (avg: 0.416)\tLoss: 3.1692 (avg: 3.1002)\tTop1: 25.000 (avg: 27.812)\tTop5: 62.500 (avg: 56.500)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.423 (avg: 0.421)\tLoss: 3.1092 (avg: 3.0972)\tTop1: 18.750 (avg: 28.312)\tTop5: 54.688 (avg: 55.469)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.416 (avg: 0.423)\tLoss: 3.3703 (avg: 3.0687)\tTop1: 26.562 (avg: 29.021)\tTop5: 53.125 (avg: 55.646)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.422 (avg: 0.424)\tLoss: 3.0531 (avg: 3.0853)\tTop1: 23.438 (avg: 28.734)\tTop5: 56.250 (avg: 55.312)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.425 (avg: 0.425)\tLoss: 3.5091 (avg: 3.0769)\tTop1: 21.875 (avg: 28.688)\tTop5: 48.438 (avg: 55.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0649\tTop 1 accuracy: 14.300\tTop 5 accuracy: 34.350\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.419 (avg: 0.415)\tLoss: 2.9927 (avg: 3.0073)\tTop1: 34.375 (avg: 30.812)\tTop5: 59.375 (avg: 57.938)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.426 (avg: 0.421)\tLoss: 2.9503 (avg: 3.0323)\tTop1: 35.938 (avg: 29.688)\tTop5: 57.812 (avg: 56.656)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.426 (avg: 0.423)\tLoss: 3.0176 (avg: 3.0637)\tTop1: 29.688 (avg: 29.104)\tTop5: 53.125 (avg: 55.896)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.419 (avg: 0.424)\tLoss: 2.8260 (avg: 3.0751)\tTop1: 37.500 (avg: 28.797)\tTop5: 64.062 (avg: 55.438)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.428 (avg: 0.425)\tLoss: 3.3963 (avg: 3.0754)\tTop1: 18.750 (avg: 28.575)\tTop5: 45.312 (avg: 55.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1269\tTop 1 accuracy: 14.100\tTop 5 accuracy: 34.400\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.420 (avg: 0.417)\tLoss: 3.3021 (avg: 3.0642)\tTop1: 32.812 (avg: 29.062)\tTop5: 53.125 (avg: 55.812)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.427 (avg: 0.422)\tLoss: 2.9957 (avg: 3.0708)\tTop1: 25.000 (avg: 28.781)\tTop5: 57.812 (avg: 56.031)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.415 (avg: 0.423)\tLoss: 3.6612 (avg: 3.0799)\tTop1: 20.312 (avg: 28.896)\tTop5: 43.750 (avg: 55.312)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.419 (avg: 0.423)\tLoss: 2.6395 (avg: 3.0667)\tTop1: 35.938 (avg: 28.812)\tTop5: 64.062 (avg: 55.500)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.427 (avg: 0.424)\tLoss: 2.9405 (avg: 3.0679)\tTop1: 31.250 (avg: 29.025)\tTop5: 64.062 (avg: 55.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0529\tTop 1 accuracy: 14.350\tTop 5 accuracy: 34.350\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.420 (avg: 0.415)\tLoss: 2.7275 (avg: 2.9842)\tTop1: 29.688 (avg: 30.438)\tTop5: 70.312 (avg: 57.500)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.430 (avg: 0.421)\tLoss: 3.0252 (avg: 3.0617)\tTop1: 34.375 (avg: 28.812)\tTop5: 59.375 (avg: 56.281)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.417 (avg: 0.423)\tLoss: 3.3068 (avg: 3.0542)\tTop1: 26.562 (avg: 29.250)\tTop5: 46.875 (avg: 56.375)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.418 (avg: 0.423)\tLoss: 3.0092 (avg: 3.0606)\tTop1: 26.562 (avg: 29.062)\tTop5: 50.000 (avg: 56.156)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.427 (avg: 0.424)\tLoss: 2.8549 (avg: 3.0542)\tTop1: 39.062 (avg: 29.250)\tTop5: 56.250 (avg: 56.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1977\tTop 1 accuracy: 14.250\tTop 5 accuracy: 34.250\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.418 (avg: 0.415)\tLoss: 2.9713 (avg: 3.0487)\tTop1: 29.688 (avg: 29.312)\tTop5: 59.375 (avg: 55.625)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.423 (avg: 0.421)\tLoss: 2.9997 (avg: 3.0099)\tTop1: 20.312 (avg: 29.750)\tTop5: 56.250 (avg: 56.719)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.421 (avg: 0.423)\tLoss: 3.0849 (avg: 3.0271)\tTop1: 25.000 (avg: 29.375)\tTop5: 51.562 (avg: 56.208)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.417 (avg: 0.424)\tLoss: 3.0203 (avg: 3.0282)\tTop1: 25.000 (avg: 29.328)\tTop5: 56.250 (avg: 56.109)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.430 (avg: 0.424)\tLoss: 2.5567 (avg: 3.0446)\tTop1: 35.938 (avg: 29.338)\tTop5: 62.500 (avg: 55.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0094\tTop 1 accuracy: 14.050\tTop 5 accuracy: 33.900\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.421 (avg: 0.416)\tLoss: 2.9185 (avg: 3.0313)\tTop1: 25.000 (avg: 29.438)\tTop5: 54.688 (avg: 57.000)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.423 (avg: 0.421)\tLoss: 2.9483 (avg: 3.0165)\tTop1: 35.938 (avg: 29.938)\tTop5: 64.062 (avg: 56.969)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.420 (avg: 0.423)\tLoss: 3.1049 (avg: 3.0167)\tTop1: 29.688 (avg: 29.604)\tTop5: 56.250 (avg: 56.729)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.412 (avg: 0.424)\tLoss: 3.0548 (avg: 3.0373)\tTop1: 37.500 (avg: 29.562)\tTop5: 57.812 (avg: 56.156)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.423 (avg: 0.424)\tLoss: 3.2488 (avg: 3.0383)\tTop1: 26.562 (avg: 29.663)\tTop5: 48.438 (avg: 56.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0858\tTop 1 accuracy: 14.050\tTop 5 accuracy: 33.850\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.423 (avg: 0.415)\tLoss: 2.7034 (avg: 2.9970)\tTop1: 35.938 (avg: 31.875)\tTop5: 60.938 (avg: 56.375)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.424 (avg: 0.421)\tLoss: 2.9098 (avg: 2.9987)\tTop1: 32.812 (avg: 31.375)\tTop5: 54.688 (avg: 55.969)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.417 (avg: 0.423)\tLoss: 3.1634 (avg: 3.0156)\tTop1: 28.125 (avg: 30.750)\tTop5: 60.938 (avg: 55.729)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.418 (avg: 0.424)\tLoss: 3.2530 (avg: 3.0349)\tTop1: 20.312 (avg: 30.062)\tTop5: 51.562 (avg: 55.641)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.420 (avg: 0.424)\tLoss: 3.5085 (avg: 3.0344)\tTop1: 21.875 (avg: 29.363)\tTop5: 54.688 (avg: 55.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2439\tTop 1 accuracy: 13.750\tTop 5 accuracy: 34.650\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.423 (avg: 0.416)\tLoss: 3.0943 (avg: 3.0296)\tTop1: 29.688 (avg: 29.375)\tTop5: 51.562 (avg: 56.188)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.426 (avg: 0.422)\tLoss: 3.1141 (avg: 3.0103)\tTop1: 34.375 (avg: 29.281)\tTop5: 54.688 (avg: 56.719)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.416 (avg: 0.422)\tLoss: 2.7391 (avg: 3.0149)\tTop1: 37.500 (avg: 29.333)\tTop5: 65.625 (avg: 56.896)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.421 (avg: 0.423)\tLoss: 3.0325 (avg: 3.0221)\tTop1: 31.250 (avg: 29.391)\tTop5: 54.688 (avg: 56.641)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.427 (avg: 0.424)\tLoss: 3.1713 (avg: 3.0273)\tTop1: 32.812 (avg: 29.413)\tTop5: 56.250 (avg: 56.563)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2366\tTop 1 accuracy: 14.100\tTop 5 accuracy: 34.100\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.416 (avg: 0.416)\tLoss: 2.4526 (avg: 3.0532)\tTop1: 39.062 (avg: 29.750)\tTop5: 65.625 (avg: 57.312)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.425 (avg: 0.421)\tLoss: 3.1941 (avg: 3.0529)\tTop1: 26.562 (avg: 29.281)\tTop5: 50.000 (avg: 56.500)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.411 (avg: 0.422)\tLoss: 2.5583 (avg: 3.0367)\tTop1: 43.750 (avg: 29.458)\tTop5: 68.750 (avg: 56.229)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.419 (avg: 0.423)\tLoss: 3.1735 (avg: 3.0289)\tTop1: 28.125 (avg: 29.609)\tTop5: 54.688 (avg: 56.234)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.424 (avg: 0.424)\tLoss: 2.7929 (avg: 3.0275)\tTop1: 32.812 (avg: 29.688)\tTop5: 57.812 (avg: 56.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1415\tTop 1 accuracy: 14.400\tTop 5 accuracy: 33.750\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.416 (avg: 0.415)\tLoss: 2.8711 (avg: 3.1038)\tTop1: 32.812 (avg: 27.875)\tTop5: 60.938 (avg: 55.000)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.420 (avg: 0.421)\tLoss: 3.1456 (avg: 3.0109)\tTop1: 28.125 (avg: 30.156)\tTop5: 57.812 (avg: 56.562)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.428 (avg: 0.423)\tLoss: 3.1573 (avg: 3.0076)\tTop1: 23.438 (avg: 29.729)\tTop5: 57.812 (avg: 57.229)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.418 (avg: 0.424)\tLoss: 3.4042 (avg: 3.0291)\tTop1: 21.875 (avg: 29.344)\tTop5: 48.438 (avg: 56.656)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.425 (avg: 0.424)\tLoss: 2.9031 (avg: 3.0214)\tTop1: 32.812 (avg: 29.425)\tTop5: 59.375 (avg: 56.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1545\tTop 1 accuracy: 13.650\tTop 5 accuracy: 34.200\n",
            "\n",
            "pct_3x3 = 0.875: top1 = 13.800000190734863 \t top5 = 34.650001525878906 \t batch time = 0.30081386119127274\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "erdtDqbBNXLA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51207
        },
        "outputId": "cef53a2f-7f63-40ba-90f5-d9319c24f2fe"
      },
      "cell_type": "code",
      "source": [
        "# base_e\n",
        "base_list = [64, 128, 192, 256]\n",
        "base_top1s = []\n",
        "base_top5s = []\n",
        "base_batch_times = []\n",
        "for base in base_list:\n",
        "  model = SqueezeNet_MetaParam(version=1.0, base=base)\n",
        "  batch_time, top1, top5 = test_model(model)\n",
        "  base_top1s.append(top1)\n",
        "  base_top5s.append(top5)\n",
        "  base_batch_times.append(batch_time)\n",
        "  print(\"base_e = {0}: top1 = {1} \\t top5 = {2} \\t batch time = {3}\\n\".format(base, top1, top5, batch_time))\n",
        "  \n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.307 (avg: 0.408)\tLoss: 5.2959 (avg: 5.3053)\tTop1: 0.000 (avg: 0.312)\tTop5: 3.125 (avg: 1.812)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.298 (avg: 0.359)\tLoss: 5.2972 (avg: 5.3021)\tTop1: 0.000 (avg: 0.281)\tTop5: 3.125 (avg: 1.844)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.301 (avg: 0.341)\tLoss: 5.2979 (avg: 5.3010)\tTop1: 0.000 (avg: 0.375)\tTop5: 3.125 (avg: 2.021)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.288 (avg: 0.331)\tLoss: 5.3000 (avg: 5.3004)\tTop1: 0.000 (avg: 0.406)\tTop5: 0.000 (avg: 1.969)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.293 (avg: 0.325)\tLoss: 5.2984 (avg: 5.3001)\tTop1: 0.000 (avg: 0.375)\tTop5: 3.125 (avg: 1.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2989\tTop 1 accuracy: 0.550\tTop 5 accuracy: 2.250\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.292 (avg: 0.293)\tLoss: 5.2978 (avg: 5.2983)\tTop1: 1.562 (avg: 0.500)\tTop5: 1.562 (avg: 2.875)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.291 (avg: 0.296)\tLoss: 5.2956 (avg: 5.2980)\tTop1: 1.562 (avg: 0.562)\tTop5: 3.125 (avg: 2.781)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.293 (avg: 0.299)\tLoss: 5.2991 (avg: 5.2979)\tTop1: 0.000 (avg: 0.521)\tTop5: 1.562 (avg: 2.562)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.296 (avg: 0.299)\tLoss: 5.2941 (avg: 5.2978)\tTop1: 0.000 (avg: 0.547)\tTop5: 4.688 (avg: 2.656)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.283 (avg: 0.299)\tLoss: 5.3017 (avg: 5.2973)\tTop1: 0.000 (avg: 0.500)\tTop5: 0.000 (avg: 2.625)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2909\tTop 1 accuracy: 0.700\tTop 5 accuracy: 2.500\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.294 (avg: 0.292)\tLoss: 5.2692 (avg: 5.2880)\tTop1: 3.125 (avg: 0.688)\tTop5: 3.125 (avg: 2.625)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.295 (avg: 0.295)\tLoss: 5.3012 (avg: 5.2936)\tTop1: 1.562 (avg: 0.469)\tTop5: 3.125 (avg: 2.531)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.284 (avg: 0.296)\tLoss: 5.3007 (avg: 5.2953)\tTop1: 0.000 (avg: 0.604)\tTop5: 1.562 (avg: 2.583)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.291 (avg: 0.295)\tLoss: 5.2929 (avg: 5.2959)\tTop1: 0.000 (avg: 0.531)\tTop5: 4.688 (avg: 2.672)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.288 (avg: 0.296)\tLoss: 5.2955 (avg: 5.2964)\tTop1: 0.000 (avg: 0.513)\tTop5: 1.562 (avg: 2.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3050\tTop 1 accuracy: 0.450\tTop 5 accuracy: 2.500\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.316 (avg: 0.312)\tLoss: 5.3127 (avg: 5.2957)\tTop1: 0.000 (avg: 0.438)\tTop5: 0.000 (avg: 3.125)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.308 (avg: 0.314)\tLoss: 5.2827 (avg: 5.2938)\tTop1: 1.562 (avg: 0.625)\tTop5: 3.125 (avg: 2.719)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.306 (avg: 0.314)\tLoss: 5.2918 (avg: 5.2942)\tTop1: 1.562 (avg: 0.583)\tTop5: 1.562 (avg: 2.458)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.304 (avg: 0.314)\tLoss: 5.3002 (avg: 5.2941)\tTop1: 0.000 (avg: 0.578)\tTop5: 1.562 (avg: 2.625)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.311 (avg: 0.313)\tLoss: 5.2661 (avg: 5.2934)\tTop1: 1.562 (avg: 0.575)\tTop5: 7.812 (avg: 2.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3031\tTop 1 accuracy: 0.500\tTop 5 accuracy: 2.850\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.301 (avg: 0.291)\tLoss: 5.2959 (avg: 5.2924)\tTop1: 1.562 (avg: 0.688)\tTop5: 4.688 (avg: 3.438)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.291 (avg: 0.297)\tLoss: 5.2978 (avg: 5.2950)\tTop1: 0.000 (avg: 0.750)\tTop5: 1.562 (avg: 3.156)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.295 (avg: 0.298)\tLoss: 5.2867 (avg: 5.2950)\tTop1: 1.562 (avg: 0.708)\tTop5: 3.125 (avg: 3.250)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.289 (avg: 0.299)\tLoss: 5.2927 (avg: 5.2943)\tTop1: 0.000 (avg: 0.609)\tTop5: 1.562 (avg: 3.016)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.301 (avg: 0.299)\tLoss: 5.2255 (avg: 5.2920)\tTop1: 3.125 (avg: 0.588)\tTop5: 10.938 (avg: 2.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2880\tTop 1 accuracy: 0.450\tTop 5 accuracy: 2.850\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.292 (avg: 0.295)\tLoss: 5.3027 (avg: 5.2735)\tTop1: 0.000 (avg: 0.500)\tTop5: 1.562 (avg: 3.500)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.304 (avg: 0.299)\tLoss: 5.2703 (avg: 5.2727)\tTop1: 0.000 (avg: 0.531)\tTop5: 1.562 (avg: 3.219)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 5.2397 (avg: 5.2736)\tTop1: 1.562 (avg: 0.583)\tTop5: 4.688 (avg: 3.438)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.289 (avg: 0.299)\tLoss: 5.2802 (avg: 5.2756)\tTop1: 0.000 (avg: 0.578)\tTop5: 4.688 (avg: 3.484)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.289 (avg: 0.299)\tLoss: 5.2616 (avg: 5.2734)\tTop1: 0.000 (avg: 0.575)\tTop5: 1.562 (avg: 3.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2044\tTop 1 accuracy: 0.550\tTop 5 accuracy: 3.350\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.291 (avg: 0.294)\tLoss: 5.3529 (avg: 5.2616)\tTop1: 0.000 (avg: 0.875)\tTop5: 0.000 (avg: 3.938)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.294 (avg: 0.297)\tLoss: 5.2688 (avg: 5.2621)\tTop1: 0.000 (avg: 0.750)\tTop5: 4.688 (avg: 3.781)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.294 (avg: 0.298)\tLoss: 5.2846 (avg: 5.2645)\tTop1: 0.000 (avg: 0.750)\tTop5: 4.688 (avg: 3.896)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.290 (avg: 0.299)\tLoss: 5.2644 (avg: 5.2628)\tTop1: 0.000 (avg: 0.812)\tTop5: 3.125 (avg: 3.953)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.290 (avg: 0.299)\tLoss: 5.2802 (avg: 5.2616)\tTop1: 1.562 (avg: 0.863)\tTop5: 7.812 (avg: 4.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0584\tTop 1 accuracy: 0.600\tTop 5 accuracy: 3.300\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.300 (avg: 0.294)\tLoss: 5.2364 (avg: 5.2477)\tTop1: 0.000 (avg: 0.875)\tTop5: 1.562 (avg: 3.875)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.297 (avg: 0.298)\tLoss: 5.2712 (avg: 5.2504)\tTop1: 3.125 (avg: 0.938)\tTop5: 7.812 (avg: 4.344)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.306 (avg: 0.302)\tLoss: 5.1871 (avg: 5.2457)\tTop1: 0.000 (avg: 1.000)\tTop5: 3.125 (avg: 4.542)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.294 (avg: 0.303)\tLoss: 5.2096 (avg: 5.2516)\tTop1: 0.000 (avg: 0.859)\tTop5: 7.812 (avg: 4.438)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.290 (avg: 0.302)\tLoss: 5.2393 (avg: 5.2512)\tTop1: 0.000 (avg: 0.850)\tTop5: 4.688 (avg: 4.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2415\tTop 1 accuracy: 0.400\tTop 5 accuracy: 3.950\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.293 (avg: 0.302)\tLoss: 5.1458 (avg: 5.2378)\tTop1: 1.562 (avg: 1.062)\tTop5: 7.812 (avg: 4.312)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.290 (avg: 0.302)\tLoss: 5.2463 (avg: 5.2358)\tTop1: 0.000 (avg: 1.062)\tTop5: 0.000 (avg: 4.000)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.290 (avg: 0.301)\tLoss: 5.1589 (avg: 5.2335)\tTop1: 0.000 (avg: 1.104)\tTop5: 3.125 (avg: 4.375)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.294 (avg: 0.301)\tLoss: 5.3178 (avg: 5.2374)\tTop1: 0.000 (avg: 1.031)\tTop5: 1.562 (avg: 4.406)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.297 (avg: 0.301)\tLoss: 5.1825 (avg: 5.2343)\tTop1: 0.000 (avg: 1.113)\tTop5: 3.125 (avg: 4.625)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2202\tTop 1 accuracy: 0.600\tTop 5 accuracy: 3.300\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.308 (avg: 0.293)\tLoss: 5.1194 (avg: 5.2063)\tTop1: 1.562 (avg: 1.438)\tTop5: 10.938 (avg: 5.188)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.291 (avg: 0.296)\tLoss: 5.2617 (avg: 5.2083)\tTop1: 1.562 (avg: 1.281)\tTop5: 6.250 (avg: 5.188)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.287 (avg: 0.297)\tLoss: 5.2255 (avg: 5.2100)\tTop1: 1.562 (avg: 1.292)\tTop5: 4.688 (avg: 5.042)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.291 (avg: 0.298)\tLoss: 5.2402 (avg: 5.2103)\tTop1: 0.000 (avg: 1.266)\tTop5: 3.125 (avg: 5.125)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.294 (avg: 0.299)\tLoss: 5.1332 (avg: 5.2139)\tTop1: 0.000 (avg: 1.225)\tTop5: 6.250 (avg: 5.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0965\tTop 1 accuracy: 1.100\tTop 5 accuracy: 4.350\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.289 (avg: 0.292)\tLoss: 5.2850 (avg: 5.1911)\tTop1: 0.000 (avg: 0.938)\tTop5: 3.125 (avg: 6.438)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.299 (avg: 0.295)\tLoss: 5.1431 (avg: 5.2021)\tTop1: 0.000 (avg: 1.031)\tTop5: 7.812 (avg: 5.969)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.287 (avg: 0.296)\tLoss: 5.1310 (avg: 5.1993)\tTop1: 1.562 (avg: 1.167)\tTop5: 3.125 (avg: 5.917)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.297 (avg: 0.299)\tLoss: 5.1782 (avg: 5.1949)\tTop1: 3.125 (avg: 1.312)\tTop5: 3.125 (avg: 5.922)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.292 (avg: 0.299)\tLoss: 5.1742 (avg: 5.1972)\tTop1: 0.000 (avg: 1.313)\tTop5: 1.562 (avg: 5.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1848\tTop 1 accuracy: 0.850\tTop 5 accuracy: 4.850\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.303 (avg: 0.299)\tLoss: 5.1356 (avg: 5.1766)\tTop1: 0.000 (avg: 1.500)\tTop5: 7.812 (avg: 7.438)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.294 (avg: 0.302)\tLoss: 5.1866 (avg: 5.1756)\tTop1: 1.562 (avg: 1.500)\tTop5: 3.125 (avg: 6.500)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.296 (avg: 0.302)\tLoss: 5.1423 (avg: 5.1805)\tTop1: 0.000 (avg: 1.438)\tTop5: 6.250 (avg: 6.125)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.293 (avg: 0.302)\tLoss: 5.2392 (avg: 5.1822)\tTop1: 1.562 (avg: 1.422)\tTop5: 6.250 (avg: 6.109)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.300 (avg: 0.302)\tLoss: 5.1953 (avg: 5.1807)\tTop1: 0.000 (avg: 1.363)\tTop5: 9.375 (avg: 5.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2076\tTop 1 accuracy: 0.950\tTop 5 accuracy: 5.350\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.291 (avg: 0.293)\tLoss: 5.2428 (avg: 5.1668)\tTop1: 3.125 (avg: 1.375)\tTop5: 3.125 (avg: 5.625)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.300 (avg: 0.297)\tLoss: 5.2282 (avg: 5.1718)\tTop1: 1.562 (avg: 1.500)\tTop5: 3.125 (avg: 5.750)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.294 (avg: 0.298)\tLoss: 5.1121 (avg: 5.1678)\tTop1: 1.562 (avg: 1.500)\tTop5: 7.812 (avg: 6.208)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.290 (avg: 0.299)\tLoss: 5.2296 (avg: 5.1703)\tTop1: 0.000 (avg: 1.578)\tTop5: 0.000 (avg: 6.078)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.288 (avg: 0.299)\tLoss: 5.3045 (avg: 5.1744)\tTop1: 0.000 (avg: 1.513)\tTop5: 0.000 (avg: 5.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1791\tTop 1 accuracy: 0.800\tTop 5 accuracy: 4.350\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.291 (avg: 0.291)\tLoss: 5.2484 (avg: 5.1300)\tTop1: 1.562 (avg: 0.750)\tTop5: 3.125 (avg: 6.938)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.287 (avg: 0.295)\tLoss: 5.2166 (avg: 5.1607)\tTop1: 1.562 (avg: 1.188)\tTop5: 7.812 (avg: 6.625)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.294 (avg: 0.298)\tLoss: 5.1132 (avg: 5.1623)\tTop1: 3.125 (avg: 1.188)\tTop5: 4.688 (avg: 6.396)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.298 (avg: 0.301)\tLoss: 5.0728 (avg: 5.1639)\tTop1: 3.125 (avg: 1.234)\tTop5: 6.250 (avg: 6.281)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.297 (avg: 0.302)\tLoss: 5.1077 (avg: 5.1635)\tTop1: 0.000 (avg: 1.225)\tTop5: 3.125 (avg: 6.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0715\tTop 1 accuracy: 0.750\tTop 5 accuracy: 5.400\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.287 (avg: 0.298)\tLoss: 5.0939 (avg: 5.1686)\tTop1: 1.562 (avg: 2.000)\tTop5: 12.500 (avg: 7.125)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.294 (avg: 0.299)\tLoss: 5.1673 (avg: 5.1637)\tTop1: 0.000 (avg: 1.625)\tTop5: 6.250 (avg: 6.625)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.296 (avg: 0.300)\tLoss: 5.2524 (avg: 5.1606)\tTop1: 0.000 (avg: 1.479)\tTop5: 1.562 (avg: 6.417)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.292 (avg: 0.301)\tLoss: 5.2078 (avg: 5.1643)\tTop1: 1.562 (avg: 1.453)\tTop5: 1.562 (avg: 6.156)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.292 (avg: 0.301)\tLoss: 5.1581 (avg: 5.1582)\tTop1: 0.000 (avg: 1.338)\tTop5: 3.125 (avg: 6.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1929\tTop 1 accuracy: 1.050\tTop 5 accuracy: 5.500\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.294 (avg: 0.295)\tLoss: 5.0712 (avg: 5.1405)\tTop1: 4.688 (avg: 1.375)\tTop5: 4.688 (avg: 5.812)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 5.1854 (avg: 5.1293)\tTop1: 4.688 (avg: 1.469)\tTop5: 12.500 (avg: 6.469)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.291 (avg: 0.297)\tLoss: 5.2138 (avg: 5.1426)\tTop1: 1.562 (avg: 1.479)\tTop5: 4.688 (avg: 6.146)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.295 (avg: 0.298)\tLoss: 5.2347 (avg: 5.1461)\tTop1: 3.125 (avg: 1.531)\tTop5: 4.688 (avg: 6.312)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.296 (avg: 0.298)\tLoss: 5.0864 (avg: 5.1509)\tTop1: 4.688 (avg: 1.538)\tTop5: 10.938 (avg: 6.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1211\tTop 1 accuracy: 1.200\tTop 5 accuracy: 5.700\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.298 (avg: 0.293)\tLoss: 5.1196 (avg: 5.1462)\tTop1: 1.562 (avg: 1.375)\tTop5: 6.250 (avg: 6.188)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.292 (avg: 0.296)\tLoss: 5.1320 (avg: 5.1386)\tTop1: 1.562 (avg: 1.344)\tTop5: 7.812 (avg: 6.375)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.293 (avg: 0.298)\tLoss: 5.0601 (avg: 5.1319)\tTop1: 0.000 (avg: 1.333)\tTop5: 3.125 (avg: 6.500)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.306 (avg: 0.299)\tLoss: 5.1463 (avg: 5.1313)\tTop1: 1.562 (avg: 1.422)\tTop5: 6.250 (avg: 6.484)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.293 (avg: 0.301)\tLoss: 5.1401 (avg: 5.1364)\tTop1: 3.125 (avg: 1.588)\tTop5: 9.375 (avg: 6.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0871\tTop 1 accuracy: 0.550\tTop 5 accuracy: 4.400\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.301 (avg: 0.294)\tLoss: 4.9703 (avg: 5.1284)\tTop1: 4.688 (avg: 1.312)\tTop5: 12.500 (avg: 6.312)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.294 (avg: 0.298)\tLoss: 5.0425 (avg: 5.1229)\tTop1: 1.562 (avg: 1.625)\tTop5: 4.688 (avg: 6.781)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.290 (avg: 0.299)\tLoss: 5.2508 (avg: 5.1275)\tTop1: 0.000 (avg: 1.583)\tTop5: 1.562 (avg: 6.646)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.295 (avg: 0.299)\tLoss: 5.1560 (avg: 5.1316)\tTop1: 3.125 (avg: 1.578)\tTop5: 7.812 (avg: 6.750)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.303 (avg: 0.299)\tLoss: 5.1981 (avg: 5.1301)\tTop1: 0.000 (avg: 1.575)\tTop5: 0.000 (avg: 6.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1188\tTop 1 accuracy: 0.850\tTop 5 accuracy: 4.550\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.293 (avg: 0.293)\tLoss: 5.0966 (avg: 5.1223)\tTop1: 1.562 (avg: 1.750)\tTop5: 6.250 (avg: 7.438)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.303 (avg: 0.296)\tLoss: 5.0099 (avg: 5.1151)\tTop1: 0.000 (avg: 1.844)\tTop5: 3.125 (avg: 7.375)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.291 (avg: 0.298)\tLoss: 5.1760 (avg: 5.1246)\tTop1: 1.562 (avg: 1.750)\tTop5: 6.250 (avg: 6.958)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.291 (avg: 0.298)\tLoss: 5.1141 (avg: 5.1310)\tTop1: 1.562 (avg: 1.672)\tTop5: 3.125 (avg: 6.750)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.290 (avg: 0.298)\tLoss: 5.1699 (avg: 5.1251)\tTop1: 0.000 (avg: 1.838)\tTop5: 4.688 (avg: 6.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1019\tTop 1 accuracy: 1.550\tTop 5 accuracy: 5.950\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.300 (avg: 0.298)\tLoss: 5.2037 (avg: 5.1324)\tTop1: 0.000 (avg: 1.562)\tTop5: 12.500 (avg: 6.625)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.298 (avg: 0.302)\tLoss: 5.1165 (avg: 5.1240)\tTop1: 1.562 (avg: 1.438)\tTop5: 1.562 (avg: 6.406)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.295 (avg: 0.302)\tLoss: 5.1461 (avg: 5.1219)\tTop1: 0.000 (avg: 1.542)\tTop5: 4.688 (avg: 6.583)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.289 (avg: 0.302)\tLoss: 5.0760 (avg: 5.1169)\tTop1: 1.562 (avg: 1.562)\tTop5: 6.250 (avg: 6.859)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.294 (avg: 0.302)\tLoss: 5.1044 (avg: 5.1175)\tTop1: 1.562 (avg: 1.575)\tTop5: 6.250 (avg: 6.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1396\tTop 1 accuracy: 1.100\tTop 5 accuracy: 5.450\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.291 (avg: 0.291)\tLoss: 5.0602 (avg: 5.0993)\tTop1: 1.562 (avg: 1.500)\tTop5: 4.688 (avg: 6.250)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.290 (avg: 0.294)\tLoss: 4.9755 (avg: 5.0998)\tTop1: 1.562 (avg: 1.844)\tTop5: 12.500 (avg: 7.688)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.288 (avg: 0.295)\tLoss: 5.1066 (avg: 5.1095)\tTop1: 0.000 (avg: 1.646)\tTop5: 14.062 (avg: 7.583)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.296 (avg: 0.295)\tLoss: 5.1062 (avg: 5.1089)\tTop1: 0.000 (avg: 1.594)\tTop5: 3.125 (avg: 7.688)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.296 (avg: 0.296)\tLoss: 5.0752 (avg: 5.1091)\tTop1: 1.562 (avg: 1.600)\tTop5: 9.375 (avg: 7.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0674\tTop 1 accuracy: 0.950\tTop 5 accuracy: 6.250\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.295 (avg: 0.303)\tLoss: 5.1336 (avg: 5.0806)\tTop1: 4.688 (avg: 2.312)\tTop5: 10.938 (avg: 8.250)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.291 (avg: 0.300)\tLoss: 5.1462 (avg: 5.0805)\tTop1: 0.000 (avg: 2.000)\tTop5: 7.812 (avg: 8.156)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.289 (avg: 0.300)\tLoss: 5.0408 (avg: 5.0797)\tTop1: 3.125 (avg: 2.083)\tTop5: 9.375 (avg: 8.333)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.299 (avg: 0.299)\tLoss: 5.0569 (avg: 5.0764)\tTop1: 1.562 (avg: 2.031)\tTop5: 4.688 (avg: 8.312)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.290 (avg: 0.299)\tLoss: 5.1262 (avg: 5.0730)\tTop1: 0.000 (avg: 1.925)\tTop5: 7.812 (avg: 7.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9346\tTop 1 accuracy: 1.750\tTop 5 accuracy: 7.650\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.291 (avg: 0.292)\tLoss: 5.1032 (avg: 5.0495)\tTop1: 1.562 (avg: 2.375)\tTop5: 9.375 (avg: 9.062)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.296 (avg: 0.295)\tLoss: 5.1287 (avg: 5.0351)\tTop1: 0.000 (avg: 1.969)\tTop5: 7.812 (avg: 8.781)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.292 (avg: 0.296)\tLoss: 5.0384 (avg: 5.0287)\tTop1: 4.688 (avg: 2.042)\tTop5: 9.375 (avg: 8.854)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.284 (avg: 0.296)\tLoss: 5.1257 (avg: 5.0374)\tTop1: 0.000 (avg: 1.906)\tTop5: 6.250 (avg: 8.562)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.293 (avg: 0.297)\tLoss: 5.1089 (avg: 5.0395)\tTop1: 1.562 (avg: 1.938)\tTop5: 7.812 (avg: 8.812)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0234\tTop 1 accuracy: 2.000\tTop 5 accuracy: 8.600\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.296 (avg: 0.294)\tLoss: 4.9898 (avg: 5.0262)\tTop1: 1.562 (avg: 2.562)\tTop5: 14.062 (avg: 9.375)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.291 (avg: 0.297)\tLoss: 4.8728 (avg: 5.0191)\tTop1: 3.125 (avg: 2.062)\tTop5: 12.500 (avg: 8.969)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.295 (avg: 0.299)\tLoss: 4.9846 (avg: 5.0087)\tTop1: 0.000 (avg: 2.167)\tTop5: 3.125 (avg: 9.229)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.302 (avg: 0.298)\tLoss: 4.8499 (avg: 5.0043)\tTop1: 3.125 (avg: 2.266)\tTop5: 15.625 (avg: 9.516)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.291 (avg: 0.298)\tLoss: 4.9523 (avg: 4.9981)\tTop1: 4.688 (avg: 2.375)\tTop5: 7.812 (avg: 9.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1514\tTop 1 accuracy: 2.200\tTop 5 accuracy: 10.050\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.287 (avg: 0.290)\tLoss: 5.0632 (avg: 4.9486)\tTop1: 1.562 (avg: 3.125)\tTop5: 9.375 (avg: 10.500)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.300 (avg: 0.295)\tLoss: 4.9402 (avg: 4.9612)\tTop1: 1.562 (avg: 2.656)\tTop5: 6.250 (avg: 10.125)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.287 (avg: 0.296)\tLoss: 5.0252 (avg: 4.9465)\tTop1: 3.125 (avg: 2.688)\tTop5: 7.812 (avg: 10.333)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.287 (avg: 0.296)\tLoss: 4.7935 (avg: 4.9409)\tTop1: 1.562 (avg: 2.531)\tTop5: 14.062 (avg: 10.344)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.288 (avg: 0.296)\tLoss: 4.8343 (avg: 4.9416)\tTop1: 1.562 (avg: 2.425)\tTop5: 6.250 (avg: 10.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9365\tTop 1 accuracy: 2.300\tTop 5 accuracy: 10.350\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.288 (avg: 0.290)\tLoss: 4.8012 (avg: 4.9136)\tTop1: 9.375 (avg: 2.812)\tTop5: 21.875 (avg: 10.812)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.287 (avg: 0.294)\tLoss: 4.7095 (avg: 4.9199)\tTop1: 6.250 (avg: 2.531)\tTop5: 17.188 (avg: 10.531)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.288 (avg: 0.295)\tLoss: 4.8235 (avg: 4.9231)\tTop1: 3.125 (avg: 2.312)\tTop5: 9.375 (avg: 10.458)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.291 (avg: 0.296)\tLoss: 4.7931 (avg: 4.9146)\tTop1: 7.812 (avg: 2.547)\tTop5: 14.062 (avg: 10.750)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.296 (avg: 0.297)\tLoss: 4.7748 (avg: 4.9036)\tTop1: 7.812 (avg: 2.650)\tTop5: 14.062 (avg: 10.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7999\tTop 1 accuracy: 3.150\tTop 5 accuracy: 11.200\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.290 (avg: 0.291)\tLoss: 4.9011 (avg: 4.8481)\tTop1: 4.688 (avg: 3.875)\tTop5: 9.375 (avg: 12.938)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.291 (avg: 0.295)\tLoss: 4.8943 (avg: 4.8859)\tTop1: 1.562 (avg: 3.281)\tTop5: 10.938 (avg: 11.906)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.294 (avg: 0.296)\tLoss: 4.8590 (avg: 4.8950)\tTop1: 1.562 (avg: 2.958)\tTop5: 7.812 (avg: 11.583)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.287 (avg: 0.296)\tLoss: 4.9154 (avg: 4.8944)\tTop1: 3.125 (avg: 2.922)\tTop5: 10.938 (avg: 11.406)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.6027 (avg: 4.8891)\tTop1: 4.688 (avg: 2.963)\tTop5: 20.312 (avg: 11.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9251\tTop 1 accuracy: 2.850\tTop 5 accuracy: 11.250\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.293 (avg: 0.291)\tLoss: 4.8734 (avg: 4.7912)\tTop1: 0.000 (avg: 2.938)\tTop5: 18.750 (avg: 15.188)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.296 (avg: 0.295)\tLoss: 4.9535 (avg: 4.8465)\tTop1: 1.562 (avg: 2.750)\tTop5: 15.625 (avg: 13.156)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.292 (avg: 0.296)\tLoss: 4.7127 (avg: 4.8424)\tTop1: 0.000 (avg: 2.771)\tTop5: 9.375 (avg: 12.979)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.294 (avg: 0.297)\tLoss: 4.9377 (avg: 4.8485)\tTop1: 0.000 (avg: 2.781)\tTop5: 4.688 (avg: 12.859)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.293 (avg: 0.297)\tLoss: 4.8368 (avg: 4.8403)\tTop1: 1.562 (avg: 2.863)\tTop5: 17.188 (avg: 13.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0303\tTop 1 accuracy: 3.100\tTop 5 accuracy: 12.250\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.285 (avg: 0.295)\tLoss: 4.7990 (avg: 4.7556)\tTop1: 6.250 (avg: 3.125)\tTop5: 10.938 (avg: 14.562)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.8195 (avg: 4.7924)\tTop1: 3.125 (avg: 3.250)\tTop5: 10.938 (avg: 13.438)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.288 (avg: 0.296)\tLoss: 4.9618 (avg: 4.8132)\tTop1: 3.125 (avg: 3.021)\tTop5: 4.688 (avg: 13.167)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.297 (avg: 0.298)\tLoss: 4.8596 (avg: 4.8135)\tTop1: 6.250 (avg: 3.234)\tTop5: 18.750 (avg: 13.281)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.291 (avg: 0.300)\tLoss: 4.8082 (avg: 4.8132)\tTop1: 3.125 (avg: 3.263)\tTop5: 15.625 (avg: 13.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0308\tTop 1 accuracy: 2.850\tTop 5 accuracy: 11.450\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.298 (avg: 0.292)\tLoss: 4.9476 (avg: 4.7871)\tTop1: 0.000 (avg: 3.625)\tTop5: 4.688 (avg: 13.312)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.288 (avg: 0.295)\tLoss: 4.7773 (avg: 4.7938)\tTop1: 3.125 (avg: 3.344)\tTop5: 9.375 (avg: 12.875)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.288 (avg: 0.296)\tLoss: 4.9144 (avg: 4.7940)\tTop1: 0.000 (avg: 3.458)\tTop5: 17.188 (avg: 13.542)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.7501 (avg: 4.7968)\tTop1: 4.688 (avg: 3.469)\tTop5: 15.625 (avg: 13.500)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.290 (avg: 0.297)\tLoss: 4.7739 (avg: 4.7918)\tTop1: 4.688 (avg: 3.425)\tTop5: 17.188 (avg: 13.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5255\tTop 1 accuracy: 4.050\tTop 5 accuracy: 14.300\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.289 (avg: 0.292)\tLoss: 4.6031 (avg: 4.6252)\tTop1: 4.688 (avg: 5.500)\tTop5: 18.750 (avg: 19.875)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.286 (avg: 0.294)\tLoss: 4.5701 (avg: 4.5978)\tTop1: 10.938 (avg: 5.750)\tTop5: 23.438 (avg: 19.906)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.287 (avg: 0.295)\tLoss: 4.7155 (avg: 4.6005)\tTop1: 1.562 (avg: 5.854)\tTop5: 12.500 (avg: 19.771)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.297 (avg: 0.295)\tLoss: 4.6780 (avg: 4.6047)\tTop1: 1.562 (avg: 5.719)\tTop5: 17.188 (avg: 19.531)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.295 (avg: 0.296)\tLoss: 4.4050 (avg: 4.5970)\tTop1: 7.812 (avg: 5.775)\tTop5: 23.438 (avg: 19.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4526\tTop 1 accuracy: 5.100\tTop 5 accuracy: 17.400\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.294 (avg: 0.292)\tLoss: 4.6088 (avg: 4.5415)\tTop1: 3.125 (avg: 6.188)\tTop5: 12.500 (avg: 21.000)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.296 (avg: 0.295)\tLoss: 4.5974 (avg: 4.5759)\tTop1: 6.250 (avg: 5.875)\tTop5: 23.438 (avg: 19.969)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.291 (avg: 0.297)\tLoss: 4.4586 (avg: 4.5522)\tTop1: 4.688 (avg: 6.375)\tTop5: 26.562 (avg: 20.604)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.292 (avg: 0.297)\tLoss: 4.7378 (avg: 4.5461)\tTop1: 3.125 (avg: 6.391)\tTop5: 14.062 (avg: 20.938)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.291 (avg: 0.297)\tLoss: 4.5545 (avg: 4.5362)\tTop1: 6.250 (avg: 6.300)\tTop5: 17.188 (avg: 20.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4882\tTop 1 accuracy: 5.550\tTop 5 accuracy: 17.800\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.294 (avg: 0.292)\tLoss: 4.6471 (avg: 4.5176)\tTop1: 9.375 (avg: 7.375)\tTop5: 20.312 (avg: 21.875)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.295 (avg: 0.296)\tLoss: 4.3745 (avg: 4.5120)\tTop1: 6.250 (avg: 7.000)\tTop5: 21.875 (avg: 21.500)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.290 (avg: 0.296)\tLoss: 4.4743 (avg: 4.5134)\tTop1: 6.250 (avg: 6.729)\tTop5: 23.438 (avg: 21.396)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.286 (avg: 0.296)\tLoss: 4.4698 (avg: 4.5139)\tTop1: 7.812 (avg: 6.719)\tTop5: 21.875 (avg: 21.172)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.301 (avg: 0.296)\tLoss: 4.4148 (avg: 4.5106)\tTop1: 12.500 (avg: 6.813)\tTop5: 32.812 (avg: 21.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3533\tTop 1 accuracy: 5.200\tTop 5 accuracy: 18.900\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.288 (avg: 0.292)\tLoss: 4.8280 (avg: 4.4371)\tTop1: 6.250 (avg: 7.875)\tTop5: 18.750 (avg: 23.500)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.290 (avg: 0.294)\tLoss: 4.4672 (avg: 4.4786)\tTop1: 4.688 (avg: 6.906)\tTop5: 28.125 (avg: 21.875)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.302 (avg: 0.296)\tLoss: 4.7414 (avg: 4.4741)\tTop1: 4.688 (avg: 6.938)\tTop5: 15.625 (avg: 21.792)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.287 (avg: 0.297)\tLoss: 4.4560 (avg: 4.4775)\tTop1: 6.250 (avg: 6.781)\tTop5: 15.625 (avg: 21.703)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.289 (avg: 0.297)\tLoss: 4.5370 (avg: 4.4910)\tTop1: 4.688 (avg: 6.713)\tTop5: 18.750 (avg: 21.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4602\tTop 1 accuracy: 5.150\tTop 5 accuracy: 18.700\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.289 (avg: 0.292)\tLoss: 4.7135 (avg: 4.4562)\tTop1: 4.688 (avg: 7.250)\tTop5: 21.875 (avg: 22.625)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.289 (avg: 0.295)\tLoss: 4.5077 (avg: 4.4660)\tTop1: 7.812 (avg: 7.625)\tTop5: 18.750 (avg: 22.781)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.290 (avg: 0.296)\tLoss: 4.7488 (avg: 4.4807)\tTop1: 3.125 (avg: 7.375)\tTop5: 12.500 (avg: 22.417)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.293 (avg: 0.296)\tLoss: 4.6610 (avg: 4.4716)\tTop1: 7.812 (avg: 7.438)\tTop5: 18.750 (avg: 22.172)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.292 (avg: 0.297)\tLoss: 4.7737 (avg: 4.4745)\tTop1: 7.812 (avg: 7.213)\tTop5: 17.188 (avg: 21.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3120\tTop 1 accuracy: 5.900\tTop 5 accuracy: 18.200\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.291 (avg: 0.292)\tLoss: 4.5494 (avg: 4.4523)\tTop1: 10.938 (avg: 7.312)\tTop5: 20.312 (avg: 22.750)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.2784 (avg: 4.4248)\tTop1: 7.812 (avg: 7.188)\tTop5: 23.438 (avg: 23.719)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.287 (avg: 0.297)\tLoss: 4.5030 (avg: 4.4485)\tTop1: 7.812 (avg: 7.479)\tTop5: 23.438 (avg: 22.771)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.291 (avg: 0.297)\tLoss: 4.6531 (avg: 4.4561)\tTop1: 3.125 (avg: 7.453)\tTop5: 14.062 (avg: 22.688)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.288 (avg: 0.297)\tLoss: 4.6483 (avg: 4.4628)\tTop1: 7.812 (avg: 7.138)\tTop5: 15.625 (avg: 22.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3970\tTop 1 accuracy: 5.450\tTop 5 accuracy: 17.950\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.290 (avg: 0.290)\tLoss: 4.2857 (avg: 4.4449)\tTop1: 9.375 (avg: 6.875)\tTop5: 20.312 (avg: 22.062)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.290 (avg: 0.293)\tLoss: 4.3053 (avg: 4.4620)\tTop1: 7.812 (avg: 7.031)\tTop5: 35.938 (avg: 22.125)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.299 (avg: 0.295)\tLoss: 4.5649 (avg: 4.4586)\tTop1: 9.375 (avg: 7.021)\tTop5: 20.312 (avg: 22.083)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.288 (avg: 0.295)\tLoss: 4.4676 (avg: 4.4631)\tTop1: 6.250 (avg: 7.156)\tTop5: 17.188 (avg: 22.047)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.2864 (avg: 4.4547)\tTop1: 7.812 (avg: 7.188)\tTop5: 26.562 (avg: 22.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3283\tTop 1 accuracy: 5.500\tTop 5 accuracy: 18.850\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.296 (avg: 0.291)\tLoss: 4.1949 (avg: 4.4292)\tTop1: 10.938 (avg: 8.625)\tTop5: 28.125 (avg: 24.562)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.286 (avg: 0.295)\tLoss: 4.5107 (avg: 4.4218)\tTop1: 7.812 (avg: 7.906)\tTop5: 21.875 (avg: 24.375)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.288 (avg: 0.297)\tLoss: 4.3475 (avg: 4.4244)\tTop1: 9.375 (avg: 7.521)\tTop5: 26.562 (avg: 23.458)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.296 (avg: 0.299)\tLoss: 4.8040 (avg: 4.4322)\tTop1: 10.938 (avg: 7.406)\tTop5: 17.188 (avg: 23.156)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.298 (avg: 0.299)\tLoss: 4.4074 (avg: 4.4308)\tTop1: 9.375 (avg: 7.338)\tTop5: 15.625 (avg: 23.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3504\tTop 1 accuracy: 5.150\tTop 5 accuracy: 18.250\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.291 (avg: 0.291)\tLoss: 4.3373 (avg: 4.4073)\tTop1: 9.375 (avg: 7.188)\tTop5: 31.250 (avg: 24.750)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.290 (avg: 0.295)\tLoss: 4.6193 (avg: 4.4256)\tTop1: 9.375 (avg: 7.125)\tTop5: 20.312 (avg: 24.125)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.294 (avg: 0.296)\tLoss: 4.3512 (avg: 4.4170)\tTop1: 7.812 (avg: 7.417)\tTop5: 26.562 (avg: 24.292)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.6280 (avg: 4.4259)\tTop1: 3.125 (avg: 7.156)\tTop5: 20.312 (avg: 24.188)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.288 (avg: 0.296)\tLoss: 4.4673 (avg: 4.4219)\tTop1: 6.250 (avg: 7.050)\tTop5: 31.250 (avg: 23.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0714\tTop 1 accuracy: 5.650\tTop 5 accuracy: 19.850\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.293 (avg: 0.291)\tLoss: 4.5390 (avg: 4.4172)\tTop1: 7.812 (avg: 6.812)\tTop5: 23.438 (avg: 22.188)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.298 (avg: 0.294)\tLoss: 4.1872 (avg: 4.3941)\tTop1: 9.375 (avg: 7.906)\tTop5: 32.812 (avg: 23.812)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.291 (avg: 0.295)\tLoss: 4.4865 (avg: 4.3937)\tTop1: 9.375 (avg: 7.917)\tTop5: 23.438 (avg: 23.583)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.287 (avg: 0.296)\tLoss: 4.4180 (avg: 4.4074)\tTop1: 6.250 (avg: 7.750)\tTop5: 28.125 (avg: 23.453)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.289 (avg: 0.297)\tLoss: 4.4968 (avg: 4.4092)\tTop1: 6.250 (avg: 7.750)\tTop5: 18.750 (avg: 23.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5149\tTop 1 accuracy: 5.750\tTop 5 accuracy: 19.450\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.296 (avg: 0.293)\tLoss: 4.2247 (avg: 4.4009)\tTop1: 4.688 (avg: 7.750)\tTop5: 28.125 (avg: 23.625)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.287 (avg: 0.295)\tLoss: 4.4299 (avg: 4.3878)\tTop1: 6.250 (avg: 7.562)\tTop5: 28.125 (avg: 24.125)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.291 (avg: 0.296)\tLoss: 4.4977 (avg: 4.4058)\tTop1: 9.375 (avg: 7.125)\tTop5: 20.312 (avg: 23.625)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.296 (avg: 0.297)\tLoss: 4.4042 (avg: 4.4055)\tTop1: 9.375 (avg: 7.312)\tTop5: 25.000 (avg: 23.703)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.290 (avg: 0.297)\tLoss: 4.2011 (avg: 4.3962)\tTop1: 9.375 (avg: 7.375)\tTop5: 28.125 (avg: 24.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3101\tTop 1 accuracy: 6.450\tTop 5 accuracy: 20.200\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.285 (avg: 0.291)\tLoss: 4.4188 (avg: 4.3382)\tTop1: 9.375 (avg: 9.312)\tTop5: 21.875 (avg: 25.375)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.289 (avg: 0.294)\tLoss: 4.1123 (avg: 4.3588)\tTop1: 14.062 (avg: 8.344)\tTop5: 28.125 (avg: 24.344)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.291 (avg: 0.295)\tLoss: 4.2288 (avg: 4.3679)\tTop1: 6.250 (avg: 8.271)\tTop5: 25.000 (avg: 24.604)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.290 (avg: 0.296)\tLoss: 4.2227 (avg: 4.3652)\tTop1: 10.938 (avg: 8.125)\tTop5: 28.125 (avg: 24.562)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.4988 (avg: 4.3802)\tTop1: 6.250 (avg: 7.838)\tTop5: 18.750 (avg: 24.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3682\tTop 1 accuracy: 6.650\tTop 5 accuracy: 20.200\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.296 (avg: 0.291)\tLoss: 4.2239 (avg: 4.3939)\tTop1: 12.500 (avg: 7.812)\tTop5: 29.688 (avg: 23.625)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.287 (avg: 0.295)\tLoss: 3.9747 (avg: 4.3606)\tTop1: 12.500 (avg: 7.844)\tTop5: 39.062 (avg: 24.562)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.5061 (avg: 4.3562)\tTop1: 3.125 (avg: 7.854)\tTop5: 18.750 (avg: 24.604)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.294 (avg: 0.297)\tLoss: 4.6407 (avg: 4.3678)\tTop1: 4.688 (avg: 7.641)\tTop5: 18.750 (avg: 24.500)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.294 (avg: 0.297)\tLoss: 4.4185 (avg: 4.3697)\tTop1: 6.250 (avg: 7.625)\tTop5: 23.438 (avg: 24.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3203\tTop 1 accuracy: 6.750\tTop 5 accuracy: 19.600\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.291 (avg: 0.292)\tLoss: 4.4693 (avg: 4.3334)\tTop1: 10.938 (avg: 8.062)\tTop5: 29.688 (avg: 25.625)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.286 (avg: 0.295)\tLoss: 4.7213 (avg: 4.3452)\tTop1: 4.688 (avg: 8.031)\tTop5: 18.750 (avg: 24.875)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.300 (avg: 0.297)\tLoss: 4.2403 (avg: 4.3549)\tTop1: 6.250 (avg: 7.521)\tTop5: 25.000 (avg: 24.438)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.291 (avg: 0.298)\tLoss: 4.4699 (avg: 4.3604)\tTop1: 4.688 (avg: 7.688)\tTop5: 18.750 (avg: 24.453)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.288 (avg: 0.298)\tLoss: 4.3791 (avg: 4.3546)\tTop1: 7.812 (avg: 7.850)\tTop5: 23.438 (avg: 24.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4482\tTop 1 accuracy: 6.450\tTop 5 accuracy: 20.300\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.300 (avg: 0.292)\tLoss: 4.5529 (avg: 4.3506)\tTop1: 7.812 (avg: 8.125)\tTop5: 15.625 (avg: 24.125)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.288 (avg: 0.297)\tLoss: 4.1967 (avg: 4.3661)\tTop1: 10.938 (avg: 7.656)\tTop5: 35.938 (avg: 24.531)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.289 (avg: 0.297)\tLoss: 4.4905 (avg: 4.3635)\tTop1: 1.562 (avg: 7.542)\tTop5: 10.938 (avg: 24.542)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.287 (avg: 0.297)\tLoss: 4.0967 (avg: 4.3485)\tTop1: 9.375 (avg: 8.047)\tTop5: 31.250 (avg: 24.766)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.288 (avg: 0.297)\tLoss: 4.4806 (avg: 4.3437)\tTop1: 3.125 (avg: 8.050)\tTop5: 18.750 (avg: 25.013)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1932\tTop 1 accuracy: 6.750\tTop 5 accuracy: 21.350\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.290 (avg: 0.292)\tLoss: 3.9816 (avg: 4.3604)\tTop1: 10.938 (avg: 7.688)\tTop5: 39.062 (avg: 26.062)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.284 (avg: 0.294)\tLoss: 4.0341 (avg: 4.3262)\tTop1: 7.812 (avg: 8.094)\tTop5: 23.438 (avg: 25.969)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.290 (avg: 0.296)\tLoss: 4.3918 (avg: 4.3093)\tTop1: 4.688 (avg: 8.396)\tTop5: 23.438 (avg: 25.979)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.3086 (avg: 4.3031)\tTop1: 4.688 (avg: 8.484)\tTop5: 25.000 (avg: 26.203)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.3267 (avg: 4.3251)\tTop1: 10.938 (avg: 8.363)\tTop5: 25.000 (avg: 25.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1784\tTop 1 accuracy: 6.200\tTop 5 accuracy: 20.600\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.301 (avg: 0.291)\tLoss: 4.3616 (avg: 4.3101)\tTop1: 7.812 (avg: 9.688)\tTop5: 20.312 (avg: 26.312)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.289 (avg: 0.294)\tLoss: 4.3314 (avg: 4.3199)\tTop1: 3.125 (avg: 9.156)\tTop5: 17.188 (avg: 26.156)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.292 (avg: 0.295)\tLoss: 4.3888 (avg: 4.3320)\tTop1: 9.375 (avg: 8.771)\tTop5: 26.562 (avg: 25.500)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.0829 (avg: 4.3175)\tTop1: 7.812 (avg: 8.859)\tTop5: 29.688 (avg: 26.031)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.5154 (avg: 4.3166)\tTop1: 4.688 (avg: 8.675)\tTop5: 23.438 (avg: 25.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3607\tTop 1 accuracy: 7.450\tTop 5 accuracy: 21.800\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.292 (avg: 0.293)\tLoss: 4.2639 (avg: 4.2971)\tTop1: 7.812 (avg: 8.375)\tTop5: 26.562 (avg: 27.500)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.287 (avg: 0.296)\tLoss: 4.2771 (avg: 4.3055)\tTop1: 6.250 (avg: 8.344)\tTop5: 25.000 (avg: 26.281)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.289 (avg: 0.297)\tLoss: 4.2343 (avg: 4.3008)\tTop1: 3.125 (avg: 8.271)\tTop5: 20.312 (avg: 25.979)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.293 (avg: 0.298)\tLoss: 4.1800 (avg: 4.3021)\tTop1: 7.812 (avg: 8.375)\tTop5: 26.562 (avg: 26.062)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.297 (avg: 0.298)\tLoss: 4.1810 (avg: 4.3073)\tTop1: 9.375 (avg: 8.250)\tTop5: 25.000 (avg: 26.013)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4674\tTop 1 accuracy: 6.950\tTop 5 accuracy: 21.350\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.290 (avg: 0.291)\tLoss: 4.3098 (avg: 4.2833)\tTop1: 4.688 (avg: 8.750)\tTop5: 20.312 (avg: 26.938)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.290 (avg: 0.294)\tLoss: 4.3663 (avg: 4.3137)\tTop1: 6.250 (avg: 8.719)\tTop5: 14.062 (avg: 25.469)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.288 (avg: 0.295)\tLoss: 4.2989 (avg: 4.3330)\tTop1: 12.500 (avg: 8.292)\tTop5: 28.125 (avg: 24.729)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.294 (avg: 0.295)\tLoss: 4.4056 (avg: 4.3208)\tTop1: 9.375 (avg: 8.594)\tTop5: 23.438 (avg: 25.156)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.290 (avg: 0.296)\tLoss: 4.2741 (avg: 4.3170)\tTop1: 6.250 (avg: 8.725)\tTop5: 28.125 (avg: 25.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4729\tTop 1 accuracy: 7.150\tTop 5 accuracy: 22.150\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.288 (avg: 0.292)\tLoss: 4.3153 (avg: 4.2118)\tTop1: 4.688 (avg: 10.812)\tTop5: 25.000 (avg: 27.688)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.296 (avg: 0.295)\tLoss: 4.5355 (avg: 4.2815)\tTop1: 7.812 (avg: 9.312)\tTop5: 20.312 (avg: 26.625)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.288 (avg: 0.296)\tLoss: 3.8893 (avg: 4.2988)\tTop1: 15.625 (avg: 9.292)\tTop5: 43.750 (avg: 26.792)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.287 (avg: 0.296)\tLoss: 4.4384 (avg: 4.2864)\tTop1: 6.250 (avg: 9.016)\tTop5: 18.750 (avg: 26.906)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.288 (avg: 0.296)\tLoss: 4.2422 (avg: 4.2780)\tTop1: 6.250 (avg: 9.062)\tTop5: 31.250 (avg: 27.013)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3488\tTop 1 accuracy: 7.900\tTop 5 accuracy: 21.550\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.292 (avg: 0.292)\tLoss: 4.8351 (avg: 4.2405)\tTop1: 7.812 (avg: 9.312)\tTop5: 17.188 (avg: 26.312)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.290 (avg: 0.296)\tLoss: 4.4831 (avg: 4.2683)\tTop1: 4.688 (avg: 9.344)\tTop5: 25.000 (avg: 26.969)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.291 (avg: 0.297)\tLoss: 4.2930 (avg: 4.2880)\tTop1: 9.375 (avg: 9.188)\tTop5: 28.125 (avg: 26.396)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.293 (avg: 0.297)\tLoss: 4.1225 (avg: 4.2753)\tTop1: 7.812 (avg: 9.156)\tTop5: 25.000 (avg: 26.500)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.300 (avg: 0.298)\tLoss: 4.2309 (avg: 4.2650)\tTop1: 7.812 (avg: 9.150)\tTop5: 25.000 (avg: 26.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3269\tTop 1 accuracy: 6.750\tTop 5 accuracy: 22.400\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.287 (avg: 0.291)\tLoss: 3.9905 (avg: 4.2015)\tTop1: 10.938 (avg: 9.938)\tTop5: 37.500 (avg: 28.375)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.296 (avg: 0.294)\tLoss: 4.0624 (avg: 4.2174)\tTop1: 4.688 (avg: 8.812)\tTop5: 34.375 (avg: 28.219)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.307 (avg: 0.296)\tLoss: 4.4068 (avg: 4.2374)\tTop1: 6.250 (avg: 8.938)\tTop5: 28.125 (avg: 28.021)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.290 (avg: 0.296)\tLoss: 3.9846 (avg: 4.2463)\tTop1: 7.812 (avg: 9.047)\tTop5: 40.625 (avg: 27.844)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.287 (avg: 0.297)\tLoss: 4.2410 (avg: 4.2575)\tTop1: 10.938 (avg: 9.138)\tTop5: 31.250 (avg: 27.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2053\tTop 1 accuracy: 7.850\tTop 5 accuracy: 22.950\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.304 (avg: 0.291)\tLoss: 4.2119 (avg: 4.2165)\tTop1: 10.938 (avg: 10.125)\tTop5: 26.562 (avg: 28.500)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.289 (avg: 0.294)\tLoss: 4.6228 (avg: 4.2615)\tTop1: 3.125 (avg: 9.938)\tTop5: 12.500 (avg: 27.531)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.288 (avg: 0.295)\tLoss: 4.7163 (avg: 4.2641)\tTop1: 6.250 (avg: 9.417)\tTop5: 17.188 (avg: 27.250)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.290 (avg: 0.296)\tLoss: 4.2330 (avg: 4.2549)\tTop1: 9.375 (avg: 9.266)\tTop5: 32.812 (avg: 27.516)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.283 (avg: 0.296)\tLoss: 3.9627 (avg: 4.2502)\tTop1: 9.375 (avg: 9.150)\tTop5: 37.500 (avg: 27.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2833\tTop 1 accuracy: 7.600\tTop 5 accuracy: 23.250\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.289 (avg: 0.293)\tLoss: 4.1764 (avg: 4.2337)\tTop1: 7.812 (avg: 9.062)\tTop5: 25.000 (avg: 27.562)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.290 (avg: 0.295)\tLoss: 4.3941 (avg: 4.2382)\tTop1: 4.688 (avg: 9.094)\tTop5: 21.875 (avg: 27.781)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.287 (avg: 0.296)\tLoss: 4.0631 (avg: 4.2399)\tTop1: 7.812 (avg: 8.896)\tTop5: 29.688 (avg: 27.750)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.294 (avg: 0.297)\tLoss: 4.3311 (avg: 4.2409)\tTop1: 4.688 (avg: 8.953)\tTop5: 25.000 (avg: 27.672)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.289 (avg: 0.297)\tLoss: 3.9872 (avg: 4.2435)\tTop1: 12.500 (avg: 8.938)\tTop5: 31.250 (avg: 27.813)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1491\tTop 1 accuracy: 6.950\tTop 5 accuracy: 21.900\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.296 (avg: 0.292)\tLoss: 4.0260 (avg: 4.1591)\tTop1: 6.250 (avg: 10.062)\tTop5: 23.438 (avg: 28.938)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.301 (avg: 0.296)\tLoss: 3.9863 (avg: 4.1849)\tTop1: 9.375 (avg: 9.875)\tTop5: 34.375 (avg: 28.562)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.294 (avg: 0.297)\tLoss: 4.0463 (avg: 4.2142)\tTop1: 12.500 (avg: 9.646)\tTop5: 34.375 (avg: 27.646)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.291 (avg: 0.297)\tLoss: 4.4620 (avg: 4.2148)\tTop1: 3.125 (avg: 9.625)\tTop5: 20.312 (avg: 27.562)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.292 (avg: 0.297)\tLoss: 4.1346 (avg: 4.2326)\tTop1: 6.250 (avg: 9.488)\tTop5: 26.562 (avg: 27.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3237\tTop 1 accuracy: 7.400\tTop 5 accuracy: 23.100\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.284 (avg: 0.292)\tLoss: 4.0904 (avg: 4.2301)\tTop1: 14.062 (avg: 10.188)\tTop5: 34.375 (avg: 28.250)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.289 (avg: 0.295)\tLoss: 4.3942 (avg: 4.2158)\tTop1: 6.250 (avg: 9.875)\tTop5: 25.000 (avg: 28.219)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.1587 (avg: 4.2293)\tTop1: 6.250 (avg: 9.396)\tTop5: 25.000 (avg: 27.729)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.293 (avg: 0.296)\tLoss: 4.1160 (avg: 4.2168)\tTop1: 10.938 (avg: 9.547)\tTop5: 29.688 (avg: 28.359)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.296 (avg: 0.297)\tLoss: 4.3677 (avg: 4.2115)\tTop1: 7.812 (avg: 9.788)\tTop5: 26.562 (avg: 28.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3212\tTop 1 accuracy: 8.550\tTop 5 accuracy: 23.600\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.289 (avg: 0.292)\tLoss: 4.2517 (avg: 4.1468)\tTop1: 4.688 (avg: 10.750)\tTop5: 34.375 (avg: 30.375)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.291 (avg: 0.295)\tLoss: 4.3661 (avg: 4.1653)\tTop1: 10.938 (avg: 10.438)\tTop5: 28.125 (avg: 29.875)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.298 (avg: 0.296)\tLoss: 4.3262 (avg: 4.1910)\tTop1: 6.250 (avg: 9.708)\tTop5: 28.125 (avg: 28.812)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.286 (avg: 0.297)\tLoss: 4.3067 (avg: 4.1996)\tTop1: 12.500 (avg: 9.828)\tTop5: 32.812 (avg: 28.766)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.290 (avg: 0.297)\tLoss: 4.3576 (avg: 4.1958)\tTop1: 7.812 (avg: 10.000)\tTop5: 29.688 (avg: 28.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5448\tTop 1 accuracy: 7.400\tTop 5 accuracy: 21.650\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.288 (avg: 0.293)\tLoss: 3.9999 (avg: 4.1835)\tTop1: 7.812 (avg: 9.188)\tTop5: 32.812 (avg: 29.438)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.288 (avg: 0.295)\tLoss: 3.9747 (avg: 4.2049)\tTop1: 14.062 (avg: 9.781)\tTop5: 31.250 (avg: 28.031)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.290 (avg: 0.296)\tLoss: 4.2792 (avg: 4.1968)\tTop1: 9.375 (avg: 9.667)\tTop5: 28.125 (avg: 28.667)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.296 (avg: 0.297)\tLoss: 4.1226 (avg: 4.1885)\tTop1: 12.500 (avg: 9.984)\tTop5: 31.250 (avg: 28.953)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.296 (avg: 0.297)\tLoss: 4.2107 (avg: 4.1890)\tTop1: 4.688 (avg: 9.900)\tTop5: 26.562 (avg: 28.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2501\tTop 1 accuracy: 8.250\tTop 5 accuracy: 23.050\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.285 (avg: 0.290)\tLoss: 4.3605 (avg: 4.0987)\tTop1: 4.688 (avg: 11.375)\tTop5: 26.562 (avg: 32.125)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.287 (avg: 0.293)\tLoss: 4.4524 (avg: 4.1464)\tTop1: 4.688 (avg: 10.656)\tTop5: 23.438 (avg: 30.812)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.290 (avg: 0.294)\tLoss: 4.0963 (avg: 4.1647)\tTop1: 7.812 (avg: 10.646)\tTop5: 28.125 (avg: 30.354)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.298 (avg: 0.295)\tLoss: 4.4380 (avg: 4.1687)\tTop1: 7.812 (avg: 10.484)\tTop5: 25.000 (avg: 30.281)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.336 (avg: 0.297)\tLoss: 4.1368 (avg: 4.1656)\tTop1: 6.250 (avg: 10.200)\tTop5: 26.562 (avg: 29.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1627\tTop 1 accuracy: 8.250\tTop 5 accuracy: 24.700\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.299 (avg: 0.291)\tLoss: 4.1329 (avg: 4.1357)\tTop1: 12.500 (avg: 10.875)\tTop5: 34.375 (avg: 30.750)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.293 (avg: 0.295)\tLoss: 3.9251 (avg: 4.1579)\tTop1: 18.750 (avg: 10.594)\tTop5: 35.938 (avg: 29.406)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.287 (avg: 0.296)\tLoss: 4.3170 (avg: 4.1632)\tTop1: 7.812 (avg: 10.625)\tTop5: 26.562 (avg: 29.271)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.287 (avg: 0.296)\tLoss: 3.6950 (avg: 4.1509)\tTop1: 15.625 (avg: 10.516)\tTop5: 35.938 (avg: 29.469)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.297 (avg: 0.297)\tLoss: 4.3114 (avg: 4.1513)\tTop1: 12.500 (avg: 10.688)\tTop5: 23.438 (avg: 29.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2333\tTop 1 accuracy: 7.500\tTop 5 accuracy: 23.300\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.290 (avg: 0.290)\tLoss: 3.9064 (avg: 4.0499)\tTop1: 18.750 (avg: 12.438)\tTop5: 31.250 (avg: 34.000)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.288 (avg: 0.293)\tLoss: 4.2454 (avg: 4.0441)\tTop1: 7.812 (avg: 12.656)\tTop5: 32.812 (avg: 33.875)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.288 (avg: 0.294)\tLoss: 4.1352 (avg: 4.0383)\tTop1: 9.375 (avg: 12.146)\tTop5: 32.812 (avg: 33.479)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.294 (avg: 0.295)\tLoss: 4.0118 (avg: 4.0447)\tTop1: 3.125 (avg: 12.047)\tTop5: 35.938 (avg: 33.219)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.287 (avg: 0.295)\tLoss: 4.0609 (avg: 4.0541)\tTop1: 10.938 (avg: 11.900)\tTop5: 29.688 (avg: 32.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1243\tTop 1 accuracy: 8.650\tTop 5 accuracy: 26.150\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.292 (avg: 0.291)\tLoss: 3.8755 (avg: 4.0087)\tTop1: 9.375 (avg: 13.062)\tTop5: 37.500 (avg: 33.688)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.285 (avg: 0.294)\tLoss: 4.2380 (avg: 4.0112)\tTop1: 6.250 (avg: 13.531)\tTop5: 29.688 (avg: 33.562)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.306 (avg: 0.296)\tLoss: 3.8102 (avg: 4.0003)\tTop1: 15.625 (avg: 13.042)\tTop5: 32.812 (avg: 34.042)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.285 (avg: 0.297)\tLoss: 4.0344 (avg: 4.0265)\tTop1: 9.375 (avg: 12.625)\tTop5: 37.500 (avg: 33.438)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.292 (avg: 0.298)\tLoss: 4.0258 (avg: 4.0286)\tTop1: 9.375 (avg: 12.663)\tTop5: 35.938 (avg: 33.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0664\tTop 1 accuracy: 8.850\tTop 5 accuracy: 26.150\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.294 (avg: 0.293)\tLoss: 3.6907 (avg: 3.9866)\tTop1: 14.062 (avg: 13.125)\tTop5: 43.750 (avg: 33.250)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.290 (avg: 0.296)\tLoss: 4.3445 (avg: 4.0038)\tTop1: 14.062 (avg: 13.000)\tTop5: 31.250 (avg: 33.812)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.288 (avg: 0.297)\tLoss: 4.3129 (avg: 4.0214)\tTop1: 9.375 (avg: 12.812)\tTop5: 28.125 (avg: 33.312)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.294 (avg: 0.297)\tLoss: 4.0946 (avg: 4.0315)\tTop1: 10.938 (avg: 12.438)\tTop5: 31.250 (avg: 32.859)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.297 (avg: 0.297)\tLoss: 3.8273 (avg: 4.0256)\tTop1: 17.188 (avg: 12.763)\tTop5: 40.625 (avg: 33.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0780\tTop 1 accuracy: 9.150\tTop 5 accuracy: 26.100\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.288 (avg: 0.291)\tLoss: 3.8659 (avg: 4.0268)\tTop1: 12.500 (avg: 13.625)\tTop5: 35.938 (avg: 34.688)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.287 (avg: 0.294)\tLoss: 4.0055 (avg: 3.9797)\tTop1: 10.938 (avg: 13.844)\tTop5: 28.125 (avg: 35.375)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.294 (avg: 0.296)\tLoss: 3.9804 (avg: 4.0099)\tTop1: 12.500 (avg: 13.500)\tTop5: 31.250 (avg: 34.396)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.291 (avg: 0.296)\tLoss: 3.7251 (avg: 4.0116)\tTop1: 7.812 (avg: 13.391)\tTop5: 35.938 (avg: 34.125)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.292 (avg: 0.297)\tLoss: 4.2590 (avg: 4.0178)\tTop1: 15.625 (avg: 13.238)\tTop5: 29.688 (avg: 33.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0273\tTop 1 accuracy: 8.800\tTop 5 accuracy: 26.250\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.293 (avg: 0.292)\tLoss: 4.0103 (avg: 3.9876)\tTop1: 12.500 (avg: 13.312)\tTop5: 37.500 (avg: 35.375)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.288 (avg: 0.296)\tLoss: 4.0738 (avg: 3.9885)\tTop1: 18.750 (avg: 12.875)\tTop5: 37.500 (avg: 34.312)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.290 (avg: 0.297)\tLoss: 3.8699 (avg: 3.9943)\tTop1: 14.062 (avg: 12.896)\tTop5: 32.812 (avg: 34.521)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.296 (avg: 0.297)\tLoss: 3.7384 (avg: 4.0059)\tTop1: 17.188 (avg: 12.859)\tTop5: 37.500 (avg: 34.031)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.295 (avg: 0.297)\tLoss: 4.1211 (avg: 4.0137)\tTop1: 12.500 (avg: 12.488)\tTop5: 28.125 (avg: 33.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0975\tTop 1 accuracy: 9.100\tTop 5 accuracy: 25.650\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.292 (avg: 0.291)\tLoss: 3.9819 (avg: 4.0269)\tTop1: 15.625 (avg: 13.688)\tTop5: 37.500 (avg: 34.812)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.293 (avg: 0.295)\tLoss: 4.0061 (avg: 4.0329)\tTop1: 10.938 (avg: 13.094)\tTop5: 35.938 (avg: 34.156)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.302 (avg: 0.296)\tLoss: 4.1438 (avg: 4.0279)\tTop1: 10.938 (avg: 12.917)\tTop5: 25.000 (avg: 33.792)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.289 (avg: 0.297)\tLoss: 4.1113 (avg: 4.0210)\tTop1: 17.188 (avg: 13.016)\tTop5: 34.375 (avg: 33.828)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.291 (avg: 0.297)\tLoss: 3.6925 (avg: 4.0135)\tTop1: 14.062 (avg: 12.913)\tTop5: 39.062 (avg: 34.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0215\tTop 1 accuracy: 9.000\tTop 5 accuracy: 25.550\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.292 (avg: 0.290)\tLoss: 4.2207 (avg: 4.0708)\tTop1: 15.625 (avg: 11.500)\tTop5: 26.562 (avg: 33.000)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.286 (avg: 0.293)\tLoss: 3.8038 (avg: 4.0307)\tTop1: 12.500 (avg: 12.750)\tTop5: 32.812 (avg: 34.000)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.286 (avg: 0.294)\tLoss: 3.9312 (avg: 4.0228)\tTop1: 10.938 (avg: 12.688)\tTop5: 28.125 (avg: 33.792)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.289 (avg: 0.295)\tLoss: 4.0263 (avg: 4.0144)\tTop1: 17.188 (avg: 12.703)\tTop5: 43.750 (avg: 34.016)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.291 (avg: 0.296)\tLoss: 4.0443 (avg: 4.0103)\tTop1: 7.812 (avg: 12.913)\tTop5: 29.688 (avg: 33.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0073\tTop 1 accuracy: 9.050\tTop 5 accuracy: 26.750\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.295 (avg: 0.296)\tLoss: 3.7945 (avg: 3.9775)\tTop1: 18.750 (avg: 12.562)\tTop5: 42.188 (avg: 33.875)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.288 (avg: 0.297)\tLoss: 4.0079 (avg: 3.9885)\tTop1: 10.938 (avg: 12.625)\tTop5: 35.938 (avg: 34.094)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.287 (avg: 0.297)\tLoss: 3.9328 (avg: 3.9913)\tTop1: 20.312 (avg: 12.771)\tTop5: 34.375 (avg: 34.312)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.288 (avg: 0.298)\tLoss: 4.2491 (avg: 4.0179)\tTop1: 10.938 (avg: 12.484)\tTop5: 26.562 (avg: 33.797)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.290 (avg: 0.298)\tLoss: 4.0972 (avg: 4.0084)\tTop1: 17.188 (avg: 12.838)\tTop5: 32.812 (avg: 34.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1328\tTop 1 accuracy: 8.650\tTop 5 accuracy: 25.750\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.302 (avg: 0.292)\tLoss: 3.9262 (avg: 3.9582)\tTop1: 15.625 (avg: 13.812)\tTop5: 37.500 (avg: 36.500)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.285 (avg: 0.295)\tLoss: 4.1763 (avg: 3.9597)\tTop1: 4.688 (avg: 13.688)\tTop5: 21.875 (avg: 35.344)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 3.9440 (avg: 3.9735)\tTop1: 15.625 (avg: 12.854)\tTop5: 40.625 (avg: 34.688)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.2282 (avg: 3.9977)\tTop1: 6.250 (avg: 12.734)\tTop5: 26.562 (avg: 34.281)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 3.9988 (avg: 4.0004)\tTop1: 12.500 (avg: 12.588)\tTop5: 35.938 (avg: 34.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0968\tTop 1 accuracy: 8.950\tTop 5 accuracy: 25.750\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.288 (avg: 0.291)\tLoss: 4.1168 (avg: 4.0014)\tTop1: 10.938 (avg: 13.938)\tTop5: 29.688 (avg: 35.062)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.290 (avg: 0.295)\tLoss: 3.9371 (avg: 3.9930)\tTop1: 6.250 (avg: 13.625)\tTop5: 34.375 (avg: 35.125)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.292 (avg: 0.296)\tLoss: 3.7539 (avg: 3.9940)\tTop1: 15.625 (avg: 13.229)\tTop5: 40.625 (avg: 34.271)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.298 (avg: 0.296)\tLoss: 4.0507 (avg: 3.9809)\tTop1: 15.625 (avg: 13.203)\tTop5: 32.812 (avg: 34.656)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.1111 (avg: 3.9972)\tTop1: 17.188 (avg: 12.750)\tTop5: 45.312 (avg: 33.950)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0427\tTop 1 accuracy: 8.850\tTop 5 accuracy: 26.300\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.290 (avg: 0.292)\tLoss: 4.2124 (avg: 3.9365)\tTop1: 14.062 (avg: 13.875)\tTop5: 31.250 (avg: 35.938)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.290 (avg: 0.295)\tLoss: 3.8943 (avg: 3.9535)\tTop1: 7.812 (avg: 13.531)\tTop5: 37.500 (avg: 35.000)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.293 (avg: 0.297)\tLoss: 4.1967 (avg: 3.9837)\tTop1: 10.938 (avg: 13.458)\tTop5: 35.938 (avg: 34.396)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.291 (avg: 0.298)\tLoss: 4.1838 (avg: 3.9949)\tTop1: 10.938 (avg: 13.391)\tTop5: 23.438 (avg: 34.203)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.295 (avg: 0.298)\tLoss: 3.8742 (avg: 3.9928)\tTop1: 12.500 (avg: 13.075)\tTop5: 40.625 (avg: 34.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0561\tTop 1 accuracy: 8.300\tTop 5 accuracy: 26.050\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.289 (avg: 0.291)\tLoss: 3.7288 (avg: 3.9825)\tTop1: 10.938 (avg: 13.000)\tTop5: 35.938 (avg: 33.812)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.289 (avg: 0.295)\tLoss: 3.9793 (avg: 3.9812)\tTop1: 15.625 (avg: 13.125)\tTop5: 40.625 (avg: 33.875)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.0650 (avg: 3.9731)\tTop1: 12.500 (avg: 13.125)\tTop5: 31.250 (avg: 34.271)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.285 (avg: 0.296)\tLoss: 4.0246 (avg: 3.9862)\tTop1: 7.812 (avg: 13.031)\tTop5: 28.125 (avg: 34.047)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.296 (avg: 0.296)\tLoss: 4.0914 (avg: 3.9980)\tTop1: 18.750 (avg: 13.038)\tTop5: 31.250 (avg: 34.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0107\tTop 1 accuracy: 9.400\tTop 5 accuracy: 26.500\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.289 (avg: 0.292)\tLoss: 4.1539 (avg: 4.0391)\tTop1: 10.938 (avg: 13.562)\tTop5: 29.688 (avg: 33.125)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.296 (avg: 0.295)\tLoss: 4.3155 (avg: 4.0017)\tTop1: 14.062 (avg: 13.594)\tTop5: 31.250 (avg: 33.875)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.298 (avg: 0.296)\tLoss: 4.0806 (avg: 3.9964)\tTop1: 12.500 (avg: 13.146)\tTop5: 32.812 (avg: 34.229)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 3.8085 (avg: 3.9885)\tTop1: 14.062 (avg: 13.094)\tTop5: 31.250 (avg: 34.000)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.291 (avg: 0.297)\tLoss: 4.3388 (avg: 3.9935)\tTop1: 10.938 (avg: 13.075)\tTop5: 31.250 (avg: 34.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0474\tTop 1 accuracy: 8.650\tTop 5 accuracy: 26.350\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.301 (avg: 0.294)\tLoss: 3.6568 (avg: 3.9644)\tTop1: 18.750 (avg: 12.812)\tTop5: 42.188 (avg: 35.062)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.302 (avg: 0.301)\tLoss: 3.9621 (avg: 3.9474)\tTop1: 9.375 (avg: 12.906)\tTop5: 35.938 (avg: 35.656)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.290 (avg: 0.301)\tLoss: 3.9463 (avg: 3.9747)\tTop1: 14.062 (avg: 12.854)\tTop5: 34.375 (avg: 34.708)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.287 (avg: 0.302)\tLoss: 3.7530 (avg: 3.9818)\tTop1: 14.062 (avg: 13.156)\tTop5: 40.625 (avg: 34.328)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.290 (avg: 0.302)\tLoss: 4.1043 (avg: 3.9903)\tTop1: 10.938 (avg: 13.000)\tTop5: 32.812 (avg: 34.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1016\tTop 1 accuracy: 9.400\tTop 5 accuracy: 26.150\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.289 (avg: 0.298)\tLoss: 3.8207 (avg: 3.9605)\tTop1: 12.500 (avg: 13.750)\tTop5: 42.188 (avg: 34.812)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.296 (avg: 0.303)\tLoss: 4.1427 (avg: 3.9700)\tTop1: 7.812 (avg: 13.531)\tTop5: 32.812 (avg: 34.781)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.298 (avg: 0.302)\tLoss: 3.9051 (avg: 3.9912)\tTop1: 12.500 (avg: 13.188)\tTop5: 42.188 (avg: 33.875)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.295 (avg: 0.302)\tLoss: 4.2670 (avg: 3.9911)\tTop1: 6.250 (avg: 13.062)\tTop5: 25.000 (avg: 33.938)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.310 (avg: 0.304)\tLoss: 3.6291 (avg: 3.9894)\tTop1: 18.750 (avg: 13.175)\tTop5: 43.750 (avg: 34.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0745\tTop 1 accuracy: 8.750\tTop 5 accuracy: 26.300\n",
            "\n",
            "base_e = 64: top1 = 9.050000190734863 \t top5 = 26.750001907348633 \t batch time = 0.2751304805278778\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.352 (avg: 0.476)\tLoss: 5.2993 (avg: 5.3019)\tTop1: 1.562 (avg: 0.375)\tTop5: 6.250 (avg: 3.000)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.356 (avg: 0.419)\tLoss: 5.3007 (avg: 5.3019)\tTop1: 0.000 (avg: 0.406)\tTop5: 0.000 (avg: 2.281)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.355 (avg: 0.400)\tLoss: 5.2969 (avg: 5.3007)\tTop1: 1.562 (avg: 0.438)\tTop5: 6.250 (avg: 2.438)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.355 (avg: 0.391)\tLoss: 5.2993 (avg: 5.3002)\tTop1: 0.000 (avg: 0.391)\tTop5: 1.562 (avg: 2.188)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.355 (avg: 0.385)\tLoss: 5.2983 (avg: 5.2999)\tTop1: 0.000 (avg: 0.388)\tTop5: 3.125 (avg: 2.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2993\tTop 1 accuracy: 0.450\tTop 5 accuracy: 1.700\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.354 (avg: 0.355)\tLoss: 5.2981 (avg: 5.2978)\tTop1: 0.000 (avg: 0.562)\tTop5: 1.562 (avg: 3.188)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 5.3000 (avg: 5.2980)\tTop1: 0.000 (avg: 0.531)\tTop5: 1.562 (avg: 2.750)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 5.2941 (avg: 5.2976)\tTop1: 1.562 (avg: 0.521)\tTop5: 6.250 (avg: 3.042)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 5.2966 (avg: 5.2976)\tTop1: 1.562 (avg: 0.531)\tTop5: 1.562 (avg: 2.906)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 5.3060 (avg: 5.2976)\tTop1: 0.000 (avg: 0.550)\tTop5: 1.562 (avg: 2.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3015\tTop 1 accuracy: 0.400\tTop 5 accuracy: 2.100\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.353 (avg: 0.354)\tLoss: 5.2877 (avg: 5.2948)\tTop1: 0.000 (avg: 0.438)\tTop5: 0.000 (avg: 2.875)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.357 (avg: 0.358)\tLoss: 5.3026 (avg: 5.2916)\tTop1: 1.562 (avg: 0.719)\tTop5: 1.562 (avg: 3.125)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 5.2996 (avg: 5.2895)\tTop1: 0.000 (avg: 0.833)\tTop5: 4.688 (avg: 3.646)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 5.3215 (avg: 5.2830)\tTop1: 0.000 (avg: 0.891)\tTop5: 4.688 (avg: 3.672)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 5.3552 (avg: 5.2781)\tTop1: 0.000 (avg: 0.913)\tTop5: 1.562 (avg: 3.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2764\tTop 1 accuracy: 0.700\tTop 5 accuracy: 3.750\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.355 (avg: 0.353)\tLoss: 5.1955 (avg: 5.2471)\tTop1: 1.562 (avg: 1.000)\tTop5: 6.250 (avg: 4.312)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.355 (avg: 0.358)\tLoss: 5.1917 (avg: 5.2406)\tTop1: 1.562 (avg: 0.875)\tTop5: 6.250 (avg: 4.250)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 5.1512 (avg: 5.2402)\tTop1: 1.562 (avg: 0.875)\tTop5: 3.125 (avg: 4.125)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 5.2457 (avg: 5.2357)\tTop1: 3.125 (avg: 0.906)\tTop5: 6.250 (avg: 4.234)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 5.3242 (avg: 5.2288)\tTop1: 3.125 (avg: 0.950)\tTop5: 7.812 (avg: 4.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1889\tTop 1 accuracy: 0.700\tTop 5 accuracy: 4.150\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.362 (avg: 0.360)\tLoss: 5.0690 (avg: 5.1934)\tTop1: 0.000 (avg: 0.875)\tTop5: 7.812 (avg: 4.938)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.362 (avg: 0.364)\tLoss: 5.1449 (avg: 5.2021)\tTop1: 1.562 (avg: 0.969)\tTop5: 7.812 (avg: 4.719)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.361 (avg: 0.366)\tLoss: 5.1858 (avg: 5.1992)\tTop1: 0.000 (avg: 0.979)\tTop5: 6.250 (avg: 4.750)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 5.1765 (avg: 5.2004)\tTop1: 0.000 (avg: 1.016)\tTop5: 7.812 (avg: 4.844)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.360 (avg: 0.367)\tLoss: 5.1831 (avg: 5.2016)\tTop1: 1.562 (avg: 1.013)\tTop5: 4.688 (avg: 4.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2233\tTop 1 accuracy: 1.150\tTop 5 accuracy: 4.050\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.359 (avg: 0.355)\tLoss: 5.1651 (avg: 5.1793)\tTop1: 3.125 (avg: 1.625)\tTop5: 7.812 (avg: 5.875)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 5.2298 (avg: 5.1803)\tTop1: 1.562 (avg: 1.312)\tTop5: 4.688 (avg: 5.656)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 5.1708 (avg: 5.1899)\tTop1: 0.000 (avg: 1.104)\tTop5: 7.812 (avg: 5.375)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 5.1872 (avg: 5.1827)\tTop1: 0.000 (avg: 1.078)\tTop5: 3.125 (avg: 5.406)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 5.1904 (avg: 5.1817)\tTop1: 1.562 (avg: 1.175)\tTop5: 6.250 (avg: 5.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1114\tTop 1 accuracy: 1.100\tTop 5 accuracy: 5.300\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.354 (avg: 0.353)\tLoss: 5.2520 (avg: 5.1541)\tTop1: 0.000 (avg: 1.250)\tTop5: 1.562 (avg: 5.562)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 5.1353 (avg: 5.1628)\tTop1: 0.000 (avg: 1.281)\tTop5: 4.688 (avg: 5.656)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 5.2590 (avg: 5.1652)\tTop1: 1.562 (avg: 1.208)\tTop5: 6.250 (avg: 5.771)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.351 (avg: 0.360)\tLoss: 5.2455 (avg: 5.1670)\tTop1: 1.562 (avg: 1.312)\tTop5: 4.688 (avg: 6.094)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 5.1718 (avg: 5.1677)\tTop1: 1.562 (avg: 1.325)\tTop5: 9.375 (avg: 6.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2512\tTop 1 accuracy: 1.200\tTop 5 accuracy: 6.500\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.355 (avg: 0.354)\tLoss: 5.1914 (avg: 5.1333)\tTop1: 0.000 (avg: 2.062)\tTop5: 9.375 (avg: 7.625)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 5.1136 (avg: 5.1366)\tTop1: 3.125 (avg: 1.812)\tTop5: 7.812 (avg: 7.844)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 5.0650 (avg: 5.1402)\tTop1: 3.125 (avg: 1.667)\tTop5: 12.500 (avg: 7.125)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.347 (avg: 0.362)\tLoss: 5.0908 (avg: 5.1423)\tTop1: 3.125 (avg: 1.641)\tTop5: 10.938 (avg: 7.219)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 5.1174 (avg: 5.1456)\tTop1: 0.000 (avg: 1.575)\tTop5: 3.125 (avg: 6.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1875\tTop 1 accuracy: 1.050\tTop 5 accuracy: 6.200\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.359 (avg: 0.356)\tLoss: 5.1890 (avg: 5.1465)\tTop1: 1.562 (avg: 0.875)\tTop5: 6.250 (avg: 7.062)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 5.1293 (avg: 5.1260)\tTop1: 1.562 (avg: 1.406)\tTop5: 9.375 (avg: 7.031)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 5.0940 (avg: 5.1269)\tTop1: 0.000 (avg: 1.312)\tTop5: 6.250 (avg: 6.792)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 5.1061 (avg: 5.1216)\tTop1: 1.562 (avg: 1.406)\tTop5: 4.688 (avg: 6.797)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.356 (avg: 0.363)\tLoss: 5.1150 (avg: 5.1186)\tTop1: 1.562 (avg: 1.388)\tTop5: 7.812 (avg: 6.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2051\tTop 1 accuracy: 1.350\tTop 5 accuracy: 7.050\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.355 (avg: 0.354)\tLoss: 5.0644 (avg: 5.0939)\tTop1: 1.562 (avg: 1.312)\tTop5: 7.812 (avg: 7.938)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 5.0510 (avg: 5.0976)\tTop1: 1.562 (avg: 1.406)\tTop5: 9.375 (avg: 7.500)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 5.1022 (avg: 5.0935)\tTop1: 1.562 (avg: 1.250)\tTop5: 9.375 (avg: 7.562)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 5.1393 (avg: 5.0932)\tTop1: 0.000 (avg: 1.328)\tTop5: 3.125 (avg: 7.281)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 5.0035 (avg: 5.0928)\tTop1: 0.000 (avg: 1.400)\tTop5: 10.938 (avg: 7.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1253\tTop 1 accuracy: 1.200\tTop 5 accuracy: 7.250\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.366 (avg: 0.354)\tLoss: 5.0367 (avg: 5.0853)\tTop1: 4.688 (avg: 2.000)\tTop5: 12.500 (avg: 8.062)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 5.0939 (avg: 5.0914)\tTop1: 0.000 (avg: 1.844)\tTop5: 9.375 (avg: 8.062)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 5.1585 (avg: 5.0982)\tTop1: 0.000 (avg: 1.625)\tTop5: 3.125 (avg: 7.500)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 5.2328 (avg: 5.0988)\tTop1: 1.562 (avg: 1.609)\tTop5: 6.250 (avg: 7.641)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.9869 (avg: 5.0948)\tTop1: 6.250 (avg: 1.625)\tTop5: 20.312 (avg: 7.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0885\tTop 1 accuracy: 1.450\tTop 5 accuracy: 6.750\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.354 (avg: 0.354)\tLoss: 5.0378 (avg: 5.0763)\tTop1: 0.000 (avg: 1.688)\tTop5: 7.812 (avg: 8.125)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 4.9777 (avg: 5.0573)\tTop1: 6.250 (avg: 1.938)\tTop5: 9.375 (avg: 8.688)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 5.0584 (avg: 5.0526)\tTop1: 3.125 (avg: 1.979)\tTop5: 10.938 (avg: 8.979)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 5.0598 (avg: 5.0565)\tTop1: 0.000 (avg: 2.094)\tTop5: 14.062 (avg: 9.250)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 5.0644 (avg: 5.0605)\tTop1: 3.125 (avg: 2.038)\tTop5: 4.688 (avg: 9.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1723\tTop 1 accuracy: 2.500\tTop 5 accuracy: 7.900\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.362 (avg: 0.360)\tLoss: 4.9695 (avg: 5.0374)\tTop1: 0.000 (avg: 2.375)\tTop5: 7.812 (avg: 9.125)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.361 (avg: 0.366)\tLoss: 5.0202 (avg: 5.0357)\tTop1: 3.125 (avg: 2.000)\tTop5: 4.688 (avg: 8.531)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 5.1095 (avg: 5.0268)\tTop1: 3.125 (avg: 2.125)\tTop5: 10.938 (avg: 8.958)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.362 (avg: 0.368)\tLoss: 5.0909 (avg: 5.0226)\tTop1: 1.562 (avg: 2.188)\tTop5: 4.688 (avg: 9.172)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.362 (avg: 0.368)\tLoss: 5.0731 (avg: 5.0247)\tTop1: 4.688 (avg: 2.188)\tTop5: 9.375 (avg: 9.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1240\tTop 1 accuracy: 1.700\tTop 5 accuracy: 9.100\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.356 (avg: 0.355)\tLoss: 4.9437 (avg: 4.9557)\tTop1: 0.000 (avg: 2.562)\tTop5: 9.375 (avg: 10.750)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.357 (avg: 0.359)\tLoss: 4.9871 (avg: 4.9592)\tTop1: 0.000 (avg: 2.812)\tTop5: 12.500 (avg: 11.188)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 5.0825 (avg: 4.9804)\tTop1: 3.125 (avg: 2.667)\tTop5: 7.812 (avg: 10.354)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.352 (avg: 0.362)\tLoss: 4.8656 (avg: 4.9879)\tTop1: 1.562 (avg: 2.641)\tTop5: 17.188 (avg: 10.000)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 5.1279 (avg: 4.9829)\tTop1: 0.000 (avg: 2.700)\tTop5: 4.688 (avg: 9.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9187\tTop 1 accuracy: 2.500\tTop 5 accuracy: 11.100\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.355 (avg: 0.353)\tLoss: 5.0331 (avg: 4.9543)\tTop1: 4.688 (avg: 2.375)\tTop5: 15.625 (avg: 10.812)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.356 (avg: 0.357)\tLoss: 4.9499 (avg: 4.9587)\tTop1: 1.562 (avg: 2.438)\tTop5: 12.500 (avg: 10.906)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.357 (avg: 0.359)\tLoss: 5.0658 (avg: 4.9588)\tTop1: 1.562 (avg: 2.333)\tTop5: 6.250 (avg: 10.458)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.363 (avg: 0.360)\tLoss: 5.2059 (avg: 4.9527)\tTop1: 3.125 (avg: 2.578)\tTop5: 7.812 (avg: 10.594)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 4.9440 (avg: 4.9593)\tTop1: 1.562 (avg: 2.500)\tTop5: 9.375 (avg: 10.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8291\tTop 1 accuracy: 2.550\tTop 5 accuracy: 9.300\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.357 (avg: 0.355)\tLoss: 5.0757 (avg: 4.8782)\tTop1: 3.125 (avg: 3.000)\tTop5: 7.812 (avg: 11.188)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.359 (avg: 0.359)\tLoss: 4.6337 (avg: 4.8852)\tTop1: 4.688 (avg: 3.031)\tTop5: 17.188 (avg: 10.844)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.353 (avg: 0.360)\tLoss: 4.7914 (avg: 4.8884)\tTop1: 4.688 (avg: 3.104)\tTop5: 15.625 (avg: 11.062)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 4.9361 (avg: 4.9131)\tTop1: 3.125 (avg: 2.938)\tTop5: 6.250 (avg: 10.672)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.8873 (avg: 4.9153)\tTop1: 6.250 (avg: 2.888)\tTop5: 23.438 (avg: 10.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9553\tTop 1 accuracy: 2.650\tTop 5 accuracy: 10.450\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.360 (avg: 0.357)\tLoss: 4.6901 (avg: 4.8546)\tTop1: 6.250 (avg: 3.688)\tTop5: 20.312 (avg: 13.500)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 4.9287 (avg: 4.8878)\tTop1: 4.688 (avg: 3.469)\tTop5: 12.500 (avg: 12.094)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 4.8832 (avg: 4.8843)\tTop1: 4.688 (avg: 3.375)\tTop5: 12.500 (avg: 12.104)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.360 (avg: 0.363)\tLoss: 4.8295 (avg: 4.8795)\tTop1: 1.562 (avg: 3.156)\tTop5: 18.750 (avg: 12.266)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.358 (avg: 0.364)\tLoss: 4.8879 (avg: 4.8781)\tTop1: 3.125 (avg: 3.300)\tTop5: 9.375 (avg: 12.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7681\tTop 1 accuracy: 3.500\tTop 5 accuracy: 12.550\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.360 (avg: 0.357)\tLoss: 4.8469 (avg: 4.8239)\tTop1: 4.688 (avg: 4.062)\tTop5: 14.062 (avg: 13.500)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 4.7411 (avg: 4.8204)\tTop1: 1.562 (avg: 3.875)\tTop5: 17.188 (avg: 13.500)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 4.9330 (avg: 4.8196)\tTop1: 0.000 (avg: 3.729)\tTop5: 9.375 (avg: 12.979)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.351 (avg: 0.362)\tLoss: 4.8409 (avg: 4.8178)\tTop1: 4.688 (avg: 3.594)\tTop5: 14.062 (avg: 13.219)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 4.9053 (avg: 4.8283)\tTop1: 4.688 (avg: 3.525)\tTop5: 14.062 (avg: 13.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7952\tTop 1 accuracy: 3.650\tTop 5 accuracy: 12.650\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.356 (avg: 0.355)\tLoss: 4.7856 (avg: 4.7916)\tTop1: 4.688 (avg: 3.250)\tTop5: 9.375 (avg: 13.375)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 5.0107 (avg: 4.7803)\tTop1: 6.250 (avg: 4.031)\tTop5: 9.375 (avg: 14.375)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 4.7323 (avg: 4.7882)\tTop1: 3.125 (avg: 3.854)\tTop5: 18.750 (avg: 14.104)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 4.8029 (avg: 4.7777)\tTop1: 3.125 (avg: 3.844)\tTop5: 10.938 (avg: 14.422)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 4.8293 (avg: 4.7849)\tTop1: 0.000 (avg: 3.650)\tTop5: 9.375 (avg: 14.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8283\tTop 1 accuracy: 4.550\tTop 5 accuracy: 15.250\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.355 (avg: 0.354)\tLoss: 4.6761 (avg: 4.6846)\tTop1: 4.688 (avg: 4.688)\tTop5: 25.000 (avg: 16.312)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.358 (avg: 0.358)\tLoss: 4.7020 (avg: 4.7350)\tTop1: 7.812 (avg: 3.969)\tTop5: 21.875 (avg: 15.031)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 4.5848 (avg: 4.7321)\tTop1: 3.125 (avg: 3.979)\tTop5: 20.312 (avg: 15.083)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 4.5726 (avg: 4.7467)\tTop1: 3.125 (avg: 3.766)\tTop5: 20.312 (avg: 14.688)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 4.7252 (avg: 4.7333)\tTop1: 1.562 (avg: 3.825)\tTop5: 9.375 (avg: 14.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8002\tTop 1 accuracy: 3.700\tTop 5 accuracy: 15.900\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.363 (avg: 0.361)\tLoss: 4.7681 (avg: 4.6828)\tTop1: 3.125 (avg: 4.188)\tTop5: 10.938 (avg: 15.688)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.361 (avg: 0.365)\tLoss: 4.7851 (avg: 4.6642)\tTop1: 6.250 (avg: 4.375)\tTop5: 18.750 (avg: 16.438)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.363 (avg: 0.366)\tLoss: 4.7627 (avg: 4.6409)\tTop1: 4.688 (avg: 4.438)\tTop5: 21.875 (avg: 17.083)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.361 (avg: 0.367)\tLoss: 4.7249 (avg: 4.6458)\tTop1: 3.125 (avg: 4.547)\tTop5: 10.938 (avg: 16.828)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 4.6703 (avg: 4.6555)\tTop1: 4.688 (avg: 4.713)\tTop5: 18.750 (avg: 16.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8346\tTop 1 accuracy: 4.250\tTop 5 accuracy: 14.300\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.351 (avg: 0.356)\tLoss: 4.6725 (avg: 4.5738)\tTop1: 4.688 (avg: 5.562)\tTop5: 14.062 (avg: 18.688)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 4.7827 (avg: 4.5852)\tTop1: 3.125 (avg: 5.438)\tTop5: 12.500 (avg: 18.312)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 4.4998 (avg: 4.5958)\tTop1: 7.812 (avg: 5.208)\tTop5: 18.750 (avg: 18.292)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 4.5716 (avg: 4.5951)\tTop1: 7.812 (avg: 5.219)\tTop5: 17.188 (avg: 18.406)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.356 (avg: 0.363)\tLoss: 4.4723 (avg: 4.6001)\tTop1: 12.500 (avg: 5.163)\tTop5: 32.812 (avg: 18.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7625\tTop 1 accuracy: 4.250\tTop 5 accuracy: 17.000\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.355 (avg: 0.354)\tLoss: 4.6488 (avg: 4.5399)\tTop1: 1.562 (avg: 5.562)\tTop5: 14.062 (avg: 18.812)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.354 (avg: 0.358)\tLoss: 4.7394 (avg: 4.5484)\tTop1: 0.000 (avg: 5.594)\tTop5: 9.375 (avg: 19.375)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 4.8647 (avg: 4.5686)\tTop1: 3.125 (avg: 5.312)\tTop5: 14.062 (avg: 18.688)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 4.7159 (avg: 4.5644)\tTop1: 3.125 (avg: 5.172)\tTop5: 14.062 (avg: 19.125)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 4.8193 (avg: 4.5495)\tTop1: 1.562 (avg: 5.350)\tTop5: 14.062 (avg: 19.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5556\tTop 1 accuracy: 5.000\tTop 5 accuracy: 19.150\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.356 (avg: 0.355)\tLoss: 4.1795 (avg: 4.4925)\tTop1: 9.375 (avg: 6.562)\tTop5: 26.562 (avg: 20.562)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.354 (avg: 0.359)\tLoss: 4.6684 (avg: 4.5118)\tTop1: 3.125 (avg: 6.875)\tTop5: 21.875 (avg: 21.719)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 4.3632 (avg: 4.5152)\tTop1: 10.938 (avg: 6.771)\tTop5: 25.000 (avg: 21.354)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 4.6148 (avg: 4.5152)\tTop1: 3.125 (avg: 6.250)\tTop5: 14.062 (avg: 20.812)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.6597 (avg: 4.5111)\tTop1: 3.125 (avg: 6.213)\tTop5: 17.188 (avg: 20.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4828\tTop 1 accuracy: 5.850\tTop 5 accuracy: 18.800\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.361 (avg: 0.356)\tLoss: 4.4081 (avg: 4.4343)\tTop1: 9.375 (avg: 7.312)\tTop5: 23.438 (avg: 22.375)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 4.2740 (avg: 4.4321)\tTop1: 9.375 (avg: 7.250)\tTop5: 23.438 (avg: 22.000)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.360 (avg: 0.361)\tLoss: 4.8253 (avg: 4.4477)\tTop1: 0.000 (avg: 6.938)\tTop5: 17.188 (avg: 21.500)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 4.4555 (avg: 4.4623)\tTop1: 3.125 (avg: 6.812)\tTop5: 18.750 (avg: 21.078)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.359 (avg: 0.363)\tLoss: 4.3155 (avg: 4.4632)\tTop1: 6.250 (avg: 6.763)\tTop5: 28.125 (avg: 20.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3641\tTop 1 accuracy: 6.800\tTop 5 accuracy: 21.050\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.355 (avg: 0.355)\tLoss: 4.4348 (avg: 4.4423)\tTop1: 6.250 (avg: 7.125)\tTop5: 25.000 (avg: 24.000)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 4.3376 (avg: 4.4363)\tTop1: 1.562 (avg: 6.750)\tTop5: 23.438 (avg: 23.062)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.358 (avg: 0.360)\tLoss: 4.4251 (avg: 4.4113)\tTop1: 7.812 (avg: 6.979)\tTop5: 25.000 (avg: 23.417)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.2855 (avg: 4.4267)\tTop1: 10.938 (avg: 6.719)\tTop5: 21.875 (avg: 22.875)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 4.5758 (avg: 4.4417)\tTop1: 10.938 (avg: 6.675)\tTop5: 23.438 (avg: 22.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3561\tTop 1 accuracy: 5.450\tTop 5 accuracy: 19.950\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.357 (avg: 0.355)\tLoss: 4.3213 (avg: 4.3754)\tTop1: 6.250 (avg: 7.312)\tTop5: 21.875 (avg: 23.438)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 4.4568 (avg: 4.3968)\tTop1: 4.688 (avg: 7.062)\tTop5: 17.188 (avg: 22.469)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 4.3270 (avg: 4.3794)\tTop1: 7.812 (avg: 7.229)\tTop5: 20.312 (avg: 22.875)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 4.3610 (avg: 4.3810)\tTop1: 4.688 (avg: 7.297)\tTop5: 21.875 (avg: 23.031)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 4.5387 (avg: 4.3880)\tTop1: 4.688 (avg: 7.250)\tTop5: 28.125 (avg: 23.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2106\tTop 1 accuracy: 7.250\tTop 5 accuracy: 22.700\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.357 (avg: 0.354)\tLoss: 4.3486 (avg: 4.2829)\tTop1: 4.688 (avg: 7.688)\tTop5: 20.312 (avg: 26.375)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.354 (avg: 0.358)\tLoss: 4.3438 (avg: 4.2983)\tTop1: 6.250 (avg: 7.656)\tTop5: 29.688 (avg: 25.750)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 4.0396 (avg: 4.3322)\tTop1: 6.250 (avg: 7.708)\tTop5: 32.812 (avg: 25.250)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 4.4248 (avg: 4.3444)\tTop1: 4.688 (avg: 7.672)\tTop5: 21.875 (avg: 24.688)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 4.7476 (avg: 4.3302)\tTop1: 3.125 (avg: 7.813)\tTop5: 18.750 (avg: 24.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9021\tTop 1 accuracy: 7.250\tTop 5 accuracy: 22.500\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.363 (avg: 0.360)\tLoss: 4.3560 (avg: 4.3132)\tTop1: 9.375 (avg: 6.875)\tTop5: 23.438 (avg: 25.750)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.361 (avg: 0.365)\tLoss: 4.2998 (avg: 4.3343)\tTop1: 9.375 (avg: 7.438)\tTop5: 26.562 (avg: 25.062)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.360 (avg: 0.366)\tLoss: 4.3066 (avg: 4.3189)\tTop1: 4.688 (avg: 7.729)\tTop5: 21.875 (avg: 25.500)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.364 (avg: 0.367)\tLoss: 4.1117 (avg: 4.3247)\tTop1: 9.375 (avg: 7.797)\tTop5: 32.812 (avg: 25.406)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.361 (avg: 0.367)\tLoss: 4.1084 (avg: 4.3047)\tTop1: 9.375 (avg: 7.650)\tTop5: 29.688 (avg: 25.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2427\tTop 1 accuracy: 6.500\tTop 5 accuracy: 22.400\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.354 (avg: 0.356)\tLoss: 4.0726 (avg: 4.1939)\tTop1: 10.938 (avg: 9.312)\tTop5: 34.375 (avg: 28.312)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 4.3514 (avg: 4.2057)\tTop1: 7.812 (avg: 9.562)\tTop5: 23.438 (avg: 28.531)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 4.6832 (avg: 4.2603)\tTop1: 6.250 (avg: 9.021)\tTop5: 18.750 (avg: 27.396)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 4.5323 (avg: 4.2803)\tTop1: 4.688 (avg: 8.656)\tTop5: 17.188 (avg: 26.562)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.356 (avg: 0.363)\tLoss: 4.0808 (avg: 4.2956)\tTop1: 10.938 (avg: 8.588)\tTop5: 29.688 (avg: 26.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1280\tTop 1 accuracy: 6.750\tTop 5 accuracy: 23.250\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.354 (avg: 0.354)\tLoss: 4.2438 (avg: 4.1241)\tTop1: 10.938 (avg: 10.000)\tTop5: 32.812 (avg: 29.375)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.356 (avg: 0.358)\tLoss: 4.1773 (avg: 4.1104)\tTop1: 9.375 (avg: 10.906)\tTop5: 32.812 (avg: 31.094)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.352 (avg: 0.360)\tLoss: 4.0648 (avg: 4.0781)\tTop1: 7.812 (avg: 11.250)\tTop5: 31.250 (avg: 31.938)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 4.0482 (avg: 4.0613)\tTop1: 15.625 (avg: 11.547)\tTop5: 31.250 (avg: 32.375)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.353 (avg: 0.361)\tLoss: 3.9209 (avg: 4.0360)\tTop1: 18.750 (avg: 12.088)\tTop5: 34.375 (avg: 32.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8821\tTop 1 accuracy: 8.750\tTop 5 accuracy: 27.200\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.357 (avg: 0.355)\tLoss: 4.0169 (avg: 3.9534)\tTop1: 17.188 (avg: 14.188)\tTop5: 40.625 (avg: 35.000)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.354 (avg: 0.359)\tLoss: 4.1633 (avg: 3.9691)\tTop1: 7.812 (avg: 13.656)\tTop5: 29.688 (avg: 35.062)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.358 (avg: 0.360)\tLoss: 4.0034 (avg: 3.9627)\tTop1: 10.938 (avg: 13.417)\tTop5: 31.250 (avg: 34.938)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.8137 (avg: 3.9585)\tTop1: 15.625 (avg: 13.500)\tTop5: 40.625 (avg: 35.062)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 4.2554 (avg: 3.9504)\tTop1: 7.812 (avg: 13.550)\tTop5: 32.812 (avg: 35.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8131\tTop 1 accuracy: 9.450\tTop 5 accuracy: 27.650\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.350 (avg: 0.357)\tLoss: 3.9421 (avg: 3.8744)\tTop1: 18.750 (avg: 15.125)\tTop5: 42.188 (avg: 37.688)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 3.7671 (avg: 3.8911)\tTop1: 15.625 (avg: 14.469)\tTop5: 40.625 (avg: 37.125)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.361 (avg: 0.363)\tLoss: 3.9734 (avg: 3.9124)\tTop1: 17.188 (avg: 14.438)\tTop5: 34.375 (avg: 36.354)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.357 (avg: 0.364)\tLoss: 3.6884 (avg: 3.9176)\tTop1: 12.500 (avg: 14.203)\tTop5: 42.188 (avg: 35.797)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.358 (avg: 0.364)\tLoss: 3.9324 (avg: 3.9303)\tTop1: 10.938 (avg: 14.113)\tTop5: 29.688 (avg: 35.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7483\tTop 1 accuracy: 9.800\tTop 5 accuracy: 28.600\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.355 (avg: 0.355)\tLoss: 3.8793 (avg: 3.9598)\tTop1: 12.500 (avg: 14.875)\tTop5: 40.625 (avg: 37.188)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.357 (avg: 0.359)\tLoss: 3.8028 (avg: 3.9328)\tTop1: 15.625 (avg: 14.094)\tTop5: 37.500 (avg: 36.656)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 3.8095 (avg: 3.9243)\tTop1: 17.188 (avg: 14.083)\tTop5: 31.250 (avg: 36.792)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 3.6676 (avg: 3.8974)\tTop1: 18.750 (avg: 14.281)\tTop5: 43.750 (avg: 36.875)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 3.7855 (avg: 3.9050)\tTop1: 15.625 (avg: 14.100)\tTop5: 32.812 (avg: 36.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6914\tTop 1 accuracy: 9.550\tTop 5 accuracy: 28.750\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.359 (avg: 0.355)\tLoss: 3.6763 (avg: 3.9031)\tTop1: 20.312 (avg: 13.250)\tTop5: 40.625 (avg: 35.062)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.365 (avg: 0.359)\tLoss: 3.7883 (avg: 3.8904)\tTop1: 14.062 (avg: 13.344)\tTop5: 39.062 (avg: 35.688)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.360 (avg: 0.361)\tLoss: 3.9442 (avg: 3.8937)\tTop1: 17.188 (avg: 13.833)\tTop5: 34.375 (avg: 35.708)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 3.9103 (avg: 3.8910)\tTop1: 9.375 (avg: 14.016)\tTop5: 40.625 (avg: 36.047)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.350 (avg: 0.362)\tLoss: 3.9443 (avg: 3.8860)\tTop1: 14.062 (avg: 14.300)\tTop5: 40.625 (avg: 36.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7287\tTop 1 accuracy: 10.450\tTop 5 accuracy: 29.850\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.357 (avg: 0.354)\tLoss: 3.8866 (avg: 3.8251)\tTop1: 12.500 (avg: 15.250)\tTop5: 35.938 (avg: 36.938)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.355 (avg: 0.358)\tLoss: 3.6023 (avg: 3.8278)\tTop1: 15.625 (avg: 15.344)\tTop5: 39.062 (avg: 37.594)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 3.8834 (avg: 3.8399)\tTop1: 15.625 (avg: 14.875)\tTop5: 32.812 (avg: 37.229)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 3.9557 (avg: 3.8691)\tTop1: 14.062 (avg: 14.578)\tTop5: 35.938 (avg: 36.625)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.0708 (avg: 3.8751)\tTop1: 12.500 (avg: 14.738)\tTop5: 32.812 (avg: 36.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6711\tTop 1 accuracy: 10.150\tTop 5 accuracy: 29.550\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.363 (avg: 0.361)\tLoss: 3.6882 (avg: 3.8606)\tTop1: 15.625 (avg: 15.250)\tTop5: 37.500 (avg: 37.812)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.363 (avg: 0.365)\tLoss: 4.1801 (avg: 3.8456)\tTop1: 10.938 (avg: 15.250)\tTop5: 32.812 (avg: 36.656)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.364 (avg: 0.367)\tLoss: 3.9310 (avg: 3.8444)\tTop1: 15.625 (avg: 15.000)\tTop5: 34.375 (avg: 36.417)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.361 (avg: 0.367)\tLoss: 4.0956 (avg: 3.8515)\tTop1: 10.938 (avg: 14.672)\tTop5: 29.688 (avg: 36.531)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.360 (avg: 0.368)\tLoss: 3.6050 (avg: 3.8637)\tTop1: 21.875 (avg: 14.663)\tTop5: 43.750 (avg: 36.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7516\tTop 1 accuracy: 9.800\tTop 5 accuracy: 29.500\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.357 (avg: 0.356)\tLoss: 3.7580 (avg: 3.8639)\tTop1: 10.938 (avg: 15.875)\tTop5: 32.812 (avg: 36.750)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.358 (avg: 0.360)\tLoss: 3.6015 (avg: 3.8564)\tTop1: 7.812 (avg: 15.688)\tTop5: 35.938 (avg: 37.250)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 3.4799 (avg: 3.8475)\tTop1: 14.062 (avg: 15.208)\tTop5: 50.000 (avg: 37.208)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 3.7707 (avg: 3.8488)\tTop1: 15.625 (avg: 15.172)\tTop5: 35.938 (avg: 37.281)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 3.9913 (avg: 3.8453)\tTop1: 7.812 (avg: 15.188)\tTop5: 25.000 (avg: 37.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6617\tTop 1 accuracy: 9.850\tTop 5 accuracy: 29.300\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.354 (avg: 0.354)\tLoss: 4.0001 (avg: 3.8127)\tTop1: 6.250 (avg: 16.125)\tTop5: 39.062 (avg: 39.812)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.355 (avg: 0.357)\tLoss: 3.6698 (avg: 3.8084)\tTop1: 20.312 (avg: 15.812)\tTop5: 42.188 (avg: 39.156)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 3.6433 (avg: 3.8330)\tTop1: 17.188 (avg: 15.125)\tTop5: 37.500 (avg: 38.250)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 3.8570 (avg: 3.8391)\tTop1: 17.188 (avg: 14.984)\tTop5: 37.500 (avg: 37.719)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.352 (avg: 0.361)\tLoss: 3.6662 (avg: 3.8356)\tTop1: 18.750 (avg: 15.213)\tTop5: 42.188 (avg: 37.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6522\tTop 1 accuracy: 10.300\tTop 5 accuracy: 30.050\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.394 (avg: 0.356)\tLoss: 3.7171 (avg: 3.8398)\tTop1: 21.875 (avg: 16.188)\tTop5: 39.062 (avg: 37.500)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.352 (avg: 0.361)\tLoss: 3.9431 (avg: 3.8193)\tTop1: 7.812 (avg: 15.562)\tTop5: 35.938 (avg: 38.000)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 3.6606 (avg: 3.8299)\tTop1: 20.312 (avg: 15.458)\tTop5: 40.625 (avg: 37.708)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 3.7763 (avg: 3.8200)\tTop1: 18.750 (avg: 15.906)\tTop5: 42.188 (avg: 38.297)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 3.8572 (avg: 3.8227)\tTop1: 15.625 (avg: 15.825)\tTop5: 32.812 (avg: 37.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6492\tTop 1 accuracy: 9.550\tTop 5 accuracy: 28.950\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.358 (avg: 0.357)\tLoss: 3.4721 (avg: 3.7652)\tTop1: 12.500 (avg: 14.688)\tTop5: 50.000 (avg: 38.438)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 3.9880 (avg: 3.8121)\tTop1: 4.688 (avg: 14.812)\tTop5: 32.812 (avg: 36.812)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.357 (avg: 0.363)\tLoss: 3.8866 (avg: 3.8220)\tTop1: 17.188 (avg: 14.750)\tTop5: 42.188 (avg: 37.500)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 4.0995 (avg: 3.8057)\tTop1: 9.375 (avg: 15.250)\tTop5: 37.500 (avg: 38.219)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.357 (avg: 0.363)\tLoss: 3.8516 (avg: 3.8123)\tTop1: 12.500 (avg: 15.300)\tTop5: 35.938 (avg: 38.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6638\tTop 1 accuracy: 10.550\tTop 5 accuracy: 30.000\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.355 (avg: 0.354)\tLoss: 3.8124 (avg: 3.7701)\tTop1: 10.938 (avg: 16.500)\tTop5: 42.188 (avg: 38.938)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 3.6739 (avg: 3.7912)\tTop1: 12.500 (avg: 15.469)\tTop5: 28.125 (avg: 38.281)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 4.0196 (avg: 3.8018)\tTop1: 7.812 (avg: 15.188)\tTop5: 34.375 (avg: 38.146)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.9620 (avg: 3.7909)\tTop1: 12.500 (avg: 15.859)\tTop5: 35.938 (avg: 38.562)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 3.7395 (avg: 3.7988)\tTop1: 9.375 (avg: 15.650)\tTop5: 35.938 (avg: 38.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6786\tTop 1 accuracy: 10.150\tTop 5 accuracy: 30.750\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.356 (avg: 0.355)\tLoss: 3.9367 (avg: 3.7906)\tTop1: 12.500 (avg: 15.750)\tTop5: 35.938 (avg: 38.438)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.359 (avg: 0.359)\tLoss: 3.4222 (avg: 3.7952)\tTop1: 17.188 (avg: 15.781)\tTop5: 50.000 (avg: 38.125)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.9333 (avg: 3.7961)\tTop1: 10.938 (avg: 15.729)\tTop5: 35.938 (avg: 38.458)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 3.9243 (avg: 3.8051)\tTop1: 14.062 (avg: 15.594)\tTop5: 42.188 (avg: 38.578)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 4.1910 (avg: 3.8009)\tTop1: 6.250 (avg: 15.613)\tTop5: 31.250 (avg: 38.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6984\tTop 1 accuracy: 9.750\tTop 5 accuracy: 28.850\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.356 (avg: 0.354)\tLoss: 3.6571 (avg: 3.7438)\tTop1: 14.062 (avg: 16.375)\tTop5: 43.750 (avg: 41.188)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.356 (avg: 0.358)\tLoss: 3.5783 (avg: 3.7383)\tTop1: 18.750 (avg: 16.938)\tTop5: 40.625 (avg: 40.781)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.5040 (avg: 3.7587)\tTop1: 18.750 (avg: 16.167)\tTop5: 37.500 (avg: 39.958)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.7500 (avg: 3.7657)\tTop1: 20.312 (avg: 16.031)\tTop5: 39.062 (avg: 39.469)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 3.7577 (avg: 3.7748)\tTop1: 14.062 (avg: 15.988)\tTop5: 34.375 (avg: 39.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7163\tTop 1 accuracy: 11.300\tTop 5 accuracy: 29.900\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.364 (avg: 0.362)\tLoss: 3.6305 (avg: 3.7354)\tTop1: 21.875 (avg: 16.500)\tTop5: 39.062 (avg: 40.750)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.363 (avg: 0.366)\tLoss: 3.4304 (avg: 3.7637)\tTop1: 17.188 (avg: 15.594)\tTop5: 45.312 (avg: 39.312)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.363 (avg: 0.367)\tLoss: 3.7725 (avg: 3.7578)\tTop1: 6.250 (avg: 16.167)\tTop5: 39.062 (avg: 39.458)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.362 (avg: 0.368)\tLoss: 3.6818 (avg: 3.7586)\tTop1: 17.188 (avg: 15.828)\tTop5: 43.750 (avg: 39.297)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.356 (avg: 0.368)\tLoss: 3.9001 (avg: 3.7679)\tTop1: 14.062 (avg: 15.663)\tTop5: 32.812 (avg: 39.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6083\tTop 1 accuracy: 11.000\tTop 5 accuracy: 30.000\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.360 (avg: 0.355)\tLoss: 3.6611 (avg: 3.7191)\tTop1: 14.062 (avg: 17.125)\tTop5: 42.188 (avg: 40.938)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.4893 (avg: 3.7472)\tTop1: 25.000 (avg: 16.719)\tTop5: 46.875 (avg: 40.000)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 3.6273 (avg: 3.7185)\tTop1: 17.188 (avg: 17.083)\tTop5: 42.188 (avg: 40.833)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 3.5535 (avg: 3.7425)\tTop1: 12.500 (avg: 16.625)\tTop5: 46.875 (avg: 39.906)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 3.5518 (avg: 3.7526)\tTop1: 12.500 (avg: 16.075)\tTop5: 37.500 (avg: 39.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6028\tTop 1 accuracy: 10.750\tTop 5 accuracy: 30.550\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.357 (avg: 0.354)\tLoss: 3.6667 (avg: 3.7009)\tTop1: 17.188 (avg: 16.375)\tTop5: 48.438 (avg: 40.500)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.355 (avg: 0.358)\tLoss: 3.5330 (avg: 3.6983)\tTop1: 21.875 (avg: 16.344)\tTop5: 42.188 (avg: 40.594)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 3.9124 (avg: 3.7370)\tTop1: 12.500 (avg: 16.125)\tTop5: 37.500 (avg: 39.750)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.8517 (avg: 3.7520)\tTop1: 21.875 (avg: 16.141)\tTop5: 39.062 (avg: 39.703)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.353 (avg: 0.361)\tLoss: 3.9360 (avg: 3.7440)\tTop1: 18.750 (avg: 16.250)\tTop5: 29.688 (avg: 39.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6717\tTop 1 accuracy: 10.950\tTop 5 accuracy: 29.350\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.363 (avg: 0.355)\tLoss: 3.7934 (avg: 3.7270)\tTop1: 15.625 (avg: 15.438)\tTop5: 37.500 (avg: 39.562)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 4.0641 (avg: 3.7213)\tTop1: 14.062 (avg: 16.656)\tTop5: 28.125 (avg: 40.281)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 3.9553 (avg: 3.7372)\tTop1: 14.062 (avg: 16.208)\tTop5: 35.938 (avg: 39.833)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.7477 (avg: 3.7346)\tTop1: 18.750 (avg: 16.344)\tTop5: 34.375 (avg: 39.906)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 3.6587 (avg: 3.7307)\tTop1: 17.188 (avg: 16.363)\tTop5: 46.875 (avg: 40.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6926\tTop 1 accuracy: 10.550\tTop 5 accuracy: 30.700\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.366 (avg: 0.357)\tLoss: 3.7173 (avg: 3.6718)\tTop1: 17.188 (avg: 17.125)\tTop5: 42.188 (avg: 42.062)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 3.4617 (avg: 3.6560)\tTop1: 15.625 (avg: 17.969)\tTop5: 50.000 (avg: 41.750)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.360 (avg: 0.363)\tLoss: 3.8973 (avg: 3.6841)\tTop1: 14.062 (avg: 17.458)\tTop5: 31.250 (avg: 40.917)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 3.6361 (avg: 3.7063)\tTop1: 21.875 (avg: 17.031)\tTop5: 48.438 (avg: 40.797)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.352 (avg: 0.364)\tLoss: 3.5872 (avg: 3.7132)\tTop1: 14.062 (avg: 16.825)\tTop5: 48.438 (avg: 40.625)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7367\tTop 1 accuracy: 10.900\tTop 5 accuracy: 30.250\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.358 (avg: 0.355)\tLoss: 3.7339 (avg: 3.6732)\tTop1: 15.625 (avg: 18.375)\tTop5: 35.938 (avg: 41.562)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.2693 (avg: 3.6772)\tTop1: 23.438 (avg: 17.375)\tTop5: 59.375 (avg: 41.375)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 3.8786 (avg: 3.6815)\tTop1: 15.625 (avg: 17.521)\tTop5: 40.625 (avg: 41.479)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 4.0180 (avg: 3.6930)\tTop1: 12.500 (avg: 17.250)\tTop5: 26.562 (avg: 40.984)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 3.6878 (avg: 3.6987)\tTop1: 17.188 (avg: 17.138)\tTop5: 42.188 (avg: 40.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7866\tTop 1 accuracy: 10.150\tTop 5 accuracy: 29.000\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.356 (avg: 0.355)\tLoss: 3.8315 (avg: 3.7156)\tTop1: 15.625 (avg: 17.312)\tTop5: 40.625 (avg: 42.500)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.357 (avg: 0.359)\tLoss: 3.7320 (avg: 3.6883)\tTop1: 20.312 (avg: 17.562)\tTop5: 40.625 (avg: 41.438)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 3.6208 (avg: 3.6977)\tTop1: 20.312 (avg: 17.271)\tTop5: 42.188 (avg: 40.729)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 3.9372 (avg: 3.6876)\tTop1: 12.500 (avg: 17.031)\tTop5: 39.062 (avg: 41.125)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 3.5729 (avg: 3.7027)\tTop1: 17.188 (avg: 16.900)\tTop5: 43.750 (avg: 40.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6980\tTop 1 accuracy: 10.750\tTop 5 accuracy: 30.800\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.354 (avg: 0.354)\tLoss: 3.4750 (avg: 3.6660)\tTop1: 25.000 (avg: 17.938)\tTop5: 45.312 (avg: 42.250)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.355 (avg: 0.358)\tLoss: 3.7565 (avg: 3.6729)\tTop1: 15.625 (avg: 17.469)\tTop5: 35.938 (avg: 41.906)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 3.4299 (avg: 3.6582)\tTop1: 17.188 (avg: 18.000)\tTop5: 43.750 (avg: 42.021)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.8671 (avg: 3.6701)\tTop1: 10.938 (avg: 17.969)\tTop5: 37.500 (avg: 41.906)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.360 (avg: 0.361)\tLoss: 3.7376 (avg: 3.6850)\tTop1: 7.812 (avg: 17.575)\tTop5: 34.375 (avg: 41.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5455\tTop 1 accuracy: 11.150\tTop 5 accuracy: 31.400\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.363 (avg: 0.362)\tLoss: 3.6252 (avg: 3.5892)\tTop1: 17.188 (avg: 19.062)\tTop5: 40.625 (avg: 43.625)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.365 (avg: 0.366)\tLoss: 3.6571 (avg: 3.5882)\tTop1: 15.625 (avg: 19.312)\tTop5: 45.312 (avg: 44.062)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.360 (avg: 0.367)\tLoss: 3.8086 (avg: 3.6388)\tTop1: 18.750 (avg: 18.625)\tTop5: 39.062 (avg: 42.875)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 3.8228 (avg: 3.6586)\tTop1: 10.938 (avg: 18.031)\tTop5: 31.250 (avg: 41.953)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.360 (avg: 0.368)\tLoss: 4.1169 (avg: 3.6674)\tTop1: 3.125 (avg: 17.550)\tTop5: 29.688 (avg: 41.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6752\tTop 1 accuracy: 11.250\tTop 5 accuracy: 30.800\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.355 (avg: 0.356)\tLoss: 3.7933 (avg: 3.5919)\tTop1: 17.188 (avg: 18.000)\tTop5: 29.688 (avg: 43.062)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 3.5978 (avg: 3.6074)\tTop1: 29.688 (avg: 18.188)\tTop5: 42.188 (avg: 42.344)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.361 (avg: 0.362)\tLoss: 3.7663 (avg: 3.6283)\tTop1: 23.438 (avg: 18.146)\tTop5: 40.625 (avg: 42.438)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.359 (avg: 0.363)\tLoss: 3.7439 (avg: 3.6472)\tTop1: 23.438 (avg: 18.141)\tTop5: 37.500 (avg: 42.312)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.356 (avg: 0.363)\tLoss: 3.5834 (avg: 3.6555)\tTop1: 17.188 (avg: 17.838)\tTop5: 42.188 (avg: 42.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5231\tTop 1 accuracy: 11.800\tTop 5 accuracy: 31.250\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.355 (avg: 0.353)\tLoss: 4.0206 (avg: 3.6702)\tTop1: 15.625 (avg: 17.375)\tTop5: 29.688 (avg: 40.625)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.356 (avg: 0.358)\tLoss: 3.6651 (avg: 3.6316)\tTop1: 20.312 (avg: 17.875)\tTop5: 45.312 (avg: 41.750)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.354 (avg: 0.359)\tLoss: 3.7266 (avg: 3.6447)\tTop1: 17.188 (avg: 17.750)\tTop5: 42.188 (avg: 41.979)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 3.8214 (avg: 3.6557)\tTop1: 23.438 (avg: 17.578)\tTop5: 35.938 (avg: 41.750)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 3.5136 (avg: 3.6578)\tTop1: 17.188 (avg: 17.838)\tTop5: 40.625 (avg: 41.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5346\tTop 1 accuracy: 11.650\tTop 5 accuracy: 31.400\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.356 (avg: 0.354)\tLoss: 3.6419 (avg: 3.5677)\tTop1: 20.312 (avg: 19.000)\tTop5: 46.875 (avg: 44.062)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.358 (avg: 0.359)\tLoss: 3.9466 (avg: 3.5814)\tTop1: 7.812 (avg: 18.594)\tTop5: 29.688 (avg: 43.438)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 3.7978 (avg: 3.6225)\tTop1: 17.188 (avg: 18.333)\tTop5: 40.625 (avg: 42.167)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.9955 (avg: 3.6323)\tTop1: 6.250 (avg: 18.031)\tTop5: 32.812 (avg: 42.297)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.4227 (avg: 3.6328)\tTop1: 26.562 (avg: 18.050)\tTop5: 50.000 (avg: 42.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5638\tTop 1 accuracy: 11.800\tTop 5 accuracy: 32.100\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.356 (avg: 0.357)\tLoss: 3.3009 (avg: 3.5691)\tTop1: 20.312 (avg: 18.688)\tTop5: 43.750 (avg: 43.062)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.361 (avg: 0.361)\tLoss: 3.1685 (avg: 3.5813)\tTop1: 21.875 (avg: 18.750)\tTop5: 62.500 (avg: 43.688)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.359 (avg: 0.363)\tLoss: 3.5342 (avg: 3.6009)\tTop1: 21.875 (avg: 18.083)\tTop5: 43.750 (avg: 43.083)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 3.6224 (avg: 3.6153)\tTop1: 23.438 (avg: 18.078)\tTop5: 39.062 (avg: 42.969)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.358 (avg: 0.364)\tLoss: 3.4057 (avg: 3.6234)\tTop1: 17.188 (avg: 17.950)\tTop5: 54.688 (avg: 42.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5226\tTop 1 accuracy: 11.300\tTop 5 accuracy: 31.150\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.354 (avg: 0.355)\tLoss: 3.4339 (avg: 3.5842)\tTop1: 15.625 (avg: 18.188)\tTop5: 46.875 (avg: 42.438)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.358 (avg: 0.360)\tLoss: 3.9999 (avg: 3.5720)\tTop1: 14.062 (avg: 19.156)\tTop5: 40.625 (avg: 43.062)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.353 (avg: 0.361)\tLoss: 3.4008 (avg: 3.5700)\tTop1: 17.188 (avg: 19.021)\tTop5: 53.125 (avg: 43.125)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 3.6059 (avg: 3.5934)\tTop1: 21.875 (avg: 18.672)\tTop5: 43.750 (avg: 42.906)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 3.5142 (avg: 3.6032)\tTop1: 23.438 (avg: 18.350)\tTop5: 42.188 (avg: 42.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6128\tTop 1 accuracy: 12.150\tTop 5 accuracy: 31.550\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.355 (avg: 0.353)\tLoss: 3.3980 (avg: 3.5974)\tTop1: 21.875 (avg: 17.125)\tTop5: 53.125 (avg: 42.375)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.358 (avg: 0.358)\tLoss: 3.9082 (avg: 3.5974)\tTop1: 12.500 (avg: 18.156)\tTop5: 37.500 (avg: 43.562)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.353 (avg: 0.360)\tLoss: 3.7860 (avg: 3.5965)\tTop1: 15.625 (avg: 18.708)\tTop5: 40.625 (avg: 43.542)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 3.3366 (avg: 3.5983)\tTop1: 21.875 (avg: 18.531)\tTop5: 53.125 (avg: 43.359)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.364 (avg: 0.362)\tLoss: 3.4500 (avg: 3.5908)\tTop1: 14.062 (avg: 18.700)\tTop5: 42.188 (avg: 43.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6487\tTop 1 accuracy: 11.100\tTop 5 accuracy: 31.850\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.356 (avg: 0.354)\tLoss: 3.4953 (avg: 3.5898)\tTop1: 12.500 (avg: 18.062)\tTop5: 42.188 (avg: 43.312)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.355 (avg: 0.358)\tLoss: 3.5024 (avg: 3.5752)\tTop1: 18.750 (avg: 18.562)\tTop5: 45.312 (avg: 44.125)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 3.3524 (avg: 3.5921)\tTop1: 21.875 (avg: 18.146)\tTop5: 54.688 (avg: 43.188)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.5921 (avg: 3.5816)\tTop1: 14.062 (avg: 18.766)\tTop5: 43.750 (avg: 43.719)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.4148 (avg: 3.5778)\tTop1: 21.875 (avg: 18.613)\tTop5: 48.438 (avg: 43.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5501\tTop 1 accuracy: 11.600\tTop 5 accuracy: 32.150\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.361 (avg: 0.361)\tLoss: 3.2853 (avg: 3.5131)\tTop1: 28.125 (avg: 20.312)\tTop5: 53.125 (avg: 45.438)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.361 (avg: 0.365)\tLoss: 3.2925 (avg: 3.4831)\tTop1: 21.875 (avg: 20.719)\tTop5: 54.688 (avg: 46.219)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.361 (avg: 0.366)\tLoss: 3.4602 (avg: 3.4728)\tTop1: 17.188 (avg: 20.354)\tTop5: 46.875 (avg: 45.771)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 3.8018 (avg: 3.4798)\tTop1: 14.062 (avg: 20.750)\tTop5: 34.375 (avg: 45.891)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.363 (avg: 0.368)\tLoss: 3.1142 (avg: 3.4730)\tTop1: 28.125 (avg: 20.725)\tTop5: 53.125 (avg: 46.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5966\tTop 1 accuracy: 12.350\tTop 5 accuracy: 33.400\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.356 (avg: 0.356)\tLoss: 3.6706 (avg: 3.5382)\tTop1: 20.312 (avg: 19.500)\tTop5: 45.312 (avg: 43.438)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.359 (avg: 0.360)\tLoss: 3.3823 (avg: 3.4981)\tTop1: 20.312 (avg: 20.781)\tTop5: 45.312 (avg: 45.375)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 3.4274 (avg: 3.4659)\tTop1: 21.875 (avg: 21.083)\tTop5: 46.875 (avg: 46.125)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.364 (avg: 0.362)\tLoss: 3.1283 (avg: 3.4526)\tTop1: 29.688 (avg: 21.078)\tTop5: 46.875 (avg: 46.328)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.357 (avg: 0.363)\tLoss: 3.9126 (avg: 3.4563)\tTop1: 14.062 (avg: 21.113)\tTop5: 39.062 (avg: 46.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6044\tTop 1 accuracy: 12.950\tTop 5 accuracy: 33.000\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.356 (avg: 0.354)\tLoss: 3.4429 (avg: 3.4434)\tTop1: 17.188 (avg: 21.875)\tTop5: 48.438 (avg: 45.688)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.355 (avg: 0.358)\tLoss: 3.9356 (avg: 3.4317)\tTop1: 18.750 (avg: 22.219)\tTop5: 32.812 (avg: 46.031)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.358 (avg: 0.360)\tLoss: 3.6714 (avg: 3.4243)\tTop1: 18.750 (avg: 21.792)\tTop5: 50.000 (avg: 46.271)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.5152 (avg: 3.4342)\tTop1: 14.062 (avg: 21.469)\tTop5: 46.875 (avg: 46.703)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 3.1359 (avg: 3.4496)\tTop1: 20.312 (avg: 21.300)\tTop5: 54.688 (avg: 46.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5677\tTop 1 accuracy: 13.150\tTop 5 accuracy: 33.050\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.356 (avg: 0.354)\tLoss: 3.7725 (avg: 3.4163)\tTop1: 18.750 (avg: 21.312)\tTop5: 42.188 (avg: 48.250)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 3.4584 (avg: 3.4420)\tTop1: 17.188 (avg: 21.125)\tTop5: 46.875 (avg: 47.312)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.351 (avg: 0.360)\tLoss: 3.5324 (avg: 3.4449)\tTop1: 20.312 (avg: 21.208)\tTop5: 42.188 (avg: 47.354)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 3.6885 (avg: 3.4443)\tTop1: 12.500 (avg: 21.172)\tTop5: 39.062 (avg: 47.141)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.7398 (avg: 3.4450)\tTop1: 17.188 (avg: 21.213)\tTop5: 34.375 (avg: 47.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6070\tTop 1 accuracy: 12.950\tTop 5 accuracy: 32.800\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.358 (avg: 0.357)\tLoss: 3.5242 (avg: 3.4631)\tTop1: 17.188 (avg: 21.688)\tTop5: 46.875 (avg: 46.188)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.361 (avg: 0.361)\tLoss: 3.3715 (avg: 3.4418)\tTop1: 21.875 (avg: 21.469)\tTop5: 46.875 (avg: 46.438)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.360 (avg: 0.363)\tLoss: 3.4602 (avg: 3.4380)\tTop1: 20.312 (avg: 21.146)\tTop5: 46.875 (avg: 46.896)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.359 (avg: 0.363)\tLoss: 3.1546 (avg: 3.4376)\tTop1: 25.000 (avg: 21.531)\tTop5: 51.562 (avg: 47.234)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.355 (avg: 0.364)\tLoss: 3.5627 (avg: 3.4396)\tTop1: 20.312 (avg: 21.363)\tTop5: 42.188 (avg: 47.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5696\tTop 1 accuracy: 13.150\tTop 5 accuracy: 32.900\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.358 (avg: 0.355)\tLoss: 3.6215 (avg: 3.4381)\tTop1: 18.750 (avg: 22.438)\tTop5: 40.625 (avg: 47.812)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 2.9556 (avg: 3.4181)\tTop1: 28.125 (avg: 22.219)\tTop5: 53.125 (avg: 48.250)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.3799 (avg: 3.4246)\tTop1: 25.000 (avg: 21.625)\tTop5: 48.438 (avg: 47.646)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 3.4157 (avg: 3.4466)\tTop1: 21.875 (avg: 21.453)\tTop5: 48.438 (avg: 46.906)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 3.3831 (avg: 3.4345)\tTop1: 23.438 (avg: 21.575)\tTop5: 48.438 (avg: 47.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5757\tTop 1 accuracy: 12.900\tTop 5 accuracy: 33.450\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.356 (avg: 0.355)\tLoss: 3.4122 (avg: 3.4276)\tTop1: 18.750 (avg: 21.625)\tTop5: 48.438 (avg: 47.875)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.361 (avg: 0.360)\tLoss: 3.2739 (avg: 3.4490)\tTop1: 29.688 (avg: 21.875)\tTop5: 48.438 (avg: 47.250)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 3.5329 (avg: 3.4366)\tTop1: 21.875 (avg: 21.896)\tTop5: 48.438 (avg: 47.208)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 3.7474 (avg: 3.4183)\tTop1: 15.625 (avg: 22.016)\tTop5: 42.188 (avg: 47.594)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 3.6044 (avg: 3.4396)\tTop1: 21.875 (avg: 21.625)\tTop5: 42.188 (avg: 46.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5619\tTop 1 accuracy: 12.800\tTop 5 accuracy: 33.250\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.356 (avg: 0.353)\tLoss: 3.0675 (avg: 3.3698)\tTop1: 29.688 (avg: 21.250)\tTop5: 62.500 (avg: 50.062)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.357 (avg: 0.358)\tLoss: 3.3897 (avg: 3.3879)\tTop1: 23.438 (avg: 21.219)\tTop5: 50.000 (avg: 49.094)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 2.9524 (avg: 3.4125)\tTop1: 28.125 (avg: 21.292)\tTop5: 54.688 (avg: 48.042)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 3.7315 (avg: 3.4227)\tTop1: 21.875 (avg: 21.516)\tTop5: 35.938 (avg: 47.656)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.5270 (avg: 3.4328)\tTop1: 23.438 (avg: 21.475)\tTop5: 39.062 (avg: 47.325)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5990\tTop 1 accuracy: 13.150\tTop 5 accuracy: 33.100\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.364 (avg: 0.361)\tLoss: 3.7128 (avg: 3.4019)\tTop1: 12.500 (avg: 21.625)\tTop5: 37.500 (avg: 47.312)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.362 (avg: 0.365)\tLoss: 3.4779 (avg: 3.4336)\tTop1: 20.312 (avg: 21.844)\tTop5: 37.500 (avg: 46.750)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 3.2468 (avg: 3.4434)\tTop1: 20.312 (avg: 21.688)\tTop5: 51.562 (avg: 46.750)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.364 (avg: 0.367)\tLoss: 3.6029 (avg: 3.4393)\tTop1: 18.750 (avg: 21.547)\tTop5: 40.625 (avg: 47.047)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.364 (avg: 0.368)\tLoss: 3.4707 (avg: 3.4276)\tTop1: 20.312 (avg: 21.450)\tTop5: 53.125 (avg: 47.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5588\tTop 1 accuracy: 13.200\tTop 5 accuracy: 33.400\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.358 (avg: 0.356)\tLoss: 3.0378 (avg: 3.4643)\tTop1: 28.125 (avg: 19.750)\tTop5: 59.375 (avg: 44.688)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 3.0647 (avg: 3.4204)\tTop1: 35.938 (avg: 21.188)\tTop5: 57.812 (avg: 46.406)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 3.1631 (avg: 3.4239)\tTop1: 28.125 (avg: 21.542)\tTop5: 57.812 (avg: 46.688)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 2.9149 (avg: 3.4286)\tTop1: 20.312 (avg: 21.672)\tTop5: 65.625 (avg: 46.859)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.359 (avg: 0.363)\tLoss: 3.2031 (avg: 3.4286)\tTop1: 28.125 (avg: 21.525)\tTop5: 51.562 (avg: 46.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5933\tTop 1 accuracy: 13.300\tTop 5 accuracy: 33.450\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.353 (avg: 0.354)\tLoss: 3.4740 (avg: 3.3476)\tTop1: 17.188 (avg: 22.688)\tTop5: 43.750 (avg: 47.750)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.356 (avg: 0.358)\tLoss: 3.4094 (avg: 3.4045)\tTop1: 23.438 (avg: 22.156)\tTop5: 48.438 (avg: 47.406)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.6916 (avg: 3.4168)\tTop1: 20.312 (avg: 22.312)\tTop5: 37.500 (avg: 47.312)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 2.9410 (avg: 3.4253)\tTop1: 34.375 (avg: 22.156)\tTop5: 59.375 (avg: 47.016)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.6637 (avg: 3.4181)\tTop1: 18.750 (avg: 21.950)\tTop5: 40.625 (avg: 47.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6511\tTop 1 accuracy: 13.100\tTop 5 accuracy: 33.000\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.355 (avg: 0.354)\tLoss: 3.0141 (avg: 3.4265)\tTop1: 31.250 (avg: 21.750)\tTop5: 59.375 (avg: 47.062)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.355 (avg: 0.358)\tLoss: 3.3956 (avg: 3.4392)\tTop1: 25.000 (avg: 21.844)\tTop5: 43.750 (avg: 46.938)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.2692 (avg: 3.4378)\tTop1: 31.250 (avg: 21.833)\tTop5: 54.688 (avg: 47.250)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 3.5368 (avg: 3.4142)\tTop1: 23.438 (avg: 21.766)\tTop5: 43.750 (avg: 47.688)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.1336 (avg: 3.4202)\tTop1: 28.125 (avg: 21.813)\tTop5: 60.938 (avg: 47.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6035\tTop 1 accuracy: 13.100\tTop 5 accuracy: 33.450\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.358 (avg: 0.356)\tLoss: 3.5245 (avg: 3.4420)\tTop1: 20.312 (avg: 21.625)\tTop5: 40.625 (avg: 47.812)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.360 (avg: 0.361)\tLoss: 3.5882 (avg: 3.4188)\tTop1: 23.438 (avg: 21.781)\tTop5: 51.562 (avg: 48.250)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.362 (avg: 0.362)\tLoss: 3.3921 (avg: 3.4313)\tTop1: 25.000 (avg: 21.646)\tTop5: 48.438 (avg: 47.667)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 3.3248 (avg: 3.4289)\tTop1: 25.000 (avg: 21.734)\tTop5: 54.688 (avg: 47.234)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 3.2322 (avg: 3.4186)\tTop1: 28.125 (avg: 21.950)\tTop5: 53.125 (avg: 47.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5793\tTop 1 accuracy: 13.050\tTop 5 accuracy: 33.100\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.356 (avg: 0.355)\tLoss: 3.6669 (avg: 3.3344)\tTop1: 18.750 (avg: 23.562)\tTop5: 45.312 (avg: 49.750)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 3.1908 (avg: 3.3670)\tTop1: 21.875 (avg: 22.594)\tTop5: 57.812 (avg: 48.750)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 3.2907 (avg: 3.4017)\tTop1: 21.875 (avg: 22.000)\tTop5: 43.750 (avg: 47.833)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.9232 (avg: 3.4117)\tTop1: 12.500 (avg: 21.797)\tTop5: 46.875 (avg: 47.719)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 3.3812 (avg: 3.4178)\tTop1: 17.188 (avg: 21.850)\tTop5: 48.438 (avg: 47.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5758\tTop 1 accuracy: 13.350\tTop 5 accuracy: 33.200\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.350 (avg: 0.354)\tLoss: 3.1834 (avg: 3.3913)\tTop1: 23.438 (avg: 22.188)\tTop5: 50.000 (avg: 48.250)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.354 (avg: 0.359)\tLoss: 3.4701 (avg: 3.3901)\tTop1: 26.562 (avg: 22.469)\tTop5: 45.312 (avg: 48.031)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.5322 (avg: 3.4187)\tTop1: 17.188 (avg: 22.229)\tTop5: 43.750 (avg: 47.438)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.0903 (avg: 3.4251)\tTop1: 32.812 (avg: 22.000)\tTop5: 56.250 (avg: 47.500)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 3.2758 (avg: 3.4171)\tTop1: 28.125 (avg: 21.888)\tTop5: 50.000 (avg: 47.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5973\tTop 1 accuracy: 13.600\tTop 5 accuracy: 33.700\n",
            "\n",
            "base_e = 128: top1 = 13.600000381469727 \t top5 = 33.70000076293945 \t batch time = 0.29372115433216095\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.448 (avg: 0.571)\tLoss: 5.2947 (avg: 5.3082)\tTop1: 1.562 (avg: 0.375)\tTop5: 4.688 (avg: 1.938)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.449 (avg: 0.514)\tLoss: 5.3007 (avg: 5.3037)\tTop1: 0.000 (avg: 0.375)\tTop5: 1.562 (avg: 2.375)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.444 (avg: 0.495)\tLoss: 5.3012 (avg: 5.3021)\tTop1: 0.000 (avg: 0.458)\tTop5: 1.562 (avg: 2.375)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.452 (avg: 0.485)\tLoss: 5.3012 (avg: 5.3013)\tTop1: 0.000 (avg: 0.469)\tTop5: 1.562 (avg: 2.297)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.451 (avg: 0.480)\tLoss: 5.2993 (avg: 5.3008)\tTop1: 0.000 (avg: 0.438)\tTop5: 0.000 (avg: 2.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2957\tTop 1 accuracy: 0.200\tTop 5 accuracy: 1.750\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.450 (avg: 0.445)\tLoss: 5.2998 (avg: 5.2977)\tTop1: 0.000 (avg: 0.312)\tTop5: 1.562 (avg: 2.438)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.441 (avg: 0.450)\tLoss: 5.2957 (avg: 5.2975)\tTop1: 0.000 (avg: 0.531)\tTop5: 4.688 (avg: 2.906)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.454 (avg: 0.452)\tLoss: 5.2896 (avg: 5.2971)\tTop1: 0.000 (avg: 0.521)\tTop5: 4.688 (avg: 2.833)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.448 (avg: 0.453)\tLoss: 5.3023 (avg: 5.2962)\tTop1: 0.000 (avg: 0.594)\tTop5: 0.000 (avg: 2.766)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.450 (avg: 0.454)\tLoss: 5.2707 (avg: 5.2932)\tTop1: 0.000 (avg: 0.638)\tTop5: 1.562 (avg: 2.813)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1512\tTop 1 accuracy: 0.600\tTop 5 accuracy: 2.900\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.450 (avg: 0.445)\tLoss: 5.2942 (avg: 5.2747)\tTop1: 1.562 (avg: 0.875)\tTop5: 3.125 (avg: 3.688)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 5.2189 (avg: 5.2718)\tTop1: 1.562 (avg: 1.031)\tTop5: 7.812 (avg: 4.281)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.449 (avg: 0.452)\tLoss: 5.2454 (avg: 5.2732)\tTop1: 1.562 (avg: 0.958)\tTop5: 6.250 (avg: 4.125)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.451 (avg: 0.453)\tLoss: 5.3107 (avg: 5.2715)\tTop1: 0.000 (avg: 0.938)\tTop5: 0.000 (avg: 3.984)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.446 (avg: 0.454)\tLoss: 5.2174 (avg: 5.2681)\tTop1: 0.000 (avg: 0.913)\tTop5: 3.125 (avg: 4.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0810\tTop 1 accuracy: 0.750\tTop 5 accuracy: 3.800\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.447 (avg: 0.445)\tLoss: 5.2610 (avg: 5.2501)\tTop1: 0.000 (avg: 0.562)\tTop5: 6.250 (avg: 4.438)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.450 (avg: 0.450)\tLoss: 5.2930 (avg: 5.2381)\tTop1: 0.000 (avg: 0.812)\tTop5: 1.562 (avg: 4.781)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.451 (avg: 0.452)\tLoss: 5.2848 (avg: 5.2389)\tTop1: 1.562 (avg: 0.896)\tTop5: 7.812 (avg: 4.729)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 5.2807 (avg: 5.2384)\tTop1: 0.000 (avg: 0.859)\tTop5: 1.562 (avg: 4.609)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.450 (avg: 0.454)\tLoss: 5.2177 (avg: 5.2366)\tTop1: 4.688 (avg: 0.900)\tTop5: 6.250 (avg: 4.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1911\tTop 1 accuracy: 1.000\tTop 5 accuracy: 4.550\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.449 (avg: 0.445)\tLoss: 5.2108 (avg: 5.1954)\tTop1: 4.688 (avg: 1.500)\tTop5: 7.812 (avg: 6.125)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.458 (avg: 0.450)\tLoss: 5.2073 (avg: 5.1960)\tTop1: 0.000 (avg: 1.250)\tTop5: 7.812 (avg: 5.906)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.454 (avg: 0.452)\tLoss: 5.2496 (avg: 5.2044)\tTop1: 0.000 (avg: 1.083)\tTop5: 6.250 (avg: 5.604)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.456 (avg: 0.453)\tLoss: 5.0834 (avg: 5.2091)\tTop1: 1.562 (avg: 1.141)\tTop5: 9.375 (avg: 5.422)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.455 (avg: 0.453)\tLoss: 5.1870 (avg: 5.2092)\tTop1: 1.562 (avg: 1.125)\tTop5: 4.688 (avg: 5.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1847\tTop 1 accuracy: 1.350\tTop 5 accuracy: 5.300\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.453 (avg: 0.445)\tLoss: 5.1804 (avg: 5.1874)\tTop1: 1.562 (avg: 1.500)\tTop5: 6.250 (avg: 5.562)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.448 (avg: 0.451)\tLoss: 5.2621 (avg: 5.1948)\tTop1: 1.562 (avg: 1.500)\tTop5: 3.125 (avg: 5.312)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.446 (avg: 0.452)\tLoss: 5.1102 (avg: 5.1885)\tTop1: 1.562 (avg: 1.521)\tTop5: 9.375 (avg: 5.729)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.451 (avg: 0.453)\tLoss: 5.1691 (avg: 5.1833)\tTop1: 0.000 (avg: 1.406)\tTop5: 0.000 (avg: 5.500)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.447 (avg: 0.454)\tLoss: 5.2143 (avg: 5.1831)\tTop1: 1.562 (avg: 1.363)\tTop5: 10.938 (avg: 5.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1437\tTop 1 accuracy: 1.100\tTop 5 accuracy: 5.250\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.454 (avg: 0.446)\tLoss: 5.1110 (avg: 5.1889)\tTop1: 0.000 (avg: 1.250)\tTop5: 6.250 (avg: 6.250)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.441 (avg: 0.451)\tLoss: 5.1279 (avg: 5.1670)\tTop1: 1.562 (avg: 1.562)\tTop5: 4.688 (avg: 6.750)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.448 (avg: 0.453)\tLoss: 5.2272 (avg: 5.1706)\tTop1: 1.562 (avg: 1.333)\tTop5: 9.375 (avg: 6.479)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.449 (avg: 0.453)\tLoss: 5.2463 (avg: 5.1734)\tTop1: 1.562 (avg: 1.297)\tTop5: 4.688 (avg: 6.156)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.450 (avg: 0.454)\tLoss: 5.2304 (avg: 5.1781)\tTop1: 0.000 (avg: 1.263)\tTop5: 7.812 (avg: 5.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2856\tTop 1 accuracy: 0.800\tTop 5 accuracy: 4.200\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.451 (avg: 0.446)\tLoss: 5.3240 (avg: 5.1979)\tTop1: 3.125 (avg: 0.812)\tTop5: 4.688 (avg: 4.375)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.449 (avg: 0.451)\tLoss: 5.1793 (avg: 5.1937)\tTop1: 3.125 (avg: 1.031)\tTop5: 9.375 (avg: 4.625)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.449 (avg: 0.453)\tLoss: 4.9568 (avg: 5.1825)\tTop1: 4.688 (avg: 1.000)\tTop5: 6.250 (avg: 4.500)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.451 (avg: 0.454)\tLoss: 5.1309 (avg: 5.1779)\tTop1: 1.562 (avg: 1.109)\tTop5: 6.250 (avg: 4.828)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.446 (avg: 0.454)\tLoss: 5.1744 (avg: 5.1817)\tTop1: 1.562 (avg: 1.150)\tTop5: 6.250 (avg: 5.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1405\tTop 1 accuracy: 1.050\tTop 5 accuracy: 4.550\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.446 (avg: 0.444)\tLoss: 5.1557 (avg: 5.1688)\tTop1: 0.000 (avg: 1.875)\tTop5: 7.812 (avg: 6.125)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.444 (avg: 0.449)\tLoss: 5.1725 (avg: 5.1588)\tTop1: 0.000 (avg: 1.719)\tTop5: 4.688 (avg: 6.219)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.449 (avg: 0.451)\tLoss: 5.1464 (avg: 5.1477)\tTop1: 4.688 (avg: 1.958)\tTop5: 7.812 (avg: 6.833)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.448 (avg: 0.453)\tLoss: 5.2520 (avg: 5.1428)\tTop1: 0.000 (avg: 1.859)\tTop5: 4.688 (avg: 6.844)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.446 (avg: 0.453)\tLoss: 5.0472 (avg: 5.1396)\tTop1: 0.000 (avg: 1.738)\tTop5: 9.375 (avg: 6.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0578\tTop 1 accuracy: 1.250\tTop 5 accuracy: 6.750\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.447 (avg: 0.443)\tLoss: 5.1198 (avg: 5.1562)\tTop1: 1.562 (avg: 1.875)\tTop5: 4.688 (avg: 6.812)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.450 (avg: 0.449)\tLoss: 5.1545 (avg: 5.1238)\tTop1: 0.000 (avg: 1.844)\tTop5: 6.250 (avg: 7.281)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.448 (avg: 0.452)\tLoss: 4.9696 (avg: 5.1171)\tTop1: 4.688 (avg: 1.979)\tTop5: 12.500 (avg: 7.375)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.449 (avg: 0.453)\tLoss: 5.1138 (avg: 5.1178)\tTop1: 1.562 (avg: 1.781)\tTop5: 12.500 (avg: 7.250)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.449 (avg: 0.453)\tLoss: 5.1631 (avg: 5.1201)\tTop1: 0.000 (avg: 1.763)\tTop5: 10.938 (avg: 7.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0390\tTop 1 accuracy: 1.500\tTop 5 accuracy: 7.750\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.449 (avg: 0.445)\tLoss: 5.0910 (avg: 5.0595)\tTop1: 1.562 (avg: 2.062)\tTop5: 9.375 (avg: 7.438)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.448 (avg: 0.451)\tLoss: 4.9881 (avg: 5.0614)\tTop1: 0.000 (avg: 1.812)\tTop5: 14.062 (avg: 8.188)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.449 (avg: 0.453)\tLoss: 4.9756 (avg: 5.0654)\tTop1: 6.250 (avg: 1.854)\tTop5: 9.375 (avg: 8.167)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 5.1707 (avg: 5.0696)\tTop1: 0.000 (avg: 1.781)\tTop5: 6.250 (avg: 8.109)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 5.0626 (avg: 5.0770)\tTop1: 1.562 (avg: 1.825)\tTop5: 4.688 (avg: 7.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0079\tTop 1 accuracy: 1.550\tTop 5 accuracy: 7.750\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.448 (avg: 0.445)\tLoss: 5.0854 (avg: 5.0903)\tTop1: 6.250 (avg: 1.875)\tTop5: 20.312 (avg: 8.312)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.449 (avg: 0.450)\tLoss: 5.0573 (avg: 5.0756)\tTop1: 6.250 (avg: 2.062)\tTop5: 10.938 (avg: 8.656)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.448 (avg: 0.452)\tLoss: 5.0738 (avg: 5.0610)\tTop1: 6.250 (avg: 2.167)\tTop5: 9.375 (avg: 9.000)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 5.1519 (avg: 5.0604)\tTop1: 1.562 (avg: 2.141)\tTop5: 3.125 (avg: 8.797)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 5.0010 (avg: 5.0542)\tTop1: 3.125 (avg: 1.963)\tTop5: 4.688 (avg: 8.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0524\tTop 1 accuracy: 2.000\tTop 5 accuracy: 7.500\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.446 (avg: 0.445)\tLoss: 4.9768 (avg: 5.0312)\tTop1: 6.250 (avg: 3.375)\tTop5: 12.500 (avg: 9.875)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.441 (avg: 0.451)\tLoss: 4.8496 (avg: 5.0329)\tTop1: 4.688 (avg: 2.562)\tTop5: 9.375 (avg: 8.906)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 5.0646 (avg: 5.0235)\tTop1: 0.000 (avg: 2.438)\tTop5: 4.688 (avg: 8.958)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 4.9660 (avg: 5.0058)\tTop1: 4.688 (avg: 2.484)\tTop5: 7.812 (avg: 9.031)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 4.9408 (avg: 5.0047)\tTop1: 3.125 (avg: 2.488)\tTop5: 10.938 (avg: 8.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9863\tTop 1 accuracy: 1.700\tTop 5 accuracy: 8.000\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.450 (avg: 0.445)\tLoss: 4.9248 (avg: 5.0086)\tTop1: 1.562 (avg: 1.250)\tTop5: 9.375 (avg: 8.062)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.451 (avg: 0.451)\tLoss: 5.0390 (avg: 4.9774)\tTop1: 0.000 (avg: 1.562)\tTop5: 7.812 (avg: 9.000)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 5.0392 (avg: 4.9598)\tTop1: 1.562 (avg: 1.833)\tTop5: 9.375 (avg: 9.292)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 5.1965 (avg: 4.9559)\tTop1: 0.000 (avg: 1.906)\tTop5: 9.375 (avg: 9.484)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.446 (avg: 0.454)\tLoss: 4.9817 (avg: 4.9523)\tTop1: 1.562 (avg: 2.000)\tTop5: 1.562 (avg: 9.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8880\tTop 1 accuracy: 2.200\tTop 5 accuracy: 10.550\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.454 (avg: 0.446)\tLoss: 5.0292 (avg: 4.8768)\tTop1: 0.000 (avg: 3.062)\tTop5: 10.938 (avg: 12.875)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.449 (avg: 0.451)\tLoss: 4.8291 (avg: 4.9115)\tTop1: 1.562 (avg: 2.625)\tTop5: 14.062 (avg: 11.062)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.446 (avg: 0.453)\tLoss: 4.7975 (avg: 4.9044)\tTop1: 3.125 (avg: 2.708)\tTop5: 12.500 (avg: 11.042)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.448 (avg: 0.453)\tLoss: 4.7757 (avg: 4.9022)\tTop1: 6.250 (avg: 2.750)\tTop5: 15.625 (avg: 11.109)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 5.0185 (avg: 4.9045)\tTop1: 0.000 (avg: 2.713)\tTop5: 10.938 (avg: 10.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8276\tTop 1 accuracy: 3.450\tTop 5 accuracy: 11.400\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.450 (avg: 0.445)\tLoss: 4.9742 (avg: 4.8384)\tTop1: 1.562 (avg: 3.000)\tTop5: 6.250 (avg: 11.500)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.451 (avg: 0.451)\tLoss: 5.0434 (avg: 4.8565)\tTop1: 0.000 (avg: 2.844)\tTop5: 6.250 (avg: 11.688)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.449 (avg: 0.453)\tLoss: 5.0279 (avg: 4.8666)\tTop1: 3.125 (avg: 2.688)\tTop5: 4.688 (avg: 11.625)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 5.0053 (avg: 4.8621)\tTop1: 1.562 (avg: 2.750)\tTop5: 9.375 (avg: 11.766)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.444 (avg: 0.454)\tLoss: 4.9156 (avg: 4.8548)\tTop1: 3.125 (avg: 3.025)\tTop5: 9.375 (avg: 12.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8210\tTop 1 accuracy: 2.900\tTop 5 accuracy: 11.900\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.449 (avg: 0.446)\tLoss: 4.8038 (avg: 4.7933)\tTop1: 3.125 (avg: 2.688)\tTop5: 10.938 (avg: 13.562)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 4.9489 (avg: 4.8503)\tTop1: 4.688 (avg: 2.656)\tTop5: 9.375 (avg: 12.469)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.447 (avg: 0.453)\tLoss: 4.5508 (avg: 4.8375)\tTop1: 7.812 (avg: 2.958)\tTop5: 17.188 (avg: 12.812)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.451 (avg: 0.454)\tLoss: 4.7138 (avg: 4.8344)\tTop1: 4.688 (avg: 3.062)\tTop5: 18.750 (avg: 12.828)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.449 (avg: 0.455)\tLoss: 4.9206 (avg: 4.8181)\tTop1: 3.125 (avg: 3.188)\tTop5: 14.062 (avg: 13.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8923\tTop 1 accuracy: 3.550\tTop 5 accuracy: 14.000\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.447 (avg: 0.445)\tLoss: 4.9038 (avg: 4.7257)\tTop1: 4.688 (avg: 4.125)\tTop5: 12.500 (avg: 15.438)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 4.8836 (avg: 4.7325)\tTop1: 4.688 (avg: 3.688)\tTop5: 17.188 (avg: 14.969)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.457 (avg: 0.453)\tLoss: 4.7720 (avg: 4.7470)\tTop1: 3.125 (avg: 3.729)\tTop5: 15.625 (avg: 14.542)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 4.9084 (avg: 4.7544)\tTop1: 1.562 (avg: 3.531)\tTop5: 12.500 (avg: 14.219)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 5.0039 (avg: 4.7608)\tTop1: 4.688 (avg: 3.663)\tTop5: 10.938 (avg: 14.325)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8543\tTop 1 accuracy: 3.350\tTop 5 accuracy: 14.350\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.449 (avg: 0.446)\tLoss: 4.9134 (avg: 4.7445)\tTop1: 0.000 (avg: 2.625)\tTop5: 10.938 (avg: 14.125)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.446 (avg: 0.451)\tLoss: 4.6633 (avg: 4.7239)\tTop1: 4.688 (avg: 3.344)\tTop5: 18.750 (avg: 14.625)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.447 (avg: 0.452)\tLoss: 4.5564 (avg: 4.7070)\tTop1: 1.562 (avg: 3.667)\tTop5: 10.938 (avg: 15.167)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.451 (avg: 0.453)\tLoss: 4.8245 (avg: 4.7155)\tTop1: 4.688 (avg: 3.828)\tTop5: 15.625 (avg: 15.281)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.451 (avg: 0.454)\tLoss: 4.8109 (avg: 4.7352)\tTop1: 3.125 (avg: 3.813)\tTop5: 15.625 (avg: 15.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6793\tTop 1 accuracy: 3.300\tTop 5 accuracy: 12.000\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.449 (avg: 0.445)\tLoss: 4.7342 (avg: 4.6779)\tTop1: 4.688 (avg: 4.562)\tTop5: 14.062 (avg: 16.000)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.453 (avg: 0.451)\tLoss: 4.9773 (avg: 4.6934)\tTop1: 3.125 (avg: 4.438)\tTop5: 10.938 (avg: 16.312)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.449 (avg: 0.453)\tLoss: 4.6822 (avg: 4.7066)\tTop1: 3.125 (avg: 4.125)\tTop5: 15.625 (avg: 15.771)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 4.7418 (avg: 4.6955)\tTop1: 1.562 (avg: 4.156)\tTop5: 17.188 (avg: 16.281)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 4.9350 (avg: 4.6995)\tTop1: 3.125 (avg: 4.163)\tTop5: 14.062 (avg: 16.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5385\tTop 1 accuracy: 4.400\tTop 5 accuracy: 16.200\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.449 (avg: 0.446)\tLoss: 4.5114 (avg: 4.6106)\tTop1: 7.812 (avg: 4.000)\tTop5: 20.312 (avg: 17.125)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 4.8607 (avg: 4.6391)\tTop1: 3.125 (avg: 3.938)\tTop5: 10.938 (avg: 16.562)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.448 (avg: 0.453)\tLoss: 4.8485 (avg: 4.6426)\tTop1: 3.125 (avg: 4.146)\tTop5: 10.938 (avg: 16.729)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.450 (avg: 0.454)\tLoss: 4.7625 (avg: 4.6573)\tTop1: 6.250 (avg: 4.000)\tTop5: 15.625 (avg: 16.609)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.449 (avg: 0.455)\tLoss: 4.8824 (avg: 4.6631)\tTop1: 1.562 (avg: 4.050)\tTop5: 10.938 (avg: 16.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4484\tTop 1 accuracy: 5.350\tTop 5 accuracy: 18.400\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.445 (avg: 0.445)\tLoss: 4.7942 (avg: 4.6023)\tTop1: 3.125 (avg: 4.750)\tTop5: 14.062 (avg: 17.875)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.449 (avg: 0.451)\tLoss: 4.6191 (avg: 4.6233)\tTop1: 7.812 (avg: 4.750)\tTop5: 21.875 (avg: 17.594)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.455 (avg: 0.453)\tLoss: 4.6109 (avg: 4.6308)\tTop1: 4.688 (avg: 4.646)\tTop5: 12.500 (avg: 17.188)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.456 (avg: 0.454)\tLoss: 4.6257 (avg: 4.6410)\tTop1: 7.812 (avg: 4.422)\tTop5: 18.750 (avg: 16.859)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.446 (avg: 0.454)\tLoss: 4.6309 (avg: 4.6418)\tTop1: 4.688 (avg: 4.425)\tTop5: 20.312 (avg: 16.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7749\tTop 1 accuracy: 4.250\tTop 5 accuracy: 15.800\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.449 (avg: 0.445)\tLoss: 4.6224 (avg: 4.5387)\tTop1: 3.125 (avg: 5.812)\tTop5: 20.312 (avg: 18.375)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.452 (avg: 0.451)\tLoss: 4.5746 (avg: 4.5498)\tTop1: 4.688 (avg: 5.562)\tTop5: 25.000 (avg: 18.219)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 4.4904 (avg: 4.5580)\tTop1: 7.812 (avg: 5.375)\tTop5: 17.188 (avg: 18.417)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 4.5865 (avg: 4.5631)\tTop1: 3.125 (avg: 5.391)\tTop5: 15.625 (avg: 18.328)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 4.7161 (avg: 4.5699)\tTop1: 3.125 (avg: 5.350)\tTop5: 20.312 (avg: 18.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7068\tTop 1 accuracy: 5.500\tTop 5 accuracy: 16.900\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.449 (avg: 0.445)\tLoss: 4.3785 (avg: 4.4734)\tTop1: 3.125 (avg: 6.250)\tTop5: 23.438 (avg: 20.000)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.447 (avg: 0.450)\tLoss: 4.6996 (avg: 4.5068)\tTop1: 1.562 (avg: 6.094)\tTop5: 15.625 (avg: 19.438)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.451 (avg: 0.452)\tLoss: 4.2506 (avg: 4.5028)\tTop1: 10.938 (avg: 6.250)\tTop5: 25.000 (avg: 19.625)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 4.6380 (avg: 4.5315)\tTop1: 4.688 (avg: 5.859)\tTop5: 20.312 (avg: 19.234)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.453 (avg: 0.454)\tLoss: 4.3025 (avg: 4.5319)\tTop1: 6.250 (avg: 5.825)\tTop5: 31.250 (avg: 19.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5591\tTop 1 accuracy: 5.550\tTop 5 accuracy: 19.500\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.450 (avg: 0.445)\tLoss: 4.2888 (avg: 4.4551)\tTop1: 9.375 (avg: 5.938)\tTop5: 23.438 (avg: 21.188)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.448 (avg: 0.450)\tLoss: 4.3946 (avg: 4.4681)\tTop1: 10.938 (avg: 6.250)\tTop5: 26.562 (avg: 21.375)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.447 (avg: 0.452)\tLoss: 4.5475 (avg: 4.4932)\tTop1: 3.125 (avg: 5.812)\tTop5: 15.625 (avg: 20.667)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.451 (avg: 0.453)\tLoss: 4.4959 (avg: 4.4925)\tTop1: 4.688 (avg: 5.812)\tTop5: 25.000 (avg: 20.875)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.451 (avg: 0.454)\tLoss: 4.3001 (avg: 4.4875)\tTop1: 10.938 (avg: 6.000)\tTop5: 26.562 (avg: 20.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6311\tTop 1 accuracy: 6.000\tTop 5 accuracy: 18.300\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.450 (avg: 0.445)\tLoss: 4.2120 (avg: 4.3710)\tTop1: 6.250 (avg: 7.938)\tTop5: 17.188 (avg: 23.562)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.453 (avg: 0.451)\tLoss: 4.4910 (avg: 4.4048)\tTop1: 4.688 (avg: 7.031)\tTop5: 18.750 (avg: 22.844)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.451 (avg: 0.453)\tLoss: 4.3840 (avg: 4.4349)\tTop1: 4.688 (avg: 6.708)\tTop5: 25.000 (avg: 22.125)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.452 (avg: 0.454)\tLoss: 4.4852 (avg: 4.4379)\tTop1: 6.250 (avg: 6.578)\tTop5: 12.500 (avg: 22.031)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.447 (avg: 0.454)\tLoss: 4.4587 (avg: 4.4435)\tTop1: 4.688 (avg: 6.638)\tTop5: 18.750 (avg: 22.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3378\tTop 1 accuracy: 7.000\tTop 5 accuracy: 20.650\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.448 (avg: 0.446)\tLoss: 4.2092 (avg: 4.3536)\tTop1: 4.688 (avg: 7.188)\tTop5: 25.000 (avg: 23.562)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 4.4007 (avg: 4.3907)\tTop1: 10.938 (avg: 7.031)\tTop5: 21.875 (avg: 22.562)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.451 (avg: 0.453)\tLoss: 4.2703 (avg: 4.4029)\tTop1: 9.375 (avg: 7.042)\tTop5: 23.438 (avg: 22.354)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 4.3341 (avg: 4.3913)\tTop1: 4.688 (avg: 7.297)\tTop5: 28.125 (avg: 22.516)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.447 (avg: 0.454)\tLoss: 4.5400 (avg: 4.3831)\tTop1: 0.000 (avg: 7.288)\tTop5: 12.500 (avg: 22.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6577\tTop 1 accuracy: 7.100\tTop 5 accuracy: 21.100\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.451 (avg: 0.445)\tLoss: 4.5627 (avg: 4.3461)\tTop1: 1.562 (avg: 7.125)\tTop5: 15.625 (avg: 23.312)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.450 (avg: 0.450)\tLoss: 4.0583 (avg: 4.3421)\tTop1: 9.375 (avg: 7.250)\tTop5: 37.500 (avg: 23.969)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.448 (avg: 0.452)\tLoss: 4.4633 (avg: 4.3760)\tTop1: 4.688 (avg: 6.958)\tTop5: 20.312 (avg: 22.938)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.449 (avg: 0.453)\tLoss: 4.3106 (avg: 4.3636)\tTop1: 4.688 (avg: 7.031)\tTop5: 23.438 (avg: 22.969)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 4.6993 (avg: 4.3691)\tTop1: 6.250 (avg: 7.125)\tTop5: 15.625 (avg: 23.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4013\tTop 1 accuracy: 7.450\tTop 5 accuracy: 22.150\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.450 (avg: 0.446)\tLoss: 4.4450 (avg: 4.3232)\tTop1: 3.125 (avg: 7.750)\tTop5: 21.875 (avg: 25.188)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.447 (avg: 0.451)\tLoss: 4.2705 (avg: 4.3175)\tTop1: 9.375 (avg: 7.750)\tTop5: 20.312 (avg: 25.062)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 4.4878 (avg: 4.3321)\tTop1: 1.562 (avg: 7.417)\tTop5: 17.188 (avg: 24.646)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.451 (avg: 0.454)\tLoss: 4.2024 (avg: 4.3375)\tTop1: 14.062 (avg: 7.531)\tTop5: 37.500 (avg: 24.734)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.450 (avg: 0.454)\tLoss: 4.4723 (avg: 4.3237)\tTop1: 10.938 (avg: 7.688)\tTop5: 21.875 (avg: 25.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5928\tTop 1 accuracy: 6.450\tTop 5 accuracy: 20.750\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.447 (avg: 0.445)\tLoss: 4.4373 (avg: 4.2135)\tTop1: 9.375 (avg: 8.625)\tTop5: 23.438 (avg: 26.562)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.450 (avg: 0.450)\tLoss: 3.9879 (avg: 4.2519)\tTop1: 14.062 (avg: 8.156)\tTop5: 35.938 (avg: 26.375)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.455 (avg: 0.452)\tLoss: 4.1849 (avg: 4.2721)\tTop1: 3.125 (avg: 7.958)\tTop5: 18.750 (avg: 26.042)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 4.4214 (avg: 4.3055)\tTop1: 4.688 (avg: 7.797)\tTop5: 18.750 (avg: 25.297)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 3.9903 (avg: 4.3110)\tTop1: 15.625 (avg: 7.875)\tTop5: 32.812 (avg: 25.325)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1512\tTop 1 accuracy: 7.650\tTop 5 accuracy: 23.600\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.452 (avg: 0.446)\tLoss: 4.0378 (avg: 4.0973)\tTop1: 3.125 (avg: 10.000)\tTop5: 29.688 (avg: 30.875)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.449 (avg: 0.451)\tLoss: 3.7377 (avg: 4.0234)\tTop1: 15.625 (avg: 11.688)\tTop5: 39.062 (avg: 33.438)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.445 (avg: 0.453)\tLoss: 4.0480 (avg: 4.0335)\tTop1: 12.500 (avg: 11.750)\tTop5: 37.500 (avg: 32.771)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.452 (avg: 0.454)\tLoss: 4.1240 (avg: 4.0206)\tTop1: 12.500 (avg: 12.359)\tTop5: 31.250 (avg: 33.219)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.452 (avg: 0.454)\tLoss: 3.9717 (avg: 4.0225)\tTop1: 7.812 (avg: 11.925)\tTop5: 37.500 (avg: 33.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3040\tTop 1 accuracy: 10.400\tTop 5 accuracy: 27.250\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.451 (avg: 0.446)\tLoss: 4.0688 (avg: 3.9151)\tTop1: 9.375 (avg: 14.875)\tTop5: 25.000 (avg: 35.875)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.444 (avg: 0.452)\tLoss: 4.0569 (avg: 3.9358)\tTop1: 15.625 (avg: 14.219)\tTop5: 35.938 (avg: 35.125)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.448 (avg: 0.453)\tLoss: 4.0382 (avg: 3.9560)\tTop1: 9.375 (avg: 13.312)\tTop5: 28.125 (avg: 34.271)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.445 (avg: 0.454)\tLoss: 3.7908 (avg: 3.9547)\tTop1: 21.875 (avg: 13.312)\tTop5: 40.625 (avg: 34.797)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.448 (avg: 0.455)\tLoss: 3.8393 (avg: 3.9474)\tTop1: 20.312 (avg: 13.563)\tTop5: 39.062 (avg: 34.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2872\tTop 1 accuracy: 10.200\tTop 5 accuracy: 27.200\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.448 (avg: 0.446)\tLoss: 3.6386 (avg: 3.9704)\tTop1: 14.062 (avg: 13.188)\tTop5: 39.062 (avg: 34.125)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 3.9594 (avg: 3.9262)\tTop1: 7.812 (avg: 14.031)\tTop5: 37.500 (avg: 35.375)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 3.6896 (avg: 3.9208)\tTop1: 15.625 (avg: 14.292)\tTop5: 39.062 (avg: 35.354)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.451 (avg: 0.454)\tLoss: 4.2070 (avg: 3.9102)\tTop1: 12.500 (avg: 14.188)\tTop5: 32.812 (avg: 35.703)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 3.9791 (avg: 3.9161)\tTop1: 17.188 (avg: 14.113)\tTop5: 29.688 (avg: 35.562)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0250\tTop 1 accuracy: 10.300\tTop 5 accuracy: 27.150\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.450 (avg: 0.446)\tLoss: 3.8701 (avg: 3.8519)\tTop1: 21.875 (avg: 15.625)\tTop5: 40.625 (avg: 37.562)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.447 (avg: 0.451)\tLoss: 4.3815 (avg: 3.8877)\tTop1: 9.375 (avg: 14.625)\tTop5: 26.562 (avg: 36.688)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.452 (avg: 0.453)\tLoss: 3.9309 (avg: 3.8746)\tTop1: 18.750 (avg: 14.479)\tTop5: 42.188 (avg: 36.604)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 3.6986 (avg: 3.8881)\tTop1: 20.312 (avg: 14.516)\tTop5: 43.750 (avg: 36.328)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 4.0698 (avg: 3.9009)\tTop1: 15.625 (avg: 14.363)\tTop5: 34.375 (avg: 35.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0782\tTop 1 accuracy: 10.600\tTop 5 accuracy: 26.750\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.451 (avg: 0.446)\tLoss: 3.8777 (avg: 3.8681)\tTop1: 15.625 (avg: 15.562)\tTop5: 40.625 (avg: 36.938)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 4.0330 (avg: 3.8581)\tTop1: 10.938 (avg: 14.812)\tTop5: 29.688 (avg: 36.375)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.447 (avg: 0.453)\tLoss: 4.1522 (avg: 3.8732)\tTop1: 15.625 (avg: 14.812)\tTop5: 35.938 (avg: 35.917)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.452 (avg: 0.454)\tLoss: 3.9914 (avg: 3.8709)\tTop1: 18.750 (avg: 15.016)\tTop5: 28.125 (avg: 36.328)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 4.0816 (avg: 3.8813)\tTop1: 18.750 (avg: 14.763)\tTop5: 34.375 (avg: 35.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9756\tTop 1 accuracy: 10.350\tTop 5 accuracy: 27.450\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.446 (avg: 0.446)\tLoss: 3.7366 (avg: 3.8844)\tTop1: 20.312 (avg: 15.312)\tTop5: 42.188 (avg: 36.625)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.449 (avg: 0.451)\tLoss: 4.2540 (avg: 3.9009)\tTop1: 15.625 (avg: 14.594)\tTop5: 34.375 (avg: 36.219)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.448 (avg: 0.453)\tLoss: 3.6769 (avg: 3.8754)\tTop1: 23.438 (avg: 14.833)\tTop5: 37.500 (avg: 36.312)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 3.9326 (avg: 3.8676)\tTop1: 17.188 (avg: 14.938)\tTop5: 40.625 (avg: 36.594)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 3.8677 (avg: 3.8651)\tTop1: 14.062 (avg: 14.938)\tTop5: 40.625 (avg: 36.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0970\tTop 1 accuracy: 10.850\tTop 5 accuracy: 27.400\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.446 (avg: 0.446)\tLoss: 3.8901 (avg: 3.8732)\tTop1: 12.500 (avg: 14.562)\tTop5: 35.938 (avg: 37.375)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.451 (avg: 0.451)\tLoss: 3.7187 (avg: 3.8537)\tTop1: 21.875 (avg: 14.844)\tTop5: 42.188 (avg: 37.656)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.448 (avg: 0.453)\tLoss: 3.9681 (avg: 3.8479)\tTop1: 10.938 (avg: 15.188)\tTop5: 34.375 (avg: 37.417)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.451 (avg: 0.454)\tLoss: 4.0933 (avg: 3.8539)\tTop1: 14.062 (avg: 15.438)\tTop5: 31.250 (avg: 37.344)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.449 (avg: 0.455)\tLoss: 3.8905 (avg: 3.8519)\tTop1: 17.188 (avg: 15.213)\tTop5: 39.062 (avg: 37.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0045\tTop 1 accuracy: 10.800\tTop 5 accuracy: 27.800\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.448 (avg: 0.446)\tLoss: 4.1579 (avg: 3.7949)\tTop1: 15.625 (avg: 17.250)\tTop5: 34.375 (avg: 38.812)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 3.7391 (avg: 3.8187)\tTop1: 15.625 (avg: 15.938)\tTop5: 48.438 (avg: 38.406)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 3.7054 (avg: 3.8247)\tTop1: 18.750 (avg: 15.812)\tTop5: 39.062 (avg: 38.312)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 3.7115 (avg: 3.8464)\tTop1: 17.188 (avg: 15.328)\tTop5: 45.312 (avg: 37.641)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.450 (avg: 0.455)\tLoss: 3.7532 (avg: 3.8385)\tTop1: 14.062 (avg: 15.175)\tTop5: 43.750 (avg: 37.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1100\tTop 1 accuracy: 11.000\tTop 5 accuracy: 28.000\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.449 (avg: 0.446)\tLoss: 3.9830 (avg: 3.8638)\tTop1: 14.062 (avg: 14.500)\tTop5: 34.375 (avg: 35.938)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.448 (avg: 0.451)\tLoss: 3.8630 (avg: 3.8434)\tTop1: 14.062 (avg: 14.375)\tTop5: 34.375 (avg: 36.625)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 3.9176 (avg: 3.8197)\tTop1: 10.938 (avg: 14.708)\tTop5: 21.875 (avg: 37.396)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.450 (avg: 0.454)\tLoss: 3.7749 (avg: 3.8320)\tTop1: 14.062 (avg: 14.891)\tTop5: 40.625 (avg: 37.359)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 4.1023 (avg: 3.8311)\tTop1: 17.188 (avg: 14.838)\tTop5: 32.812 (avg: 37.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8899\tTop 1 accuracy: 11.300\tTop 5 accuracy: 28.000\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.449 (avg: 0.447)\tLoss: 3.6890 (avg: 3.8177)\tTop1: 17.188 (avg: 15.812)\tTop5: 42.188 (avg: 38.875)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.450 (avg: 0.452)\tLoss: 4.1490 (avg: 3.8202)\tTop1: 9.375 (avg: 15.719)\tTop5: 26.562 (avg: 38.375)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.448 (avg: 0.453)\tLoss: 3.9588 (avg: 3.8145)\tTop1: 4.688 (avg: 15.500)\tTop5: 29.688 (avg: 38.208)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.450 (avg: 0.454)\tLoss: 3.9498 (avg: 3.8133)\tTop1: 14.062 (avg: 15.516)\tTop5: 37.500 (avg: 38.203)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.448 (avg: 0.455)\tLoss: 4.1207 (avg: 3.8221)\tTop1: 15.625 (avg: 15.438)\tTop5: 34.375 (avg: 38.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1181\tTop 1 accuracy: 11.400\tTop 5 accuracy: 27.800\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.449 (avg: 0.445)\tLoss: 3.6684 (avg: 3.7218)\tTop1: 14.062 (avg: 15.562)\tTop5: 34.375 (avg: 39.000)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.449 (avg: 0.451)\tLoss: 3.8022 (avg: 3.7443)\tTop1: 14.062 (avg: 15.344)\tTop5: 43.750 (avg: 39.156)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.452 (avg: 0.453)\tLoss: 3.9022 (avg: 3.7497)\tTop1: 14.062 (avg: 15.625)\tTop5: 34.375 (avg: 39.458)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 4.2008 (avg: 3.7750)\tTop1: 12.500 (avg: 15.609)\tTop5: 20.312 (avg: 38.922)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.446 (avg: 0.454)\tLoss: 3.5893 (avg: 3.7942)\tTop1: 20.312 (avg: 15.475)\tTop5: 56.250 (avg: 38.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0455\tTop 1 accuracy: 11.400\tTop 5 accuracy: 28.850\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.449 (avg: 0.446)\tLoss: 3.6170 (avg: 3.7826)\tTop1: 20.312 (avg: 16.875)\tTop5: 45.312 (avg: 38.812)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.448 (avg: 0.451)\tLoss: 3.5284 (avg: 3.7699)\tTop1: 20.312 (avg: 16.656)\tTop5: 46.875 (avg: 39.781)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.449 (avg: 0.453)\tLoss: 3.8044 (avg: 3.7695)\tTop1: 14.062 (avg: 16.333)\tTop5: 34.375 (avg: 39.396)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.454 (avg: 0.454)\tLoss: 3.7632 (avg: 3.7839)\tTop1: 20.312 (avg: 16.109)\tTop5: 42.188 (avg: 38.891)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.450 (avg: 0.454)\tLoss: 3.5027 (avg: 3.7873)\tTop1: 18.750 (avg: 15.900)\tTop5: 45.312 (avg: 38.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9435\tTop 1 accuracy: 11.350\tTop 5 accuracy: 28.600\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.450 (avg: 0.447)\tLoss: 3.9879 (avg: 3.7318)\tTop1: 12.500 (avg: 17.375)\tTop5: 32.812 (avg: 41.125)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.451 (avg: 0.452)\tLoss: 3.7260 (avg: 3.7330)\tTop1: 17.188 (avg: 16.656)\tTop5: 42.188 (avg: 39.688)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.451 (avg: 0.454)\tLoss: 3.5768 (avg: 3.7625)\tTop1: 15.625 (avg: 16.521)\tTop5: 40.625 (avg: 39.250)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.451 (avg: 0.455)\tLoss: 3.8430 (avg: 3.7629)\tTop1: 17.188 (avg: 16.375)\tTop5: 35.938 (avg: 39.422)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.452 (avg: 0.455)\tLoss: 4.5534 (avg: 3.7639)\tTop1: 4.688 (avg: 16.325)\tTop5: 17.188 (avg: 39.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9373\tTop 1 accuracy: 11.400\tTop 5 accuracy: 28.750\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.449 (avg: 0.445)\tLoss: 3.5649 (avg: 3.7687)\tTop1: 20.312 (avg: 17.750)\tTop5: 48.438 (avg: 40.438)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.451 (avg: 0.451)\tLoss: 3.6039 (avg: 3.7213)\tTop1: 15.625 (avg: 16.938)\tTop5: 42.188 (avg: 40.219)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.452 (avg: 0.453)\tLoss: 3.5511 (avg: 3.7453)\tTop1: 20.312 (avg: 16.542)\tTop5: 42.188 (avg: 39.583)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.447 (avg: 0.454)\tLoss: 4.0033 (avg: 3.7568)\tTop1: 17.188 (avg: 16.609)\tTop5: 35.938 (avg: 39.438)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.454 (avg: 0.455)\tLoss: 3.5710 (avg: 3.7566)\tTop1: 17.188 (avg: 16.475)\tTop5: 35.938 (avg: 39.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9206\tTop 1 accuracy: 11.550\tTop 5 accuracy: 29.200\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.447 (avg: 0.445)\tLoss: 3.7268 (avg: 3.7775)\tTop1: 20.312 (avg: 15.625)\tTop5: 42.188 (avg: 38.750)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 3.7266 (avg: 3.7531)\tTop1: 12.500 (avg: 15.719)\tTop5: 34.375 (avg: 38.719)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.446 (avg: 0.453)\tLoss: 3.3874 (avg: 3.7473)\tTop1: 21.875 (avg: 15.854)\tTop5: 43.750 (avg: 39.292)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.447 (avg: 0.454)\tLoss: 3.6977 (avg: 3.7398)\tTop1: 18.750 (avg: 16.672)\tTop5: 48.438 (avg: 39.594)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.446 (avg: 0.454)\tLoss: 3.9935 (avg: 3.7407)\tTop1: 17.188 (avg: 16.425)\tTop5: 42.188 (avg: 39.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8758\tTop 1 accuracy: 11.550\tTop 5 accuracy: 29.100\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.451 (avg: 0.446)\tLoss: 3.6873 (avg: 3.6832)\tTop1: 20.312 (avg: 16.500)\tTop5: 34.375 (avg: 40.688)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.453 (avg: 0.451)\tLoss: 3.8058 (avg: 3.6356)\tTop1: 20.312 (avg: 17.438)\tTop5: 35.938 (avg: 42.312)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.443 (avg: 0.453)\tLoss: 3.9417 (avg: 3.6714)\tTop1: 15.625 (avg: 17.479)\tTop5: 37.500 (avg: 41.417)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 3.4365 (avg: 3.7087)\tTop1: 23.438 (avg: 17.000)\tTop5: 39.062 (avg: 40.328)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.447 (avg: 0.455)\tLoss: 3.9875 (avg: 3.7291)\tTop1: 14.062 (avg: 16.838)\tTop5: 40.625 (avg: 39.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8495\tTop 1 accuracy: 11.600\tTop 5 accuracy: 28.950\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.450 (avg: 0.445)\tLoss: 3.7341 (avg: 3.7222)\tTop1: 17.188 (avg: 17.312)\tTop5: 46.875 (avg: 41.125)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.451 (avg: 0.450)\tLoss: 3.7100 (avg: 3.6906)\tTop1: 18.750 (avg: 17.625)\tTop5: 43.750 (avg: 41.562)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.447 (avg: 0.453)\tLoss: 3.8414 (avg: 3.7102)\tTop1: 14.062 (avg: 17.417)\tTop5: 40.625 (avg: 41.000)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 3.6313 (avg: 3.7023)\tTop1: 20.312 (avg: 17.531)\tTop5: 46.875 (avg: 41.234)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 3.7197 (avg: 3.7128)\tTop1: 15.625 (avg: 17.163)\tTop5: 40.625 (avg: 40.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8198\tTop 1 accuracy: 10.850\tTop 5 accuracy: 28.650\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.448 (avg: 0.446)\tLoss: 3.6128 (avg: 3.6281)\tTop1: 18.750 (avg: 17.562)\tTop5: 43.750 (avg: 40.875)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.454 (avg: 0.451)\tLoss: 3.5405 (avg: 3.6554)\tTop1: 15.625 (avg: 17.469)\tTop5: 46.875 (avg: 40.938)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.452 (avg: 0.453)\tLoss: 3.5820 (avg: 3.6815)\tTop1: 21.875 (avg: 17.354)\tTop5: 43.750 (avg: 40.729)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 3.6057 (avg: 3.6965)\tTop1: 10.938 (avg: 17.000)\tTop5: 42.188 (avg: 40.516)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.449 (avg: 0.455)\tLoss: 3.5532 (avg: 3.7001)\tTop1: 15.625 (avg: 16.913)\tTop5: 37.500 (avg: 40.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8457\tTop 1 accuracy: 11.850\tTop 5 accuracy: 30.250\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.449 (avg: 0.446)\tLoss: 3.8869 (avg: 3.6848)\tTop1: 17.188 (avg: 17.312)\tTop5: 35.938 (avg: 40.750)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.451 (avg: 0.451)\tLoss: 3.6200 (avg: 3.7082)\tTop1: 20.312 (avg: 17.156)\tTop5: 42.188 (avg: 40.219)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.449 (avg: 0.453)\tLoss: 3.7392 (avg: 3.6871)\tTop1: 17.188 (avg: 17.458)\tTop5: 40.625 (avg: 41.000)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 3.6563 (avg: 3.6901)\tTop1: 17.188 (avg: 17.125)\tTop5: 35.938 (avg: 40.703)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.449 (avg: 0.455)\tLoss: 3.5864 (avg: 3.6801)\tTop1: 17.188 (avg: 17.400)\tTop5: 42.188 (avg: 40.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7265\tTop 1 accuracy: 11.850\tTop 5 accuracy: 28.850\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.441 (avg: 0.445)\tLoss: 3.4190 (avg: 3.6421)\tTop1: 15.625 (avg: 18.625)\tTop5: 54.688 (avg: 41.438)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.451 (avg: 0.451)\tLoss: 4.0637 (avg: 3.6639)\tTop1: 9.375 (avg: 18.031)\tTop5: 34.375 (avg: 41.500)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 3.8897 (avg: 3.6750)\tTop1: 15.625 (avg: 18.021)\tTop5: 37.500 (avg: 41.062)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 3.5430 (avg: 3.6719)\tTop1: 20.312 (avg: 17.969)\tTop5: 51.562 (avg: 41.656)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.449 (avg: 0.455)\tLoss: 3.8968 (avg: 3.6726)\tTop1: 9.375 (avg: 17.588)\tTop5: 37.500 (avg: 41.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6840\tTop 1 accuracy: 12.000\tTop 5 accuracy: 29.900\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.449 (avg: 0.446)\tLoss: 3.5696 (avg: 3.6475)\tTop1: 14.062 (avg: 17.500)\tTop5: 50.000 (avg: 43.000)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.448 (avg: 0.451)\tLoss: 3.7452 (avg: 3.6550)\tTop1: 14.062 (avg: 17.094)\tTop5: 40.625 (avg: 42.344)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.446 (avg: 0.453)\tLoss: 3.8186 (avg: 3.6508)\tTop1: 14.062 (avg: 17.500)\tTop5: 48.438 (avg: 42.417)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 3.6038 (avg: 3.6576)\tTop1: 17.188 (avg: 17.406)\tTop5: 40.625 (avg: 42.047)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 3.7737 (avg: 3.6587)\tTop1: 15.625 (avg: 17.338)\tTop5: 40.625 (avg: 41.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9976\tTop 1 accuracy: 11.250\tTop 5 accuracy: 29.200\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.448 (avg: 0.445)\tLoss: 3.4335 (avg: 3.6152)\tTop1: 23.438 (avg: 18.562)\tTop5: 50.000 (avg: 43.500)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.451 (avg: 0.450)\tLoss: 3.8982 (avg: 3.6213)\tTop1: 12.500 (avg: 18.000)\tTop5: 39.062 (avg: 43.438)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.447 (avg: 0.452)\tLoss: 3.8531 (avg: 3.6298)\tTop1: 10.938 (avg: 17.958)\tTop5: 34.375 (avg: 43.000)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.457 (avg: 0.454)\tLoss: 3.6461 (avg: 3.6413)\tTop1: 20.312 (avg: 18.109)\tTop5: 40.625 (avg: 42.547)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.452 (avg: 0.454)\tLoss: 3.6671 (avg: 3.6406)\tTop1: 18.750 (avg: 18.050)\tTop5: 40.625 (avg: 42.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9536\tTop 1 accuracy: 12.150\tTop 5 accuracy: 29.450\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.449 (avg: 0.446)\tLoss: 3.8197 (avg: 3.6430)\tTop1: 12.500 (avg: 18.062)\tTop5: 35.938 (avg: 42.875)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 3.8614 (avg: 3.6337)\tTop1: 17.188 (avg: 18.594)\tTop5: 39.062 (avg: 42.719)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.447 (avg: 0.453)\tLoss: 3.6281 (avg: 3.6292)\tTop1: 20.312 (avg: 18.333)\tTop5: 32.812 (avg: 42.062)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 3.7941 (avg: 3.6359)\tTop1: 15.625 (avg: 17.875)\tTop5: 45.312 (avg: 41.797)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 3.8156 (avg: 3.6310)\tTop1: 12.500 (avg: 18.000)\tTop5: 32.812 (avg: 42.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0340\tTop 1 accuracy: 11.350\tTop 5 accuracy: 30.600\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.448 (avg: 0.446)\tLoss: 3.3999 (avg: 3.5848)\tTop1: 25.000 (avg: 18.562)\tTop5: 46.875 (avg: 42.312)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.450 (avg: 0.452)\tLoss: 3.5303 (avg: 3.5978)\tTop1: 18.750 (avg: 18.469)\tTop5: 50.000 (avg: 43.000)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.450 (avg: 0.454)\tLoss: 3.6714 (avg: 3.6124)\tTop1: 21.875 (avg: 18.167)\tTop5: 39.062 (avg: 42.917)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.454 (avg: 0.454)\tLoss: 3.6155 (avg: 3.6165)\tTop1: 21.875 (avg: 18.516)\tTop5: 40.625 (avg: 42.625)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.450 (avg: 0.455)\tLoss: 3.3268 (avg: 3.6100)\tTop1: 26.562 (avg: 18.375)\tTop5: 54.688 (avg: 42.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8039\tTop 1 accuracy: 11.750\tTop 5 accuracy: 31.000\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.461 (avg: 0.447)\tLoss: 3.5284 (avg: 3.5433)\tTop1: 18.750 (avg: 19.938)\tTop5: 39.062 (avg: 44.625)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.451 (avg: 0.452)\tLoss: 3.6749 (avg: 3.5897)\tTop1: 9.375 (avg: 18.156)\tTop5: 40.625 (avg: 43.344)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.453 (avg: 0.454)\tLoss: 3.6950 (avg: 3.5815)\tTop1: 21.875 (avg: 18.958)\tTop5: 37.500 (avg: 43.604)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.451 (avg: 0.455)\tLoss: 3.6531 (avg: 3.5771)\tTop1: 17.188 (avg: 18.625)\tTop5: 42.188 (avg: 43.750)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.451 (avg: 0.456)\tLoss: 3.6195 (avg: 3.5908)\tTop1: 12.500 (avg: 18.475)\tTop5: 43.750 (avg: 43.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8519\tTop 1 accuracy: 11.900\tTop 5 accuracy: 29.550\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.449 (avg: 0.446)\tLoss: 3.6964 (avg: 3.5522)\tTop1: 15.625 (avg: 19.188)\tTop5: 39.062 (avg: 43.500)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 3.6122 (avg: 3.5561)\tTop1: 17.188 (avg: 19.000)\tTop5: 42.188 (avg: 43.312)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.451 (avg: 0.453)\tLoss: 3.3639 (avg: 3.5738)\tTop1: 28.125 (avg: 19.000)\tTop5: 42.188 (avg: 42.750)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.452 (avg: 0.454)\tLoss: 3.8195 (avg: 3.5756)\tTop1: 15.625 (avg: 19.391)\tTop5: 37.500 (avg: 43.109)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.450 (avg: 0.455)\tLoss: 3.3259 (avg: 3.5782)\tTop1: 25.000 (avg: 19.388)\tTop5: 50.000 (avg: 43.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8035\tTop 1 accuracy: 11.300\tTop 5 accuracy: 29.750\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.449 (avg: 0.446)\tLoss: 3.3863 (avg: 3.5008)\tTop1: 21.875 (avg: 19.625)\tTop5: 51.562 (avg: 45.812)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 3.5984 (avg: 3.5443)\tTop1: 15.625 (avg: 19.312)\tTop5: 43.750 (avg: 44.938)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.449 (avg: 0.453)\tLoss: 3.6530 (avg: 3.5626)\tTop1: 17.188 (avg: 19.042)\tTop5: 42.188 (avg: 44.125)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 3.7489 (avg: 3.5735)\tTop1: 17.188 (avg: 18.828)\tTop5: 32.812 (avg: 43.703)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.453 (avg: 0.455)\tLoss: 3.8691 (avg: 3.5729)\tTop1: 12.500 (avg: 18.800)\tTop5: 39.062 (avg: 43.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7974\tTop 1 accuracy: 12.300\tTop 5 accuracy: 31.000\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.452 (avg: 0.446)\tLoss: 3.4708 (avg: 3.5091)\tTop1: 23.438 (avg: 21.375)\tTop5: 50.000 (avg: 45.375)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.449 (avg: 0.451)\tLoss: 3.0520 (avg: 3.5056)\tTop1: 21.875 (avg: 19.906)\tTop5: 57.812 (avg: 44.625)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.449 (avg: 0.453)\tLoss: 3.5893 (avg: 3.5340)\tTop1: 17.188 (avg: 19.417)\tTop5: 40.625 (avg: 44.312)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 3.6156 (avg: 3.5548)\tTop1: 23.438 (avg: 19.203)\tTop5: 39.062 (avg: 43.812)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.449 (avg: 0.455)\tLoss: 3.4486 (avg: 3.5551)\tTop1: 25.000 (avg: 19.463)\tTop5: 53.125 (avg: 43.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7334\tTop 1 accuracy: 11.350\tTop 5 accuracy: 30.600\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.452 (avg: 0.445)\tLoss: 3.6180 (avg: 3.4840)\tTop1: 20.312 (avg: 20.938)\tTop5: 43.750 (avg: 45.625)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 3.6090 (avg: 3.5110)\tTop1: 15.625 (avg: 20.500)\tTop5: 39.062 (avg: 44.875)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.455 (avg: 0.453)\tLoss: 3.4402 (avg: 3.5213)\tTop1: 17.188 (avg: 20.125)\tTop5: 48.438 (avg: 44.688)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.454 (avg: 0.454)\tLoss: 3.1932 (avg: 3.5117)\tTop1: 29.688 (avg: 20.156)\tTop5: 53.125 (avg: 45.125)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.458 (avg: 0.455)\tLoss: 3.6419 (avg: 3.5407)\tTop1: 10.938 (avg: 19.925)\tTop5: 43.750 (avg: 44.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7550\tTop 1 accuracy: 13.300\tTop 5 accuracy: 31.750\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.452 (avg: 0.446)\tLoss: 3.5859 (avg: 3.5003)\tTop1: 21.875 (avg: 20.688)\tTop5: 45.312 (avg: 45.375)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.451 (avg: 0.451)\tLoss: 3.6698 (avg: 3.4986)\tTop1: 25.000 (avg: 19.875)\tTop5: 37.500 (avg: 45.031)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.447 (avg: 0.453)\tLoss: 3.6264 (avg: 3.4942)\tTop1: 15.625 (avg: 19.896)\tTop5: 45.312 (avg: 45.083)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 3.3699 (avg: 3.5074)\tTop1: 23.438 (avg: 19.703)\tTop5: 54.688 (avg: 44.844)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.449 (avg: 0.455)\tLoss: 3.5607 (avg: 3.5072)\tTop1: 17.188 (avg: 19.513)\tTop5: 46.875 (avg: 44.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8594\tTop 1 accuracy: 11.950\tTop 5 accuracy: 31.250\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.445 (avg: 0.446)\tLoss: 3.1934 (avg: 3.3531)\tTop1: 20.312 (avg: 21.938)\tTop5: 56.250 (avg: 48.562)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.447 (avg: 0.451)\tLoss: 3.3694 (avg: 3.3962)\tTop1: 21.875 (avg: 21.781)\tTop5: 50.000 (avg: 47.531)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 3.5433 (avg: 3.4008)\tTop1: 20.312 (avg: 22.250)\tTop5: 43.750 (avg: 47.521)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.453 (avg: 0.454)\tLoss: 3.0907 (avg: 3.3919)\tTop1: 29.688 (avg: 22.484)\tTop5: 59.375 (avg: 47.875)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.453 (avg: 0.455)\tLoss: 3.3024 (avg: 3.3841)\tTop1: 29.688 (avg: 22.438)\tTop5: 45.312 (avg: 47.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8523\tTop 1 accuracy: 13.100\tTop 5 accuracy: 31.400\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.449 (avg: 0.446)\tLoss: 3.3206 (avg: 3.3327)\tTop1: 25.000 (avg: 23.062)\tTop5: 50.000 (avg: 48.688)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.451 (avg: 0.451)\tLoss: 3.6566 (avg: 3.4001)\tTop1: 21.875 (avg: 22.219)\tTop5: 42.188 (avg: 47.406)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.451 (avg: 0.453)\tLoss: 3.5977 (avg: 3.3673)\tTop1: 10.938 (avg: 22.979)\tTop5: 37.500 (avg: 48.479)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 3.4174 (avg: 3.3581)\tTop1: 21.875 (avg: 23.312)\tTop5: 46.875 (avg: 48.641)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.449 (avg: 0.455)\tLoss: 3.1005 (avg: 3.3591)\tTop1: 25.000 (avg: 23.325)\tTop5: 50.000 (avg: 48.563)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8059\tTop 1 accuracy: 12.900\tTop 5 accuracy: 32.000\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.455 (avg: 0.446)\tLoss: 3.1695 (avg: 3.3421)\tTop1: 31.250 (avg: 22.250)\tTop5: 56.250 (avg: 50.125)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.452 (avg: 0.451)\tLoss: 3.2791 (avg: 3.3502)\tTop1: 21.875 (avg: 22.656)\tTop5: 45.312 (avg: 48.969)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.447 (avg: 0.453)\tLoss: 3.4200 (avg: 3.3529)\tTop1: 21.875 (avg: 22.688)\tTop5: 48.438 (avg: 49.188)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.452 (avg: 0.454)\tLoss: 3.2943 (avg: 3.3476)\tTop1: 26.562 (avg: 23.062)\tTop5: 43.750 (avg: 49.297)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.453 (avg: 0.455)\tLoss: 3.5352 (avg: 3.3474)\tTop1: 21.875 (avg: 23.200)\tTop5: 46.875 (avg: 49.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7130\tTop 1 accuracy: 13.050\tTop 5 accuracy: 32.200\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.449 (avg: 0.446)\tLoss: 3.0947 (avg: 3.3463)\tTop1: 23.438 (avg: 23.625)\tTop5: 53.125 (avg: 47.875)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.449 (avg: 0.451)\tLoss: 3.4482 (avg: 3.3460)\tTop1: 23.438 (avg: 23.812)\tTop5: 46.875 (avg: 48.094)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 3.4108 (avg: 3.3673)\tTop1: 21.875 (avg: 23.438)\tTop5: 53.125 (avg: 47.875)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.452 (avg: 0.454)\tLoss: 3.3110 (avg: 3.3459)\tTop1: 23.438 (avg: 23.672)\tTop5: 45.312 (avg: 48.438)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.447 (avg: 0.455)\tLoss: 3.4184 (avg: 3.3500)\tTop1: 25.000 (avg: 23.525)\tTop5: 50.000 (avg: 48.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8300\tTop 1 accuracy: 12.900\tTop 5 accuracy: 31.900\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.449 (avg: 0.446)\tLoss: 3.1337 (avg: 3.3451)\tTop1: 21.875 (avg: 24.125)\tTop5: 48.438 (avg: 46.688)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.446 (avg: 0.451)\tLoss: 2.8955 (avg: 3.3422)\tTop1: 26.562 (avg: 23.750)\tTop5: 53.125 (avg: 48.344)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 3.3402 (avg: 3.3392)\tTop1: 21.875 (avg: 23.562)\tTop5: 45.312 (avg: 48.667)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.453 (avg: 0.454)\tLoss: 3.6426 (avg: 3.3482)\tTop1: 17.188 (avg: 23.484)\tTop5: 42.188 (avg: 48.812)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.451 (avg: 0.455)\tLoss: 2.9924 (avg: 3.3413)\tTop1: 29.688 (avg: 23.525)\tTop5: 57.812 (avg: 48.950)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7064\tTop 1 accuracy: 12.900\tTop 5 accuracy: 32.350\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.450 (avg: 0.446)\tLoss: 3.0405 (avg: 3.3462)\tTop1: 23.438 (avg: 23.812)\tTop5: 51.562 (avg: 49.625)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.452 (avg: 0.451)\tLoss: 3.3205 (avg: 3.3344)\tTop1: 25.000 (avg: 23.344)\tTop5: 48.438 (avg: 49.375)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.450 (avg: 0.453)\tLoss: 3.5889 (avg: 3.3340)\tTop1: 21.875 (avg: 23.646)\tTop5: 42.188 (avg: 49.042)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.461 (avg: 0.454)\tLoss: 3.6870 (avg: 3.3392)\tTop1: 17.188 (avg: 23.344)\tTop5: 35.938 (avg: 49.016)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.450 (avg: 0.455)\tLoss: 3.2260 (avg: 3.3369)\tTop1: 21.875 (avg: 23.638)\tTop5: 46.875 (avg: 48.950)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8292\tTop 1 accuracy: 13.000\tTop 5 accuracy: 32.100\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.451 (avg: 0.446)\tLoss: 3.4046 (avg: 3.3044)\tTop1: 18.750 (avg: 23.062)\tTop5: 37.500 (avg: 49.500)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.451 (avg: 0.451)\tLoss: 3.2727 (avg: 3.3346)\tTop1: 20.312 (avg: 22.812)\tTop5: 48.438 (avg: 49.094)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.449 (avg: 0.453)\tLoss: 3.3490 (avg: 3.3120)\tTop1: 18.750 (avg: 23.771)\tTop5: 53.125 (avg: 49.458)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 3.3400 (avg: 3.3277)\tTop1: 29.688 (avg: 23.828)\tTop5: 45.312 (avg: 48.891)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.450 (avg: 0.455)\tLoss: 3.3859 (avg: 3.3333)\tTop1: 18.750 (avg: 23.750)\tTop5: 46.875 (avg: 48.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7923\tTop 1 accuracy: 13.000\tTop 5 accuracy: 32.250\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.448 (avg: 0.445)\tLoss: 3.5825 (avg: 3.3971)\tTop1: 17.188 (avg: 22.688)\tTop5: 50.000 (avg: 47.812)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.448 (avg: 0.451)\tLoss: 3.5585 (avg: 3.3792)\tTop1: 23.438 (avg: 22.875)\tTop5: 46.875 (avg: 48.125)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.441 (avg: 0.453)\tLoss: 3.4070 (avg: 3.3415)\tTop1: 20.312 (avg: 23.250)\tTop5: 50.000 (avg: 49.188)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 3.3404 (avg: 3.3376)\tTop1: 18.750 (avg: 23.266)\tTop5: 46.875 (avg: 48.766)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.453 (avg: 0.454)\tLoss: 3.4417 (avg: 3.3309)\tTop1: 12.500 (avg: 23.600)\tTop5: 43.750 (avg: 49.063)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8196\tTop 1 accuracy: 13.050\tTop 5 accuracy: 32.200\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.448 (avg: 0.446)\tLoss: 3.1645 (avg: 3.3299)\tTop1: 35.938 (avg: 22.438)\tTop5: 53.125 (avg: 50.500)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.450 (avg: 0.452)\tLoss: 3.5612 (avg: 3.2849)\tTop1: 14.062 (avg: 24.156)\tTop5: 40.625 (avg: 51.000)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.451 (avg: 0.454)\tLoss: 3.5743 (avg: 3.3231)\tTop1: 21.875 (avg: 24.125)\tTop5: 42.188 (avg: 50.021)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.454 (avg: 0.455)\tLoss: 3.7745 (avg: 3.3234)\tTop1: 17.188 (avg: 23.891)\tTop5: 39.062 (avg: 49.734)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.451 (avg: 0.455)\tLoss: 3.1058 (avg: 3.3232)\tTop1: 29.688 (avg: 23.638)\tTop5: 57.812 (avg: 49.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7972\tTop 1 accuracy: 13.200\tTop 5 accuracy: 31.750\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.459 (avg: 0.446)\tLoss: 3.0350 (avg: 3.3348)\tTop1: 29.688 (avg: 23.938)\tTop5: 59.375 (avg: 49.125)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 3.3428 (avg: 3.2989)\tTop1: 18.750 (avg: 24.344)\tTop5: 51.562 (avg: 50.031)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.447 (avg: 0.453)\tLoss: 3.3796 (avg: 3.2985)\tTop1: 23.438 (avg: 23.771)\tTop5: 46.875 (avg: 49.625)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.450 (avg: 0.454)\tLoss: 3.1385 (avg: 3.3200)\tTop1: 25.000 (avg: 23.562)\tTop5: 50.000 (avg: 49.359)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.450 (avg: 0.455)\tLoss: 3.4848 (avg: 3.3262)\tTop1: 18.750 (avg: 23.638)\tTop5: 45.312 (avg: 49.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7554\tTop 1 accuracy: 13.000\tTop 5 accuracy: 32.650\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.446 (avg: 0.447)\tLoss: 3.1473 (avg: 3.2884)\tTop1: 25.000 (avg: 24.750)\tTop5: 51.562 (avg: 49.500)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.452 (avg: 0.452)\tLoss: 3.4272 (avg: 3.3024)\tTop1: 20.312 (avg: 24.406)\tTop5: 43.750 (avg: 49.125)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.452 (avg: 0.454)\tLoss: 3.4813 (avg: 3.3005)\tTop1: 20.312 (avg: 24.562)\tTop5: 46.875 (avg: 49.354)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.450 (avg: 0.455)\tLoss: 3.7455 (avg: 3.3010)\tTop1: 10.938 (avg: 24.312)\tTop5: 37.500 (avg: 49.344)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.451 (avg: 0.455)\tLoss: 3.4586 (avg: 3.3178)\tTop1: 15.625 (avg: 24.150)\tTop5: 48.438 (avg: 49.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7256\tTop 1 accuracy: 12.850\tTop 5 accuracy: 32.150\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.445 (avg: 0.446)\tLoss: 2.9810 (avg: 3.2934)\tTop1: 21.875 (avg: 24.062)\tTop5: 57.812 (avg: 49.625)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.448 (avg: 0.452)\tLoss: 3.5233 (avg: 3.3296)\tTop1: 23.438 (avg: 23.781)\tTop5: 39.062 (avg: 48.688)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.448 (avg: 0.453)\tLoss: 3.1981 (avg: 3.3323)\tTop1: 21.875 (avg: 23.438)\tTop5: 50.000 (avg: 48.396)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.451 (avg: 0.454)\tLoss: 3.1128 (avg: 3.3140)\tTop1: 34.375 (avg: 24.031)\tTop5: 57.812 (avg: 49.125)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.454 (avg: 0.455)\tLoss: 2.9528 (avg: 3.3164)\tTop1: 23.438 (avg: 23.900)\tTop5: 56.250 (avg: 49.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7915\tTop 1 accuracy: 12.850\tTop 5 accuracy: 32.700\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.450 (avg: 0.446)\tLoss: 3.1468 (avg: 3.2957)\tTop1: 29.688 (avg: 23.062)\tTop5: 51.562 (avg: 49.188)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.455 (avg: 0.451)\tLoss: 3.3361 (avg: 3.3037)\tTop1: 26.562 (avg: 22.969)\tTop5: 46.875 (avg: 48.969)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.449 (avg: 0.453)\tLoss: 3.3693 (avg: 3.3165)\tTop1: 25.000 (avg: 23.146)\tTop5: 46.875 (avg: 48.688)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.450 (avg: 0.454)\tLoss: 3.5421 (avg: 3.2992)\tTop1: 18.750 (avg: 23.812)\tTop5: 46.875 (avg: 49.312)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.451 (avg: 0.454)\tLoss: 3.1701 (avg: 3.3093)\tTop1: 28.125 (avg: 24.013)\tTop5: 48.438 (avg: 49.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8081\tTop 1 accuracy: 12.750\tTop 5 accuracy: 32.450\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.452 (avg: 0.446)\tLoss: 3.2783 (avg: 3.2928)\tTop1: 15.625 (avg: 24.062)\tTop5: 50.000 (avg: 49.250)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.452 (avg: 0.451)\tLoss: 3.4605 (avg: 3.2656)\tTop1: 29.688 (avg: 24.719)\tTop5: 51.562 (avg: 49.750)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.452 (avg: 0.453)\tLoss: 3.1781 (avg: 3.2746)\tTop1: 21.875 (avg: 24.458)\tTop5: 59.375 (avg: 49.750)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.449 (avg: 0.454)\tLoss: 3.0046 (avg: 3.3105)\tTop1: 28.125 (avg: 24.078)\tTop5: 56.250 (avg: 49.547)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 3.7453 (avg: 3.3070)\tTop1: 10.938 (avg: 23.963)\tTop5: 43.750 (avg: 49.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7967\tTop 1 accuracy: 13.300\tTop 5 accuracy: 32.450\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.450 (avg: 0.446)\tLoss: 3.6888 (avg: 3.3226)\tTop1: 25.000 (avg: 23.438)\tTop5: 43.750 (avg: 47.938)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.451 (avg: 0.451)\tLoss: 3.4589 (avg: 3.3343)\tTop1: 28.125 (avg: 23.750)\tTop5: 51.562 (avg: 49.406)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.449 (avg: 0.453)\tLoss: 3.6204 (avg: 3.3233)\tTop1: 17.188 (avg: 24.083)\tTop5: 37.500 (avg: 49.354)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.451 (avg: 0.454)\tLoss: 2.8839 (avg: 3.3170)\tTop1: 28.125 (avg: 23.969)\tTop5: 73.438 (avg: 49.438)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.449 (avg: 0.455)\tLoss: 3.1334 (avg: 3.3031)\tTop1: 32.812 (avg: 24.350)\tTop5: 51.562 (avg: 49.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8643\tTop 1 accuracy: 12.700\tTop 5 accuracy: 32.700\n",
            "\n",
            "base_e = 192: top1 = 12.850000381469727 \t top5 = 32.70000076293945 \t batch time = 0.3212682828307152\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.518 (avg: 0.674)\tLoss: 5.2981 (avg: 5.3034)\tTop1: 1.562 (avg: 0.562)\tTop5: 3.125 (avg: 2.875)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.532 (avg: 0.604)\tLoss: 5.2988 (avg: 5.3010)\tTop1: 0.000 (avg: 0.688)\tTop5: 1.562 (avg: 2.844)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.527 (avg: 0.581)\tLoss: 5.2975 (avg: 5.3005)\tTop1: 1.562 (avg: 0.646)\tTop5: 1.562 (avg: 2.667)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.529 (avg: 0.569)\tLoss: 5.3020 (avg: 5.3001)\tTop1: 0.000 (avg: 0.547)\tTop5: 0.000 (avg: 2.438)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.527 (avg: 0.563)\tLoss: 5.2969 (avg: 5.2997)\tTop1: 0.000 (avg: 0.538)\tTop5: 4.688 (avg: 2.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3009\tTop 1 accuracy: 0.350\tTop 5 accuracy: 2.050\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.524 (avg: 0.522)\tLoss: 5.2784 (avg: 5.2929)\tTop1: 0.000 (avg: 0.812)\tTop5: 3.125 (avg: 3.312)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.528 (avg: 0.529)\tLoss: 5.3100 (avg: 5.2892)\tTop1: 0.000 (avg: 0.688)\tTop5: 0.000 (avg: 2.906)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.529 (avg: 0.531)\tLoss: 5.2956 (avg: 5.2873)\tTop1: 0.000 (avg: 0.604)\tTop5: 1.562 (avg: 2.833)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.528 (avg: 0.532)\tLoss: 5.2451 (avg: 5.2844)\tTop1: 1.562 (avg: 0.578)\tTop5: 6.250 (avg: 2.984)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.523 (avg: 0.533)\tLoss: 5.2514 (avg: 5.2817)\tTop1: 0.000 (avg: 0.525)\tTop5: 3.125 (avg: 2.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2711\tTop 1 accuracy: 0.700\tTop 5 accuracy: 2.750\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.523 (avg: 0.521)\tLoss: 5.2741 (avg: 5.2658)\tTop1: 0.000 (avg: 0.562)\tTop5: 1.562 (avg: 3.625)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.535 (avg: 0.528)\tLoss: 5.2949 (avg: 5.2603)\tTop1: 0.000 (avg: 0.531)\tTop5: 10.938 (avg: 3.750)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.540 (avg: 0.530)\tLoss: 5.2961 (avg: 5.2729)\tTop1: 1.562 (avg: 0.583)\tTop5: 6.250 (avg: 3.396)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.520 (avg: 0.531)\tLoss: 5.2982 (avg: 5.2791)\tTop1: 0.000 (avg: 0.688)\tTop5: 0.000 (avg: 3.297)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.533 (avg: 0.532)\tLoss: 5.2930 (avg: 5.2826)\tTop1: 0.000 (avg: 0.625)\tTop5: 0.000 (avg: 3.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2957\tTop 1 accuracy: 0.450\tTop 5 accuracy: 2.100\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.531 (avg: 0.523)\tLoss: 5.2565 (avg: 5.2843)\tTop1: 0.000 (avg: 0.500)\tTop5: 3.125 (avg: 3.000)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.519 (avg: 0.529)\tLoss: 5.3023 (avg: 5.2801)\tTop1: 3.125 (avg: 0.656)\tTop5: 4.688 (avg: 3.375)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.527 (avg: 0.531)\tLoss: 5.2608 (avg: 5.2768)\tTop1: 0.000 (avg: 0.583)\tTop5: 4.688 (avg: 3.250)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.524 (avg: 0.532)\tLoss: 5.2711 (avg: 5.2695)\tTop1: 1.562 (avg: 0.719)\tTop5: 4.688 (avg: 3.719)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.525 (avg: 0.532)\tLoss: 5.2695 (avg: 5.2687)\tTop1: 1.562 (avg: 0.775)\tTop5: 4.688 (avg: 3.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2717\tTop 1 accuracy: 0.700\tTop 5 accuracy: 3.450\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.520 (avg: 0.521)\tLoss: 5.2653 (avg: 5.2612)\tTop1: 0.000 (avg: 0.938)\tTop5: 3.125 (avg: 4.312)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.532 (avg: 0.528)\tLoss: 5.2423 (avg: 5.2653)\tTop1: 0.000 (avg: 0.844)\tTop5: 1.562 (avg: 4.156)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.536 (avg: 0.530)\tLoss: 5.1023 (avg: 5.2562)\tTop1: 0.000 (avg: 1.021)\tTop5: 10.938 (avg: 4.646)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.520 (avg: 0.531)\tLoss: 5.1493 (avg: 5.2549)\tTop1: 0.000 (avg: 0.922)\tTop5: 3.125 (avg: 4.516)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.530 (avg: 0.532)\tLoss: 5.2834 (avg: 5.2545)\tTop1: 0.000 (avg: 0.875)\tTop5: 3.125 (avg: 4.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2559\tTop 1 accuracy: 0.550\tTop 5 accuracy: 3.950\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.532 (avg: 0.522)\tLoss: 5.2529 (avg: 5.2424)\tTop1: 3.125 (avg: 1.000)\tTop5: 3.125 (avg: 4.250)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.526 (avg: 0.528)\tLoss: 5.2592 (avg: 5.2375)\tTop1: 3.125 (avg: 0.875)\tTop5: 7.812 (avg: 4.094)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.530 (avg: 0.530)\tLoss: 5.2703 (avg: 5.2439)\tTop1: 0.000 (avg: 0.854)\tTop5: 1.562 (avg: 3.917)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.525 (avg: 0.531)\tLoss: 5.2740 (avg: 5.2436)\tTop1: 1.562 (avg: 0.828)\tTop5: 3.125 (avg: 3.938)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.523 (avg: 0.532)\tLoss: 5.2410 (avg: 5.2460)\tTop1: 0.000 (avg: 0.925)\tTop5: 3.125 (avg: 3.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2761\tTop 1 accuracy: 0.650\tTop 5 accuracy: 3.750\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.521 (avg: 0.521)\tLoss: 5.2286 (avg: 5.2454)\tTop1: 0.000 (avg: 1.000)\tTop5: 4.688 (avg: 4.375)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.531 (avg: 0.528)\tLoss: 5.2484 (avg: 5.2358)\tTop1: 1.562 (avg: 1.000)\tTop5: 1.562 (avg: 4.562)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.536 (avg: 0.530)\tLoss: 5.1730 (avg: 5.2307)\tTop1: 0.000 (avg: 1.021)\tTop5: 6.250 (avg: 4.771)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.518 (avg: 0.530)\tLoss: 5.2680 (avg: 5.2306)\tTop1: 0.000 (avg: 1.109)\tTop5: 1.562 (avg: 4.750)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.525 (avg: 0.531)\tLoss: 5.2731 (avg: 5.2297)\tTop1: 0.000 (avg: 0.988)\tTop5: 3.125 (avg: 4.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2830\tTop 1 accuracy: 0.800\tTop 5 accuracy: 4.200\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.529 (avg: 0.520)\tLoss: 5.1446 (avg: 5.2097)\tTop1: 0.000 (avg: 1.125)\tTop5: 1.562 (avg: 4.125)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.526 (avg: 0.527)\tLoss: 5.1840 (avg: 5.2117)\tTop1: 3.125 (avg: 1.156)\tTop5: 9.375 (avg: 4.906)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.523 (avg: 0.529)\tLoss: 5.2901 (avg: 5.2122)\tTop1: 0.000 (avg: 1.208)\tTop5: 3.125 (avg: 5.104)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.535 (avg: 0.530)\tLoss: 5.1152 (avg: 5.2134)\tTop1: 3.125 (avg: 1.234)\tTop5: 9.375 (avg: 5.016)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.520 (avg: 0.531)\tLoss: 5.2793 (avg: 5.2147)\tTop1: 0.000 (avg: 1.250)\tTop5: 1.562 (avg: 5.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2597\tTop 1 accuracy: 1.550\tTop 5 accuracy: 5.350\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.525 (avg: 0.521)\tLoss: 5.0805 (avg: 5.1973)\tTop1: 1.562 (avg: 1.750)\tTop5: 9.375 (avg: 6.062)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.529 (avg: 0.527)\tLoss: 5.2178 (avg: 5.1980)\tTop1: 1.562 (avg: 1.594)\tTop5: 1.562 (avg: 5.844)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.531 (avg: 0.530)\tLoss: 5.1322 (avg: 5.2016)\tTop1: 1.562 (avg: 1.479)\tTop5: 10.938 (avg: 5.583)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.524 (avg: 0.531)\tLoss: 5.0365 (avg: 5.1993)\tTop1: 3.125 (avg: 1.484)\tTop5: 9.375 (avg: 6.047)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.525 (avg: 0.531)\tLoss: 5.1472 (avg: 5.1980)\tTop1: 1.562 (avg: 1.438)\tTop5: 9.375 (avg: 6.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3769\tTop 1 accuracy: 1.200\tTop 5 accuracy: 5.300\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.528 (avg: 0.521)\tLoss: 5.2346 (avg: 5.1942)\tTop1: 1.562 (avg: 1.688)\tTop5: 4.688 (avg: 6.250)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.527 (avg: 0.528)\tLoss: 5.1266 (avg: 5.1827)\tTop1: 1.562 (avg: 1.406)\tTop5: 9.375 (avg: 6.250)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.524 (avg: 0.530)\tLoss: 5.1694 (avg: 5.1903)\tTop1: 0.000 (avg: 1.354)\tTop5: 3.125 (avg: 6.104)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.527 (avg: 0.531)\tLoss: 5.2565 (avg: 5.1899)\tTop1: 0.000 (avg: 1.359)\tTop5: 3.125 (avg: 6.203)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.526 (avg: 0.531)\tLoss: 5.1551 (avg: 5.1817)\tTop1: 1.562 (avg: 1.463)\tTop5: 6.250 (avg: 6.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2845\tTop 1 accuracy: 1.350\tTop 5 accuracy: 5.300\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.526 (avg: 0.522)\tLoss: 5.1794 (avg: 5.1568)\tTop1: 0.000 (avg: 1.500)\tTop5: 6.250 (avg: 7.250)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.530 (avg: 0.528)\tLoss: 5.1861 (avg: 5.1787)\tTop1: 0.000 (avg: 1.469)\tTop5: 4.688 (avg: 6.344)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.539 (avg: 0.530)\tLoss: 5.1079 (avg: 5.1678)\tTop1: 1.562 (avg: 1.458)\tTop5: 10.938 (avg: 6.833)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.518 (avg: 0.531)\tLoss: 5.1797 (avg: 5.1724)\tTop1: 0.000 (avg: 1.469)\tTop5: 4.688 (avg: 6.750)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.527 (avg: 0.531)\tLoss: 5.2032 (avg: 5.1744)\tTop1: 4.688 (avg: 1.513)\tTop5: 6.250 (avg: 6.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3008\tTop 1 accuracy: 2.100\tTop 5 accuracy: 6.800\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.531 (avg: 0.522)\tLoss: 5.1139 (avg: 5.1425)\tTop1: 0.000 (avg: 1.812)\tTop5: 7.812 (avg: 7.438)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.527 (avg: 0.528)\tLoss: 5.1133 (avg: 5.1421)\tTop1: 1.562 (avg: 1.719)\tTop5: 15.625 (avg: 8.062)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.526 (avg: 0.530)\tLoss: 5.1184 (avg: 5.1447)\tTop1: 1.562 (avg: 2.021)\tTop5: 9.375 (avg: 7.854)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.526 (avg: 0.531)\tLoss: 5.1339 (avg: 5.1552)\tTop1: 4.688 (avg: 1.875)\tTop5: 6.250 (avg: 7.453)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.522 (avg: 0.531)\tLoss: 5.0196 (avg: 5.1471)\tTop1: 4.688 (avg: 2.000)\tTop5: 14.062 (avg: 7.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2528\tTop 1 accuracy: 2.750\tTop 5 accuracy: 8.600\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.524 (avg: 0.521)\tLoss: 5.0787 (avg: 5.0979)\tTop1: 4.688 (avg: 2.875)\tTop5: 9.375 (avg: 8.625)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.531 (avg: 0.528)\tLoss: 5.0725 (avg: 5.1047)\tTop1: 1.562 (avg: 2.438)\tTop5: 6.250 (avg: 8.594)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.539 (avg: 0.531)\tLoss: 5.0266 (avg: 5.1144)\tTop1: 3.125 (avg: 2.292)\tTop5: 9.375 (avg: 8.625)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.517 (avg: 0.531)\tLoss: 5.2682 (avg: 5.1215)\tTop1: 0.000 (avg: 2.250)\tTop5: 4.688 (avg: 8.500)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.529 (avg: 0.532)\tLoss: 5.1187 (avg: 5.1191)\tTop1: 3.125 (avg: 2.213)\tTop5: 7.812 (avg: 8.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2516\tTop 1 accuracy: 2.000\tTop 5 accuracy: 8.950\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.527 (avg: 0.522)\tLoss: 5.0555 (avg: 5.0686)\tTop1: 1.562 (avg: 2.375)\tTop5: 6.250 (avg: 10.438)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.528 (avg: 0.528)\tLoss: 5.1043 (avg: 5.0810)\tTop1: 3.125 (avg: 2.219)\tTop5: 14.062 (avg: 9.156)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.530 (avg: 0.530)\tLoss: 4.9871 (avg: 5.0760)\tTop1: 3.125 (avg: 2.292)\tTop5: 9.375 (avg: 9.125)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.526 (avg: 0.531)\tLoss: 5.1157 (avg: 5.0796)\tTop1: 3.125 (avg: 2.297)\tTop5: 4.688 (avg: 9.047)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.521 (avg: 0.532)\tLoss: 5.0900 (avg: 5.0838)\tTop1: 1.562 (avg: 2.263)\tTop5: 6.250 (avg: 9.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9192\tTop 1 accuracy: 2.000\tTop 5 accuracy: 8.600\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.524 (avg: 0.522)\tLoss: 5.1382 (avg: 5.0609)\tTop1: 0.000 (avg: 2.438)\tTop5: 3.125 (avg: 8.812)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.532 (avg: 0.528)\tLoss: 4.9391 (avg: 5.0836)\tTop1: 3.125 (avg: 1.875)\tTop5: 12.500 (avg: 8.062)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.540 (avg: 0.531)\tLoss: 5.0508 (avg: 5.0853)\tTop1: 3.125 (avg: 1.854)\tTop5: 12.500 (avg: 8.000)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.521 (avg: 0.531)\tLoss: 5.0382 (avg: 5.0773)\tTop1: 1.562 (avg: 1.922)\tTop5: 9.375 (avg: 8.375)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.530 (avg: 0.532)\tLoss: 5.0453 (avg: 5.0715)\tTop1: 6.250 (avg: 2.025)\tTop5: 10.938 (avg: 8.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1230\tTop 1 accuracy: 2.600\tTop 5 accuracy: 10.300\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.532 (avg: 0.522)\tLoss: 5.0391 (avg: 5.0194)\tTop1: 3.125 (avg: 2.500)\tTop5: 6.250 (avg: 9.688)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.525 (avg: 0.529)\tLoss: 5.0200 (avg: 5.0272)\tTop1: 1.562 (avg: 2.688)\tTop5: 10.938 (avg: 9.656)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.533 (avg: 0.531)\tLoss: 5.1592 (avg: 5.0243)\tTop1: 1.562 (avg: 2.833)\tTop5: 4.688 (avg: 9.875)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.529 (avg: 0.532)\tLoss: 4.9617 (avg: 5.0395)\tTop1: 3.125 (avg: 2.484)\tTop5: 7.812 (avg: 9.344)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.522 (avg: 0.532)\tLoss: 5.0701 (avg: 5.0337)\tTop1: 1.562 (avg: 2.425)\tTop5: 6.250 (avg: 9.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0288\tTop 1 accuracy: 2.150\tTop 5 accuracy: 10.400\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.524 (avg: 0.521)\tLoss: 4.8495 (avg: 4.9817)\tTop1: 4.688 (avg: 2.562)\tTop5: 14.062 (avg: 10.438)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.529 (avg: 0.528)\tLoss: 4.9945 (avg: 4.9808)\tTop1: 1.562 (avg: 2.125)\tTop5: 9.375 (avg: 10.062)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.539 (avg: 0.531)\tLoss: 5.0722 (avg: 5.0040)\tTop1: 3.125 (avg: 2.167)\tTop5: 7.812 (avg: 9.958)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.519 (avg: 0.531)\tLoss: 5.0507 (avg: 5.0006)\tTop1: 1.562 (avg: 2.312)\tTop5: 9.375 (avg: 10.047)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.528 (avg: 0.532)\tLoss: 4.9262 (avg: 4.9933)\tTop1: 4.688 (avg: 2.413)\tTop5: 14.062 (avg: 10.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0970\tTop 1 accuracy: 2.400\tTop 5 accuracy: 10.100\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.538 (avg: 0.522)\tLoss: 5.0527 (avg: 4.9823)\tTop1: 1.562 (avg: 2.375)\tTop5: 9.375 (avg: 10.250)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.527 (avg: 0.528)\tLoss: 4.9282 (avg: 4.9672)\tTop1: 1.562 (avg: 2.281)\tTop5: 9.375 (avg: 10.719)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.530 (avg: 0.531)\tLoss: 5.0648 (avg: 4.9799)\tTop1: 0.000 (avg: 2.500)\tTop5: 4.688 (avg: 10.688)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.527 (avg: 0.532)\tLoss: 5.0167 (avg: 4.9712)\tTop1: 0.000 (avg: 2.562)\tTop5: 10.938 (avg: 10.844)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.526 (avg: 0.532)\tLoss: 5.0312 (avg: 4.9668)\tTop1: 1.562 (avg: 2.550)\tTop5: 6.250 (avg: 10.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7704\tTop 1 accuracy: 2.800\tTop 5 accuracy: 10.450\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.524 (avg: 0.523)\tLoss: 4.9978 (avg: 4.8912)\tTop1: 0.000 (avg: 2.688)\tTop5: 10.938 (avg: 11.375)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.530 (avg: 0.529)\tLoss: 4.8232 (avg: 4.9124)\tTop1: 3.125 (avg: 2.719)\tTop5: 14.062 (avg: 11.562)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.537 (avg: 0.531)\tLoss: 4.6428 (avg: 4.9131)\tTop1: 6.250 (avg: 2.812)\tTop5: 20.312 (avg: 11.708)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.521 (avg: 0.532)\tLoss: 4.7454 (avg: 4.9072)\tTop1: 10.938 (avg: 2.719)\tTop5: 20.312 (avg: 11.641)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.527 (avg: 0.532)\tLoss: 4.9052 (avg: 4.9047)\tTop1: 3.125 (avg: 2.838)\tTop5: 15.625 (avg: 11.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6091\tTop 1 accuracy: 3.450\tTop 5 accuracy: 11.000\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.529 (avg: 0.522)\tLoss: 4.8320 (avg: 4.8564)\tTop1: 1.562 (avg: 3.500)\tTop5: 15.625 (avg: 14.062)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.528 (avg: 0.529)\tLoss: 4.9812 (avg: 4.8633)\tTop1: 0.000 (avg: 3.531)\tTop5: 9.375 (avg: 13.188)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.535 (avg: 0.531)\tLoss: 4.8501 (avg: 4.8747)\tTop1: 3.125 (avg: 3.083)\tTop5: 9.375 (avg: 12.375)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.528 (avg: 0.532)\tLoss: 4.8079 (avg: 4.8746)\tTop1: 4.688 (avg: 3.344)\tTop5: 15.625 (avg: 12.484)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.523 (avg: 0.533)\tLoss: 4.9793 (avg: 4.8680)\tTop1: 1.562 (avg: 3.438)\tTop5: 3.125 (avg: 12.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0927\tTop 1 accuracy: 3.350\tTop 5 accuracy: 11.000\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.525 (avg: 0.522)\tLoss: 4.9039 (avg: 4.8148)\tTop1: 1.562 (avg: 3.750)\tTop5: 12.500 (avg: 14.125)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.529 (avg: 0.529)\tLoss: 4.8386 (avg: 4.8055)\tTop1: 0.000 (avg: 3.625)\tTop5: 12.500 (avg: 13.906)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.538 (avg: 0.531)\tLoss: 4.8065 (avg: 4.7943)\tTop1: 1.562 (avg: 3.688)\tTop5: 9.375 (avg: 14.229)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.518 (avg: 0.532)\tLoss: 4.7812 (avg: 4.7958)\tTop1: 1.562 (avg: 3.453)\tTop5: 7.812 (avg: 14.016)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.530 (avg: 0.532)\tLoss: 5.0100 (avg: 4.8028)\tTop1: 1.562 (avg: 3.513)\tTop5: 7.812 (avg: 13.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3857\tTop 1 accuracy: 3.400\tTop 5 accuracy: 12.350\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.533 (avg: 0.522)\tLoss: 4.8455 (avg: 4.8034)\tTop1: 4.688 (avg: 3.750)\tTop5: 14.062 (avg: 14.250)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.528 (avg: 0.529)\tLoss: 5.0800 (avg: 4.7677)\tTop1: 1.562 (avg: 4.281)\tTop5: 7.812 (avg: 14.500)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.526 (avg: 0.531)\tLoss: 4.6374 (avg: 4.7616)\tTop1: 1.562 (avg: 4.292)\tTop5: 14.062 (avg: 14.250)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.529 (avg: 0.532)\tLoss: 4.7439 (avg: 4.7663)\tTop1: 6.250 (avg: 4.312)\tTop5: 18.750 (avg: 14.281)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.523 (avg: 0.532)\tLoss: 4.6446 (avg: 4.7748)\tTop1: 4.688 (avg: 4.263)\tTop5: 15.625 (avg: 14.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9970\tTop 1 accuracy: 3.800\tTop 5 accuracy: 14.250\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.523 (avg: 0.522)\tLoss: 4.5036 (avg: 4.6010)\tTop1: 4.688 (avg: 4.812)\tTop5: 12.500 (avg: 18.875)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.524 (avg: 0.529)\tLoss: 4.6456 (avg: 4.6137)\tTop1: 6.250 (avg: 5.219)\tTop5: 23.438 (avg: 18.781)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.539 (avg: 0.531)\tLoss: 4.8081 (avg: 4.6424)\tTop1: 1.562 (avg: 5.104)\tTop5: 9.375 (avg: 17.604)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.524 (avg: 0.532)\tLoss: 4.5632 (avg: 4.6406)\tTop1: 9.375 (avg: 5.094)\tTop5: 23.438 (avg: 17.359)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.533 (avg: 0.533)\tLoss: 4.7744 (avg: 4.6547)\tTop1: 6.250 (avg: 4.875)\tTop5: 10.938 (avg: 17.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8148\tTop 1 accuracy: 4.850\tTop 5 accuracy: 15.750\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.532 (avg: 0.522)\tLoss: 4.1855 (avg: 4.5690)\tTop1: 12.500 (avg: 6.688)\tTop5: 28.125 (avg: 18.750)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.528 (avg: 0.529)\tLoss: 4.6012 (avg: 4.6305)\tTop1: 10.938 (avg: 5.781)\tTop5: 15.625 (avg: 16.844)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.527 (avg: 0.531)\tLoss: 4.3657 (avg: 4.6305)\tTop1: 9.375 (avg: 5.542)\tTop5: 23.438 (avg: 16.958)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.529 (avg: 0.532)\tLoss: 4.7960 (avg: 4.6422)\tTop1: 7.812 (avg: 5.312)\tTop5: 18.750 (avg: 16.984)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.526 (avg: 0.533)\tLoss: 4.8437 (avg: 4.6356)\tTop1: 4.688 (avg: 5.338)\tTop5: 10.938 (avg: 17.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6609\tTop 1 accuracy: 6.300\tTop 5 accuracy: 18.150\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.524 (avg: 0.522)\tLoss: 4.8069 (avg: 4.5048)\tTop1: 4.688 (avg: 6.625)\tTop5: 18.750 (avg: 21.562)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.531 (avg: 0.529)\tLoss: 4.4159 (avg: 4.5177)\tTop1: 10.938 (avg: 6.188)\tTop5: 25.000 (avg: 20.469)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.537 (avg: 0.530)\tLoss: 4.4294 (avg: 4.5423)\tTop1: 7.812 (avg: 5.562)\tTop5: 26.562 (avg: 19.729)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.523 (avg: 0.532)\tLoss: 4.4618 (avg: 4.5489)\tTop1: 9.375 (avg: 5.625)\tTop5: 23.438 (avg: 19.719)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.528 (avg: 0.532)\tLoss: 4.8196 (avg: 4.5573)\tTop1: 7.812 (avg: 5.538)\tTop5: 14.062 (avg: 19.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1933\tTop 1 accuracy: 6.450\tTop 5 accuracy: 20.300\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.531 (avg: 0.522)\tLoss: 4.4983 (avg: 4.5059)\tTop1: 9.375 (avg: 6.188)\tTop5: 25.000 (avg: 18.938)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.526 (avg: 0.529)\tLoss: 4.4847 (avg: 4.5147)\tTop1: 6.250 (avg: 5.844)\tTop5: 15.625 (avg: 19.125)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.526 (avg: 0.531)\tLoss: 4.4249 (avg: 4.5294)\tTop1: 6.250 (avg: 5.500)\tTop5: 26.562 (avg: 19.438)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.532 (avg: 0.532)\tLoss: 4.4665 (avg: 4.5258)\tTop1: 4.688 (avg: 5.750)\tTop5: 25.000 (avg: 19.609)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.524 (avg: 0.533)\tLoss: 4.5621 (avg: 4.5285)\tTop1: 6.250 (avg: 5.838)\tTop5: 17.188 (avg: 19.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4252\tTop 1 accuracy: 6.050\tTop 5 accuracy: 19.350\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.525 (avg: 0.522)\tLoss: 4.1779 (avg: 4.4364)\tTop1: 12.500 (avg: 7.250)\tTop5: 31.250 (avg: 22.938)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.533 (avg: 0.529)\tLoss: 4.2674 (avg: 4.4296)\tTop1: 9.375 (avg: 6.969)\tTop5: 29.688 (avg: 22.281)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.536 (avg: 0.531)\tLoss: 4.8140 (avg: 4.4502)\tTop1: 3.125 (avg: 6.771)\tTop5: 9.375 (avg: 21.438)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.520 (avg: 0.532)\tLoss: 4.2468 (avg: 4.4626)\tTop1: 9.375 (avg: 6.750)\tTop5: 21.875 (avg: 21.188)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.530 (avg: 0.532)\tLoss: 4.6544 (avg: 4.4680)\tTop1: 6.250 (avg: 6.738)\tTop5: 25.000 (avg: 21.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4873\tTop 1 accuracy: 6.500\tTop 5 accuracy: 19.600\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.531 (avg: 0.523)\tLoss: 4.2356 (avg: 4.3825)\tTop1: 6.250 (avg: 7.688)\tTop5: 29.688 (avg: 23.188)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.526 (avg: 0.529)\tLoss: 4.4617 (avg: 4.3919)\tTop1: 4.688 (avg: 7.188)\tTop5: 25.000 (avg: 23.094)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.529 (avg: 0.531)\tLoss: 4.4375 (avg: 4.4087)\tTop1: 7.812 (avg: 7.000)\tTop5: 25.000 (avg: 23.208)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.529 (avg: 0.532)\tLoss: 4.4877 (avg: 4.4032)\tTop1: 3.125 (avg: 7.156)\tTop5: 23.438 (avg: 23.219)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.521 (avg: 0.533)\tLoss: 4.5862 (avg: 4.4166)\tTop1: 1.562 (avg: 6.963)\tTop5: 28.125 (avg: 23.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1369\tTop 1 accuracy: 6.750\tTop 5 accuracy: 21.000\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.535 (avg: 0.523)\tLoss: 4.6302 (avg: 4.2735)\tTop1: 4.688 (avg: 9.000)\tTop5: 21.875 (avg: 26.188)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.532 (avg: 0.529)\tLoss: 4.2774 (avg: 4.3274)\tTop1: 7.812 (avg: 7.812)\tTop5: 28.125 (avg: 24.906)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.538 (avg: 0.531)\tLoss: 4.5345 (avg: 4.3289)\tTop1: 7.812 (avg: 7.792)\tTop5: 21.875 (avg: 24.583)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.521 (avg: 0.532)\tLoss: 4.5726 (avg: 4.3590)\tTop1: 4.688 (avg: 7.438)\tTop5: 18.750 (avg: 24.250)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.528 (avg: 0.532)\tLoss: 4.4138 (avg: 4.3725)\tTop1: 10.938 (avg: 7.600)\tTop5: 20.312 (avg: 24.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3569\tTop 1 accuracy: 7.150\tTop 5 accuracy: 20.950\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.524 (avg: 0.522)\tLoss: 4.6482 (avg: 4.2982)\tTop1: 4.688 (avg: 9.438)\tTop5: 9.375 (avg: 24.312)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.529 (avg: 0.529)\tLoss: 4.4542 (avg: 4.3284)\tTop1: 1.562 (avg: 9.000)\tTop5: 21.875 (avg: 24.312)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.527 (avg: 0.531)\tLoss: 4.5939 (avg: 4.3497)\tTop1: 9.375 (avg: 8.500)\tTop5: 20.312 (avg: 23.938)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.528 (avg: 0.532)\tLoss: 4.3631 (avg: 4.3491)\tTop1: 10.938 (avg: 8.688)\tTop5: 25.000 (avg: 24.078)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.525 (avg: 0.533)\tLoss: 4.5347 (avg: 4.3576)\tTop1: 4.688 (avg: 8.538)\tTop5: 17.188 (avg: 24.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2722\tTop 1 accuracy: 7.700\tTop 5 accuracy: 22.300\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.516 (avg: 0.523)\tLoss: 4.2698 (avg: 4.1737)\tTop1: 12.500 (avg: 10.188)\tTop5: 28.125 (avg: 28.562)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.529 (avg: 0.529)\tLoss: 4.0356 (avg: 4.1398)\tTop1: 9.375 (avg: 10.719)\tTop5: 35.938 (avg: 29.281)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.538 (avg: 0.531)\tLoss: 4.0824 (avg: 4.1142)\tTop1: 15.625 (avg: 11.146)\tTop5: 29.688 (avg: 30.000)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.522 (avg: 0.532)\tLoss: 3.9775 (avg: 4.1051)\tTop1: 18.750 (avg: 11.828)\tTop5: 35.938 (avg: 30.797)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.531 (avg: 0.533)\tLoss: 3.7625 (avg: 4.0760)\tTop1: 10.938 (avg: 12.000)\tTop5: 34.375 (avg: 31.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7306\tTop 1 accuracy: 9.750\tTop 5 accuracy: 26.600\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.532 (avg: 0.523)\tLoss: 4.2071 (avg: 3.9990)\tTop1: 9.375 (avg: 13.500)\tTop5: 21.875 (avg: 33.062)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.527 (avg: 0.529)\tLoss: 3.7277 (avg: 4.0199)\tTop1: 18.750 (avg: 13.656)\tTop5: 40.625 (avg: 33.375)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.523 (avg: 0.531)\tLoss: 3.9754 (avg: 4.0001)\tTop1: 14.062 (avg: 13.604)\tTop5: 28.125 (avg: 33.667)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.527 (avg: 0.532)\tLoss: 3.6861 (avg: 4.0169)\tTop1: 9.375 (avg: 13.016)\tTop5: 40.625 (avg: 33.250)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.524 (avg: 0.533)\tLoss: 4.0145 (avg: 4.0026)\tTop1: 7.812 (avg: 13.263)\tTop5: 32.812 (avg: 33.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8547\tTop 1 accuracy: 10.800\tTop 5 accuracy: 28.100\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.524 (avg: 0.522)\tLoss: 4.3605 (avg: 3.9889)\tTop1: 9.375 (avg: 13.688)\tTop5: 28.125 (avg: 34.625)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.529 (avg: 0.528)\tLoss: 4.0378 (avg: 3.9593)\tTop1: 12.500 (avg: 14.062)\tTop5: 28.125 (avg: 35.844)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.537 (avg: 0.530)\tLoss: 4.1841 (avg: 3.9719)\tTop1: 10.938 (avg: 14.042)\tTop5: 28.125 (avg: 35.500)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.519 (avg: 0.531)\tLoss: 4.0402 (avg: 3.9569)\tTop1: 9.375 (avg: 14.094)\tTop5: 28.125 (avg: 35.641)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.527 (avg: 0.532)\tLoss: 4.1322 (avg: 3.9652)\tTop1: 15.625 (avg: 13.988)\tTop5: 37.500 (avg: 35.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7367\tTop 1 accuracy: 10.300\tTop 5 accuracy: 28.400\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.532 (avg: 0.522)\tLoss: 4.1327 (avg: 3.9235)\tTop1: 15.625 (avg: 14.375)\tTop5: 40.625 (avg: 35.625)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.525 (avg: 0.528)\tLoss: 3.8074 (avg: 3.9386)\tTop1: 12.500 (avg: 14.000)\tTop5: 40.625 (avg: 35.125)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.528 (avg: 0.530)\tLoss: 3.7818 (avg: 3.9377)\tTop1: 15.625 (avg: 13.896)\tTop5: 40.625 (avg: 34.708)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.529 (avg: 0.531)\tLoss: 3.9166 (avg: 3.9342)\tTop1: 10.938 (avg: 14.062)\tTop5: 43.750 (avg: 34.891)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.517 (avg: 0.532)\tLoss: 4.1782 (avg: 3.9456)\tTop1: 10.938 (avg: 13.763)\tTop5: 31.250 (avg: 34.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6074\tTop 1 accuracy: 10.750\tTop 5 accuracy: 29.100\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.525 (avg: 0.522)\tLoss: 3.7394 (avg: 3.8643)\tTop1: 17.188 (avg: 16.312)\tTop5: 37.500 (avg: 37.438)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.529 (avg: 0.528)\tLoss: 3.7539 (avg: 3.8899)\tTop1: 12.500 (avg: 15.000)\tTop5: 32.812 (avg: 36.125)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.536 (avg: 0.531)\tLoss: 3.9743 (avg: 3.9100)\tTop1: 15.625 (avg: 14.604)\tTop5: 34.375 (avg: 36.062)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.522 (avg: 0.532)\tLoss: 3.8250 (avg: 3.9227)\tTop1: 10.938 (avg: 14.609)\tTop5: 35.938 (avg: 35.844)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.533 (avg: 0.532)\tLoss: 4.0228 (avg: 3.9277)\tTop1: 10.938 (avg: 14.150)\tTop5: 32.812 (avg: 35.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8038\tTop 1 accuracy: 10.250\tTop 5 accuracy: 29.150\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.529 (avg: 0.523)\tLoss: 4.0964 (avg: 3.8602)\tTop1: 18.750 (avg: 15.250)\tTop5: 31.250 (avg: 37.438)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.524 (avg: 0.529)\tLoss: 4.2709 (avg: 3.8818)\tTop1: 7.812 (avg: 14.781)\tTop5: 23.438 (avg: 37.094)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.526 (avg: 0.531)\tLoss: 3.8660 (avg: 3.8925)\tTop1: 4.688 (avg: 14.312)\tTop5: 40.625 (avg: 36.688)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.529 (avg: 0.532)\tLoss: 3.8757 (avg: 3.8970)\tTop1: 6.250 (avg: 14.281)\tTop5: 35.938 (avg: 36.594)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.525 (avg: 0.532)\tLoss: 4.1552 (avg: 3.9057)\tTop1: 14.062 (avg: 14.475)\tTop5: 32.812 (avg: 36.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8347\tTop 1 accuracy: 11.100\tTop 5 accuracy: 29.150\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.518 (avg: 0.522)\tLoss: 3.8624 (avg: 3.8925)\tTop1: 12.500 (avg: 15.250)\tTop5: 39.062 (avg: 36.688)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.531 (avg: 0.528)\tLoss: 4.1081 (avg: 3.8980)\tTop1: 12.500 (avg: 14.906)\tTop5: 34.375 (avg: 36.094)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.539 (avg: 0.531)\tLoss: 3.6454 (avg: 3.8865)\tTop1: 12.500 (avg: 15.167)\tTop5: 42.188 (avg: 36.729)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.520 (avg: 0.532)\tLoss: 3.7797 (avg: 3.8788)\tTop1: 17.188 (avg: 15.031)\tTop5: 43.750 (avg: 37.031)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.529 (avg: 0.532)\tLoss: 4.0027 (avg: 3.8870)\tTop1: 10.938 (avg: 15.013)\tTop5: 35.938 (avg: 36.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6663\tTop 1 accuracy: 11.000\tTop 5 accuracy: 29.950\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.540 (avg: 0.522)\tLoss: 4.0564 (avg: 3.8683)\tTop1: 12.500 (avg: 13.812)\tTop5: 31.250 (avg: 36.062)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.528 (avg: 0.529)\tLoss: 3.8176 (avg: 3.8921)\tTop1: 12.500 (avg: 14.125)\tTop5: 32.812 (avg: 35.844)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.529 (avg: 0.531)\tLoss: 3.8158 (avg: 3.8728)\tTop1: 17.188 (avg: 15.312)\tTop5: 32.812 (avg: 36.917)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.526 (avg: 0.532)\tLoss: 4.0106 (avg: 3.8667)\tTop1: 17.188 (avg: 15.203)\tTop5: 39.062 (avg: 37.094)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.525 (avg: 0.533)\tLoss: 3.8833 (avg: 3.8727)\tTop1: 15.625 (avg: 14.800)\tTop5: 35.938 (avg: 36.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9429\tTop 1 accuracy: 10.350\tTop 5 accuracy: 28.900\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.525 (avg: 0.523)\tLoss: 3.6963 (avg: 3.8375)\tTop1: 12.500 (avg: 16.375)\tTop5: 39.062 (avg: 38.500)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.523 (avg: 0.529)\tLoss: 4.1262 (avg: 3.7956)\tTop1: 10.938 (avg: 16.125)\tTop5: 32.812 (avg: 39.312)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.539 (avg: 0.531)\tLoss: 3.9377 (avg: 3.8305)\tTop1: 15.625 (avg: 15.750)\tTop5: 35.938 (avg: 38.479)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.519 (avg: 0.532)\tLoss: 3.8639 (avg: 3.8493)\tTop1: 17.188 (avg: 15.547)\tTop5: 34.375 (avg: 37.781)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.532 (avg: 0.533)\tLoss: 3.7984 (avg: 3.8549)\tTop1: 12.500 (avg: 15.663)\tTop5: 39.062 (avg: 37.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9105\tTop 1 accuracy: 11.000\tTop 5 accuracy: 29.000\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.530 (avg: 0.522)\tLoss: 3.5939 (avg: 3.8051)\tTop1: 20.312 (avg: 16.000)\tTop5: 40.625 (avg: 39.250)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.531 (avg: 0.529)\tLoss: 3.6712 (avg: 3.8182)\tTop1: 21.875 (avg: 15.719)\tTop5: 37.500 (avg: 38.094)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.532 (avg: 0.531)\tLoss: 4.0865 (avg: 3.8338)\tTop1: 12.500 (avg: 15.854)\tTop5: 29.688 (avg: 37.667)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.526 (avg: 0.532)\tLoss: 3.9781 (avg: 3.8317)\tTop1: 10.938 (avg: 15.859)\tTop5: 34.375 (avg: 37.406)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.524 (avg: 0.533)\tLoss: 4.0434 (avg: 3.8454)\tTop1: 7.812 (avg: 15.763)\tTop5: 32.812 (avg: 37.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9301\tTop 1 accuracy: 10.750\tTop 5 accuracy: 29.650\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.525 (avg: 0.521)\tLoss: 3.9762 (avg: 3.8157)\tTop1: 20.312 (avg: 17.188)\tTop5: 34.375 (avg: 38.750)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.532 (avg: 0.529)\tLoss: 3.6182 (avg: 3.7927)\tTop1: 18.750 (avg: 17.125)\tTop5: 46.875 (avg: 38.344)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.539 (avg: 0.531)\tLoss: 3.7542 (avg: 3.8257)\tTop1: 4.688 (avg: 16.250)\tTop5: 37.500 (avg: 37.458)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.518 (avg: 0.532)\tLoss: 4.0383 (avg: 3.8287)\tTop1: 7.812 (avg: 16.531)\tTop5: 21.875 (avg: 37.422)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.532 (avg: 0.532)\tLoss: 3.7448 (avg: 3.8254)\tTop1: 15.625 (avg: 16.450)\tTop5: 37.500 (avg: 38.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7964\tTop 1 accuracy: 11.550\tTop 5 accuracy: 29.400\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.531 (avg: 0.522)\tLoss: 3.9568 (avg: 3.8178)\tTop1: 7.812 (avg: 16.375)\tTop5: 35.938 (avg: 38.875)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.534 (avg: 0.529)\tLoss: 3.8938 (avg: 3.8215)\tTop1: 10.938 (avg: 16.562)\tTop5: 29.688 (avg: 38.500)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.529 (avg: 0.531)\tLoss: 3.5881 (avg: 3.8190)\tTop1: 18.750 (avg: 16.417)\tTop5: 40.625 (avg: 38.812)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.528 (avg: 0.532)\tLoss: 3.8066 (avg: 3.8096)\tTop1: 14.062 (avg: 16.203)\tTop5: 40.625 (avg: 38.859)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.524 (avg: 0.532)\tLoss: 3.7630 (avg: 3.8126)\tTop1: 10.938 (avg: 15.888)\tTop5: 37.500 (avg: 38.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7302\tTop 1 accuracy: 11.450\tTop 5 accuracy: 31.050\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.523 (avg: 0.522)\tLoss: 3.6423 (avg: 3.7701)\tTop1: 18.750 (avg: 18.000)\tTop5: 42.188 (avg: 39.938)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.529 (avg: 0.529)\tLoss: 3.8969 (avg: 3.7906)\tTop1: 21.875 (avg: 17.250)\tTop5: 35.938 (avg: 39.625)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.530 (avg: 0.531)\tLoss: 3.8674 (avg: 3.8011)\tTop1: 14.062 (avg: 16.229)\tTop5: 26.562 (avg: 38.958)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.525 (avg: 0.532)\tLoss: 3.9434 (avg: 3.8010)\tTop1: 18.750 (avg: 16.125)\tTop5: 32.812 (avg: 38.859)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.527 (avg: 0.533)\tLoss: 3.9827 (avg: 3.7969)\tTop1: 14.062 (avg: 16.163)\tTop5: 32.812 (avg: 39.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7634\tTop 1 accuracy: 11.200\tTop 5 accuracy: 30.800\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.532 (avg: 0.522)\tLoss: 3.8111 (avg: 3.7943)\tTop1: 18.750 (avg: 16.500)\tTop5: 45.312 (avg: 40.438)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.525 (avg: 0.528)\tLoss: 3.4287 (avg: 3.7832)\tTop1: 28.125 (avg: 16.969)\tTop5: 42.188 (avg: 39.375)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.526 (avg: 0.530)\tLoss: 3.7858 (avg: 3.7868)\tTop1: 12.500 (avg: 16.854)\tTop5: 35.938 (avg: 39.188)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.530 (avg: 0.532)\tLoss: 3.5586 (avg: 3.7896)\tTop1: 18.750 (avg: 16.625)\tTop5: 39.062 (avg: 39.094)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.524 (avg: 0.532)\tLoss: 3.8523 (avg: 3.7884)\tTop1: 12.500 (avg: 16.325)\tTop5: 32.812 (avg: 39.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6400\tTop 1 accuracy: 11.300\tTop 5 accuracy: 30.650\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.524 (avg: 0.522)\tLoss: 3.7664 (avg: 3.8254)\tTop1: 23.438 (avg: 16.500)\tTop5: 45.312 (avg: 39.250)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.526 (avg: 0.529)\tLoss: 3.6719 (avg: 3.7946)\tTop1: 20.312 (avg: 16.656)\tTop5: 40.625 (avg: 39.562)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.537 (avg: 0.531)\tLoss: 4.0190 (avg: 3.7685)\tTop1: 9.375 (avg: 17.146)\tTop5: 31.250 (avg: 39.938)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.519 (avg: 0.532)\tLoss: 3.5717 (avg: 3.7811)\tTop1: 26.562 (avg: 16.719)\tTop5: 46.875 (avg: 39.500)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.531 (avg: 0.533)\tLoss: 3.7389 (avg: 3.7732)\tTop1: 14.062 (avg: 16.788)\tTop5: 35.938 (avg: 39.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6183\tTop 1 accuracy: 11.600\tTop 5 accuracy: 30.600\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.531 (avg: 0.522)\tLoss: 3.6532 (avg: 3.6935)\tTop1: 15.625 (avg: 17.438)\tTop5: 45.312 (avg: 42.750)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.522 (avg: 0.529)\tLoss: 3.9642 (avg: 3.7472)\tTop1: 15.625 (avg: 17.094)\tTop5: 34.375 (avg: 40.344)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.531 (avg: 0.531)\tLoss: 3.7376 (avg: 3.7533)\tTop1: 10.938 (avg: 16.833)\tTop5: 32.812 (avg: 40.146)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.531 (avg: 0.532)\tLoss: 3.6289 (avg: 3.7408)\tTop1: 15.625 (avg: 17.109)\tTop5: 46.875 (avg: 40.578)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.526 (avg: 0.533)\tLoss: 3.9941 (avg: 3.7573)\tTop1: 10.938 (avg: 16.750)\tTop5: 31.250 (avg: 40.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8437\tTop 1 accuracy: 11.400\tTop 5 accuracy: 29.300\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.525 (avg: 0.522)\tLoss: 3.7679 (avg: 3.7796)\tTop1: 20.312 (avg: 16.875)\tTop5: 43.750 (avg: 39.062)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.531 (avg: 0.528)\tLoss: 3.7531 (avg: 3.7327)\tTop1: 15.625 (avg: 16.875)\tTop5: 29.688 (avg: 39.781)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.541 (avg: 0.531)\tLoss: 3.7684 (avg: 3.7508)\tTop1: 17.188 (avg: 16.479)\tTop5: 35.938 (avg: 40.083)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.520 (avg: 0.532)\tLoss: 4.0751 (avg: 3.7427)\tTop1: 12.500 (avg: 16.906)\tTop5: 31.250 (avg: 40.422)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.530 (avg: 0.533)\tLoss: 3.5615 (avg: 3.7397)\tTop1: 20.312 (avg: 17.100)\tTop5: 46.875 (avg: 40.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8032\tTop 1 accuracy: 12.150\tTop 5 accuracy: 31.000\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.527 (avg: 0.522)\tLoss: 3.5731 (avg: 3.7033)\tTop1: 23.438 (avg: 17.188)\tTop5: 51.562 (avg: 41.312)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.525 (avg: 0.528)\tLoss: 3.7998 (avg: 3.7641)\tTop1: 18.750 (avg: 17.031)\tTop5: 37.500 (avg: 40.031)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.527 (avg: 0.531)\tLoss: 3.5970 (avg: 3.7179)\tTop1: 9.375 (avg: 17.062)\tTop5: 46.875 (avg: 41.042)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.527 (avg: 0.532)\tLoss: 3.8438 (avg: 3.7172)\tTop1: 14.062 (avg: 17.172)\tTop5: 32.812 (avg: 40.625)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.530 (avg: 0.532)\tLoss: 3.7580 (avg: 3.7228)\tTop1: 12.500 (avg: 17.062)\tTop5: 32.812 (avg: 40.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8179\tTop 1 accuracy: 11.450\tTop 5 accuracy: 29.900\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.524 (avg: 0.522)\tLoss: 3.8277 (avg: 3.6460)\tTop1: 12.500 (avg: 19.188)\tTop5: 32.812 (avg: 41.688)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.531 (avg: 0.529)\tLoss: 3.9269 (avg: 3.6971)\tTop1: 10.938 (avg: 18.406)\tTop5: 35.938 (avg: 41.344)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.538 (avg: 0.531)\tLoss: 3.4932 (avg: 3.6896)\tTop1: 26.562 (avg: 17.854)\tTop5: 45.312 (avg: 41.688)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.522 (avg: 0.532)\tLoss: 3.3453 (avg: 3.6970)\tTop1: 20.312 (avg: 17.625)\tTop5: 48.438 (avg: 41.469)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.530 (avg: 0.533)\tLoss: 3.9211 (avg: 3.7073)\tTop1: 9.375 (avg: 17.488)\tTop5: 35.938 (avg: 41.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6205\tTop 1 accuracy: 12.750\tTop 5 accuracy: 32.450\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.534 (avg: 0.524)\tLoss: 3.3415 (avg: 3.6453)\tTop1: 25.000 (avg: 18.062)\tTop5: 45.312 (avg: 41.750)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.529 (avg: 0.530)\tLoss: 3.8585 (avg: 3.6815)\tTop1: 14.062 (avg: 18.156)\tTop5: 32.812 (avg: 40.562)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.529 (avg: 0.532)\tLoss: 3.6569 (avg: 3.6830)\tTop1: 12.500 (avg: 18.062)\tTop5: 43.750 (avg: 41.146)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.525 (avg: 0.533)\tLoss: 3.6416 (avg: 3.6966)\tTop1: 15.625 (avg: 17.953)\tTop5: 43.750 (avg: 41.156)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.527 (avg: 0.533)\tLoss: 3.9263 (avg: 3.6927)\tTop1: 14.062 (avg: 17.938)\tTop5: 37.500 (avg: 41.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6495\tTop 1 accuracy: 12.500\tTop 5 accuracy: 32.750\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.524 (avg: 0.522)\tLoss: 3.8087 (avg: 3.6421)\tTop1: 18.750 (avg: 18.875)\tTop5: 40.625 (avg: 42.188)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.532 (avg: 0.529)\tLoss: 3.5453 (avg: 3.6616)\tTop1: 18.750 (avg: 18.938)\tTop5: 42.188 (avg: 41.906)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.539 (avg: 0.530)\tLoss: 3.7450 (avg: 3.6701)\tTop1: 14.062 (avg: 18.146)\tTop5: 37.500 (avg: 41.312)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.522 (avg: 0.532)\tLoss: 3.6610 (avg: 3.6650)\tTop1: 10.938 (avg: 17.766)\tTop5: 40.625 (avg: 41.562)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.529 (avg: 0.532)\tLoss: 3.8827 (avg: 3.6761)\tTop1: 12.500 (avg: 17.675)\tTop5: 39.062 (avg: 41.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1152\tTop 1 accuracy: 12.650\tTop 5 accuracy: 31.200\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.530 (avg: 0.522)\tLoss: 3.5379 (avg: 3.6375)\tTop1: 10.938 (avg: 18.688)\tTop5: 45.312 (avg: 42.438)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.530 (avg: 0.529)\tLoss: 3.5626 (avg: 3.6583)\tTop1: 17.188 (avg: 18.531)\tTop5: 39.062 (avg: 42.156)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.524 (avg: 0.531)\tLoss: 3.5022 (avg: 3.6648)\tTop1: 20.312 (avg: 18.562)\tTop5: 50.000 (avg: 41.688)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.525 (avg: 0.532)\tLoss: 3.6245 (avg: 3.6540)\tTop1: 17.188 (avg: 18.375)\tTop5: 37.500 (avg: 42.266)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.521 (avg: 0.533)\tLoss: 3.5458 (avg: 3.6574)\tTop1: 25.000 (avg: 18.175)\tTop5: 50.000 (avg: 41.950)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5915\tTop 1 accuracy: 11.600\tTop 5 accuracy: 31.900\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.521 (avg: 0.522)\tLoss: 3.6996 (avg: 3.6079)\tTop1: 14.062 (avg: 17.812)\tTop5: 42.188 (avg: 44.000)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.534 (avg: 0.529)\tLoss: 3.7340 (avg: 3.6017)\tTop1: 14.062 (avg: 18.750)\tTop5: 40.625 (avg: 43.500)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.541 (avg: 0.531)\tLoss: 3.9272 (avg: 3.6350)\tTop1: 17.188 (avg: 18.562)\tTop5: 45.312 (avg: 42.729)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.524 (avg: 0.532)\tLoss: 3.5931 (avg: 3.6349)\tTop1: 15.625 (avg: 18.531)\tTop5: 43.750 (avg: 42.766)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.533 (avg: 0.533)\tLoss: 3.8667 (avg: 3.6390)\tTop1: 14.062 (avg: 18.413)\tTop5: 32.812 (avg: 42.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7934\tTop 1 accuracy: 11.700\tTop 5 accuracy: 31.650\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.528 (avg: 0.522)\tLoss: 3.6012 (avg: 3.6182)\tTop1: 20.312 (avg: 18.562)\tTop5: 48.438 (avg: 43.250)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.527 (avg: 0.529)\tLoss: 3.8466 (avg: 3.6018)\tTop1: 14.062 (avg: 19.188)\tTop5: 43.750 (avg: 43.812)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.528 (avg: 0.531)\tLoss: 3.4073 (avg: 3.6215)\tTop1: 25.000 (avg: 18.750)\tTop5: 48.438 (avg: 43.271)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.525 (avg: 0.532)\tLoss: 3.8382 (avg: 3.6439)\tTop1: 15.625 (avg: 18.328)\tTop5: 37.500 (avg: 42.250)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.526 (avg: 0.533)\tLoss: 3.4173 (avg: 3.6441)\tTop1: 20.312 (avg: 18.388)\tTop5: 45.312 (avg: 42.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6739\tTop 1 accuracy: 12.350\tTop 5 accuracy: 32.700\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.526 (avg: 0.523)\tLoss: 3.4961 (avg: 3.6316)\tTop1: 14.062 (avg: 18.625)\tTop5: 45.312 (avg: 42.375)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.531 (avg: 0.529)\tLoss: 3.8035 (avg: 3.6197)\tTop1: 17.188 (avg: 18.875)\tTop5: 37.500 (avg: 42.500)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.539 (avg: 0.531)\tLoss: 3.6238 (avg: 3.6382)\tTop1: 21.875 (avg: 18.500)\tTop5: 48.438 (avg: 42.375)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.520 (avg: 0.532)\tLoss: 3.6726 (avg: 3.6265)\tTop1: 17.188 (avg: 18.578)\tTop5: 45.312 (avg: 42.719)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.533 (avg: 0.533)\tLoss: 3.2413 (avg: 3.6152)\tTop1: 21.875 (avg: 18.825)\tTop5: 54.688 (avg: 42.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8887\tTop 1 accuracy: 12.700\tTop 5 accuracy: 32.300\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.530 (avg: 0.522)\tLoss: 3.6910 (avg: 3.5858)\tTop1: 15.625 (avg: 20.062)\tTop5: 46.875 (avg: 44.250)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.529 (avg: 0.529)\tLoss: 3.4675 (avg: 3.5716)\tTop1: 28.125 (avg: 19.812)\tTop5: 48.438 (avg: 44.781)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.531 (avg: 0.531)\tLoss: 3.4788 (avg: 3.5821)\tTop1: 25.000 (avg: 19.958)\tTop5: 43.750 (avg: 44.312)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.527 (avg: 0.532)\tLoss: 3.7796 (avg: 3.5853)\tTop1: 18.750 (avg: 19.656)\tTop5: 40.625 (avg: 44.297)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.528 (avg: 0.532)\tLoss: 3.7868 (avg: 3.5960)\tTop1: 21.875 (avg: 19.463)\tTop5: 40.625 (avg: 43.950)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6739\tTop 1 accuracy: 12.400\tTop 5 accuracy: 32.600\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.526 (avg: 0.522)\tLoss: 3.7121 (avg: 3.5855)\tTop1: 20.312 (avg: 19.250)\tTop5: 37.500 (avg: 44.000)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.527 (avg: 0.528)\tLoss: 3.3489 (avg: 3.5605)\tTop1: 25.000 (avg: 19.594)\tTop5: 48.438 (avg: 44.625)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.540 (avg: 0.531)\tLoss: 3.8665 (avg: 3.5758)\tTop1: 17.188 (avg: 19.250)\tTop5: 39.062 (avg: 44.417)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.521 (avg: 0.531)\tLoss: 3.7914 (avg: 3.5844)\tTop1: 12.500 (avg: 18.797)\tTop5: 35.938 (avg: 43.812)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.528 (avg: 0.532)\tLoss: 3.7908 (avg: 3.5923)\tTop1: 15.625 (avg: 18.850)\tTop5: 43.750 (avg: 43.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0934\tTop 1 accuracy: 11.350\tTop 5 accuracy: 31.050\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.530 (avg: 0.522)\tLoss: 3.6513 (avg: 3.5540)\tTop1: 17.188 (avg: 19.188)\tTop5: 46.875 (avg: 45.438)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.522 (avg: 0.529)\tLoss: 3.7222 (avg: 3.5858)\tTop1: 20.312 (avg: 18.688)\tTop5: 34.375 (avg: 43.688)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.528 (avg: 0.531)\tLoss: 3.5686 (avg: 3.5766)\tTop1: 18.750 (avg: 19.229)\tTop5: 40.625 (avg: 44.417)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.529 (avg: 0.532)\tLoss: 3.6432 (avg: 3.5795)\tTop1: 21.875 (avg: 19.422)\tTop5: 50.000 (avg: 44.078)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.524 (avg: 0.533)\tLoss: 3.5803 (avg: 3.5709)\tTop1: 15.625 (avg: 19.375)\tTop5: 39.062 (avg: 44.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6188\tTop 1 accuracy: 13.150\tTop 5 accuracy: 33.300\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.525 (avg: 0.523)\tLoss: 3.3360 (avg: 3.5420)\tTop1: 29.688 (avg: 21.125)\tTop5: 50.000 (avg: 44.125)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.530 (avg: 0.529)\tLoss: 3.6919 (avg: 3.5423)\tTop1: 17.188 (avg: 20.312)\tTop5: 42.188 (avg: 44.219)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.540 (avg: 0.531)\tLoss: 3.7926 (avg: 3.5510)\tTop1: 14.062 (avg: 20.000)\tTop5: 39.062 (avg: 43.958)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.525 (avg: 0.532)\tLoss: 3.3598 (avg: 3.5608)\tTop1: 25.000 (avg: 19.891)\tTop5: 56.250 (avg: 44.156)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.530 (avg: 0.533)\tLoss: 3.6684 (avg: 3.5514)\tTop1: 15.625 (avg: 19.850)\tTop5: 43.750 (avg: 44.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7744\tTop 1 accuracy: 13.600\tTop 5 accuracy: 32.950\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.530 (avg: 0.523)\tLoss: 3.6223 (avg: 3.4863)\tTop1: 25.000 (avg: 20.375)\tTop5: 43.750 (avg: 45.375)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.528 (avg: 0.529)\tLoss: 3.5232 (avg: 3.5154)\tTop1: 20.312 (avg: 20.281)\tTop5: 50.000 (avg: 44.844)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.531 (avg: 0.531)\tLoss: 3.7055 (avg: 3.5493)\tTop1: 15.625 (avg: 19.792)\tTop5: 39.062 (avg: 44.500)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.536 (avg: 0.533)\tLoss: 3.3905 (avg: 3.5385)\tTop1: 25.000 (avg: 19.953)\tTop5: 50.000 (avg: 44.391)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.523 (avg: 0.533)\tLoss: 3.5961 (avg: 3.5362)\tTop1: 20.312 (avg: 20.000)\tTop5: 40.625 (avg: 44.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6088\tTop 1 accuracy: 13.350\tTop 5 accuracy: 33.800\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.526 (avg: 0.522)\tLoss: 3.5055 (avg: 3.4538)\tTop1: 18.750 (avg: 22.000)\tTop5: 40.625 (avg: 48.062)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.534 (avg: 0.529)\tLoss: 3.5864 (avg: 3.4218)\tTop1: 15.625 (avg: 22.438)\tTop5: 39.062 (avg: 47.594)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.537 (avg: 0.531)\tLoss: 3.7637 (avg: 3.4214)\tTop1: 15.625 (avg: 22.167)\tTop5: 45.312 (avg: 47.458)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.518 (avg: 0.532)\tLoss: 3.4053 (avg: 3.4046)\tTop1: 21.875 (avg: 22.453)\tTop5: 54.688 (avg: 47.984)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.526 (avg: 0.533)\tLoss: 3.5913 (avg: 3.3998)\tTop1: 26.562 (avg: 22.563)\tTop5: 50.000 (avg: 48.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6708\tTop 1 accuracy: 13.700\tTop 5 accuracy: 34.950\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.533 (avg: 0.523)\tLoss: 3.3171 (avg: 3.3158)\tTop1: 26.562 (avg: 24.625)\tTop5: 45.312 (avg: 49.125)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.522 (avg: 0.529)\tLoss: 3.5016 (avg: 3.3509)\tTop1: 23.438 (avg: 24.062)\tTop5: 42.188 (avg: 49.125)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.530 (avg: 0.531)\tLoss: 2.9862 (avg: 3.3485)\tTop1: 26.562 (avg: 23.458)\tTop5: 62.500 (avg: 49.500)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.530 (avg: 0.532)\tLoss: 3.4573 (avg: 3.3711)\tTop1: 28.125 (avg: 23.141)\tTop5: 50.000 (avg: 48.844)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.526 (avg: 0.533)\tLoss: 3.4691 (avg: 3.3700)\tTop1: 20.312 (avg: 23.200)\tTop5: 46.875 (avg: 48.563)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6718\tTop 1 accuracy: 14.100\tTop 5 accuracy: 34.950\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.526 (avg: 0.522)\tLoss: 3.3231 (avg: 3.2995)\tTop1: 25.000 (avg: 25.938)\tTop5: 50.000 (avg: 49.500)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.532 (avg: 0.528)\tLoss: 3.5612 (avg: 3.3342)\tTop1: 15.625 (avg: 24.625)\tTop5: 46.875 (avg: 49.594)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.541 (avg: 0.531)\tLoss: 3.2332 (avg: 3.3609)\tTop1: 28.125 (avg: 23.917)\tTop5: 50.000 (avg: 49.042)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.520 (avg: 0.532)\tLoss: 3.2966 (avg: 3.3621)\tTop1: 20.312 (avg: 23.547)\tTop5: 51.562 (avg: 49.156)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.535 (avg: 0.533)\tLoss: 3.3796 (avg: 3.3569)\tTop1: 25.000 (avg: 23.450)\tTop5: 46.875 (avg: 49.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6745\tTop 1 accuracy: 14.100\tTop 5 accuracy: 34.950\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.530 (avg: 0.523)\tLoss: 3.4051 (avg: 3.3528)\tTop1: 31.250 (avg: 23.875)\tTop5: 50.000 (avg: 49.062)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.528 (avg: 0.529)\tLoss: 3.3168 (avg: 3.3294)\tTop1: 25.000 (avg: 24.531)\tTop5: 43.750 (avg: 49.469)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.528 (avg: 0.531)\tLoss: 2.9670 (avg: 3.3369)\tTop1: 29.688 (avg: 24.125)\tTop5: 54.688 (avg: 49.083)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.529 (avg: 0.532)\tLoss: 3.3238 (avg: 3.3486)\tTop1: 26.562 (avg: 23.781)\tTop5: 45.312 (avg: 48.734)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.523 (avg: 0.533)\tLoss: 3.3330 (avg: 3.3571)\tTop1: 17.188 (avg: 23.563)\tTop5: 51.562 (avg: 48.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7214\tTop 1 accuracy: 14.100\tTop 5 accuracy: 34.600\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.520 (avg: 0.522)\tLoss: 3.5140 (avg: 3.3468)\tTop1: 23.438 (avg: 24.750)\tTop5: 53.125 (avg: 49.750)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.539 (avg: 0.529)\tLoss: 3.5877 (avg: 3.3543)\tTop1: 18.750 (avg: 24.625)\tTop5: 35.938 (avg: 48.812)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.541 (avg: 0.531)\tLoss: 3.3359 (avg: 3.3551)\tTop1: 25.000 (avg: 24.271)\tTop5: 50.000 (avg: 48.521)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.516 (avg: 0.532)\tLoss: 3.2770 (avg: 3.3597)\tTop1: 20.312 (avg: 23.875)\tTop5: 53.125 (avg: 48.469)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.529 (avg: 0.532)\tLoss: 3.2135 (avg: 3.3531)\tTop1: 28.125 (avg: 24.100)\tTop5: 56.250 (avg: 48.813)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6928\tTop 1 accuracy: 14.200\tTop 5 accuracy: 34.650\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.529 (avg: 0.523)\tLoss: 3.4408 (avg: 3.3189)\tTop1: 21.875 (avg: 25.312)\tTop5: 45.312 (avg: 49.375)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.527 (avg: 0.529)\tLoss: 3.3583 (avg: 3.3236)\tTop1: 15.625 (avg: 24.375)\tTop5: 43.750 (avg: 49.094)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.528 (avg: 0.531)\tLoss: 3.3995 (avg: 3.3466)\tTop1: 28.125 (avg: 24.167)\tTop5: 50.000 (avg: 48.792)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.527 (avg: 0.532)\tLoss: 3.5020 (avg: 3.3400)\tTop1: 25.000 (avg: 23.828)\tTop5: 43.750 (avg: 49.141)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.525 (avg: 0.533)\tLoss: 3.4156 (avg: 3.3447)\tTop1: 23.438 (avg: 23.975)\tTop5: 43.750 (avg: 49.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7546\tTop 1 accuracy: 14.050\tTop 5 accuracy: 35.050\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.524 (avg: 0.522)\tLoss: 3.5274 (avg: 3.3094)\tTop1: 20.312 (avg: 24.250)\tTop5: 46.875 (avg: 51.562)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.529 (avg: 0.529)\tLoss: 3.3211 (avg: 3.3146)\tTop1: 28.125 (avg: 24.469)\tTop5: 46.875 (avg: 50.875)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.548 (avg: 0.531)\tLoss: 3.3388 (avg: 3.3197)\tTop1: 21.875 (avg: 24.417)\tTop5: 50.000 (avg: 50.208)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.522 (avg: 0.532)\tLoss: 3.5441 (avg: 3.3393)\tTop1: 17.188 (avg: 23.688)\tTop5: 40.625 (avg: 49.344)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.532 (avg: 0.533)\tLoss: 3.3475 (avg: 3.3392)\tTop1: 25.000 (avg: 23.975)\tTop5: 46.875 (avg: 49.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7684\tTop 1 accuracy: 14.300\tTop 5 accuracy: 34.900\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.531 (avg: 0.523)\tLoss: 3.4496 (avg: 3.3351)\tTop1: 23.438 (avg: 23.688)\tTop5: 43.750 (avg: 48.750)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.529 (avg: 0.530)\tLoss: 3.1836 (avg: 3.3629)\tTop1: 28.125 (avg: 23.031)\tTop5: 56.250 (avg: 48.062)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.528 (avg: 0.531)\tLoss: 3.3973 (avg: 3.3257)\tTop1: 21.875 (avg: 23.812)\tTop5: 51.562 (avg: 49.000)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.530 (avg: 0.532)\tLoss: 3.1969 (avg: 3.3545)\tTop1: 26.562 (avg: 23.656)\tTop5: 59.375 (avg: 48.797)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.528 (avg: 0.533)\tLoss: 3.2766 (avg: 3.3444)\tTop1: 25.000 (avg: 23.800)\tTop5: 51.562 (avg: 49.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7040\tTop 1 accuracy: 14.500\tTop 5 accuracy: 34.950\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.522 (avg: 0.522)\tLoss: 3.5802 (avg: 3.3093)\tTop1: 20.312 (avg: 23.625)\tTop5: 48.438 (avg: 49.688)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.531 (avg: 0.529)\tLoss: 3.0280 (avg: 3.3246)\tTop1: 21.875 (avg: 23.312)\tTop5: 53.125 (avg: 48.719)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.538 (avg: 0.531)\tLoss: 2.9733 (avg: 3.3213)\tTop1: 34.375 (avg: 23.896)\tTop5: 64.062 (avg: 49.042)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.521 (avg: 0.532)\tLoss: 3.0885 (avg: 3.3292)\tTop1: 28.125 (avg: 23.844)\tTop5: 51.562 (avg: 49.109)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.532 (avg: 0.533)\tLoss: 3.7331 (avg: 3.3312)\tTop1: 14.062 (avg: 24.025)\tTop5: 35.938 (avg: 49.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6950\tTop 1 accuracy: 14.000\tTop 5 accuracy: 34.650\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.529 (avg: 0.522)\tLoss: 3.1319 (avg: 3.2960)\tTop1: 32.812 (avg: 25.375)\tTop5: 50.000 (avg: 49.688)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.526 (avg: 0.529)\tLoss: 3.5865 (avg: 3.3351)\tTop1: 20.312 (avg: 24.156)\tTop5: 42.188 (avg: 48.812)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.529 (avg: 0.531)\tLoss: 3.3883 (avg: 3.3481)\tTop1: 23.438 (avg: 23.688)\tTop5: 50.000 (avg: 48.354)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.526 (avg: 0.532)\tLoss: 3.0890 (avg: 3.3485)\tTop1: 29.688 (avg: 23.672)\tTop5: 57.812 (avg: 48.734)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.524 (avg: 0.532)\tLoss: 3.3570 (avg: 3.3345)\tTop1: 25.000 (avg: 23.913)\tTop5: 48.438 (avg: 49.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7674\tTop 1 accuracy: 14.300\tTop 5 accuracy: 35.000\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.524 (avg: 0.523)\tLoss: 3.4848 (avg: 3.3232)\tTop1: 17.188 (avg: 24.750)\tTop5: 53.125 (avg: 49.375)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.530 (avg: 0.528)\tLoss: 3.8619 (avg: 3.3497)\tTop1: 15.625 (avg: 23.750)\tTop5: 43.750 (avg: 48.844)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.542 (avg: 0.531)\tLoss: 3.6592 (avg: 3.3375)\tTop1: 23.438 (avg: 24.125)\tTop5: 46.875 (avg: 49.188)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.522 (avg: 0.532)\tLoss: 3.2652 (avg: 3.3233)\tTop1: 23.438 (avg: 24.141)\tTop5: 51.562 (avg: 49.281)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.532 (avg: 0.533)\tLoss: 2.9452 (avg: 3.3237)\tTop1: 39.062 (avg: 24.425)\tTop5: 59.375 (avg: 49.313)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7012\tTop 1 accuracy: 14.000\tTop 5 accuracy: 34.950\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.531 (avg: 0.523)\tLoss: 3.3447 (avg: 3.3355)\tTop1: 17.188 (avg: 24.938)\tTop5: 46.875 (avg: 48.500)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.531 (avg: 0.529)\tLoss: 3.1995 (avg: 3.3127)\tTop1: 23.438 (avg: 25.281)\tTop5: 56.250 (avg: 49.719)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.529 (avg: 0.531)\tLoss: 3.4594 (avg: 3.3154)\tTop1: 34.375 (avg: 25.229)\tTop5: 48.438 (avg: 50.000)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.531 (avg: 0.532)\tLoss: 3.3650 (avg: 3.3300)\tTop1: 18.750 (avg: 24.453)\tTop5: 48.438 (avg: 49.703)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.523 (avg: 0.533)\tLoss: 3.5008 (avg: 3.3175)\tTop1: 29.688 (avg: 24.500)\tTop5: 48.438 (avg: 49.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7059\tTop 1 accuracy: 13.800\tTop 5 accuracy: 34.600\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.523 (avg: 0.523)\tLoss: 3.3640 (avg: 3.3204)\tTop1: 20.312 (avg: 23.875)\tTop5: 48.438 (avg: 48.812)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.530 (avg: 0.529)\tLoss: 3.0804 (avg: 3.2896)\tTop1: 25.000 (avg: 23.812)\tTop5: 50.000 (avg: 50.000)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.543 (avg: 0.531)\tLoss: 3.3593 (avg: 3.2929)\tTop1: 23.438 (avg: 24.062)\tTop5: 45.312 (avg: 50.354)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.517 (avg: 0.532)\tLoss: 3.7626 (avg: 3.3023)\tTop1: 18.750 (avg: 24.250)\tTop5: 34.375 (avg: 50.094)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.531 (avg: 0.533)\tLoss: 3.4338 (avg: 3.3182)\tTop1: 25.000 (avg: 24.250)\tTop5: 48.438 (avg: 49.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7435\tTop 1 accuracy: 14.550\tTop 5 accuracy: 34.200\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.528 (avg: 0.522)\tLoss: 3.3096 (avg: 3.3045)\tTop1: 20.312 (avg: 25.250)\tTop5: 56.250 (avg: 50.000)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.528 (avg: 0.529)\tLoss: 3.0796 (avg: 3.2906)\tTop1: 31.250 (avg: 25.031)\tTop5: 53.125 (avg: 49.750)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.532 (avg: 0.531)\tLoss: 3.4267 (avg: 3.2888)\tTop1: 18.750 (avg: 25.312)\tTop5: 53.125 (avg: 50.417)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.526 (avg: 0.532)\tLoss: 3.3469 (avg: 3.3142)\tTop1: 31.250 (avg: 24.344)\tTop5: 54.688 (avg: 49.750)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.530 (avg: 0.533)\tLoss: 3.0194 (avg: 3.3137)\tTop1: 26.562 (avg: 24.363)\tTop5: 51.562 (avg: 49.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7345\tTop 1 accuracy: 14.350\tTop 5 accuracy: 35.100\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.523 (avg: 0.523)\tLoss: 3.1466 (avg: 3.3046)\tTop1: 21.875 (avg: 24.000)\tTop5: 54.688 (avg: 50.688)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.535 (avg: 0.529)\tLoss: 3.3145 (avg: 3.2881)\tTop1: 28.125 (avg: 24.906)\tTop5: 48.438 (avg: 50.469)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.541 (avg: 0.531)\tLoss: 3.6415 (avg: 3.3010)\tTop1: 15.625 (avg: 24.396)\tTop5: 43.750 (avg: 50.208)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.521 (avg: 0.532)\tLoss: 3.2705 (avg: 3.3161)\tTop1: 28.125 (avg: 24.156)\tTop5: 48.438 (avg: 49.859)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.533 (avg: 0.533)\tLoss: 3.2315 (avg: 3.3075)\tTop1: 17.188 (avg: 24.250)\tTop5: 50.000 (avg: 50.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8183\tTop 1 accuracy: 14.100\tTop 5 accuracy: 34.550\n",
            "\n",
            "base_e = 256: top1 = 14.350000381469727 \t top5 = 35.10000228881836 \t batch time = 0.34821106493473053\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0iwvDbUeOLMY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51207
        },
        "outputId": "15ec5bce-c818-40ed-b8d1-cd7339bd447a"
      },
      "cell_type": "code",
      "source": [
        "# incr_e\n",
        "incr_list = [64, 128, 192, 256]\n",
        "incr_top1s = []\n",
        "incr_top5s = []\n",
        "incr_batch_times = []\n",
        "for incr in incr_list:\n",
        "  model = SqueezeNet_MetaParam(version=1.0, incr=incr)\n",
        "  batch_time, top1, top5 = test_model(model)\n",
        "  incr_top1s.append(top1)\n",
        "  incr_top5s.append(top5)\n",
        "  incr_batch_times.append(batch_time)\n",
        "  print(\"incr_e = {0}: top1 = {1} \\t top5 = {2} \\t batch time = {3}\\n\".format(incr, top1, top5, batch_time))\n",
        "  \n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.293 (avg: 0.323)\tLoss: 5.3006 (avg: 5.3057)\tTop1: 0.000 (avg: 0.125)\tTop5: 1.562 (avg: 2.312)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.295 (avg: 0.312)\tLoss: 5.3003 (avg: 5.3022)\tTop1: 0.000 (avg: 0.250)\tTop5: 1.562 (avg: 1.875)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.299 (avg: 0.309)\tLoss: 5.2973 (avg: 5.3010)\tTop1: 0.000 (avg: 0.229)\tTop5: 6.250 (avg: 1.833)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.300 (avg: 0.307)\tLoss: 5.2978 (avg: 5.3003)\tTop1: 0.000 (avg: 0.266)\tTop5: 1.562 (avg: 1.891)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.292 (avg: 0.306)\tLoss: 5.2976 (avg: 5.3000)\tTop1: 0.000 (avg: 0.325)\tTop5: 0.000 (avg: 1.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2991\tTop 1 accuracy: 0.250\tTop 5 accuracy: 2.050\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.293 (avg: 0.294)\tLoss: 5.2966 (avg: 5.2975)\tTop1: 0.000 (avg: 0.500)\tTop5: 1.562 (avg: 2.188)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.289 (avg: 0.297)\tLoss: 5.3236 (avg: 5.2965)\tTop1: 0.000 (avg: 0.500)\tTop5: 1.562 (avg: 2.344)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.295 (avg: 0.299)\tLoss: 5.2817 (avg: 5.2938)\tTop1: 0.000 (avg: 0.500)\tTop5: 1.562 (avg: 2.500)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.290 (avg: 0.299)\tLoss: 5.2811 (avg: 5.2879)\tTop1: 0.000 (avg: 0.562)\tTop5: 4.688 (avg: 2.609)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.295 (avg: 0.299)\tLoss: 5.2982 (avg: 5.2888)\tTop1: 0.000 (avg: 0.525)\tTop5: 1.562 (avg: 2.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3018\tTop 1 accuracy: 0.400\tTop 5 accuracy: 2.450\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.293 (avg: 0.294)\tLoss: 5.3067 (avg: 5.2845)\tTop1: 0.000 (avg: 0.500)\tTop5: 0.000 (avg: 2.625)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.296 (avg: 0.298)\tLoss: 5.2316 (avg: 5.2759)\tTop1: 1.562 (avg: 0.562)\tTop5: 6.250 (avg: 3.125)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.292 (avg: 0.299)\tLoss: 5.3506 (avg: 5.2718)\tTop1: 0.000 (avg: 0.583)\tTop5: 6.250 (avg: 3.354)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.286 (avg: 0.299)\tLoss: 5.2375 (avg: 5.2714)\tTop1: 1.562 (avg: 0.656)\tTop5: 4.688 (avg: 3.703)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.300 (avg: 0.300)\tLoss: 5.2810 (avg: 5.2701)\tTop1: 0.000 (avg: 0.663)\tTop5: 6.250 (avg: 3.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3165\tTop 1 accuracy: 0.550\tTop 5 accuracy: 3.650\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.297 (avg: 0.295)\tLoss: 5.2572 (avg: 5.2528)\tTop1: 0.000 (avg: 0.812)\tTop5: 3.125 (avg: 4.250)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.299 (avg: 0.298)\tLoss: 5.2687 (avg: 5.2496)\tTop1: 0.000 (avg: 0.688)\tTop5: 6.250 (avg: 4.281)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 5.1861 (avg: 5.2469)\tTop1: 0.000 (avg: 0.771)\tTop5: 6.250 (avg: 4.250)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.292 (avg: 0.300)\tLoss: 5.2493 (avg: 5.2491)\tTop1: 0.000 (avg: 0.750)\tTop5: 4.688 (avg: 4.359)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.296 (avg: 0.300)\tLoss: 5.3166 (avg: 5.2452)\tTop1: 1.562 (avg: 0.838)\tTop5: 6.250 (avg: 4.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.4016\tTop 1 accuracy: 0.800\tTop 5 accuracy: 3.600\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.292 (avg: 0.294)\tLoss: 5.3123 (avg: 5.2407)\tTop1: 0.000 (avg: 0.875)\tTop5: 1.562 (avg: 4.438)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.287 (avg: 0.296)\tLoss: 5.2863 (avg: 5.2376)\tTop1: 0.000 (avg: 0.938)\tTop5: 0.000 (avg: 4.531)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.301 (avg: 0.298)\tLoss: 5.2111 (avg: 5.2283)\tTop1: 1.562 (avg: 1.083)\tTop5: 10.938 (avg: 5.208)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.294 (avg: 0.298)\tLoss: 5.2440 (avg: 5.2317)\tTop1: 0.000 (avg: 1.109)\tTop5: 6.250 (avg: 5.078)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.289 (avg: 0.299)\tLoss: 5.2254 (avg: 5.2288)\tTop1: 3.125 (avg: 1.138)\tTop5: 3.125 (avg: 5.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3551\tTop 1 accuracy: 1.500\tTop 5 accuracy: 5.400\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.295 (avg: 0.295)\tLoss: 5.2469 (avg: 5.2010)\tTop1: 0.000 (avg: 1.500)\tTop5: 3.125 (avg: 6.500)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.292 (avg: 0.298)\tLoss: 5.2210 (avg: 5.2156)\tTop1: 3.125 (avg: 1.531)\tTop5: 9.375 (avg: 6.312)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.298 (avg: 0.300)\tLoss: 5.1459 (avg: 5.2063)\tTop1: 1.562 (avg: 1.604)\tTop5: 6.250 (avg: 6.229)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.294 (avg: 0.300)\tLoss: 5.1835 (avg: 5.2036)\tTop1: 1.562 (avg: 1.625)\tTop5: 7.812 (avg: 6.547)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.293 (avg: 0.300)\tLoss: 5.2258 (avg: 5.2054)\tTop1: 1.562 (avg: 1.550)\tTop5: 3.125 (avg: 6.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3922\tTop 1 accuracy: 1.150\tTop 5 accuracy: 5.300\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.301 (avg: 0.294)\tLoss: 5.2580 (avg: 5.2027)\tTop1: 1.562 (avg: 1.688)\tTop5: 4.688 (avg: 6.000)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.292 (avg: 0.297)\tLoss: 5.1911 (avg: 5.2011)\tTop1: 3.125 (avg: 1.469)\tTop5: 3.125 (avg: 5.875)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.292 (avg: 0.298)\tLoss: 5.2535 (avg: 5.1907)\tTop1: 1.562 (avg: 1.667)\tTop5: 6.250 (avg: 6.479)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.293 (avg: 0.299)\tLoss: 5.1638 (avg: 5.1872)\tTop1: 1.562 (avg: 1.734)\tTop5: 4.688 (avg: 6.891)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.304 (avg: 0.299)\tLoss: 5.1940 (avg: 5.1881)\tTop1: 0.000 (avg: 1.600)\tTop5: 4.688 (avg: 6.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3759\tTop 1 accuracy: 1.450\tTop 5 accuracy: 6.850\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.305 (avg: 0.297)\tLoss: 5.1550 (avg: 5.1646)\tTop1: 1.562 (avg: 1.812)\tTop5: 7.812 (avg: 6.688)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.296 (avg: 0.301)\tLoss: 5.1473 (avg: 5.1677)\tTop1: 3.125 (avg: 1.688)\tTop5: 6.250 (avg: 6.969)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.292 (avg: 0.301)\tLoss: 5.0798 (avg: 5.1593)\tTop1: 3.125 (avg: 1.896)\tTop5: 9.375 (avg: 7.042)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.296 (avg: 0.301)\tLoss: 5.2875 (avg: 5.1629)\tTop1: 0.000 (avg: 2.000)\tTop5: 3.125 (avg: 7.141)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.308 (avg: 0.302)\tLoss: 5.3068 (avg: 5.1683)\tTop1: 0.000 (avg: 1.900)\tTop5: 3.125 (avg: 7.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.4520\tTop 1 accuracy: 1.800\tTop 5 accuracy: 6.300\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.292 (avg: 0.295)\tLoss: 5.0080 (avg: 5.1407)\tTop1: 3.125 (avg: 1.562)\tTop5: 9.375 (avg: 7.812)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.301 (avg: 0.298)\tLoss: 5.2568 (avg: 5.1508)\tTop1: 1.562 (avg: 1.719)\tTop5: 4.688 (avg: 7.969)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.294 (avg: 0.299)\tLoss: 5.1169 (avg: 5.1602)\tTop1: 3.125 (avg: 1.708)\tTop5: 6.250 (avg: 7.708)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.295 (avg: 0.299)\tLoss: 5.2347 (avg: 5.1614)\tTop1: 1.562 (avg: 1.672)\tTop5: 4.688 (avg: 7.703)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.300 (avg: 0.300)\tLoss: 5.0629 (avg: 5.1543)\tTop1: 0.000 (avg: 1.725)\tTop5: 3.125 (avg: 7.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.5388\tTop 1 accuracy: 1.800\tTop 5 accuracy: 6.800\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.293 (avg: 0.294)\tLoss: 5.1174 (avg: 5.1208)\tTop1: 1.562 (avg: 2.375)\tTop5: 9.375 (avg: 8.250)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.293 (avg: 0.298)\tLoss: 5.1516 (avg: 5.1179)\tTop1: 4.688 (avg: 2.125)\tTop5: 7.812 (avg: 8.500)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.306 (avg: 0.300)\tLoss: 5.0712 (avg: 5.1255)\tTop1: 0.000 (avg: 2.125)\tTop5: 12.500 (avg: 8.792)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.293 (avg: 0.301)\tLoss: 5.2045 (avg: 5.1360)\tTop1: 4.688 (avg: 1.984)\tTop5: 6.250 (avg: 8.156)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.291 (avg: 0.301)\tLoss: 5.2595 (avg: 5.1426)\tTop1: 0.000 (avg: 1.863)\tTop5: 4.688 (avg: 7.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2731\tTop 1 accuracy: 2.550\tTop 5 accuracy: 8.200\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.292 (avg: 0.295)\tLoss: 5.1445 (avg: 5.1193)\tTop1: 1.562 (avg: 2.125)\tTop5: 9.375 (avg: 8.062)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.295 (avg: 0.298)\tLoss: 5.0523 (avg: 5.1056)\tTop1: 0.000 (avg: 1.938)\tTop5: 9.375 (avg: 8.094)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.302 (avg: 0.299)\tLoss: 5.0090 (avg: 5.1094)\tTop1: 4.688 (avg: 1.938)\tTop5: 9.375 (avg: 7.812)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.290 (avg: 0.300)\tLoss: 5.1081 (avg: 5.1111)\tTop1: 1.562 (avg: 2.109)\tTop5: 7.812 (avg: 8.094)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.295 (avg: 0.300)\tLoss: 5.1459 (avg: 5.1124)\tTop1: 3.125 (avg: 2.188)\tTop5: 10.938 (avg: 7.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2255\tTop 1 accuracy: 2.450\tTop 5 accuracy: 9.250\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.296 (avg: 0.294)\tLoss: 5.0901 (avg: 5.0927)\tTop1: 0.000 (avg: 2.250)\tTop5: 7.812 (avg: 8.938)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.295 (avg: 0.298)\tLoss: 4.9690 (avg: 5.0840)\tTop1: 4.688 (avg: 2.344)\tTop5: 12.500 (avg: 9.094)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 5.1277 (avg: 5.0936)\tTop1: 0.000 (avg: 2.312)\tTop5: 6.250 (avg: 9.208)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.289 (avg: 0.299)\tLoss: 5.0809 (avg: 5.1024)\tTop1: 0.000 (avg: 2.156)\tTop5: 9.375 (avg: 8.797)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.295 (avg: 0.299)\tLoss: 5.1706 (avg: 5.1026)\tTop1: 3.125 (avg: 2.100)\tTop5: 7.812 (avg: 8.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2500\tTop 1 accuracy: 1.850\tTop 5 accuracy: 8.800\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.303 (avg: 0.297)\tLoss: 5.1233 (avg: 5.0679)\tTop1: 3.125 (avg: 2.562)\tTop5: 9.375 (avg: 9.375)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.290 (avg: 0.299)\tLoss: 5.0323 (avg: 5.0770)\tTop1: 3.125 (avg: 2.375)\tTop5: 6.250 (avg: 9.125)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.294 (avg: 0.300)\tLoss: 5.1122 (avg: 5.0833)\tTop1: 4.688 (avg: 2.375)\tTop5: 9.375 (avg: 8.917)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.294 (avg: 0.300)\tLoss: 5.0303 (avg: 5.0819)\tTop1: 3.125 (avg: 2.484)\tTop5: 15.625 (avg: 9.078)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.292 (avg: 0.300)\tLoss: 5.0790 (avg: 5.0802)\tTop1: 1.562 (avg: 2.400)\tTop5: 9.375 (avg: 9.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0504\tTop 1 accuracy: 2.050\tTop 5 accuracy: 9.450\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.288 (avg: 0.294)\tLoss: 5.1397 (avg: 5.0373)\tTop1: 1.562 (avg: 2.688)\tTop5: 9.375 (avg: 10.812)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.299 (avg: 0.297)\tLoss: 5.0423 (avg: 5.0720)\tTop1: 6.250 (avg: 2.438)\tTop5: 12.500 (avg: 10.219)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.297 (avg: 0.298)\tLoss: 5.1705 (avg: 5.0654)\tTop1: 1.562 (avg: 2.708)\tTop5: 6.250 (avg: 10.062)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.297 (avg: 0.298)\tLoss: 4.9894 (avg: 5.0683)\tTop1: 1.562 (avg: 2.609)\tTop5: 12.500 (avg: 9.531)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.290 (avg: 0.299)\tLoss: 5.0446 (avg: 5.0659)\tTop1: 6.250 (avg: 2.550)\tTop5: 9.375 (avg: 9.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2042\tTop 1 accuracy: 3.000\tTop 5 accuracy: 9.050\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.291 (avg: 0.294)\tLoss: 5.0562 (avg: 5.0272)\tTop1: 4.688 (avg: 3.125)\tTop5: 9.375 (avg: 10.188)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.296 (avg: 0.297)\tLoss: 5.0204 (avg: 5.0405)\tTop1: 3.125 (avg: 3.062)\tTop5: 9.375 (avg: 9.906)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.304 (avg: 0.298)\tLoss: 5.0647 (avg: 5.0335)\tTop1: 3.125 (avg: 2.979)\tTop5: 9.375 (avg: 10.292)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.294 (avg: 0.299)\tLoss: 4.9769 (avg: 5.0393)\tTop1: 6.250 (avg: 2.812)\tTop5: 14.062 (avg: 10.266)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.294 (avg: 0.300)\tLoss: 5.0398 (avg: 5.0447)\tTop1: 3.125 (avg: 2.750)\tTop5: 12.500 (avg: 10.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9702\tTop 1 accuracy: 3.000\tTop 5 accuracy: 9.200\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.300 (avg: 0.295)\tLoss: 5.1280 (avg: 5.0208)\tTop1: 0.000 (avg: 2.562)\tTop5: 3.125 (avg: 9.750)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.291 (avg: 0.298)\tLoss: 5.0283 (avg: 5.0332)\tTop1: 0.000 (avg: 2.500)\tTop5: 9.375 (avg: 9.969)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.297 (avg: 0.300)\tLoss: 4.9155 (avg: 5.0276)\tTop1: 1.562 (avg: 2.583)\tTop5: 15.625 (avg: 10.250)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.290 (avg: 0.300)\tLoss: 4.7553 (avg: 5.0259)\tTop1: 6.250 (avg: 2.781)\tTop5: 14.062 (avg: 10.344)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.296 (avg: 0.300)\tLoss: 5.0894 (avg: 5.0240)\tTop1: 1.562 (avg: 2.775)\tTop5: 7.812 (avg: 10.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8219\tTop 1 accuracy: 3.450\tTop 5 accuracy: 10.650\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.306 (avg: 0.295)\tLoss: 5.2465 (avg: 5.0077)\tTop1: 1.562 (avg: 2.812)\tTop5: 3.125 (avg: 10.938)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.290 (avg: 0.299)\tLoss: 4.9523 (avg: 4.9940)\tTop1: 4.688 (avg: 2.969)\tTop5: 9.375 (avg: 10.969)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.289 (avg: 0.300)\tLoss: 5.0452 (avg: 4.9950)\tTop1: 3.125 (avg: 2.792)\tTop5: 14.062 (avg: 11.083)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.305 (avg: 0.301)\tLoss: 5.0169 (avg: 4.9998)\tTop1: 1.562 (avg: 2.609)\tTop5: 9.375 (avg: 10.938)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.298 (avg: 0.301)\tLoss: 5.1408 (avg: 4.9964)\tTop1: 1.562 (avg: 2.738)\tTop5: 7.812 (avg: 11.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8591\tTop 1 accuracy: 2.250\tTop 5 accuracy: 9.850\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.300 (avg: 0.296)\tLoss: 5.1577 (avg: 4.9840)\tTop1: 3.125 (avg: 2.750)\tTop5: 6.250 (avg: 11.312)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 5.1243 (avg: 4.9695)\tTop1: 1.562 (avg: 3.156)\tTop5: 6.250 (avg: 11.312)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.297 (avg: 0.300)\tLoss: 5.1205 (avg: 4.9655)\tTop1: 4.688 (avg: 3.104)\tTop5: 9.375 (avg: 11.562)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.297 (avg: 0.301)\tLoss: 4.8053 (avg: 4.9596)\tTop1: 4.688 (avg: 3.328)\tTop5: 12.500 (avg: 11.469)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.290 (avg: 0.301)\tLoss: 4.9930 (avg: 4.9602)\tTop1: 3.125 (avg: 3.250)\tTop5: 10.938 (avg: 11.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7196\tTop 1 accuracy: 2.550\tTop 5 accuracy: 10.750\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.295 (avg: 0.295)\tLoss: 5.1262 (avg: 4.9117)\tTop1: 4.688 (avg: 3.750)\tTop5: 12.500 (avg: 13.125)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.293 (avg: 0.298)\tLoss: 5.0508 (avg: 4.9037)\tTop1: 0.000 (avg: 3.656)\tTop5: 7.812 (avg: 12.969)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.293 (avg: 0.299)\tLoss: 4.9374 (avg: 4.9144)\tTop1: 4.688 (avg: 3.417)\tTop5: 12.500 (avg: 12.646)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.293 (avg: 0.299)\tLoss: 4.9146 (avg: 4.9165)\tTop1: 1.562 (avg: 3.375)\tTop5: 9.375 (avg: 12.578)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.305 (avg: 0.300)\tLoss: 4.8017 (avg: 4.9234)\tTop1: 6.250 (avg: 3.213)\tTop5: 17.188 (avg: 12.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8037\tTop 1 accuracy: 3.100\tTop 5 accuracy: 12.300\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.300 (avg: 0.294)\tLoss: 5.1041 (avg: 4.8313)\tTop1: 3.125 (avg: 3.812)\tTop5: 7.812 (avg: 14.312)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.300 (avg: 0.297)\tLoss: 4.9018 (avg: 4.8802)\tTop1: 4.688 (avg: 3.625)\tTop5: 14.062 (avg: 12.875)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.291 (avg: 0.298)\tLoss: 4.8074 (avg: 4.8785)\tTop1: 0.000 (avg: 3.438)\tTop5: 9.375 (avg: 12.438)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.290 (avg: 0.298)\tLoss: 4.9981 (avg: 4.8765)\tTop1: 0.000 (avg: 3.688)\tTop5: 3.125 (avg: 12.672)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.300 (avg: 0.299)\tLoss: 4.8148 (avg: 4.8764)\tTop1: 4.688 (avg: 3.725)\tTop5: 15.625 (avg: 12.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8207\tTop 1 accuracy: 4.050\tTop 5 accuracy: 12.100\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.294 (avg: 0.294)\tLoss: 4.7401 (avg: 4.7941)\tTop1: 1.562 (avg: 3.312)\tTop5: 12.500 (avg: 13.312)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.295 (avg: 0.298)\tLoss: 4.7956 (avg: 4.8053)\tTop1: 3.125 (avg: 4.188)\tTop5: 14.062 (avg: 14.250)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.300 (avg: 0.299)\tLoss: 4.8880 (avg: 4.8132)\tTop1: 1.562 (avg: 4.271)\tTop5: 15.625 (avg: 14.438)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 4.8592 (avg: 4.8225)\tTop1: 3.125 (avg: 4.016)\tTop5: 12.500 (avg: 14.078)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.292 (avg: 0.299)\tLoss: 4.7940 (avg: 4.8192)\tTop1: 4.688 (avg: 3.975)\tTop5: 17.188 (avg: 14.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6320\tTop 1 accuracy: 5.200\tTop 5 accuracy: 14.100\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.292 (avg: 0.293)\tLoss: 4.8601 (avg: 4.7221)\tTop1: 3.125 (avg: 5.500)\tTop5: 10.938 (avg: 16.875)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.289 (avg: 0.296)\tLoss: 4.7951 (avg: 4.7516)\tTop1: 4.688 (avg: 4.812)\tTop5: 10.938 (avg: 16.000)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.294 (avg: 0.298)\tLoss: 4.8461 (avg: 4.7634)\tTop1: 4.688 (avg: 4.438)\tTop5: 14.062 (avg: 15.021)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.298 (avg: 0.298)\tLoss: 4.7244 (avg: 4.7782)\tTop1: 6.250 (avg: 4.281)\tTop5: 17.188 (avg: 14.547)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.293 (avg: 0.299)\tLoss: 4.7201 (avg: 4.7809)\tTop1: 4.688 (avg: 4.300)\tTop5: 15.625 (avg: 14.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8220\tTop 1 accuracy: 3.450\tTop 5 accuracy: 14.900\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.295 (avg: 0.293)\tLoss: 4.9564 (avg: 4.7300)\tTop1: 3.125 (avg: 4.625)\tTop5: 12.500 (avg: 16.062)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.296 (avg: 0.297)\tLoss: 4.8153 (avg: 4.7311)\tTop1: 3.125 (avg: 4.312)\tTop5: 10.938 (avg: 15.750)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.295 (avg: 0.298)\tLoss: 4.5822 (avg: 4.7277)\tTop1: 4.688 (avg: 4.562)\tTop5: 17.188 (avg: 16.042)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.289 (avg: 0.299)\tLoss: 4.9375 (avg: 4.7333)\tTop1: 4.688 (avg: 4.484)\tTop5: 10.938 (avg: 15.969)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.301 (avg: 0.299)\tLoss: 4.9300 (avg: 4.7359)\tTop1: 4.688 (avg: 4.463)\tTop5: 15.625 (avg: 16.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7220\tTop 1 accuracy: 4.300\tTop 5 accuracy: 15.250\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.296 (avg: 0.295)\tLoss: 4.5378 (avg: 4.6928)\tTop1: 6.250 (avg: 5.062)\tTop5: 20.312 (avg: 16.938)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.300 (avg: 0.298)\tLoss: 4.6924 (avg: 4.6742)\tTop1: 6.250 (avg: 5.344)\tTop5: 17.188 (avg: 17.312)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.289 (avg: 0.298)\tLoss: 4.7637 (avg: 4.6805)\tTop1: 3.125 (avg: 5.271)\tTop5: 9.375 (avg: 16.979)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.290 (avg: 0.299)\tLoss: 4.5753 (avg: 4.6941)\tTop1: 1.562 (avg: 4.953)\tTop5: 23.438 (avg: 16.594)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.293 (avg: 0.299)\tLoss: 4.7062 (avg: 4.6979)\tTop1: 6.250 (avg: 4.900)\tTop5: 23.438 (avg: 16.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4975\tTop 1 accuracy: 5.250\tTop 5 accuracy: 16.050\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.294 (avg: 0.293)\tLoss: 4.3197 (avg: 4.6226)\tTop1: 9.375 (avg: 5.938)\tTop5: 26.562 (avg: 18.375)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.291 (avg: 0.297)\tLoss: 4.4571 (avg: 4.6319)\tTop1: 6.250 (avg: 5.219)\tTop5: 23.438 (avg: 17.969)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.292 (avg: 0.298)\tLoss: 4.5063 (avg: 4.6344)\tTop1: 10.938 (avg: 5.292)\tTop5: 21.875 (avg: 17.750)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.297 (avg: 0.299)\tLoss: 4.7092 (avg: 4.6503)\tTop1: 4.688 (avg: 5.266)\tTop5: 14.062 (avg: 17.156)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.294 (avg: 0.299)\tLoss: 4.6189 (avg: 4.6514)\tTop1: 7.812 (avg: 5.175)\tTop5: 17.188 (avg: 17.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6721\tTop 1 accuracy: 5.700\tTop 5 accuracy: 17.600\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.291 (avg: 0.294)\tLoss: 4.5578 (avg: 4.5557)\tTop1: 9.375 (avg: 5.312)\tTop5: 20.312 (avg: 19.062)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.294 (avg: 0.298)\tLoss: 4.5399 (avg: 4.5829)\tTop1: 6.250 (avg: 5.375)\tTop5: 17.188 (avg: 18.938)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.312 (avg: 0.301)\tLoss: 4.5149 (avg: 4.5893)\tTop1: 6.250 (avg: 4.896)\tTop5: 18.750 (avg: 18.354)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.290 (avg: 0.302)\tLoss: 4.7141 (avg: 4.5971)\tTop1: 6.250 (avg: 4.984)\tTop5: 15.625 (avg: 18.562)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.290 (avg: 0.302)\tLoss: 4.5728 (avg: 4.6090)\tTop1: 4.688 (avg: 4.950)\tTop5: 9.375 (avg: 18.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6344\tTop 1 accuracy: 4.850\tTop 5 accuracy: 16.600\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.293 (avg: 0.295)\tLoss: 4.0716 (avg: 4.5135)\tTop1: 12.500 (avg: 6.938)\tTop5: 34.375 (avg: 19.938)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.296 (avg: 0.298)\tLoss: 4.5041 (avg: 4.5244)\tTop1: 4.688 (avg: 6.625)\tTop5: 17.188 (avg: 19.906)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 4.5303 (avg: 4.5479)\tTop1: 4.688 (avg: 6.396)\tTop5: 18.750 (avg: 19.458)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.290 (avg: 0.299)\tLoss: 4.4737 (avg: 4.5346)\tTop1: 6.250 (avg: 6.469)\tTop5: 15.625 (avg: 19.641)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.289 (avg: 0.299)\tLoss: 4.4404 (avg: 4.5400)\tTop1: 9.375 (avg: 6.300)\tTop5: 26.562 (avg: 19.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6997\tTop 1 accuracy: 5.700\tTop 5 accuracy: 17.850\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.301 (avg: 0.294)\tLoss: 4.5689 (avg: 4.4942)\tTop1: 7.812 (avg: 6.938)\tTop5: 20.312 (avg: 20.938)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.290 (avg: 0.297)\tLoss: 4.5215 (avg: 4.4760)\tTop1: 7.812 (avg: 7.031)\tTop5: 21.875 (avg: 21.688)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.295 (avg: 0.299)\tLoss: 4.6604 (avg: 4.5051)\tTop1: 3.125 (avg: 6.646)\tTop5: 15.625 (avg: 20.854)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.293 (avg: 0.300)\tLoss: 4.2167 (avg: 4.5117)\tTop1: 6.250 (avg: 6.547)\tTop5: 21.875 (avg: 20.547)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.303 (avg: 0.300)\tLoss: 4.6482 (avg: 4.5164)\tTop1: 1.562 (avg: 6.800)\tTop5: 17.188 (avg: 20.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5621\tTop 1 accuracy: 5.750\tTop 5 accuracy: 19.000\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.294 (avg: 0.295)\tLoss: 4.6935 (avg: 4.4452)\tTop1: 4.688 (avg: 6.688)\tTop5: 15.625 (avg: 22.375)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.290 (avg: 0.298)\tLoss: 4.4360 (avg: 4.5081)\tTop1: 3.125 (avg: 6.000)\tTop5: 21.875 (avg: 21.375)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.293 (avg: 0.298)\tLoss: 4.3580 (avg: 4.5080)\tTop1: 6.250 (avg: 6.146)\tTop5: 21.875 (avg: 21.312)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.294 (avg: 0.299)\tLoss: 4.3636 (avg: 4.4990)\tTop1: 12.500 (avg: 6.266)\tTop5: 25.000 (avg: 21.500)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 4.5812 (avg: 4.4956)\tTop1: 1.562 (avg: 6.400)\tTop5: 14.062 (avg: 21.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6133\tTop 1 accuracy: 6.400\tTop 5 accuracy: 19.650\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.294 (avg: 0.294)\tLoss: 4.6260 (avg: 4.4268)\tTop1: 3.125 (avg: 6.875)\tTop5: 14.062 (avg: 23.250)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.291 (avg: 0.298)\tLoss: 4.3947 (avg: 4.4046)\tTop1: 9.375 (avg: 7.719)\tTop5: 21.875 (avg: 23.219)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.295 (avg: 0.299)\tLoss: 4.4353 (avg: 4.4362)\tTop1: 6.250 (avg: 7.625)\tTop5: 20.312 (avg: 22.792)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.292 (avg: 0.299)\tLoss: 4.3878 (avg: 4.4287)\tTop1: 6.250 (avg: 7.594)\tTop5: 20.312 (avg: 23.297)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 4.3045 (avg: 4.4316)\tTop1: 6.250 (avg: 7.463)\tTop5: 23.438 (avg: 23.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7786\tTop 1 accuracy: 6.000\tTop 5 accuracy: 20.100\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.294 (avg: 0.294)\tLoss: 4.1926 (avg: 4.2290)\tTop1: 4.688 (avg: 9.750)\tTop5: 23.438 (avg: 27.312)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.293 (avg: 0.297)\tLoss: 4.1207 (avg: 4.2217)\tTop1: 12.500 (avg: 10.031)\tTop5: 31.250 (avg: 27.906)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.295 (avg: 0.299)\tLoss: 3.9387 (avg: 4.2106)\tTop1: 14.062 (avg: 10.250)\tTop5: 37.500 (avg: 28.167)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.303 (avg: 0.300)\tLoss: 4.1815 (avg: 4.1900)\tTop1: 6.250 (avg: 10.500)\tTop5: 25.000 (avg: 28.750)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.293 (avg: 0.300)\tLoss: 3.9202 (avg: 4.1834)\tTop1: 12.500 (avg: 10.475)\tTop5: 39.062 (avg: 29.063)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3568\tTop 1 accuracy: 8.350\tTop 5 accuracy: 24.500\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.301 (avg: 0.294)\tLoss: 3.8723 (avg: 4.0968)\tTop1: 21.875 (avg: 13.125)\tTop5: 43.750 (avg: 33.375)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.294 (avg: 0.298)\tLoss: 4.0462 (avg: 4.0837)\tTop1: 10.938 (avg: 13.000)\tTop5: 23.438 (avg: 32.156)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.298 (avg: 0.298)\tLoss: 4.3581 (avg: 4.0984)\tTop1: 6.250 (avg: 12.500)\tTop5: 26.562 (avg: 31.646)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 4.3992 (avg: 4.1060)\tTop1: 9.375 (avg: 12.438)\tTop5: 26.562 (avg: 31.547)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.303 (avg: 0.299)\tLoss: 4.0594 (avg: 4.1003)\tTop1: 12.500 (avg: 12.313)\tTop5: 29.688 (avg: 31.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3803\tTop 1 accuracy: 8.450\tTop 5 accuracy: 24.950\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.294 (avg: 0.296)\tLoss: 3.7122 (avg: 4.1018)\tTop1: 18.750 (avg: 12.625)\tTop5: 42.188 (avg: 32.000)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.302 (avg: 0.300)\tLoss: 4.2988 (avg: 4.0801)\tTop1: 10.938 (avg: 12.344)\tTop5: 20.312 (avg: 31.938)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.292 (avg: 0.301)\tLoss: 4.0267 (avg: 4.0960)\tTop1: 10.938 (avg: 12.125)\tTop5: 31.250 (avg: 31.583)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.295 (avg: 0.301)\tLoss: 4.0204 (avg: 4.0873)\tTop1: 12.500 (avg: 12.125)\tTop5: 34.375 (avg: 31.562)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.304 (avg: 0.301)\tLoss: 4.5183 (avg: 4.0749)\tTop1: 7.812 (avg: 12.375)\tTop5: 21.875 (avg: 32.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1751\tTop 1 accuracy: 8.800\tTop 5 accuracy: 25.400\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.296 (avg: 0.295)\tLoss: 4.2073 (avg: 4.0395)\tTop1: 9.375 (avg: 13.062)\tTop5: 34.375 (avg: 33.125)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.298 (avg: 0.298)\tLoss: 4.1842 (avg: 4.0391)\tTop1: 10.938 (avg: 12.250)\tTop5: 39.062 (avg: 33.531)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.300 (avg: 0.299)\tLoss: 4.0307 (avg: 4.0333)\tTop1: 10.938 (avg: 12.583)\tTop5: 28.125 (avg: 33.438)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.292 (avg: 0.300)\tLoss: 4.1643 (avg: 4.0483)\tTop1: 9.375 (avg: 12.375)\tTop5: 26.562 (avg: 32.531)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.291 (avg: 0.300)\tLoss: 3.7546 (avg: 4.0565)\tTop1: 12.500 (avg: 12.313)\tTop5: 35.938 (avg: 32.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2716\tTop 1 accuracy: 8.900\tTop 5 accuracy: 26.250\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.295 (avg: 0.295)\tLoss: 3.9631 (avg: 3.9758)\tTop1: 14.062 (avg: 13.188)\tTop5: 37.500 (avg: 35.188)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.298 (avg: 0.299)\tLoss: 4.1258 (avg: 4.0220)\tTop1: 15.625 (avg: 12.719)\tTop5: 31.250 (avg: 33.906)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.303 (avg: 0.299)\tLoss: 4.1195 (avg: 4.0211)\tTop1: 7.812 (avg: 12.896)\tTop5: 28.125 (avg: 33.917)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.287 (avg: 0.300)\tLoss: 3.7794 (avg: 4.0215)\tTop1: 10.938 (avg: 12.953)\tTop5: 37.500 (avg: 34.141)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.292 (avg: 0.300)\tLoss: 4.0551 (avg: 4.0336)\tTop1: 12.500 (avg: 12.638)\tTop5: 31.250 (avg: 33.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2522\tTop 1 accuracy: 9.200\tTop 5 accuracy: 25.650\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.294 (avg: 0.294)\tLoss: 3.7323 (avg: 3.9615)\tTop1: 15.625 (avg: 14.000)\tTop5: 42.188 (avg: 33.688)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.294 (avg: 0.298)\tLoss: 3.9547 (avg: 4.0058)\tTop1: 10.938 (avg: 13.156)\tTop5: 31.250 (avg: 33.562)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.293 (avg: 0.299)\tLoss: 4.0156 (avg: 4.0185)\tTop1: 12.500 (avg: 13.000)\tTop5: 29.688 (avg: 33.458)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.299 (avg: 0.300)\tLoss: 3.9626 (avg: 4.0218)\tTop1: 12.500 (avg: 12.953)\tTop5: 29.688 (avg: 33.516)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.295 (avg: 0.300)\tLoss: 4.0389 (avg: 4.0198)\tTop1: 12.500 (avg: 12.938)\tTop5: 31.250 (avg: 33.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2500\tTop 1 accuracy: 9.400\tTop 5 accuracy: 26.300\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.301 (avg: 0.293)\tLoss: 4.0615 (avg: 4.0004)\tTop1: 9.375 (avg: 13.312)\tTop5: 34.375 (avg: 34.562)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.288 (avg: 0.297)\tLoss: 4.2415 (avg: 4.0038)\tTop1: 10.938 (avg: 13.656)\tTop5: 26.562 (avg: 34.781)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.293 (avg: 0.298)\tLoss: 4.3294 (avg: 4.0119)\tTop1: 6.250 (avg: 13.208)\tTop5: 29.688 (avg: 34.354)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.296 (avg: 0.299)\tLoss: 4.0717 (avg: 3.9993)\tTop1: 14.062 (avg: 13.469)\tTop5: 31.250 (avg: 34.594)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.303 (avg: 0.299)\tLoss: 4.1297 (avg: 4.0010)\tTop1: 6.250 (avg: 13.225)\tTop5: 23.438 (avg: 34.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0593\tTop 1 accuracy: 9.500\tTop 5 accuracy: 26.100\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.295 (avg: 0.293)\tLoss: 4.1536 (avg: 3.9611)\tTop1: 10.938 (avg: 13.188)\tTop5: 25.000 (avg: 33.938)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.297 (avg: 0.297)\tLoss: 4.1142 (avg: 3.9529)\tTop1: 14.062 (avg: 13.875)\tTop5: 34.375 (avg: 34.812)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.294 (avg: 0.298)\tLoss: 4.1780 (avg: 3.9575)\tTop1: 10.938 (avg: 13.812)\tTop5: 31.250 (avg: 34.667)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.294 (avg: 0.299)\tLoss: 4.1755 (avg: 3.9761)\tTop1: 18.750 (avg: 13.328)\tTop5: 29.688 (avg: 34.297)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.299 (avg: 0.300)\tLoss: 3.9297 (avg: 3.9854)\tTop1: 17.188 (avg: 13.188)\tTop5: 45.312 (avg: 33.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3318\tTop 1 accuracy: 9.150\tTop 5 accuracy: 26.250\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.292 (avg: 0.295)\tLoss: 4.1791 (avg: 3.9221)\tTop1: 15.625 (avg: 14.250)\tTop5: 29.688 (avg: 37.062)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.291 (avg: 0.298)\tLoss: 3.8521 (avg: 3.9473)\tTop1: 7.812 (avg: 13.531)\tTop5: 32.812 (avg: 35.625)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.302 (avg: 0.299)\tLoss: 3.5764 (avg: 3.9776)\tTop1: 23.438 (avg: 13.396)\tTop5: 46.875 (avg: 34.625)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.289 (avg: 0.300)\tLoss: 4.0116 (avg: 3.9715)\tTop1: 10.938 (avg: 13.391)\tTop5: 40.625 (avg: 34.984)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.295 (avg: 0.300)\tLoss: 4.1835 (avg: 3.9720)\tTop1: 7.812 (avg: 13.363)\tTop5: 26.562 (avg: 34.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3299\tTop 1 accuracy: 9.000\tTop 5 accuracy: 24.950\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.295 (avg: 0.295)\tLoss: 3.6411 (avg: 3.9554)\tTop1: 17.188 (avg: 13.688)\tTop5: 45.312 (avg: 34.875)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.294 (avg: 0.298)\tLoss: 3.8947 (avg: 3.9576)\tTop1: 12.500 (avg: 13.781)\tTop5: 34.375 (avg: 34.250)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.298 (avg: 0.299)\tLoss: 3.8455 (avg: 3.9519)\tTop1: 15.625 (avg: 14.083)\tTop5: 37.500 (avg: 35.104)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.291 (avg: 0.300)\tLoss: 4.0362 (avg: 3.9580)\tTop1: 9.375 (avg: 13.969)\tTop5: 29.688 (avg: 34.906)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.295 (avg: 0.300)\tLoss: 3.9945 (avg: 3.9544)\tTop1: 12.500 (avg: 14.163)\tTop5: 34.375 (avg: 34.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3073\tTop 1 accuracy: 9.500\tTop 5 accuracy: 26.000\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.291 (avg: 0.297)\tLoss: 4.0765 (avg: 3.9361)\tTop1: 17.188 (avg: 14.062)\tTop5: 29.688 (avg: 34.938)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.292 (avg: 0.299)\tLoss: 3.8728 (avg: 3.9386)\tTop1: 14.062 (avg: 14.344)\tTop5: 37.500 (avg: 35.438)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.290 (avg: 0.300)\tLoss: 3.9317 (avg: 3.9429)\tTop1: 10.938 (avg: 14.062)\tTop5: 35.938 (avg: 35.000)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.295 (avg: 0.300)\tLoss: 3.6722 (avg: 3.9339)\tTop1: 12.500 (avg: 14.359)\tTop5: 35.938 (avg: 35.281)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.295 (avg: 0.300)\tLoss: 4.1449 (avg: 3.9435)\tTop1: 7.812 (avg: 14.313)\tTop5: 29.688 (avg: 35.325)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2566\tTop 1 accuracy: 10.600\tTop 5 accuracy: 27.650\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.294 (avg: 0.295)\tLoss: 3.8779 (avg: 3.8833)\tTop1: 23.438 (avg: 14.625)\tTop5: 40.625 (avg: 37.188)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.293 (avg: 0.298)\tLoss: 4.0951 (avg: 3.9213)\tTop1: 17.188 (avg: 14.031)\tTop5: 43.750 (avg: 36.344)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.296 (avg: 0.299)\tLoss: 3.4734 (avg: 3.9294)\tTop1: 23.438 (avg: 13.979)\tTop5: 42.188 (avg: 35.792)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.300 (avg: 0.300)\tLoss: 3.9303 (avg: 3.9245)\tTop1: 20.312 (avg: 14.250)\tTop5: 32.812 (avg: 35.562)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.291 (avg: 0.300)\tLoss: 4.0534 (avg: 3.9222)\tTop1: 10.938 (avg: 14.263)\tTop5: 35.938 (avg: 35.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2954\tTop 1 accuracy: 9.850\tTop 5 accuracy: 27.400\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.297 (avg: 0.293)\tLoss: 4.0679 (avg: 3.8499)\tTop1: 6.250 (avg: 16.000)\tTop5: 35.938 (avg: 38.625)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.293 (avg: 0.296)\tLoss: 4.1385 (avg: 3.8807)\tTop1: 17.188 (avg: 15.688)\tTop5: 34.375 (avg: 37.312)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.293 (avg: 0.297)\tLoss: 3.6308 (avg: 3.8872)\tTop1: 26.562 (avg: 15.771)\tTop5: 46.875 (avg: 37.083)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.288 (avg: 0.298)\tLoss: 4.1576 (avg: 3.9007)\tTop1: 6.250 (avg: 15.156)\tTop5: 20.312 (avg: 36.359)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.299 (avg: 0.298)\tLoss: 3.8029 (avg: 3.9060)\tTop1: 20.312 (avg: 15.125)\tTop5: 43.750 (avg: 36.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2652\tTop 1 accuracy: 10.100\tTop 5 accuracy: 27.100\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.298 (avg: 0.294)\tLoss: 3.4151 (avg: 3.8489)\tTop1: 21.875 (avg: 15.000)\tTop5: 45.312 (avg: 37.062)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.295 (avg: 0.297)\tLoss: 3.6799 (avg: 3.8559)\tTop1: 12.500 (avg: 15.188)\tTop5: 40.625 (avg: 37.281)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.290 (avg: 0.298)\tLoss: 3.6286 (avg: 3.8618)\tTop1: 14.062 (avg: 14.958)\tTop5: 39.062 (avg: 37.042)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.293 (avg: 0.299)\tLoss: 4.1142 (avg: 3.8754)\tTop1: 12.500 (avg: 14.672)\tTop5: 31.250 (avg: 36.797)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.300 (avg: 0.300)\tLoss: 3.9126 (avg: 3.8929)\tTop1: 17.188 (avg: 14.388)\tTop5: 35.938 (avg: 36.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1169\tTop 1 accuracy: 10.250\tTop 5 accuracy: 28.200\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.294 (avg: 0.294)\tLoss: 3.7550 (avg: 3.8650)\tTop1: 21.875 (avg: 15.250)\tTop5: 45.312 (avg: 36.938)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.290 (avg: 0.297)\tLoss: 4.2805 (avg: 3.8473)\tTop1: 9.375 (avg: 15.438)\tTop5: 31.250 (avg: 37.312)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.303 (avg: 0.299)\tLoss: 3.8728 (avg: 3.8548)\tTop1: 20.312 (avg: 15.333)\tTop5: 32.812 (avg: 36.958)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.296 (avg: 0.299)\tLoss: 3.7919 (avg: 3.8741)\tTop1: 15.625 (avg: 15.109)\tTop5: 39.062 (avg: 36.484)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.293 (avg: 0.300)\tLoss: 4.1820 (avg: 3.8777)\tTop1: 9.375 (avg: 15.050)\tTop5: 31.250 (avg: 36.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0534\tTop 1 accuracy: 11.200\tTop 5 accuracy: 27.900\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.292 (avg: 0.294)\tLoss: 3.7304 (avg: 3.8486)\tTop1: 20.312 (avg: 14.500)\tTop5: 43.750 (avg: 36.500)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.291 (avg: 0.298)\tLoss: 3.8380 (avg: 3.8450)\tTop1: 17.188 (avg: 15.469)\tTop5: 39.062 (avg: 37.406)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.301 (avg: 0.299)\tLoss: 3.5952 (avg: 3.8596)\tTop1: 20.312 (avg: 15.000)\tTop5: 37.500 (avg: 37.125)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.293 (avg: 0.301)\tLoss: 3.8770 (avg: 3.8648)\tTop1: 15.625 (avg: 15.219)\tTop5: 32.812 (avg: 37.312)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.290 (avg: 0.301)\tLoss: 3.9242 (avg: 3.8627)\tTop1: 10.938 (avg: 15.388)\tTop5: 32.812 (avg: 37.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1359\tTop 1 accuracy: 10.500\tTop 5 accuracy: 28.350\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.294 (avg: 0.294)\tLoss: 3.4505 (avg: 3.8723)\tTop1: 21.875 (avg: 15.000)\tTop5: 48.438 (avg: 36.250)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.295 (avg: 0.298)\tLoss: 3.7922 (avg: 3.8488)\tTop1: 12.500 (avg: 15.719)\tTop5: 31.250 (avg: 36.406)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.294 (avg: 0.299)\tLoss: 3.7720 (avg: 3.8318)\tTop1: 17.188 (avg: 16.125)\tTop5: 42.188 (avg: 37.188)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.303 (avg: 0.300)\tLoss: 4.2332 (avg: 3.8385)\tTop1: 15.625 (avg: 16.078)\tTop5: 29.688 (avg: 37.172)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.292 (avg: 0.300)\tLoss: 3.8415 (avg: 3.8481)\tTop1: 9.375 (avg: 15.638)\tTop5: 35.938 (avg: 37.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1733\tTop 1 accuracy: 10.500\tTop 5 accuracy: 27.500\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.305 (avg: 0.296)\tLoss: 3.8276 (avg: 3.8151)\tTop1: 23.438 (avg: 15.312)\tTop5: 40.625 (avg: 37.438)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.296 (avg: 0.299)\tLoss: 4.0238 (avg: 3.8198)\tTop1: 12.500 (avg: 15.344)\tTop5: 31.250 (avg: 37.906)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.294 (avg: 0.300)\tLoss: 3.7619 (avg: 3.8138)\tTop1: 10.938 (avg: 15.750)\tTop5: 34.375 (avg: 38.104)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.299 (avg: 0.301)\tLoss: 4.2007 (avg: 3.8197)\tTop1: 10.938 (avg: 15.516)\tTop5: 31.250 (avg: 38.172)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.297 (avg: 0.301)\tLoss: 3.8344 (avg: 3.8200)\tTop1: 12.500 (avg: 15.625)\tTop5: 32.812 (avg: 38.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2516\tTop 1 accuracy: 10.950\tTop 5 accuracy: 27.950\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.303 (avg: 0.295)\tLoss: 3.8928 (avg: 3.7091)\tTop1: 10.938 (avg: 17.562)\tTop5: 32.812 (avg: 40.000)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.290 (avg: 0.298)\tLoss: 3.8834 (avg: 3.7708)\tTop1: 17.188 (avg: 16.281)\tTop5: 29.688 (avg: 38.688)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.288 (avg: 0.298)\tLoss: 3.4643 (avg: 3.7799)\tTop1: 20.312 (avg: 15.958)\tTop5: 46.875 (avg: 38.812)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.297 (avg: 0.299)\tLoss: 3.9294 (avg: 3.7923)\tTop1: 18.750 (avg: 15.797)\tTop5: 31.250 (avg: 38.578)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.303 (avg: 0.299)\tLoss: 4.0959 (avg: 3.8060)\tTop1: 12.500 (avg: 15.875)\tTop5: 28.125 (avg: 38.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1968\tTop 1 accuracy: 10.850\tTop 5 accuracy: 28.650\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.290 (avg: 0.294)\tLoss: 3.9966 (avg: 3.7928)\tTop1: 15.625 (avg: 16.625)\tTop5: 29.688 (avg: 37.625)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.301 (avg: 0.298)\tLoss: 3.8042 (avg: 3.7897)\tTop1: 9.375 (avg: 16.375)\tTop5: 40.625 (avg: 38.062)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.302 (avg: 0.299)\tLoss: 4.0777 (avg: 3.7966)\tTop1: 12.500 (avg: 16.479)\tTop5: 25.000 (avg: 38.042)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 3.9565 (avg: 3.7924)\tTop1: 15.625 (avg: 16.734)\tTop5: 37.500 (avg: 38.594)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.290 (avg: 0.300)\tLoss: 3.7352 (avg: 3.7887)\tTop1: 14.062 (avg: 16.638)\tTop5: 35.938 (avg: 38.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2259\tTop 1 accuracy: 11.700\tTop 5 accuracy: 28.550\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.292 (avg: 0.295)\tLoss: 3.6633 (avg: 3.7989)\tTop1: 18.750 (avg: 15.562)\tTop5: 40.625 (avg: 38.375)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.300 (avg: 0.298)\tLoss: 3.7143 (avg: 3.7740)\tTop1: 21.875 (avg: 16.125)\tTop5: 37.500 (avg: 39.219)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.302 (avg: 0.299)\tLoss: 3.8358 (avg: 3.7727)\tTop1: 14.062 (avg: 16.458)\tTop5: 34.375 (avg: 39.438)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.288 (avg: 0.300)\tLoss: 3.9451 (avg: 3.7810)\tTop1: 15.625 (avg: 16.172)\tTop5: 37.500 (avg: 39.047)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.290 (avg: 0.300)\tLoss: 3.7033 (avg: 3.7782)\tTop1: 14.062 (avg: 16.150)\tTop5: 40.625 (avg: 39.062)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2043\tTop 1 accuracy: 10.800\tTop 5 accuracy: 28.200\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.298 (avg: 0.295)\tLoss: 3.6824 (avg: 3.7685)\tTop1: 17.188 (avg: 16.375)\tTop5: 42.188 (avg: 37.875)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.294 (avg: 0.299)\tLoss: 3.1994 (avg: 3.7646)\tTop1: 28.125 (avg: 16.531)\tTop5: 57.812 (avg: 39.000)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.298 (avg: 0.301)\tLoss: 3.5391 (avg: 3.7627)\tTop1: 20.312 (avg: 16.312)\tTop5: 37.500 (avg: 38.875)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.290 (avg: 0.301)\tLoss: 3.9632 (avg: 3.7683)\tTop1: 12.500 (avg: 16.469)\tTop5: 29.688 (avg: 39.000)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.297 (avg: 0.301)\tLoss: 3.6913 (avg: 3.7544)\tTop1: 15.625 (avg: 16.688)\tTop5: 37.500 (avg: 39.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9711\tTop 1 accuracy: 11.800\tTop 5 accuracy: 28.800\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.298 (avg: 0.295)\tLoss: 3.9664 (avg: 3.7745)\tTop1: 14.062 (avg: 16.188)\tTop5: 37.500 (avg: 39.062)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 3.5982 (avg: 3.7671)\tTop1: 21.875 (avg: 15.969)\tTop5: 39.062 (avg: 39.125)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.298 (avg: 0.301)\tLoss: 4.2559 (avg: 3.7601)\tTop1: 4.688 (avg: 16.271)\tTop5: 28.125 (avg: 39.083)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.299 (avg: 0.301)\tLoss: 3.4209 (avg: 3.7413)\tTop1: 18.750 (avg: 16.438)\tTop5: 43.750 (avg: 39.703)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.296 (avg: 0.302)\tLoss: 3.5818 (avg: 3.7353)\tTop1: 18.750 (avg: 16.713)\tTop5: 42.188 (avg: 39.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3914\tTop 1 accuracy: 11.000\tTop 5 accuracy: 29.400\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.294 (avg: 0.295)\tLoss: 3.6512 (avg: 3.6630)\tTop1: 18.750 (avg: 17.375)\tTop5: 40.625 (avg: 41.000)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.293 (avg: 0.300)\tLoss: 3.7704 (avg: 3.7200)\tTop1: 12.500 (avg: 16.281)\tTop5: 35.938 (avg: 40.750)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.305 (avg: 0.301)\tLoss: 3.9258 (avg: 3.7326)\tTop1: 17.188 (avg: 16.438)\tTop5: 34.375 (avg: 40.375)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.293 (avg: 0.301)\tLoss: 3.5093 (avg: 3.7385)\tTop1: 15.625 (avg: 16.516)\tTop5: 42.188 (avg: 40.047)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.292 (avg: 0.301)\tLoss: 3.8939 (avg: 3.7372)\tTop1: 18.750 (avg: 16.725)\tTop5: 42.188 (avg: 40.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1346\tTop 1 accuracy: 11.350\tTop 5 accuracy: 29.100\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.298 (avg: 0.296)\tLoss: 3.8440 (avg: 3.6643)\tTop1: 9.375 (avg: 17.625)\tTop5: 34.375 (avg: 40.188)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.297 (avg: 0.299)\tLoss: 3.7351 (avg: 3.6552)\tTop1: 17.188 (avg: 17.875)\tTop5: 35.938 (avg: 41.438)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.293 (avg: 0.299)\tLoss: 3.4314 (avg: 3.6771)\tTop1: 17.188 (avg: 17.625)\tTop5: 37.500 (avg: 40.958)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.285 (avg: 0.299)\tLoss: 3.8210 (avg: 3.6891)\tTop1: 15.625 (avg: 17.391)\tTop5: 40.625 (avg: 41.078)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.294 (avg: 0.300)\tLoss: 3.6305 (avg: 3.7077)\tTop1: 18.750 (avg: 17.025)\tTop5: 39.062 (avg: 40.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1264\tTop 1 accuracy: 12.050\tTop 5 accuracy: 29.500\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.305 (avg: 0.296)\tLoss: 3.7113 (avg: 3.6288)\tTop1: 17.188 (avg: 19.562)\tTop5: 35.938 (avg: 42.000)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.295 (avg: 0.299)\tLoss: 3.7898 (avg: 3.6544)\tTop1: 18.750 (avg: 19.031)\tTop5: 42.188 (avg: 42.094)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.291 (avg: 0.300)\tLoss: 3.6288 (avg: 3.6646)\tTop1: 21.875 (avg: 18.458)\tTop5: 35.938 (avg: 41.667)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.300 (avg: 0.300)\tLoss: 3.7961 (avg: 3.6960)\tTop1: 14.062 (avg: 17.766)\tTop5: 42.188 (avg: 40.703)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.294 (avg: 0.300)\tLoss: 3.7456 (avg: 3.6952)\tTop1: 15.625 (avg: 17.562)\tTop5: 34.375 (avg: 40.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0808\tTop 1 accuracy: 10.700\tTop 5 accuracy: 29.450\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.293 (avg: 0.294)\tLoss: 3.8299 (avg: 3.7336)\tTop1: 21.875 (avg: 17.938)\tTop5: 37.500 (avg: 39.688)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.289 (avg: 0.297)\tLoss: 3.8074 (avg: 3.6555)\tTop1: 17.188 (avg: 18.312)\tTop5: 35.938 (avg: 41.438)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.290 (avg: 0.299)\tLoss: 3.6177 (avg: 3.6707)\tTop1: 18.750 (avg: 18.042)\tTop5: 39.062 (avg: 41.292)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.293 (avg: 0.299)\tLoss: 3.5225 (avg: 3.6693)\tTop1: 21.875 (avg: 17.781)\tTop5: 46.875 (avg: 41.453)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.300 (avg: 0.300)\tLoss: 3.5291 (avg: 3.6748)\tTop1: 15.625 (avg: 17.650)\tTop5: 42.188 (avg: 40.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2433\tTop 1 accuracy: 11.050\tTop 5 accuracy: 28.950\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.290 (avg: 0.295)\tLoss: 3.5432 (avg: 3.6079)\tTop1: 26.562 (avg: 17.812)\tTop5: 42.188 (avg: 43.875)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.294 (avg: 0.298)\tLoss: 3.7209 (avg: 3.6329)\tTop1: 20.312 (avg: 18.000)\tTop5: 37.500 (avg: 42.688)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.300 (avg: 0.299)\tLoss: 3.6565 (avg: 3.6275)\tTop1: 21.875 (avg: 18.500)\tTop5: 45.312 (avg: 42.729)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 3.5181 (avg: 3.6335)\tTop1: 25.000 (avg: 18.656)\tTop5: 48.438 (avg: 42.641)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.291 (avg: 0.300)\tLoss: 3.4758 (avg: 3.6518)\tTop1: 29.688 (avg: 18.450)\tTop5: 57.812 (avg: 42.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4331\tTop 1 accuracy: 12.000\tTop 5 accuracy: 30.800\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.294 (avg: 0.294)\tLoss: 4.1104 (avg: 3.5575)\tTop1: 17.188 (avg: 19.562)\tTop5: 34.375 (avg: 43.438)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.296 (avg: 0.297)\tLoss: 3.8102 (avg: 3.6168)\tTop1: 15.625 (avg: 18.500)\tTop5: 31.250 (avg: 42.062)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.309 (avg: 0.298)\tLoss: 3.4323 (avg: 3.6224)\tTop1: 21.875 (avg: 17.854)\tTop5: 53.125 (avg: 42.458)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.292 (avg: 0.299)\tLoss: 3.3711 (avg: 3.6340)\tTop1: 23.438 (avg: 17.922)\tTop5: 48.438 (avg: 42.312)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 3.3031 (avg: 3.6401)\tTop1: 21.875 (avg: 18.138)\tTop5: 51.562 (avg: 42.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2528\tTop 1 accuracy: 11.650\tTop 5 accuracy: 29.500\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.295 (avg: 0.297)\tLoss: 3.7233 (avg: 3.6232)\tTop1: 12.500 (avg: 17.000)\tTop5: 37.500 (avg: 41.438)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 3.5342 (avg: 3.6214)\tTop1: 18.750 (avg: 17.250)\tTop5: 46.875 (avg: 41.844)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.293 (avg: 0.299)\tLoss: 3.5717 (avg: 3.6319)\tTop1: 20.312 (avg: 17.417)\tTop5: 46.875 (avg: 42.188)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.296 (avg: 0.300)\tLoss: 3.6528 (avg: 3.6224)\tTop1: 20.312 (avg: 17.969)\tTop5: 37.500 (avg: 42.484)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.301 (avg: 0.300)\tLoss: 3.6969 (avg: 3.6305)\tTop1: 18.750 (avg: 18.088)\tTop5: 37.500 (avg: 42.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0757\tTop 1 accuracy: 11.600\tTop 5 accuracy: 30.050\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.292 (avg: 0.296)\tLoss: 3.1616 (avg: 3.4902)\tTop1: 25.000 (avg: 21.125)\tTop5: 50.000 (avg: 46.625)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.289 (avg: 0.299)\tLoss: 3.3326 (avg: 3.4647)\tTop1: 23.438 (avg: 21.156)\tTop5: 53.125 (avg: 46.906)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.294 (avg: 0.300)\tLoss: 3.5269 (avg: 3.4704)\tTop1: 20.312 (avg: 20.875)\tTop5: 48.438 (avg: 46.500)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.297 (avg: 0.300)\tLoss: 3.3344 (avg: 3.4859)\tTop1: 23.438 (avg: 20.797)\tTop5: 43.750 (avg: 46.016)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.294 (avg: 0.300)\tLoss: 3.4330 (avg: 3.4900)\tTop1: 35.938 (avg: 20.875)\tTop5: 53.125 (avg: 45.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2040\tTop 1 accuracy: 12.700\tTop 5 accuracy: 31.550\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.293 (avg: 0.295)\tLoss: 3.6058 (avg: 3.4838)\tTop1: 15.625 (avg: 21.062)\tTop5: 40.625 (avg: 45.812)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.293 (avg: 0.298)\tLoss: 3.0728 (avg: 3.4619)\tTop1: 29.688 (avg: 22.031)\tTop5: 56.250 (avg: 46.625)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.296 (avg: 0.299)\tLoss: 3.6915 (avg: 3.4697)\tTop1: 15.625 (avg: 21.729)\tTop5: 40.625 (avg: 46.583)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.300 (avg: 0.299)\tLoss: 3.3603 (avg: 3.4591)\tTop1: 29.688 (avg: 22.141)\tTop5: 48.438 (avg: 46.547)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.295 (avg: 0.300)\tLoss: 3.2271 (avg: 3.4506)\tTop1: 28.125 (avg: 22.438)\tTop5: 53.125 (avg: 46.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2345\tTop 1 accuracy: 13.150\tTop 5 accuracy: 31.900\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.297 (avg: 0.293)\tLoss: 3.6083 (avg: 3.4595)\tTop1: 18.750 (avg: 21.688)\tTop5: 40.625 (avg: 46.312)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.291 (avg: 0.297)\tLoss: 3.6275 (avg: 3.4560)\tTop1: 20.312 (avg: 21.656)\tTop5: 42.188 (avg: 46.562)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.297 (avg: 0.298)\tLoss: 3.2694 (avg: 3.4200)\tTop1: 25.000 (avg: 22.542)\tTop5: 54.688 (avg: 47.854)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.292 (avg: 0.299)\tLoss: 3.6464 (avg: 3.4378)\tTop1: 12.500 (avg: 22.062)\tTop5: 39.062 (avg: 47.172)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.305 (avg: 0.299)\tLoss: 3.2467 (avg: 3.4433)\tTop1: 21.875 (avg: 22.075)\tTop5: 50.000 (avg: 47.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1545\tTop 1 accuracy: 12.950\tTop 5 accuracy: 31.750\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.298 (avg: 0.296)\tLoss: 3.3910 (avg: 3.3799)\tTop1: 31.250 (avg: 22.938)\tTop5: 50.000 (avg: 49.125)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.300 (avg: 0.298)\tLoss: 3.3068 (avg: 3.3996)\tTop1: 15.625 (avg: 22.969)\tTop5: 48.438 (avg: 48.562)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.289 (avg: 0.299)\tLoss: 3.3713 (avg: 3.4147)\tTop1: 25.000 (avg: 22.417)\tTop5: 45.312 (avg: 48.208)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.291 (avg: 0.300)\tLoss: 3.3765 (avg: 3.4449)\tTop1: 26.562 (avg: 21.797)\tTop5: 46.875 (avg: 47.422)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.304 (avg: 0.300)\tLoss: 3.5343 (avg: 3.4339)\tTop1: 18.750 (avg: 21.938)\tTop5: 43.750 (avg: 47.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1396\tTop 1 accuracy: 12.650\tTop 5 accuracy: 30.800\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.292 (avg: 0.294)\tLoss: 3.3446 (avg: 3.3953)\tTop1: 26.562 (avg: 23.375)\tTop5: 50.000 (avg: 48.062)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.289 (avg: 0.297)\tLoss: 3.8299 (avg: 3.4360)\tTop1: 10.938 (avg: 22.625)\tTop5: 35.938 (avg: 47.406)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.301 (avg: 0.299)\tLoss: 3.2944 (avg: 3.4165)\tTop1: 28.125 (avg: 22.562)\tTop5: 56.250 (avg: 47.667)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.296 (avg: 0.299)\tLoss: 3.0816 (avg: 3.4341)\tTop1: 34.375 (avg: 22.359)\tTop5: 56.250 (avg: 46.766)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.293 (avg: 0.300)\tLoss: 3.3556 (avg: 3.4295)\tTop1: 31.250 (avg: 22.475)\tTop5: 50.000 (avg: 47.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1494\tTop 1 accuracy: 13.800\tTop 5 accuracy: 31.700\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.289 (avg: 0.294)\tLoss: 3.4265 (avg: 3.4199)\tTop1: 25.000 (avg: 21.938)\tTop5: 34.375 (avg: 46.625)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.291 (avg: 0.298)\tLoss: 3.2564 (avg: 3.4103)\tTop1: 17.188 (avg: 22.562)\tTop5: 56.250 (avg: 47.750)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.303 (avg: 0.299)\tLoss: 3.0624 (avg: 3.4010)\tTop1: 29.688 (avg: 22.958)\tTop5: 48.438 (avg: 47.917)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.297 (avg: 0.300)\tLoss: 3.8711 (avg: 3.4179)\tTop1: 17.188 (avg: 22.578)\tTop5: 34.375 (avg: 47.297)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.294 (avg: 0.301)\tLoss: 3.7219 (avg: 3.4273)\tTop1: 15.625 (avg: 22.338)\tTop5: 43.750 (avg: 47.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1805\tTop 1 accuracy: 13.000\tTop 5 accuracy: 31.500\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.294 (avg: 0.294)\tLoss: 3.8082 (avg: 3.3929)\tTop1: 14.062 (avg: 22.938)\tTop5: 39.062 (avg: 46.375)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.301 (avg: 0.297)\tLoss: 3.4176 (avg: 3.4142)\tTop1: 25.000 (avg: 22.094)\tTop5: 51.562 (avg: 46.969)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.294 (avg: 0.299)\tLoss: 3.4078 (avg: 3.4187)\tTop1: 23.438 (avg: 22.125)\tTop5: 51.562 (avg: 47.354)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.299 (avg: 0.300)\tLoss: 3.5016 (avg: 3.4237)\tTop1: 15.625 (avg: 21.984)\tTop5: 43.750 (avg: 47.703)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.293 (avg: 0.300)\tLoss: 3.7738 (avg: 3.4238)\tTop1: 20.312 (avg: 22.113)\tTop5: 40.625 (avg: 47.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2332\tTop 1 accuracy: 13.300\tTop 5 accuracy: 31.550\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.303 (avg: 0.294)\tLoss: 3.5159 (avg: 3.4624)\tTop1: 17.188 (avg: 22.688)\tTop5: 51.562 (avg: 47.562)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.291 (avg: 0.298)\tLoss: 3.6411 (avg: 3.4517)\tTop1: 14.062 (avg: 22.562)\tTop5: 43.750 (avg: 47.312)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.293 (avg: 0.299)\tLoss: 4.0006 (avg: 3.4387)\tTop1: 14.062 (avg: 22.417)\tTop5: 34.375 (avg: 47.125)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.292 (avg: 0.300)\tLoss: 3.1794 (avg: 3.4415)\tTop1: 15.625 (avg: 21.766)\tTop5: 53.125 (avg: 46.812)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.296 (avg: 0.300)\tLoss: 3.4665 (avg: 3.4223)\tTop1: 23.438 (avg: 22.038)\tTop5: 48.438 (avg: 47.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1872\tTop 1 accuracy: 12.950\tTop 5 accuracy: 31.450\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.294 (avg: 0.295)\tLoss: 3.2886 (avg: 3.4064)\tTop1: 26.562 (avg: 20.625)\tTop5: 43.750 (avg: 46.875)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.291 (avg: 0.298)\tLoss: 3.3716 (avg: 3.4016)\tTop1: 17.188 (avg: 21.844)\tTop5: 50.000 (avg: 47.375)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.293 (avg: 0.299)\tLoss: 3.3181 (avg: 3.4118)\tTop1: 25.000 (avg: 21.938)\tTop5: 50.000 (avg: 47.062)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.294 (avg: 0.300)\tLoss: 3.4322 (avg: 3.4143)\tTop1: 21.875 (avg: 21.672)\tTop5: 39.062 (avg: 47.188)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.302 (avg: 0.300)\tLoss: 3.0612 (avg: 3.4131)\tTop1: 32.812 (avg: 22.100)\tTop5: 54.688 (avg: 47.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1193\tTop 1 accuracy: 13.250\tTop 5 accuracy: 32.150\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.295 (avg: 0.295)\tLoss: 3.0535 (avg: 3.3609)\tTop1: 29.688 (avg: 24.000)\tTop5: 57.812 (avg: 49.000)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.301 (avg: 0.299)\tLoss: 3.4002 (avg: 3.3827)\tTop1: 25.000 (avg: 23.688)\tTop5: 42.188 (avg: 48.562)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.295 (avg: 0.300)\tLoss: 3.3384 (avg: 3.4094)\tTop1: 26.562 (avg: 22.938)\tTop5: 50.000 (avg: 47.542)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.293 (avg: 0.300)\tLoss: 3.4895 (avg: 3.4155)\tTop1: 23.438 (avg: 22.844)\tTop5: 42.188 (avg: 47.375)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.291 (avg: 0.300)\tLoss: 3.0998 (avg: 3.4144)\tTop1: 26.562 (avg: 22.700)\tTop5: 56.250 (avg: 47.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0910\tTop 1 accuracy: 13.400\tTop 5 accuracy: 31.550\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.294 (avg: 0.294)\tLoss: 3.4361 (avg: 3.4172)\tTop1: 23.438 (avg: 22.812)\tTop5: 54.688 (avg: 48.250)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.292 (avg: 0.297)\tLoss: 3.3000 (avg: 3.3772)\tTop1: 25.000 (avg: 22.875)\tTop5: 51.562 (avg: 48.750)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.302 (avg: 0.298)\tLoss: 3.0628 (avg: 3.3980)\tTop1: 31.250 (avg: 22.646)\tTop5: 53.125 (avg: 48.125)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 3.5057 (avg: 3.4019)\tTop1: 20.312 (avg: 22.719)\tTop5: 50.000 (avg: 48.016)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.290 (avg: 0.299)\tLoss: 3.3236 (avg: 3.4124)\tTop1: 18.750 (avg: 22.525)\tTop5: 51.562 (avg: 47.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1194\tTop 1 accuracy: 13.450\tTop 5 accuracy: 31.800\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.293 (avg: 0.295)\tLoss: 4.0451 (avg: 3.4131)\tTop1: 18.750 (avg: 23.062)\tTop5: 39.062 (avg: 48.562)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.291 (avg: 0.298)\tLoss: 3.7349 (avg: 3.4079)\tTop1: 12.500 (avg: 22.156)\tTop5: 45.312 (avg: 47.938)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 3.6310 (avg: 3.4256)\tTop1: 17.188 (avg: 22.354)\tTop5: 34.375 (avg: 47.562)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.298 (avg: 0.299)\tLoss: 3.3567 (avg: 3.3950)\tTop1: 21.875 (avg: 22.750)\tTop5: 48.438 (avg: 47.891)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.295 (avg: 0.299)\tLoss: 3.4547 (avg: 3.4021)\tTop1: 23.438 (avg: 22.763)\tTop5: 45.312 (avg: 47.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2354\tTop 1 accuracy: 13.300\tTop 5 accuracy: 31.550\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.304 (avg: 0.295)\tLoss: 3.6726 (avg: 3.4047)\tTop1: 12.500 (avg: 22.562)\tTop5: 39.062 (avg: 47.812)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 3.6630 (avg: 3.4262)\tTop1: 28.125 (avg: 21.906)\tTop5: 48.438 (avg: 47.094)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.302 (avg: 0.300)\tLoss: 3.4978 (avg: 3.4285)\tTop1: 29.688 (avg: 22.229)\tTop5: 48.438 (avg: 47.188)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.294 (avg: 0.301)\tLoss: 3.2890 (avg: 3.4170)\tTop1: 20.312 (avg: 22.422)\tTop5: 50.000 (avg: 47.500)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.297 (avg: 0.301)\tLoss: 3.5929 (avg: 3.4051)\tTop1: 23.438 (avg: 22.575)\tTop5: 42.188 (avg: 47.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1678\tTop 1 accuracy: 13.450\tTop 5 accuracy: 31.700\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.296 (avg: 0.297)\tLoss: 3.0323 (avg: 3.4141)\tTop1: 26.562 (avg: 21.562)\tTop5: 56.250 (avg: 48.812)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.296 (avg: 0.299)\tLoss: 3.4646 (avg: 3.4043)\tTop1: 17.188 (avg: 21.969)\tTop5: 43.750 (avg: 48.188)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.297 (avg: 0.300)\tLoss: 3.6933 (avg: 3.4086)\tTop1: 21.875 (avg: 21.833)\tTop5: 39.062 (avg: 47.875)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.294 (avg: 0.301)\tLoss: 3.3817 (avg: 3.3942)\tTop1: 23.438 (avg: 22.547)\tTop5: 53.125 (avg: 48.344)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.299 (avg: 0.301)\tLoss: 3.4308 (avg: 3.3972)\tTop1: 23.438 (avg: 22.363)\tTop5: 40.625 (avg: 48.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2601\tTop 1 accuracy: 13.550\tTop 5 accuracy: 31.600\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.291 (avg: 0.294)\tLoss: 3.3763 (avg: 3.3813)\tTop1: 26.562 (avg: 23.125)\tTop5: 53.125 (avg: 49.188)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.303 (avg: 0.298)\tLoss: 3.4239 (avg: 3.3974)\tTop1: 21.875 (avg: 22.719)\tTop5: 39.062 (avg: 48.000)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.292 (avg: 0.299)\tLoss: 3.0750 (avg: 3.4030)\tTop1: 29.688 (avg: 22.938)\tTop5: 60.938 (avg: 48.333)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.289 (avg: 0.299)\tLoss: 3.4156 (avg: 3.4084)\tTop1: 25.000 (avg: 22.594)\tTop5: 56.250 (avg: 47.984)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.293 (avg: 0.300)\tLoss: 3.0765 (avg: 3.3893)\tTop1: 28.125 (avg: 22.975)\tTop5: 60.938 (avg: 48.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1313\tTop 1 accuracy: 12.750\tTop 5 accuracy: 31.700\n",
            "\n",
            "incr_e = 64: top1 = 13.250000953674316 \t top5 = 32.150001525878906 \t batch time = 0.2708441764116287\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.361 (avg: 0.359)\tLoss: 5.2968 (avg: 5.3115)\tTop1: 0.000 (avg: 0.500)\tTop5: 1.562 (avg: 2.562)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.361 (avg: 0.364)\tLoss: 5.3002 (avg: 5.3053)\tTop1: 0.000 (avg: 0.344)\tTop5: 1.562 (avg: 2.375)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.361 (avg: 0.365)\tLoss: 5.2989 (avg: 5.3032)\tTop1: 0.000 (avg: 0.333)\tTop5: 1.562 (avg: 2.146)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.362 (avg: 0.366)\tLoss: 5.2989 (avg: 5.3022)\tTop1: 0.000 (avg: 0.359)\tTop5: 4.688 (avg: 2.141)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.361 (avg: 0.366)\tLoss: 5.2977 (avg: 5.3015)\tTop1: 1.562 (avg: 0.338)\tTop5: 3.125 (avg: 2.062)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3002\tTop 1 accuracy: 0.400\tTop 5 accuracy: 2.750\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.357 (avg: 0.355)\tLoss: 5.2962 (avg: 5.2981)\tTop1: 0.000 (avg: 0.500)\tTop5: 3.125 (avg: 2.500)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.357 (avg: 0.359)\tLoss: 5.2954 (avg: 5.2977)\tTop1: 1.562 (avg: 0.500)\tTop5: 3.125 (avg: 2.750)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 5.2891 (avg: 5.2971)\tTop1: 0.000 (avg: 0.542)\tTop5: 3.125 (avg: 2.854)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 5.2869 (avg: 5.2938)\tTop1: 0.000 (avg: 0.578)\tTop5: 1.562 (avg: 2.781)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 5.2430 (avg: 5.2930)\tTop1: 1.562 (avg: 0.588)\tTop5: 3.125 (avg: 2.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3039\tTop 1 accuracy: 0.500\tTop 5 accuracy: 2.800\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.354 (avg: 0.352)\tLoss: 5.2913 (avg: 5.2838)\tTop1: 1.562 (avg: 0.750)\tTop5: 3.125 (avg: 2.750)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.353 (avg: 0.356)\tLoss: 5.2544 (avg: 5.2741)\tTop1: 4.688 (avg: 0.875)\tTop5: 9.375 (avg: 3.344)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.355 (avg: 0.358)\tLoss: 5.2858 (avg: 5.2722)\tTop1: 0.000 (avg: 0.833)\tTop5: 0.000 (avg: 3.271)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.360 (avg: 0.359)\tLoss: 5.1757 (avg: 5.2662)\tTop1: 1.562 (avg: 0.938)\tTop5: 6.250 (avg: 3.656)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.354 (avg: 0.359)\tLoss: 5.2560 (avg: 5.2661)\tTop1: 1.562 (avg: 0.988)\tTop5: 4.688 (avg: 3.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2623\tTop 1 accuracy: 0.800\tTop 5 accuracy: 4.950\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.354 (avg: 0.353)\tLoss: 5.2848 (avg: 5.2718)\tTop1: 0.000 (avg: 0.938)\tTop5: 1.562 (avg: 3.812)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 5.2744 (avg: 5.2557)\tTop1: 1.562 (avg: 0.750)\tTop5: 9.375 (avg: 4.406)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.352 (avg: 0.358)\tLoss: 5.2078 (avg: 5.2509)\tTop1: 3.125 (avg: 0.917)\tTop5: 7.812 (avg: 4.583)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 5.2417 (avg: 5.2544)\tTop1: 1.562 (avg: 0.891)\tTop5: 4.688 (avg: 4.375)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 5.2608 (avg: 5.2533)\tTop1: 0.000 (avg: 1.038)\tTop5: 4.688 (avg: 4.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2544\tTop 1 accuracy: 1.300\tTop 5 accuracy: 5.250\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.356 (avg: 0.355)\tLoss: 5.1670 (avg: 5.2418)\tTop1: 3.125 (avg: 1.562)\tTop5: 10.938 (avg: 5.500)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 5.2562 (avg: 5.2425)\tTop1: 0.000 (avg: 1.094)\tTop5: 1.562 (avg: 5.031)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 5.2486 (avg: 5.2370)\tTop1: 4.688 (avg: 1.396)\tTop5: 9.375 (avg: 5.688)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 5.2992 (avg: 5.2378)\tTop1: 1.562 (avg: 1.297)\tTop5: 6.250 (avg: 5.297)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 5.2540 (avg: 5.2438)\tTop1: 0.000 (avg: 1.288)\tTop5: 4.688 (avg: 5.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2241\tTop 1 accuracy: 1.200\tTop 5 accuracy: 4.400\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.355 (avg: 0.354)\tLoss: 5.3320 (avg: 5.2354)\tTop1: 1.562 (avg: 1.000)\tTop5: 3.125 (avg: 6.062)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.355 (avg: 0.358)\tLoss: 5.2168 (avg: 5.2438)\tTop1: 1.562 (avg: 0.906)\tTop5: 6.250 (avg: 5.250)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.354 (avg: 0.359)\tLoss: 5.1702 (avg: 5.2416)\tTop1: 6.250 (avg: 1.188)\tTop5: 14.062 (avg: 5.354)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 5.2691 (avg: 5.2356)\tTop1: 0.000 (avg: 1.422)\tTop5: 1.562 (avg: 5.672)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 5.0881 (avg: 5.2317)\tTop1: 1.562 (avg: 1.350)\tTop5: 9.375 (avg: 5.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1807\tTop 1 accuracy: 1.150\tTop 5 accuracy: 5.450\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.355 (avg: 0.355)\tLoss: 5.2125 (avg: 5.2126)\tTop1: 0.000 (avg: 1.250)\tTop5: 12.500 (avg: 6.688)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 5.2193 (avg: 5.2175)\tTop1: 1.562 (avg: 1.469)\tTop5: 9.375 (avg: 6.688)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 5.1182 (avg: 5.2196)\tTop1: 4.688 (avg: 1.438)\tTop5: 7.812 (avg: 6.354)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 5.2688 (avg: 5.2195)\tTop1: 0.000 (avg: 1.406)\tTop5: 3.125 (avg: 6.250)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 5.4075 (avg: 5.2144)\tTop1: 0.000 (avg: 1.425)\tTop5: 0.000 (avg: 6.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3721\tTop 1 accuracy: 0.950\tTop 5 accuracy: 5.750\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.354 (avg: 0.353)\tLoss: 5.1949 (avg: 5.2093)\tTop1: 0.000 (avg: 1.062)\tTop5: 3.125 (avg: 5.562)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.355 (avg: 0.357)\tLoss: 5.1387 (avg: 5.1963)\tTop1: 0.000 (avg: 1.344)\tTop5: 9.375 (avg: 6.500)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.351 (avg: 0.358)\tLoss: 5.2451 (avg: 5.1989)\tTop1: 0.000 (avg: 1.458)\tTop5: 7.812 (avg: 6.625)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.357 (avg: 0.359)\tLoss: 5.0385 (avg: 5.1963)\tTop1: 0.000 (avg: 1.469)\tTop5: 9.375 (avg: 6.844)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 5.2100 (avg: 5.1955)\tTop1: 4.688 (avg: 1.488)\tTop5: 4.688 (avg: 6.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1513\tTop 1 accuracy: 0.950\tTop 5 accuracy: 5.850\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.362 (avg: 0.360)\tLoss: 5.2472 (avg: 5.1872)\tTop1: 1.562 (avg: 1.562)\tTop5: 7.812 (avg: 6.750)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.360 (avg: 0.364)\tLoss: 5.1321 (avg: 5.1887)\tTop1: 1.562 (avg: 1.562)\tTop5: 9.375 (avg: 6.906)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.361 (avg: 0.365)\tLoss: 5.1518 (avg: 5.1942)\tTop1: 3.125 (avg: 1.292)\tTop5: 6.250 (avg: 6.625)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.362 (avg: 0.366)\tLoss: 5.1566 (avg: 5.1931)\tTop1: 1.562 (avg: 1.359)\tTop5: 9.375 (avg: 6.562)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.360 (avg: 0.366)\tLoss: 5.1589 (avg: 5.1896)\tTop1: 3.125 (avg: 1.500)\tTop5: 4.688 (avg: 6.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2406\tTop 1 accuracy: 1.100\tTop 5 accuracy: 5.700\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.355 (avg: 0.353)\tLoss: 5.1937 (avg: 5.1508)\tTop1: 0.000 (avg: 1.688)\tTop5: 4.688 (avg: 7.375)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.357 (avg: 0.358)\tLoss: 5.0894 (avg: 5.1598)\tTop1: 3.125 (avg: 1.781)\tTop5: 6.250 (avg: 7.062)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 5.1713 (avg: 5.1577)\tTop1: 0.000 (avg: 1.750)\tTop5: 6.250 (avg: 7.396)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 5.1167 (avg: 5.1615)\tTop1: 3.125 (avg: 1.719)\tTop5: 12.500 (avg: 7.438)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 5.2674 (avg: 5.1655)\tTop1: 0.000 (avg: 1.738)\tTop5: 3.125 (avg: 7.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1911\tTop 1 accuracy: 1.550\tTop 5 accuracy: 6.450\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.355 (avg: 0.352)\tLoss: 5.2235 (avg: 5.1312)\tTop1: 3.125 (avg: 1.812)\tTop5: 4.688 (avg: 9.188)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.354 (avg: 0.356)\tLoss: 5.2077 (avg: 5.1532)\tTop1: 0.000 (avg: 1.844)\tTop5: 3.125 (avg: 8.375)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.353 (avg: 0.358)\tLoss: 5.1428 (avg: 5.1680)\tTop1: 4.688 (avg: 1.875)\tTop5: 9.375 (avg: 8.375)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.361 (avg: 0.359)\tLoss: 5.1532 (avg: 5.1633)\tTop1: 4.688 (avg: 1.812)\tTop5: 4.688 (avg: 8.078)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.351 (avg: 0.359)\tLoss: 5.0924 (avg: 5.1609)\tTop1: 0.000 (avg: 1.775)\tTop5: 9.375 (avg: 7.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0266\tTop 1 accuracy: 2.000\tTop 5 accuracy: 6.950\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.354 (avg: 0.353)\tLoss: 5.2334 (avg: 5.1172)\tTop1: 1.562 (avg: 2.125)\tTop5: 4.688 (avg: 7.562)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.354 (avg: 0.357)\tLoss: 5.1831 (avg: 5.1154)\tTop1: 0.000 (avg: 2.188)\tTop5: 3.125 (avg: 8.406)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.362 (avg: 0.359)\tLoss: 5.1163 (avg: 5.1272)\tTop1: 1.562 (avg: 1.938)\tTop5: 10.938 (avg: 8.000)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 5.0470 (avg: 5.1341)\tTop1: 3.125 (avg: 1.953)\tTop5: 9.375 (avg: 8.062)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 5.1718 (avg: 5.1350)\tTop1: 3.125 (avg: 1.900)\tTop5: 10.938 (avg: 8.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1314\tTop 1 accuracy: 1.700\tTop 5 accuracy: 7.750\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.356 (avg: 0.355)\tLoss: 5.1042 (avg: 5.1356)\tTop1: 1.562 (avg: 1.625)\tTop5: 9.375 (avg: 7.750)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 5.1228 (avg: 5.1447)\tTop1: 7.812 (avg: 1.562)\tTop5: 10.938 (avg: 7.219)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 5.1532 (avg: 5.1332)\tTop1: 1.562 (avg: 1.771)\tTop5: 7.812 (avg: 7.438)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 5.0697 (avg: 5.1332)\tTop1: 3.125 (avg: 1.828)\tTop5: 7.812 (avg: 7.859)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.361 (avg: 0.362)\tLoss: 5.1416 (avg: 5.1298)\tTop1: 1.562 (avg: 1.913)\tTop5: 9.375 (avg: 8.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1225\tTop 1 accuracy: 2.000\tTop 5 accuracy: 7.900\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.355 (avg: 0.354)\tLoss: 4.9914 (avg: 5.1035)\tTop1: 1.562 (avg: 1.938)\tTop5: 14.062 (avg: 9.375)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.360 (avg: 0.359)\tLoss: 5.2005 (avg: 5.1189)\tTop1: 4.688 (avg: 2.031)\tTop5: 9.375 (avg: 8.875)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 5.2539 (avg: 5.1140)\tTop1: 1.562 (avg: 2.208)\tTop5: 3.125 (avg: 8.708)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 5.2313 (avg: 5.1195)\tTop1: 1.562 (avg: 2.344)\tTop5: 7.812 (avg: 9.047)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 4.9853 (avg: 5.1126)\tTop1: 3.125 (avg: 2.388)\tTop5: 14.062 (avg: 9.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1115\tTop 1 accuracy: 3.300\tTop 5 accuracy: 9.400\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.356 (avg: 0.355)\tLoss: 5.0450 (avg: 5.0773)\tTop1: 4.688 (avg: 2.062)\tTop5: 12.500 (avg: 9.188)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 5.1601 (avg: 5.0958)\tTop1: 0.000 (avg: 2.125)\tTop5: 4.688 (avg: 8.688)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 5.0451 (avg: 5.0978)\tTop1: 4.688 (avg: 2.021)\tTop5: 12.500 (avg: 8.958)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 5.0462 (avg: 5.0979)\tTop1: 1.562 (avg: 2.156)\tTop5: 6.250 (avg: 9.094)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 5.1253 (avg: 5.0999)\tTop1: 1.562 (avg: 2.175)\tTop5: 9.375 (avg: 9.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1705\tTop 1 accuracy: 1.850\tTop 5 accuracy: 7.200\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.355 (avg: 0.352)\tLoss: 5.1506 (avg: 5.1213)\tTop1: 3.125 (avg: 1.875)\tTop5: 9.375 (avg: 8.375)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.361 (avg: 0.357)\tLoss: 5.0638 (avg: 5.0988)\tTop1: 1.562 (avg: 2.031)\tTop5: 10.938 (avg: 9.375)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.356 (avg: 0.358)\tLoss: 5.0374 (avg: 5.0966)\tTop1: 3.125 (avg: 2.042)\tTop5: 7.812 (avg: 9.021)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 5.1828 (avg: 5.0983)\tTop1: 1.562 (avg: 2.172)\tTop5: 7.812 (avg: 9.000)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 5.1450 (avg: 5.0939)\tTop1: 1.562 (avg: 2.175)\tTop5: 4.688 (avg: 8.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0156\tTop 1 accuracy: 3.050\tTop 5 accuracy: 9.550\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.360 (avg: 0.358)\tLoss: 5.0775 (avg: 5.0650)\tTop1: 0.000 (avg: 2.375)\tTop5: 9.375 (avg: 8.688)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.367 (avg: 0.363)\tLoss: 5.0443 (avg: 5.0581)\tTop1: 6.250 (avg: 2.656)\tTop5: 15.625 (avg: 9.625)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.360 (avg: 0.364)\tLoss: 5.1296 (avg: 5.0710)\tTop1: 1.562 (avg: 2.375)\tTop5: 6.250 (avg: 9.521)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.360 (avg: 0.365)\tLoss: 5.1669 (avg: 5.0677)\tTop1: 3.125 (avg: 2.375)\tTop5: 10.938 (avg: 9.609)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.361 (avg: 0.366)\tLoss: 5.1386 (avg: 5.0688)\tTop1: 3.125 (avg: 2.425)\tTop5: 15.625 (avg: 9.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7794\tTop 1 accuracy: 2.800\tTop 5 accuracy: 8.850\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.355 (avg: 0.355)\tLoss: 5.0208 (avg: 5.0207)\tTop1: 0.000 (avg: 2.812)\tTop5: 10.938 (avg: 10.750)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.357 (avg: 0.359)\tLoss: 5.0877 (avg: 5.0346)\tTop1: 3.125 (avg: 2.906)\tTop5: 7.812 (avg: 10.281)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 4.8882 (avg: 5.0402)\tTop1: 1.562 (avg: 2.625)\tTop5: 10.938 (avg: 9.771)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 5.0090 (avg: 5.0485)\tTop1: 1.562 (avg: 2.469)\tTop5: 9.375 (avg: 9.688)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 5.0608 (avg: 5.0572)\tTop1: 1.562 (avg: 2.425)\tTop5: 10.938 (avg: 9.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0475\tTop 1 accuracy: 3.050\tTop 5 accuracy: 9.600\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.355 (avg: 0.353)\tLoss: 5.0403 (avg: 5.0164)\tTop1: 0.000 (avg: 2.875)\tTop5: 10.938 (avg: 11.938)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.356 (avg: 0.357)\tLoss: 5.0426 (avg: 5.0197)\tTop1: 0.000 (avg: 2.844)\tTop5: 6.250 (avg: 10.656)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.360 (avg: 0.359)\tLoss: 5.0511 (avg: 5.0276)\tTop1: 3.125 (avg: 2.812)\tTop5: 9.375 (avg: 10.542)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.354 (avg: 0.359)\tLoss: 4.9547 (avg: 5.0251)\tTop1: 3.125 (avg: 2.844)\tTop5: 10.938 (avg: 10.547)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 4.9741 (avg: 5.0322)\tTop1: 4.688 (avg: 2.800)\tTop5: 10.938 (avg: 10.325)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7609\tTop 1 accuracy: 3.150\tTop 5 accuracy: 10.500\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.355 (avg: 0.353)\tLoss: 4.9304 (avg: 5.0265)\tTop1: 1.562 (avg: 3.000)\tTop5: 9.375 (avg: 9.500)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.362 (avg: 0.358)\tLoss: 5.0793 (avg: 5.0093)\tTop1: 0.000 (avg: 2.812)\tTop5: 7.812 (avg: 10.438)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 4.9853 (avg: 5.0236)\tTop1: 0.000 (avg: 2.500)\tTop5: 14.062 (avg: 10.312)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.358 (avg: 0.360)\tLoss: 4.9014 (avg: 5.0196)\tTop1: 1.562 (avg: 2.594)\tTop5: 17.188 (avg: 10.625)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 5.0864 (avg: 5.0189)\tTop1: 0.000 (avg: 2.588)\tTop5: 9.375 (avg: 10.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9689\tTop 1 accuracy: 2.250\tTop 5 accuracy: 8.750\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.358 (avg: 0.356)\tLoss: 4.9088 (avg: 4.9496)\tTop1: 4.688 (avg: 3.188)\tTop5: 15.625 (avg: 11.250)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 4.9464 (avg: 4.9569)\tTop1: 0.000 (avg: 3.125)\tTop5: 6.250 (avg: 11.500)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 4.9576 (avg: 4.9864)\tTop1: 6.250 (avg: 2.812)\tTop5: 9.375 (avg: 11.396)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 5.0466 (avg: 4.9990)\tTop1: 0.000 (avg: 2.594)\tTop5: 12.500 (avg: 10.984)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 4.8704 (avg: 5.0093)\tTop1: 6.250 (avg: 2.513)\tTop5: 17.188 (avg: 10.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8890\tTop 1 accuracy: 3.100\tTop 5 accuracy: 10.050\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.355 (avg: 0.354)\tLoss: 4.9387 (avg: 4.9081)\tTop1: 1.562 (avg: 3.625)\tTop5: 10.938 (avg: 12.250)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.357 (avg: 0.358)\tLoss: 5.0395 (avg: 4.9738)\tTop1: 0.000 (avg: 2.969)\tTop5: 6.250 (avg: 10.844)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 4.8999 (avg: 4.9840)\tTop1: 0.000 (avg: 2.875)\tTop5: 10.938 (avg: 11.000)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.350 (avg: 0.360)\tLoss: 4.8060 (avg: 4.9756)\tTop1: 6.250 (avg: 3.094)\tTop5: 15.625 (avg: 11.469)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 4.8448 (avg: 4.9822)\tTop1: 3.125 (avg: 2.963)\tTop5: 17.188 (avg: 11.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8035\tTop 1 accuracy: 2.600\tTop 5 accuracy: 9.750\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.355 (avg: 0.354)\tLoss: 4.9792 (avg: 4.9492)\tTop1: 3.125 (avg: 2.812)\tTop5: 14.062 (avg: 12.188)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.356 (avg: 0.358)\tLoss: 4.9577 (avg: 4.9358)\tTop1: 4.688 (avg: 3.219)\tTop5: 14.062 (avg: 12.281)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 4.7527 (avg: 4.9396)\tTop1: 4.688 (avg: 2.938)\tTop5: 18.750 (avg: 12.042)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 4.8039 (avg: 4.9460)\tTop1: 10.938 (avg: 3.016)\tTop5: 23.438 (avg: 11.672)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.361 (avg: 0.361)\tLoss: 5.1120 (avg: 4.9381)\tTop1: 1.562 (avg: 3.025)\tTop5: 4.688 (avg: 11.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7769\tTop 1 accuracy: 3.050\tTop 5 accuracy: 11.100\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.355 (avg: 0.353)\tLoss: 4.8331 (avg: 4.8922)\tTop1: 1.562 (avg: 3.562)\tTop5: 10.938 (avg: 12.875)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.355 (avg: 0.357)\tLoss: 4.7532 (avg: 4.8893)\tTop1: 4.688 (avg: 3.250)\tTop5: 10.938 (avg: 12.438)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.349 (avg: 0.358)\tLoss: 4.9193 (avg: 4.8731)\tTop1: 6.250 (avg: 3.542)\tTop5: 12.500 (avg: 13.042)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.353 (avg: 0.359)\tLoss: 4.8400 (avg: 4.8846)\tTop1: 4.688 (avg: 3.422)\tTop5: 12.500 (avg: 12.781)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 4.8955 (avg: 4.8904)\tTop1: 3.125 (avg: 3.438)\tTop5: 10.938 (avg: 12.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8080\tTop 1 accuracy: 3.550\tTop 5 accuracy: 12.100\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.362 (avg: 0.360)\tLoss: 4.8242 (avg: 4.8383)\tTop1: 4.688 (avg: 4.438)\tTop5: 10.938 (avg: 15.375)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.360 (avg: 0.364)\tLoss: 4.7735 (avg: 4.8562)\tTop1: 4.688 (avg: 3.969)\tTop5: 15.625 (avg: 13.875)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.362 (avg: 0.366)\tLoss: 4.7643 (avg: 4.8454)\tTop1: 4.688 (avg: 3.958)\tTop5: 9.375 (avg: 14.271)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 4.7460 (avg: 4.8442)\tTop1: 9.375 (avg: 3.984)\tTop5: 17.188 (avg: 14.266)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.361 (avg: 0.367)\tLoss: 4.9021 (avg: 4.8438)\tTop1: 6.250 (avg: 3.963)\tTop5: 14.062 (avg: 14.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5790\tTop 1 accuracy: 2.950\tTop 5 accuracy: 11.750\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.351 (avg: 0.355)\tLoss: 4.6477 (avg: 4.7560)\tTop1: 1.562 (avg: 4.312)\tTop5: 18.750 (avg: 16.000)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.358 (avg: 0.360)\tLoss: 4.8637 (avg: 4.7548)\tTop1: 4.688 (avg: 4.281)\tTop5: 10.938 (avg: 15.688)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 4.7029 (avg: 4.7814)\tTop1: 9.375 (avg: 4.104)\tTop5: 17.188 (avg: 15.188)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 4.6175 (avg: 4.7836)\tTop1: 4.688 (avg: 4.062)\tTop5: 21.875 (avg: 15.188)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 4.8588 (avg: 4.7822)\tTop1: 4.688 (avg: 4.175)\tTop5: 14.062 (avg: 15.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7252\tTop 1 accuracy: 4.350\tTop 5 accuracy: 14.600\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.354 (avg: 0.352)\tLoss: 4.6343 (avg: 4.7063)\tTop1: 3.125 (avg: 5.062)\tTop5: 20.312 (avg: 17.188)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.353 (avg: 0.357)\tLoss: 4.9083 (avg: 4.7441)\tTop1: 3.125 (avg: 4.344)\tTop5: 15.625 (avg: 16.000)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.355 (avg: 0.358)\tLoss: 4.5234 (avg: 4.7446)\tTop1: 9.375 (avg: 4.417)\tTop5: 23.438 (avg: 15.583)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 5.1309 (avg: 4.7391)\tTop1: 0.000 (avg: 4.344)\tTop5: 14.062 (avg: 16.078)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 4.6070 (avg: 4.7580)\tTop1: 1.562 (avg: 4.038)\tTop5: 20.312 (avg: 15.563)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7659\tTop 1 accuracy: 3.650\tTop 5 accuracy: 13.300\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.355 (avg: 0.353)\tLoss: 4.5683 (avg: 4.6776)\tTop1: 1.562 (avg: 4.750)\tTop5: 17.188 (avg: 17.625)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.354 (avg: 0.358)\tLoss: 4.8270 (avg: 4.6931)\tTop1: 4.688 (avg: 4.250)\tTop5: 10.938 (avg: 16.938)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 4.7706 (avg: 4.6959)\tTop1: 4.688 (avg: 4.438)\tTop5: 18.750 (avg: 16.375)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 4.8344 (avg: 4.7070)\tTop1: 1.562 (avg: 4.328)\tTop5: 7.812 (avg: 16.031)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 4.9437 (avg: 4.6987)\tTop1: 6.250 (avg: 4.538)\tTop5: 15.625 (avg: 16.325)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6531\tTop 1 accuracy: 5.100\tTop 5 accuracy: 15.450\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.357 (avg: 0.355)\tLoss: 4.7325 (avg: 4.6302)\tTop1: 6.250 (avg: 4.938)\tTop5: 18.750 (avg: 17.938)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.367 (avg: 0.360)\tLoss: 4.6373 (avg: 4.6359)\tTop1: 4.688 (avg: 4.875)\tTop5: 14.062 (avg: 17.656)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.8802 (avg: 4.6584)\tTop1: 3.125 (avg: 4.458)\tTop5: 10.938 (avg: 17.208)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 4.5230 (avg: 4.6424)\tTop1: 6.250 (avg: 4.750)\tTop5: 12.500 (avg: 17.422)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 4.6180 (avg: 4.6361)\tTop1: 4.688 (avg: 4.825)\tTop5: 14.062 (avg: 17.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8328\tTop 1 accuracy: 4.550\tTop 5 accuracy: 15.300\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.356 (avg: 0.354)\tLoss: 4.8130 (avg: 4.6104)\tTop1: 1.562 (avg: 5.438)\tTop5: 14.062 (avg: 17.812)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.357 (avg: 0.358)\tLoss: 4.6683 (avg: 4.5605)\tTop1: 4.688 (avg: 5.719)\tTop5: 12.500 (avg: 19.438)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 4.7206 (avg: 4.5907)\tTop1: 1.562 (avg: 5.292)\tTop5: 15.625 (avg: 18.896)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.3857 (avg: 4.5899)\tTop1: 10.938 (avg: 5.359)\tTop5: 29.688 (avg: 18.625)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.6194 (avg: 4.5856)\tTop1: 3.125 (avg: 5.425)\tTop5: 15.625 (avg: 18.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6263\tTop 1 accuracy: 4.850\tTop 5 accuracy: 17.050\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.353 (avg: 0.354)\tLoss: 4.3616 (avg: 4.4986)\tTop1: 6.250 (avg: 6.312)\tTop5: 20.312 (avg: 21.500)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.360 (avg: 0.358)\tLoss: 4.2252 (avg: 4.4373)\tTop1: 7.812 (avg: 7.375)\tTop5: 29.688 (avg: 23.312)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 4.2551 (avg: 4.4194)\tTop1: 15.625 (avg: 7.417)\tTop5: 32.812 (avg: 23.562)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 4.4804 (avg: 4.4058)\tTop1: 1.562 (avg: 7.578)\tTop5: 28.125 (avg: 23.656)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.351 (avg: 0.361)\tLoss: 4.4054 (avg: 4.3869)\tTop1: 7.812 (avg: 7.688)\tTop5: 17.188 (avg: 24.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3733\tTop 1 accuracy: 6.900\tTop 5 accuracy: 22.150\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.356 (avg: 0.354)\tLoss: 4.4064 (avg: 4.3073)\tTop1: 1.562 (avg: 9.000)\tTop5: 25.000 (avg: 26.938)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.361 (avg: 0.358)\tLoss: 4.4829 (avg: 4.3168)\tTop1: 4.688 (avg: 8.969)\tTop5: 20.312 (avg: 26.375)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.354 (avg: 0.359)\tLoss: 4.3820 (avg: 4.3146)\tTop1: 14.062 (avg: 9.125)\tTop5: 29.688 (avg: 26.250)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 4.2093 (avg: 4.3010)\tTop1: 9.375 (avg: 9.188)\tTop5: 21.875 (avg: 26.266)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 4.0819 (avg: 4.3003)\tTop1: 12.500 (avg: 8.838)\tTop5: 35.938 (avg: 26.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3088\tTop 1 accuracy: 7.250\tTop 5 accuracy: 22.750\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 4.3636 (avg: 4.2691)\tTop1: 7.812 (avg: 8.062)\tTop5: 28.125 (avg: 27.188)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.362 (avg: 0.365)\tLoss: 4.1128 (avg: 4.2840)\tTop1: 10.938 (avg: 8.469)\tTop5: 35.938 (avg: 27.000)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.361 (avg: 0.366)\tLoss: 4.1567 (avg: 4.2747)\tTop1: 12.500 (avg: 8.917)\tTop5: 31.250 (avg: 27.167)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 4.5245 (avg: 4.2919)\tTop1: 7.812 (avg: 8.812)\tTop5: 25.000 (avg: 26.875)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.364 (avg: 0.367)\tLoss: 4.1777 (avg: 4.2785)\tTop1: 15.625 (avg: 8.975)\tTop5: 29.688 (avg: 26.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1533\tTop 1 accuracy: 7.300\tTop 5 accuracy: 22.550\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.363 (avg: 0.356)\tLoss: 4.3671 (avg: 4.2844)\tTop1: 12.500 (avg: 9.062)\tTop5: 23.438 (avg: 26.500)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.359 (avg: 0.360)\tLoss: 4.1125 (avg: 4.2837)\tTop1: 6.250 (avg: 8.969)\tTop5: 21.875 (avg: 26.219)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 4.4316 (avg: 4.2641)\tTop1: 4.688 (avg: 9.104)\tTop5: 28.125 (avg: 27.229)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 4.3167 (avg: 4.2637)\tTop1: 12.500 (avg: 9.266)\tTop5: 23.438 (avg: 27.453)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 4.1858 (avg: 4.2630)\tTop1: 7.812 (avg: 9.500)\tTop5: 32.812 (avg: 27.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2473\tTop 1 accuracy: 7.650\tTop 5 accuracy: 23.050\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.357 (avg: 0.354)\tLoss: 4.0991 (avg: 4.2812)\tTop1: 10.938 (avg: 8.625)\tTop5: 28.125 (avg: 26.812)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.357 (avg: 0.359)\tLoss: 4.1704 (avg: 4.2370)\tTop1: 14.062 (avg: 9.156)\tTop5: 31.250 (avg: 27.781)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 4.2091 (avg: 4.2395)\tTop1: 10.938 (avg: 9.229)\tTop5: 31.250 (avg: 27.771)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.3074 (avg: 4.2480)\tTop1: 10.938 (avg: 9.453)\tTop5: 28.125 (avg: 27.703)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 3.9355 (avg: 4.2480)\tTop1: 17.188 (avg: 9.400)\tTop5: 37.500 (avg: 27.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3131\tTop 1 accuracy: 7.900\tTop 5 accuracy: 23.450\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.358 (avg: 0.355)\tLoss: 4.2728 (avg: 4.1640)\tTop1: 3.125 (avg: 9.688)\tTop5: 28.125 (avg: 30.375)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 4.2130 (avg: 4.2287)\tTop1: 6.250 (avg: 9.469)\tTop5: 29.688 (avg: 28.781)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.3035 (avg: 4.2326)\tTop1: 15.625 (avg: 9.333)\tTop5: 28.125 (avg: 28.354)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 4.0493 (avg: 4.2300)\tTop1: 10.938 (avg: 9.531)\tTop5: 32.812 (avg: 28.094)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 4.2253 (avg: 4.2212)\tTop1: 10.938 (avg: 9.763)\tTop5: 29.688 (avg: 28.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1241\tTop 1 accuracy: 7.850\tTop 5 accuracy: 23.650\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.361 (avg: 0.358)\tLoss: 4.2310 (avg: 4.1637)\tTop1: 6.250 (avg: 10.312)\tTop5: 31.250 (avg: 30.062)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.359 (avg: 0.363)\tLoss: 3.9422 (avg: 4.1887)\tTop1: 21.875 (avg: 10.156)\tTop5: 42.188 (avg: 29.344)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.362 (avg: 0.365)\tLoss: 4.1823 (avg: 4.2065)\tTop1: 6.250 (avg: 9.583)\tTop5: 31.250 (avg: 28.562)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.361 (avg: 0.366)\tLoss: 4.0302 (avg: 4.2105)\tTop1: 20.312 (avg: 9.953)\tTop5: 32.812 (avg: 28.141)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.361 (avg: 0.367)\tLoss: 4.0508 (avg: 4.2069)\tTop1: 12.500 (avg: 9.900)\tTop5: 29.688 (avg: 28.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1080\tTop 1 accuracy: 7.900\tTop 5 accuracy: 24.000\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.358 (avg: 0.355)\tLoss: 4.3492 (avg: 4.1559)\tTop1: 4.688 (avg: 10.188)\tTop5: 23.438 (avg: 29.812)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.354 (avg: 0.359)\tLoss: 3.9999 (avg: 4.1525)\tTop1: 6.250 (avg: 10.312)\tTop5: 32.812 (avg: 29.906)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 4.1246 (avg: 4.1999)\tTop1: 9.375 (avg: 9.854)\tTop5: 29.688 (avg: 29.062)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.0264 (avg: 4.1890)\tTop1: 15.625 (avg: 10.062)\tTop5: 32.812 (avg: 29.484)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.2682 (avg: 4.1883)\tTop1: 7.812 (avg: 10.150)\tTop5: 21.875 (avg: 29.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3962\tTop 1 accuracy: 8.100\tTop 5 accuracy: 23.500\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.357 (avg: 0.355)\tLoss: 3.9098 (avg: 4.1341)\tTop1: 7.812 (avg: 11.062)\tTop5: 31.250 (avg: 30.688)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 4.4658 (avg: 4.1736)\tTop1: 9.375 (avg: 10.375)\tTop5: 21.875 (avg: 29.781)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 4.1275 (avg: 4.1766)\tTop1: 6.250 (avg: 10.083)\tTop5: 32.812 (avg: 29.583)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 4.0447 (avg: 4.1747)\tTop1: 12.500 (avg: 9.922)\tTop5: 29.688 (avg: 29.438)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 4.0895 (avg: 4.1702)\tTop1: 12.500 (avg: 10.225)\tTop5: 37.500 (avg: 29.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3594\tTop 1 accuracy: 8.450\tTop 5 accuracy: 23.800\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.355 (avg: 0.353)\tLoss: 4.1635 (avg: 4.1191)\tTop1: 10.938 (avg: 10.750)\tTop5: 28.125 (avg: 29.875)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.354 (avg: 0.357)\tLoss: 3.7760 (avg: 4.1043)\tTop1: 20.312 (avg: 11.000)\tTop5: 37.500 (avg: 30.562)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 4.0338 (avg: 4.1467)\tTop1: 7.812 (avg: 11.167)\tTop5: 26.562 (avg: 29.688)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 4.2460 (avg: 4.1562)\tTop1: 6.250 (avg: 11.094)\tTop5: 21.875 (avg: 29.375)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 4.0408 (avg: 4.1616)\tTop1: 9.375 (avg: 10.738)\tTop5: 29.688 (avg: 29.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2517\tTop 1 accuracy: 8.150\tTop 5 accuracy: 24.250\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.363 (avg: 0.360)\tLoss: 4.1909 (avg: 4.1558)\tTop1: 14.062 (avg: 9.875)\tTop5: 32.812 (avg: 29.375)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.363 (avg: 0.364)\tLoss: 3.9045 (avg: 4.1698)\tTop1: 10.938 (avg: 9.906)\tTop5: 35.938 (avg: 29.719)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.362 (avg: 0.366)\tLoss: 4.2504 (avg: 4.1589)\tTop1: 15.625 (avg: 10.021)\tTop5: 31.250 (avg: 30.042)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.361 (avg: 0.367)\tLoss: 4.1303 (avg: 4.1508)\tTop1: 7.812 (avg: 10.328)\tTop5: 29.688 (avg: 30.297)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.360 (avg: 0.367)\tLoss: 3.8810 (avg: 4.1435)\tTop1: 14.062 (avg: 10.463)\tTop5: 35.938 (avg: 30.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0788\tTop 1 accuracy: 7.900\tTop 5 accuracy: 23.750\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.357 (avg: 0.355)\tLoss: 4.3482 (avg: 4.1277)\tTop1: 6.250 (avg: 11.000)\tTop5: 21.875 (avg: 29.938)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 4.3568 (avg: 4.1151)\tTop1: 15.625 (avg: 11.062)\tTop5: 29.688 (avg: 30.125)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 4.0546 (avg: 4.1261)\tTop1: 15.625 (avg: 10.896)\tTop5: 39.062 (avg: 30.167)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 4.4776 (avg: 4.1302)\tTop1: 7.812 (avg: 10.609)\tTop5: 18.750 (avg: 30.531)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 4.3013 (avg: 4.1278)\tTop1: 4.688 (avg: 10.850)\tTop5: 29.688 (avg: 30.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1596\tTop 1 accuracy: 8.300\tTop 5 accuracy: 25.000\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.355 (avg: 0.353)\tLoss: 4.2360 (avg: 4.1148)\tTop1: 10.938 (avg: 11.750)\tTop5: 23.438 (avg: 32.250)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.356 (avg: 0.358)\tLoss: 4.2535 (avg: 4.0869)\tTop1: 14.062 (avg: 11.500)\tTop5: 28.125 (avg: 31.938)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.349 (avg: 0.359)\tLoss: 4.0722 (avg: 4.1037)\tTop1: 14.062 (avg: 11.167)\tTop5: 31.250 (avg: 31.083)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 4.2201 (avg: 4.1141)\tTop1: 9.375 (avg: 11.219)\tTop5: 28.125 (avg: 30.938)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.353 (avg: 0.360)\tLoss: 4.2487 (avg: 4.1226)\tTop1: 7.812 (avg: 11.238)\tTop5: 29.688 (avg: 30.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1513\tTop 1 accuracy: 9.350\tTop 5 accuracy: 25.950\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.354 (avg: 0.354)\tLoss: 4.0175 (avg: 4.0791)\tTop1: 10.938 (avg: 11.250)\tTop5: 34.375 (avg: 32.000)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.355 (avg: 0.358)\tLoss: 4.0412 (avg: 4.1112)\tTop1: 10.938 (avg: 10.500)\tTop5: 29.688 (avg: 30.562)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 4.1159 (avg: 4.1053)\tTop1: 17.188 (avg: 11.146)\tTop5: 32.812 (avg: 31.083)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 4.0049 (avg: 4.1078)\tTop1: 12.500 (avg: 11.188)\tTop5: 34.375 (avg: 31.125)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 4.1741 (avg: 4.1117)\tTop1: 9.375 (avg: 11.163)\tTop5: 29.688 (avg: 30.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9576\tTop 1 accuracy: 9.150\tTop 5 accuracy: 25.300\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.356 (avg: 0.356)\tLoss: 3.8766 (avg: 4.0382)\tTop1: 20.312 (avg: 11.500)\tTop5: 39.062 (avg: 32.250)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 4.0737 (avg: 4.0531)\tTop1: 15.625 (avg: 12.406)\tTop5: 37.500 (avg: 32.125)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.353 (avg: 0.361)\tLoss: 4.3043 (avg: 4.0819)\tTop1: 6.250 (avg: 12.000)\tTop5: 31.250 (avg: 31.625)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.354 (avg: 0.362)\tLoss: 3.9893 (avg: 4.0803)\tTop1: 10.938 (avg: 12.000)\tTop5: 37.500 (avg: 31.641)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.357 (avg: 0.363)\tLoss: 3.9186 (avg: 4.0906)\tTop1: 18.750 (avg: 11.575)\tTop5: 29.688 (avg: 31.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9977\tTop 1 accuracy: 9.350\tTop 5 accuracy: 25.750\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.355 (avg: 0.354)\tLoss: 4.2120 (avg: 4.0893)\tTop1: 12.500 (avg: 11.750)\tTop5: 37.500 (avg: 32.250)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.359 (avg: 0.359)\tLoss: 3.8987 (avg: 4.0705)\tTop1: 7.812 (avg: 11.531)\tTop5: 31.250 (avg: 31.844)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.8763 (avg: 4.0597)\tTop1: 12.500 (avg: 11.917)\tTop5: 37.500 (avg: 32.354)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 4.1185 (avg: 4.0607)\tTop1: 10.938 (avg: 11.906)\tTop5: 28.125 (avg: 32.219)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.354 (avg: 0.361)\tLoss: 3.9939 (avg: 4.0769)\tTop1: 12.500 (avg: 11.613)\tTop5: 28.125 (avg: 31.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7651\tTop 1 accuracy: 9.650\tTop 5 accuracy: 26.050\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.358 (avg: 0.357)\tLoss: 3.8800 (avg: 4.0725)\tTop1: 14.062 (avg: 12.438)\tTop5: 35.938 (avg: 31.875)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.360 (avg: 0.361)\tLoss: 3.9154 (avg: 4.0417)\tTop1: 21.875 (avg: 12.750)\tTop5: 37.500 (avg: 32.812)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 4.2362 (avg: 4.0580)\tTop1: 14.062 (avg: 12.562)\tTop5: 28.125 (avg: 32.146)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 4.3134 (avg: 4.0668)\tTop1: 10.938 (avg: 12.406)\tTop5: 31.250 (avg: 32.062)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.361 (avg: 0.364)\tLoss: 3.7224 (avg: 4.0621)\tTop1: 14.062 (avg: 12.338)\tTop5: 40.625 (avg: 32.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1875\tTop 1 accuracy: 8.400\tTop 5 accuracy: 25.450\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.355 (avg: 0.355)\tLoss: 4.0980 (avg: 4.0361)\tTop1: 3.125 (avg: 12.562)\tTop5: 25.000 (avg: 33.250)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.359 (avg: 0.359)\tLoss: 4.1480 (avg: 4.0534)\tTop1: 17.188 (avg: 12.188)\tTop5: 32.812 (avg: 32.906)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 3.7099 (avg: 4.0412)\tTop1: 14.062 (avg: 12.438)\tTop5: 37.500 (avg: 32.562)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 4.1040 (avg: 4.0609)\tTop1: 12.500 (avg: 12.000)\tTop5: 34.375 (avg: 32.156)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.354 (avg: 0.362)\tLoss: 3.8947 (avg: 4.0526)\tTop1: 12.500 (avg: 12.013)\tTop5: 40.625 (avg: 32.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9307\tTop 1 accuracy: 9.150\tTop 5 accuracy: 27.400\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.366 (avg: 0.367)\tLoss: 4.0754 (avg: 4.0183)\tTop1: 15.625 (avg: 12.375)\tTop5: 37.500 (avg: 34.125)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.371 (avg: 0.372)\tLoss: 3.9669 (avg: 4.0335)\tTop1: 10.938 (avg: 12.312)\tTop5: 39.062 (avg: 32.781)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.368 (avg: 0.373)\tLoss: 4.2124 (avg: 4.0312)\tTop1: 14.062 (avg: 12.250)\tTop5: 31.250 (avg: 33.250)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.365 (avg: 0.373)\tLoss: 4.0604 (avg: 4.0422)\tTop1: 9.375 (avg: 11.984)\tTop5: 25.000 (avg: 32.641)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.364 (avg: 0.373)\tLoss: 4.0387 (avg: 4.0454)\tTop1: 10.938 (avg: 12.250)\tTop5: 31.250 (avg: 32.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2280\tTop 1 accuracy: 9.350\tTop 5 accuracy: 26.150\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.358 (avg: 0.356)\tLoss: 4.0192 (avg: 3.9903)\tTop1: 15.625 (avg: 12.625)\tTop5: 32.812 (avg: 33.562)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.7970 (avg: 4.0054)\tTop1: 18.750 (avg: 12.188)\tTop5: 39.062 (avg: 33.844)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 3.8997 (avg: 4.0192)\tTop1: 10.938 (avg: 11.938)\tTop5: 32.812 (avg: 33.125)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 4.0428 (avg: 4.0330)\tTop1: 20.312 (avg: 11.891)\tTop5: 31.250 (avg: 32.703)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.355 (avg: 0.363)\tLoss: 4.0419 (avg: 4.0387)\tTop1: 9.375 (avg: 11.913)\tTop5: 31.250 (avg: 32.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9164\tTop 1 accuracy: 9.800\tTop 5 accuracy: 26.500\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.356 (avg: 0.353)\tLoss: 3.7851 (avg: 4.0447)\tTop1: 17.188 (avg: 12.375)\tTop5: 39.062 (avg: 31.938)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.356 (avg: 0.358)\tLoss: 3.9278 (avg: 4.0014)\tTop1: 10.938 (avg: 13.375)\tTop5: 39.062 (avg: 33.750)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.354 (avg: 0.359)\tLoss: 4.4277 (avg: 3.9907)\tTop1: 9.375 (avg: 13.250)\tTop5: 20.312 (avg: 33.750)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.353 (avg: 0.360)\tLoss: 3.6705 (avg: 4.0010)\tTop1: 26.562 (avg: 13.141)\tTop5: 46.875 (avg: 33.750)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 3.9727 (avg: 4.0052)\tTop1: 14.062 (avg: 12.925)\tTop5: 37.500 (avg: 33.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9834\tTop 1 accuracy: 9.750\tTop 5 accuracy: 25.850\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.356 (avg: 0.354)\tLoss: 3.7733 (avg: 3.9449)\tTop1: 14.062 (avg: 15.125)\tTop5: 39.062 (avg: 35.000)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.355 (avg: 0.358)\tLoss: 3.9872 (avg: 3.9744)\tTop1: 9.375 (avg: 14.469)\tTop5: 34.375 (avg: 34.156)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.9494 (avg: 3.9703)\tTop1: 17.188 (avg: 13.708)\tTop5: 35.938 (avg: 34.000)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 4.2148 (avg: 3.9942)\tTop1: 6.250 (avg: 13.141)\tTop5: 20.312 (avg: 33.781)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 4.0073 (avg: 4.0048)\tTop1: 10.938 (avg: 12.825)\tTop5: 34.375 (avg: 33.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9376\tTop 1 accuracy: 9.650\tTop 5 accuracy: 26.850\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.357 (avg: 0.356)\tLoss: 3.9242 (avg: 3.9684)\tTop1: 10.938 (avg: 13.000)\tTop5: 39.062 (avg: 34.750)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.352 (avg: 0.360)\tLoss: 4.1959 (avg: 3.9969)\tTop1: 7.812 (avg: 12.438)\tTop5: 39.062 (avg: 34.188)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 3.9057 (avg: 3.9756)\tTop1: 15.625 (avg: 12.896)\tTop5: 40.625 (avg: 34.542)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 4.1151 (avg: 3.9863)\tTop1: 18.750 (avg: 13.031)\tTop5: 35.938 (avg: 34.359)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 4.0040 (avg: 3.9802)\tTop1: 7.812 (avg: 13.200)\tTop5: 35.938 (avg: 34.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7955\tTop 1 accuracy: 9.800\tTop 5 accuracy: 26.100\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.355 (avg: 0.355)\tLoss: 4.0709 (avg: 3.9535)\tTop1: 12.500 (avg: 12.750)\tTop5: 29.688 (avg: 34.688)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.358 (avg: 0.359)\tLoss: 3.9911 (avg: 3.9732)\tTop1: 12.500 (avg: 12.688)\tTop5: 40.625 (avg: 34.438)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.347 (avg: 0.360)\tLoss: 3.7005 (avg: 3.9801)\tTop1: 15.625 (avg: 12.854)\tTop5: 39.062 (avg: 34.208)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.9499 (avg: 3.9831)\tTop1: 7.812 (avg: 12.656)\tTop5: 32.812 (avg: 34.062)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.355 (avg: 0.362)\tLoss: 3.7666 (avg: 3.9808)\tTop1: 15.625 (avg: 12.625)\tTop5: 42.188 (avg: 34.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9342\tTop 1 accuracy: 9.850\tTop 5 accuracy: 28.000\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.356 (avg: 0.355)\tLoss: 4.0323 (avg: 3.8911)\tTop1: 9.375 (avg: 14.500)\tTop5: 28.125 (avg: 36.562)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.356 (avg: 0.359)\tLoss: 3.9982 (avg: 3.9418)\tTop1: 15.625 (avg: 13.938)\tTop5: 31.250 (avg: 34.688)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.360 (avg: 0.360)\tLoss: 3.9128 (avg: 3.9545)\tTop1: 15.625 (avg: 13.646)\tTop5: 29.688 (avg: 34.188)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.7783 (avg: 3.9618)\tTop1: 10.938 (avg: 13.406)\tTop5: 40.625 (avg: 34.047)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.359 (avg: 0.362)\tLoss: 4.1333 (avg: 3.9646)\tTop1: 15.625 (avg: 13.575)\tTop5: 21.875 (avg: 34.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0211\tTop 1 accuracy: 9.250\tTop 5 accuracy: 26.950\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.355 (avg: 0.353)\tLoss: 3.8843 (avg: 3.9057)\tTop1: 17.188 (avg: 14.250)\tTop5: 35.938 (avg: 35.938)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.357 (avg: 0.358)\tLoss: 4.1083 (avg: 3.9448)\tTop1: 10.938 (avg: 13.000)\tTop5: 32.812 (avg: 35.062)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 3.5487 (avg: 3.9489)\tTop1: 28.125 (avg: 13.167)\tTop5: 46.875 (avg: 35.146)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.360 (avg: 0.360)\tLoss: 3.9859 (avg: 3.9374)\tTop1: 14.062 (avg: 13.281)\tTop5: 31.250 (avg: 35.344)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 4.0793 (avg: 3.9537)\tTop1: 6.250 (avg: 13.038)\tTop5: 28.125 (avg: 34.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7878\tTop 1 accuracy: 9.750\tTop 5 accuracy: 27.950\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.362 (avg: 0.361)\tLoss: 3.9037 (avg: 3.8652)\tTop1: 18.750 (avg: 16.000)\tTop5: 34.375 (avg: 38.062)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.363 (avg: 0.366)\tLoss: 3.9993 (avg: 3.8942)\tTop1: 12.500 (avg: 15.219)\tTop5: 37.500 (avg: 36.656)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.363 (avg: 0.367)\tLoss: 4.0437 (avg: 3.9314)\tTop1: 10.938 (avg: 13.979)\tTop5: 35.938 (avg: 35.167)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.364 (avg: 0.368)\tLoss: 3.5099 (avg: 3.9533)\tTop1: 20.312 (avg: 13.719)\tTop5: 48.438 (avg: 34.938)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.362 (avg: 0.368)\tLoss: 3.9293 (avg: 3.9515)\tTop1: 10.938 (avg: 13.925)\tTop5: 31.250 (avg: 34.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7537\tTop 1 accuracy: 9.700\tTop 5 accuracy: 27.650\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.361 (avg: 0.356)\tLoss: 3.8103 (avg: 3.9278)\tTop1: 15.625 (avg: 13.500)\tTop5: 40.625 (avg: 34.625)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 3.6458 (avg: 3.8867)\tTop1: 21.875 (avg: 14.312)\tTop5: 45.312 (avg: 35.844)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.360 (avg: 0.361)\tLoss: 4.0981 (avg: 3.9118)\tTop1: 7.812 (avg: 14.062)\tTop5: 29.688 (avg: 35.188)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.359 (avg: 0.363)\tLoss: 4.2751 (avg: 3.9147)\tTop1: 17.188 (avg: 14.172)\tTop5: 39.062 (avg: 35.406)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.360 (avg: 0.364)\tLoss: 3.9800 (avg: 3.9205)\tTop1: 15.625 (avg: 13.875)\tTop5: 28.125 (avg: 35.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8333\tTop 1 accuracy: 10.650\tTop 5 accuracy: 28.850\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.356 (avg: 0.355)\tLoss: 4.0829 (avg: 3.9018)\tTop1: 15.625 (avg: 13.500)\tTop5: 26.562 (avg: 35.250)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.359 (avg: 0.359)\tLoss: 3.8028 (avg: 3.8874)\tTop1: 12.500 (avg: 13.938)\tTop5: 40.625 (avg: 35.969)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.5541 (avg: 3.8982)\tTop1: 15.625 (avg: 13.625)\tTop5: 45.312 (avg: 35.542)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 3.8275 (avg: 3.9065)\tTop1: 12.500 (avg: 13.719)\tTop5: 46.875 (avg: 35.703)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.364 (avg: 0.362)\tLoss: 3.8179 (avg: 3.9091)\tTop1: 10.938 (avg: 13.913)\tTop5: 43.750 (avg: 36.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1037\tTop 1 accuracy: 10.500\tTop 5 accuracy: 27.750\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.357 (avg: 0.355)\tLoss: 3.8102 (avg: 3.8839)\tTop1: 20.312 (avg: 14.625)\tTop5: 46.875 (avg: 37.250)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.7899 (avg: 3.9185)\tTop1: 18.750 (avg: 14.125)\tTop5: 40.625 (avg: 36.000)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.6455 (avg: 3.9071)\tTop1: 15.625 (avg: 14.042)\tTop5: 42.188 (avg: 36.062)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 3.8949 (avg: 3.9017)\tTop1: 12.500 (avg: 13.953)\tTop5: 31.250 (avg: 35.781)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.358 (avg: 0.363)\tLoss: 3.8583 (avg: 3.8932)\tTop1: 14.062 (avg: 14.275)\tTop5: 35.938 (avg: 36.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9262\tTop 1 accuracy: 10.300\tTop 5 accuracy: 27.550\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.363 (avg: 0.361)\tLoss: 3.9427 (avg: 3.8383)\tTop1: 14.062 (avg: 15.438)\tTop5: 35.938 (avg: 38.312)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.364 (avg: 0.365)\tLoss: 3.5989 (avg: 3.8300)\tTop1: 14.062 (avg: 15.562)\tTop5: 37.500 (avg: 38.531)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.357 (avg: 0.367)\tLoss: 3.5797 (avg: 3.8137)\tTop1: 18.750 (avg: 16.062)\tTop5: 39.062 (avg: 38.750)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.360 (avg: 0.366)\tLoss: 3.6416 (avg: 3.7907)\tTop1: 20.312 (avg: 16.375)\tTop5: 42.188 (avg: 39.203)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.357 (avg: 0.366)\tLoss: 3.7966 (avg: 3.7921)\tTop1: 9.375 (avg: 16.188)\tTop5: 46.875 (avg: 39.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6519\tTop 1 accuracy: 10.800\tTop 5 accuracy: 29.100\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.355 (avg: 0.356)\tLoss: 4.0840 (avg: 3.8134)\tTop1: 15.625 (avg: 15.812)\tTop5: 34.375 (avg: 39.062)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 3.6469 (avg: 3.7652)\tTop1: 15.625 (avg: 16.406)\tTop5: 42.188 (avg: 40.219)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.9167 (avg: 3.7698)\tTop1: 15.625 (avg: 15.917)\tTop5: 34.375 (avg: 39.750)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.357 (avg: 0.362)\tLoss: 3.6574 (avg: 3.7569)\tTop1: 15.625 (avg: 15.906)\tTop5: 37.500 (avg: 39.734)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 3.9614 (avg: 3.7616)\tTop1: 10.938 (avg: 16.225)\tTop5: 35.938 (avg: 39.562)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6784\tTop 1 accuracy: 11.200\tTop 5 accuracy: 29.850\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.355 (avg: 0.355)\tLoss: 3.7146 (avg: 3.7413)\tTop1: 18.750 (avg: 16.812)\tTop5: 32.812 (avg: 39.125)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.357 (avg: 0.359)\tLoss: 3.8160 (avg: 3.7407)\tTop1: 20.312 (avg: 16.906)\tTop5: 34.375 (avg: 39.750)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.5256 (avg: 3.7457)\tTop1: 25.000 (avg: 16.938)\tTop5: 46.875 (avg: 39.792)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.357 (avg: 0.361)\tLoss: 3.7655 (avg: 3.7495)\tTop1: 9.375 (avg: 16.859)\tTop5: 40.625 (avg: 39.922)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.360 (avg: 0.362)\tLoss: 3.9395 (avg: 3.7529)\tTop1: 14.062 (avg: 16.925)\tTop5: 35.938 (avg: 39.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6751\tTop 1 accuracy: 11.000\tTop 5 accuracy: 29.250\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.354 (avg: 0.353)\tLoss: 3.5514 (avg: 3.6820)\tTop1: 20.312 (avg: 17.375)\tTop5: 46.875 (avg: 41.500)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.354 (avg: 0.358)\tLoss: 3.7823 (avg: 3.7094)\tTop1: 14.062 (avg: 17.406)\tTop5: 40.625 (avg: 41.031)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 3.8068 (avg: 3.7266)\tTop1: 12.500 (avg: 17.312)\tTop5: 39.062 (avg: 40.354)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 3.5746 (avg: 3.7353)\tTop1: 21.875 (avg: 17.406)\tTop5: 48.438 (avg: 40.266)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 3.9024 (avg: 3.7460)\tTop1: 15.625 (avg: 17.213)\tTop5: 35.938 (avg: 40.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6932\tTop 1 accuracy: 11.100\tTop 5 accuracy: 29.550\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.362 (avg: 0.361)\tLoss: 3.6809 (avg: 3.7717)\tTop1: 18.750 (avg: 17.250)\tTop5: 45.312 (avg: 39.750)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.362 (avg: 0.365)\tLoss: 3.6294 (avg: 3.7511)\tTop1: 25.000 (avg: 17.719)\tTop5: 42.188 (avg: 39.656)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.364 (avg: 0.366)\tLoss: 3.8050 (avg: 3.7630)\tTop1: 12.500 (avg: 16.792)\tTop5: 35.938 (avg: 39.229)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.362 (avg: 0.367)\tLoss: 3.9465 (avg: 3.7566)\tTop1: 15.625 (avg: 16.766)\tTop5: 37.500 (avg: 39.766)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.362 (avg: 0.368)\tLoss: 3.9930 (avg: 3.7445)\tTop1: 15.625 (avg: 16.975)\tTop5: 32.812 (avg: 40.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6281\tTop 1 accuracy: 10.900\tTop 5 accuracy: 29.550\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.358 (avg: 0.355)\tLoss: 3.4780 (avg: 3.7480)\tTop1: 23.438 (avg: 16.125)\tTop5: 48.438 (avg: 41.188)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.357 (avg: 0.360)\tLoss: 3.6798 (avg: 3.7540)\tTop1: 15.625 (avg: 16.281)\tTop5: 35.938 (avg: 40.438)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.7508 (avg: 3.7516)\tTop1: 20.312 (avg: 16.583)\tTop5: 42.188 (avg: 40.125)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.356 (avg: 0.362)\tLoss: 3.5898 (avg: 3.7339)\tTop1: 25.000 (avg: 17.109)\tTop5: 50.000 (avg: 40.531)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.358 (avg: 0.362)\tLoss: 3.9391 (avg: 3.7387)\tTop1: 12.500 (avg: 16.913)\tTop5: 40.625 (avg: 40.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6682\tTop 1 accuracy: 11.300\tTop 5 accuracy: 29.700\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.358 (avg: 0.353)\tLoss: 3.3527 (avg: 3.6687)\tTop1: 31.250 (avg: 18.750)\tTop5: 56.250 (avg: 42.312)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.357 (avg: 0.357)\tLoss: 3.6163 (avg: 3.7148)\tTop1: 21.875 (avg: 18.469)\tTop5: 40.625 (avg: 41.281)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 3.9811 (avg: 3.7167)\tTop1: 15.625 (avg: 17.792)\tTop5: 35.938 (avg: 40.708)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.353 (avg: 0.360)\tLoss: 3.6411 (avg: 3.7272)\tTop1: 23.438 (avg: 17.344)\tTop5: 50.000 (avg: 40.688)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.356 (avg: 0.360)\tLoss: 4.0327 (avg: 3.7383)\tTop1: 12.500 (avg: 17.100)\tTop5: 35.938 (avg: 40.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6285\tTop 1 accuracy: 11.450\tTop 5 accuracy: 29.300\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.350 (avg: 0.355)\tLoss: 3.2052 (avg: 3.7098)\tTop1: 28.125 (avg: 17.562)\tTop5: 60.938 (avg: 41.625)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.356 (avg: 0.358)\tLoss: 3.9277 (avg: 3.7486)\tTop1: 14.062 (avg: 17.562)\tTop5: 35.938 (avg: 40.688)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 3.6248 (avg: 3.7480)\tTop1: 21.875 (avg: 17.458)\tTop5: 43.750 (avg: 40.188)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.8910 (avg: 3.7374)\tTop1: 10.938 (avg: 17.328)\tTop5: 32.812 (avg: 40.375)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 3.6816 (avg: 3.7365)\tTop1: 15.625 (avg: 17.250)\tTop5: 40.625 (avg: 40.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7609\tTop 1 accuracy: 11.200\tTop 5 accuracy: 30.050\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.360 (avg: 0.358)\tLoss: 3.8136 (avg: 3.7430)\tTop1: 15.625 (avg: 16.375)\tTop5: 40.625 (avg: 40.562)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.355 (avg: 0.363)\tLoss: 3.4501 (avg: 3.7225)\tTop1: 20.312 (avg: 16.062)\tTop5: 51.562 (avg: 40.719)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.360 (avg: 0.365)\tLoss: 4.1332 (avg: 3.7304)\tTop1: 12.500 (avg: 16.146)\tTop5: 28.125 (avg: 40.188)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.359 (avg: 0.365)\tLoss: 3.6998 (avg: 3.7222)\tTop1: 12.500 (avg: 17.047)\tTop5: 51.562 (avg: 40.688)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.360 (avg: 0.366)\tLoss: 3.8289 (avg: 3.7348)\tTop1: 12.500 (avg: 16.950)\tTop5: 39.062 (avg: 40.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7846\tTop 1 accuracy: 11.100\tTop 5 accuracy: 30.450\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.359 (avg: 0.357)\tLoss: 4.1740 (avg: 3.6935)\tTop1: 7.812 (avg: 17.812)\tTop5: 28.125 (avg: 41.750)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.358 (avg: 0.361)\tLoss: 3.6736 (avg: 3.7037)\tTop1: 20.312 (avg: 17.688)\tTop5: 48.438 (avg: 41.188)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.360 (avg: 0.363)\tLoss: 3.7534 (avg: 3.7282)\tTop1: 20.312 (avg: 17.250)\tTop5: 42.188 (avg: 40.375)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.359 (avg: 0.364)\tLoss: 3.5677 (avg: 3.7122)\tTop1: 21.875 (avg: 17.469)\tTop5: 45.312 (avg: 41.094)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.358 (avg: 0.364)\tLoss: 3.6991 (avg: 3.7275)\tTop1: 18.750 (avg: 17.175)\tTop5: 43.750 (avg: 40.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7062\tTop 1 accuracy: 11.300\tTop 5 accuracy: 30.250\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.357 (avg: 0.356)\tLoss: 4.2843 (avg: 3.7086)\tTop1: 17.188 (avg: 18.312)\tTop5: 31.250 (avg: 40.938)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.358 (avg: 0.360)\tLoss: 3.4816 (avg: 3.7136)\tTop1: 21.875 (avg: 18.062)\tTop5: 48.438 (avg: 40.812)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.360 (avg: 0.363)\tLoss: 3.6651 (avg: 3.7285)\tTop1: 15.625 (avg: 17.250)\tTop5: 43.750 (avg: 40.667)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.360 (avg: 0.363)\tLoss: 3.5897 (avg: 3.7272)\tTop1: 15.625 (avg: 17.438)\tTop5: 48.438 (avg: 40.594)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.360 (avg: 0.364)\tLoss: 3.9230 (avg: 3.7244)\tTop1: 9.375 (avg: 17.312)\tTop5: 35.938 (avg: 40.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6985\tTop 1 accuracy: 11.450\tTop 5 accuracy: 30.300\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.355 (avg: 0.356)\tLoss: 3.7203 (avg: 3.7123)\tTop1: 17.188 (avg: 18.438)\tTop5: 48.438 (avg: 41.438)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 3.7521 (avg: 3.7243)\tTop1: 18.750 (avg: 17.812)\tTop5: 31.250 (avg: 40.906)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.350 (avg: 0.360)\tLoss: 3.7290 (avg: 3.7548)\tTop1: 17.188 (avg: 17.521)\tTop5: 40.625 (avg: 39.938)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.356 (avg: 0.361)\tLoss: 3.3496 (avg: 3.7400)\tTop1: 29.688 (avg: 17.484)\tTop5: 50.000 (avg: 40.047)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.355 (avg: 0.361)\tLoss: 3.3961 (avg: 3.7245)\tTop1: 18.750 (avg: 17.475)\tTop5: 48.438 (avg: 40.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6582\tTop 1 accuracy: 11.300\tTop 5 accuracy: 30.000\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.361 (avg: 0.360)\tLoss: 3.7308 (avg: 3.7219)\tTop1: 17.188 (avg: 17.125)\tTop5: 39.062 (avg: 40.000)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.362 (avg: 0.365)\tLoss: 3.7979 (avg: 3.7097)\tTop1: 17.188 (avg: 17.719)\tTop5: 43.750 (avg: 40.000)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.363 (avg: 0.366)\tLoss: 3.7230 (avg: 3.7184)\tTop1: 17.188 (avg: 17.292)\tTop5: 40.625 (avg: 40.625)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.363 (avg: 0.367)\tLoss: 4.1010 (avg: 3.7182)\tTop1: 14.062 (avg: 17.578)\tTop5: 31.250 (avg: 40.609)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.362 (avg: 0.368)\tLoss: 3.6413 (avg: 3.7199)\tTop1: 15.625 (avg: 17.625)\tTop5: 39.062 (avg: 40.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7008\tTop 1 accuracy: 11.400\tTop 5 accuracy: 30.000\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.358 (avg: 0.356)\tLoss: 4.1451 (avg: 3.7670)\tTop1: 12.500 (avg: 17.750)\tTop5: 29.688 (avg: 40.250)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.358 (avg: 0.360)\tLoss: 3.5766 (avg: 3.7336)\tTop1: 21.875 (avg: 18.000)\tTop5: 50.000 (avg: 40.812)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.363 (avg: 0.362)\tLoss: 3.9167 (avg: 3.7426)\tTop1: 14.062 (avg: 17.479)\tTop5: 37.500 (avg: 40.604)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.354 (avg: 0.362)\tLoss: 3.8228 (avg: 3.7320)\tTop1: 15.625 (avg: 17.516)\tTop5: 35.938 (avg: 40.734)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.356 (avg: 0.363)\tLoss: 3.6963 (avg: 3.7247)\tTop1: 15.625 (avg: 17.413)\tTop5: 42.188 (avg: 40.813)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6306\tTop 1 accuracy: 11.200\tTop 5 accuracy: 29.800\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.358 (avg: 0.354)\tLoss: 3.7901 (avg: 3.7341)\tTop1: 20.312 (avg: 17.375)\tTop5: 40.625 (avg: 39.562)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.354 (avg: 0.358)\tLoss: 3.7702 (avg: 3.6909)\tTop1: 17.188 (avg: 18.062)\tTop5: 43.750 (avg: 40.406)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.355 (avg: 0.359)\tLoss: 3.6095 (avg: 3.7031)\tTop1: 21.875 (avg: 17.625)\tTop5: 42.188 (avg: 40.833)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.354 (avg: 0.360)\tLoss: 3.9238 (avg: 3.6916)\tTop1: 20.312 (avg: 18.078)\tTop5: 42.188 (avg: 41.469)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.355 (avg: 0.360)\tLoss: 3.9707 (avg: 3.7102)\tTop1: 12.500 (avg: 17.538)\tTop5: 32.812 (avg: 40.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6685\tTop 1 accuracy: 11.400\tTop 5 accuracy: 29.950\n",
            "\n",
            "incr_e = 128: top1 = 11.100000381469727 \t top5 = 30.450000762939453 \t batch time = 0.29502278566360474\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.444 (avg: 0.522)\tLoss: 5.2949 (avg: 5.3079)\tTop1: 0.000 (avg: 0.125)\tTop5: 3.125 (avg: 1.938)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.436 (avg: 0.486)\tLoss: 5.2971 (avg: 5.3032)\tTop1: 1.562 (avg: 0.250)\tTop5: 1.562 (avg: 2.156)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.442 (avg: 0.474)\tLoss: 5.2971 (avg: 5.3017)\tTop1: 0.000 (avg: 0.312)\tTop5: 1.562 (avg: 2.167)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.441 (avg: 0.468)\tLoss: 5.2977 (avg: 5.3009)\tTop1: 0.000 (avg: 0.359)\tTop5: 0.000 (avg: 2.094)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.450 (avg: 0.465)\tLoss: 5.2996 (avg: 5.3004)\tTop1: 0.000 (avg: 0.338)\tTop5: 1.562 (avg: 2.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3014\tTop 1 accuracy: 0.400\tTop 5 accuracy: 2.500\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.443 (avg: 0.439)\tLoss: 5.2979 (avg: 5.2977)\tTop1: 0.000 (avg: 0.625)\tTop5: 6.250 (avg: 2.938)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.441 (avg: 0.444)\tLoss: 5.2958 (avg: 5.2976)\tTop1: 0.000 (avg: 0.531)\tTop5: 4.688 (avg: 2.625)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.439 (avg: 0.446)\tLoss: 5.2995 (avg: 5.2977)\tTop1: 0.000 (avg: 0.500)\tTop5: 1.562 (avg: 2.646)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.442 (avg: 0.447)\tLoss: 5.2812 (avg: 5.2974)\tTop1: 0.000 (avg: 0.547)\tTop5: 6.250 (avg: 2.672)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.443 (avg: 0.447)\tLoss: 5.2929 (avg: 5.2974)\tTop1: 0.000 (avg: 0.538)\tTop5: 3.125 (avg: 2.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3090\tTop 1 accuracy: 0.550\tTop 5 accuracy: 2.150\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.447 (avg: 0.440)\tLoss: 5.3027 (avg: 5.2953)\tTop1: 0.000 (avg: 0.688)\tTop5: 1.562 (avg: 2.062)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.443 (avg: 0.445)\tLoss: 5.2908 (avg: 5.2912)\tTop1: 1.562 (avg: 0.688)\tTop5: 1.562 (avg: 2.469)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.436 (avg: 0.447)\tLoss: 5.3168 (avg: 5.2875)\tTop1: 0.000 (avg: 0.562)\tTop5: 0.000 (avg: 2.438)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.443 (avg: 0.448)\tLoss: 5.2978 (avg: 5.2869)\tTop1: 0.000 (avg: 0.562)\tTop5: 0.000 (avg: 2.594)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.448 (avg: 0.448)\tLoss: 5.2322 (avg: 5.2846)\tTop1: 1.562 (avg: 0.600)\tTop5: 6.250 (avg: 2.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3247\tTop 1 accuracy: 0.500\tTop 5 accuracy: 2.800\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.441 (avg: 0.439)\tLoss: 5.3036 (avg: 5.2659)\tTop1: 0.000 (avg: 0.688)\tTop5: 3.125 (avg: 4.438)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.449 (avg: 0.445)\tLoss: 5.2599 (avg: 5.2606)\tTop1: 0.000 (avg: 0.906)\tTop5: 4.688 (avg: 4.438)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.439 (avg: 0.447)\tLoss: 5.3057 (avg: 5.2588)\tTop1: 0.000 (avg: 0.958)\tTop5: 1.562 (avg: 4.271)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.439 (avg: 0.448)\tLoss: 5.2833 (avg: 5.2573)\tTop1: 0.000 (avg: 0.844)\tTop5: 0.000 (avg: 4.391)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.444 (avg: 0.448)\tLoss: 5.2202 (avg: 5.2571)\tTop1: 0.000 (avg: 0.813)\tTop5: 4.688 (avg: 4.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3308\tTop 1 accuracy: 0.550\tTop 5 accuracy: 2.750\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.442 (avg: 0.439)\tLoss: 5.2727 (avg: 5.2249)\tTop1: 0.000 (avg: 0.938)\tTop5: 1.562 (avg: 4.375)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.441 (avg: 0.445)\tLoss: 5.2396 (avg: 5.2412)\tTop1: 3.125 (avg: 1.062)\tTop5: 3.125 (avg: 4.188)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.445 (avg: 0.447)\tLoss: 5.3185 (avg: 5.2442)\tTop1: 1.562 (avg: 0.958)\tTop5: 3.125 (avg: 4.167)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.452 (avg: 0.448)\tLoss: 5.2905 (avg: 5.2447)\tTop1: 0.000 (avg: 1.016)\tTop5: 3.125 (avg: 4.125)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.441 (avg: 0.448)\tLoss: 5.2253 (avg: 5.2425)\tTop1: 0.000 (avg: 1.025)\tTop5: 3.125 (avg: 4.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3869\tTop 1 accuracy: 0.700\tTop 5 accuracy: 3.850\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.444 (avg: 0.439)\tLoss: 5.2124 (avg: 5.2418)\tTop1: 0.000 (avg: 1.000)\tTop5: 3.125 (avg: 4.062)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.448 (avg: 0.444)\tLoss: 5.1993 (avg: 5.2326)\tTop1: 3.125 (avg: 1.188)\tTop5: 7.812 (avg: 4.469)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.440 (avg: 0.446)\tLoss: 5.2348 (avg: 5.2348)\tTop1: 0.000 (avg: 1.188)\tTop5: 4.688 (avg: 4.479)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.445 (avg: 0.447)\tLoss: 5.2139 (avg: 5.2383)\tTop1: 0.000 (avg: 1.078)\tTop5: 3.125 (avg: 4.531)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.445 (avg: 0.448)\tLoss: 5.1643 (avg: 5.2352)\tTop1: 0.000 (avg: 1.013)\tTop5: 1.562 (avg: 4.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3947\tTop 1 accuracy: 0.800\tTop 5 accuracy: 3.550\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.446 (avg: 0.439)\tLoss: 5.2454 (avg: 5.2288)\tTop1: 0.000 (avg: 0.750)\tTop5: 4.688 (avg: 4.750)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.444 (avg: 0.444)\tLoss: 5.1820 (avg: 5.2353)\tTop1: 3.125 (avg: 0.688)\tTop5: 9.375 (avg: 4.781)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.442 (avg: 0.446)\tLoss: 5.2346 (avg: 5.2296)\tTop1: 0.000 (avg: 0.833)\tTop5: 3.125 (avg: 4.854)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.441 (avg: 0.447)\tLoss: 5.2192 (avg: 5.2300)\tTop1: 1.562 (avg: 0.906)\tTop5: 4.688 (avg: 4.906)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.446 (avg: 0.447)\tLoss: 5.3006 (avg: 5.2278)\tTop1: 0.000 (avg: 0.963)\tTop5: 3.125 (avg: 4.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3779\tTop 1 accuracy: 1.100\tTop 5 accuracy: 4.450\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.438 (avg: 0.439)\tLoss: 5.2002 (avg: 5.2086)\tTop1: 3.125 (avg: 1.438)\tTop5: 6.250 (avg: 4.875)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.445 (avg: 0.444)\tLoss: 5.2483 (avg: 5.2132)\tTop1: 1.562 (avg: 1.219)\tTop5: 9.375 (avg: 5.000)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.442 (avg: 0.446)\tLoss: 5.1756 (avg: 5.2188)\tTop1: 0.000 (avg: 1.292)\tTop5: 6.250 (avg: 5.167)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.442 (avg: 0.447)\tLoss: 5.2723 (avg: 5.2197)\tTop1: 0.000 (avg: 1.219)\tTop5: 4.688 (avg: 5.016)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.442 (avg: 0.447)\tLoss: 5.1994 (avg: 5.2205)\tTop1: 0.000 (avg: 1.250)\tTop5: 6.250 (avg: 5.063)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3407\tTop 1 accuracy: 0.800\tTop 5 accuracy: 4.050\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.438 (avg: 0.438)\tLoss: 5.1770 (avg: 5.1887)\tTop1: 1.562 (avg: 1.125)\tTop5: 7.812 (avg: 5.812)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.440 (avg: 0.444)\tLoss: 5.2474 (avg: 5.2053)\tTop1: 7.812 (avg: 1.281)\tTop5: 9.375 (avg: 5.000)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.441 (avg: 0.446)\tLoss: 5.2348 (avg: 5.2092)\tTop1: 1.562 (avg: 1.229)\tTop5: 7.812 (avg: 4.938)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.442 (avg: 0.447)\tLoss: 5.2733 (avg: 5.2135)\tTop1: 1.562 (avg: 1.266)\tTop5: 6.250 (avg: 4.953)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.441 (avg: 0.447)\tLoss: 5.1839 (avg: 5.2127)\tTop1: 0.000 (avg: 1.250)\tTop5: 7.812 (avg: 4.950)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3025\tTop 1 accuracy: 0.800\tTop 5 accuracy: 4.700\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.442 (avg: 0.439)\tLoss: 5.2211 (avg: 5.1926)\tTop1: 3.125 (avg: 1.125)\tTop5: 9.375 (avg: 6.438)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.439 (avg: 0.444)\tLoss: 5.2475 (avg: 5.2068)\tTop1: 0.000 (avg: 0.969)\tTop5: 7.812 (avg: 5.906)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.440 (avg: 0.446)\tLoss: 5.1392 (avg: 5.2025)\tTop1: 1.562 (avg: 0.854)\tTop5: 4.688 (avg: 5.604)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.443 (avg: 0.447)\tLoss: 5.2629 (avg: 5.2020)\tTop1: 0.000 (avg: 0.969)\tTop5: 1.562 (avg: 5.516)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.440 (avg: 0.447)\tLoss: 5.2029 (avg: 5.2058)\tTop1: 0.000 (avg: 1.025)\tTop5: 7.812 (avg: 5.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2576\tTop 1 accuracy: 0.750\tTop 5 accuracy: 4.950\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.439 (avg: 0.438)\tLoss: 5.1599 (avg: 5.2011)\tTop1: 1.562 (avg: 1.500)\tTop5: 4.688 (avg: 5.312)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.446 (avg: 0.444)\tLoss: 5.2174 (avg: 5.2052)\tTop1: 1.562 (avg: 1.344)\tTop5: 4.688 (avg: 5.469)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.439 (avg: 0.446)\tLoss: 5.3051 (avg: 5.2074)\tTop1: 0.000 (avg: 1.188)\tTop5: 6.250 (avg: 5.208)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.442 (avg: 0.447)\tLoss: 5.1520 (avg: 5.2033)\tTop1: 3.125 (avg: 1.328)\tTop5: 12.500 (avg: 5.375)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.447 (avg: 0.447)\tLoss: 5.1433 (avg: 5.2028)\tTop1: 1.562 (avg: 1.425)\tTop5: 4.688 (avg: 5.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1945\tTop 1 accuracy: 1.100\tTop 5 accuracy: 4.150\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.445 (avg: 0.439)\tLoss: 5.2483 (avg: 5.2078)\tTop1: 0.000 (avg: 1.250)\tTop5: 3.125 (avg: 5.500)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.446 (avg: 0.444)\tLoss: 5.1232 (avg: 5.2030)\tTop1: 0.000 (avg: 1.188)\tTop5: 3.125 (avg: 5.656)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.443 (avg: 0.446)\tLoss: 5.2512 (avg: 5.1953)\tTop1: 0.000 (avg: 1.375)\tTop5: 1.562 (avg: 6.000)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.441 (avg: 0.447)\tLoss: 5.2516 (avg: 5.1960)\tTop1: 3.125 (avg: 1.375)\tTop5: 4.688 (avg: 5.891)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.442 (avg: 0.448)\tLoss: 5.1772 (avg: 5.1926)\tTop1: 1.562 (avg: 1.363)\tTop5: 6.250 (avg: 5.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2701\tTop 1 accuracy: 1.400\tTop 5 accuracy: 5.850\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.444 (avg: 0.438)\tLoss: 5.2325 (avg: 5.1610)\tTop1: 1.562 (avg: 1.812)\tTop5: 6.250 (avg: 7.312)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.440 (avg: 0.444)\tLoss: 5.2202 (avg: 5.1752)\tTop1: 1.562 (avg: 1.781)\tTop5: 7.812 (avg: 7.188)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.444 (avg: 0.446)\tLoss: 5.2082 (avg: 5.1724)\tTop1: 3.125 (avg: 1.708)\tTop5: 3.125 (avg: 6.854)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.445 (avg: 0.447)\tLoss: 5.1684 (avg: 5.1763)\tTop1: 3.125 (avg: 1.547)\tTop5: 4.688 (avg: 6.625)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.441 (avg: 0.448)\tLoss: 5.1860 (avg: 5.1786)\tTop1: 4.688 (avg: 1.488)\tTop5: 9.375 (avg: 6.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2596\tTop 1 accuracy: 1.100\tTop 5 accuracy: 6.000\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.442 (avg: 0.438)\tLoss: 5.1659 (avg: 5.1807)\tTop1: 1.562 (avg: 1.500)\tTop5: 4.688 (avg: 5.750)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.440 (avg: 0.444)\tLoss: 5.2770 (avg: 5.1784)\tTop1: 4.688 (avg: 1.500)\tTop5: 9.375 (avg: 6.656)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.440 (avg: 0.445)\tLoss: 5.1284 (avg: 5.1773)\tTop1: 1.562 (avg: 1.542)\tTop5: 6.250 (avg: 6.583)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.444 (avg: 0.446)\tLoss: 5.2099 (avg: 5.1696)\tTop1: 1.562 (avg: 1.719)\tTop5: 6.250 (avg: 6.672)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.445 (avg: 0.447)\tLoss: 5.2271 (avg: 5.1673)\tTop1: 3.125 (avg: 1.688)\tTop5: 10.938 (avg: 6.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3358\tTop 1 accuracy: 1.450\tTop 5 accuracy: 5.950\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.445 (avg: 0.439)\tLoss: 5.0794 (avg: 5.1383)\tTop1: 3.125 (avg: 1.688)\tTop5: 7.812 (avg: 6.812)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.449 (avg: 0.444)\tLoss: 5.1016 (avg: 5.1547)\tTop1: 0.000 (avg: 1.719)\tTop5: 4.688 (avg: 6.906)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.441 (avg: 0.446)\tLoss: 5.1499 (avg: 5.1515)\tTop1: 3.125 (avg: 2.021)\tTop5: 7.812 (avg: 7.271)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.441 (avg: 0.447)\tLoss: 5.3711 (avg: 5.1491)\tTop1: 1.562 (avg: 1.906)\tTop5: 6.250 (avg: 7.344)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.449 (avg: 0.447)\tLoss: 5.1225 (avg: 5.1458)\tTop1: 3.125 (avg: 1.825)\tTop5: 6.250 (avg: 7.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0843\tTop 1 accuracy: 1.850\tTop 5 accuracy: 6.950\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.446 (avg: 0.439)\tLoss: 5.1549 (avg: 5.1341)\tTop1: 1.562 (avg: 1.500)\tTop5: 12.500 (avg: 6.750)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.448 (avg: 0.445)\tLoss: 5.0893 (avg: 5.1281)\tTop1: 1.562 (avg: 1.656)\tTop5: 12.500 (avg: 7.344)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.445 (avg: 0.446)\tLoss: 5.0952 (avg: 5.1403)\tTop1: 4.688 (avg: 1.708)\tTop5: 10.938 (avg: 7.312)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.447 (avg: 0.447)\tLoss: 5.2409 (avg: 5.1312)\tTop1: 1.562 (avg: 1.719)\tTop5: 4.688 (avg: 7.453)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.442 (avg: 0.448)\tLoss: 5.1253 (avg: 5.1300)\tTop1: 4.688 (avg: 1.875)\tTop5: 6.250 (avg: 7.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8887\tTop 1 accuracy: 1.450\tTop 5 accuracy: 7.100\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.441 (avg: 0.438)\tLoss: 5.1476 (avg: 5.1213)\tTop1: 0.000 (avg: 1.812)\tTop5: 6.250 (avg: 7.500)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.441 (avg: 0.444)\tLoss: 5.1394 (avg: 5.1315)\tTop1: 1.562 (avg: 1.625)\tTop5: 6.250 (avg: 7.219)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.446 (avg: 0.446)\tLoss: 5.1760 (avg: 5.1179)\tTop1: 7.812 (avg: 1.833)\tTop5: 12.500 (avg: 7.958)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.446 (avg: 0.447)\tLoss: 5.0502 (avg: 5.1190)\tTop1: 3.125 (avg: 1.828)\tTop5: 6.250 (avg: 7.766)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.440 (avg: 0.448)\tLoss: 4.9894 (avg: 5.1216)\tTop1: 0.000 (avg: 1.800)\tTop5: 10.938 (avg: 7.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9857\tTop 1 accuracy: 1.950\tTop 5 accuracy: 6.750\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.445 (avg: 0.439)\tLoss: 5.1740 (avg: 5.0833)\tTop1: 1.562 (avg: 1.625)\tTop5: 9.375 (avg: 8.375)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.447 (avg: 0.444)\tLoss: 5.1798 (avg: 5.0977)\tTop1: 1.562 (avg: 1.688)\tTop5: 4.688 (avg: 8.344)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.446 (avg: 0.446)\tLoss: 5.0147 (avg: 5.1012)\tTop1: 3.125 (avg: 2.042)\tTop5: 12.500 (avg: 8.667)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.445 (avg: 0.447)\tLoss: 5.1823 (avg: 5.1032)\tTop1: 3.125 (avg: 1.984)\tTop5: 9.375 (avg: 8.422)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.447 (avg: 0.448)\tLoss: 5.2405 (avg: 5.1026)\tTop1: 0.000 (avg: 2.088)\tTop5: 4.688 (avg: 8.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2062\tTop 1 accuracy: 1.500\tTop 5 accuracy: 7.800\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.444 (avg: 0.440)\tLoss: 5.1986 (avg: 5.0564)\tTop1: 0.000 (avg: 2.438)\tTop5: 7.812 (avg: 9.688)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.443 (avg: 0.445)\tLoss: 5.1619 (avg: 5.0667)\tTop1: 1.562 (avg: 2.250)\tTop5: 10.938 (avg: 9.594)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.440 (avg: 0.446)\tLoss: 5.0482 (avg: 5.0747)\tTop1: 1.562 (avg: 2.062)\tTop5: 4.688 (avg: 9.083)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.439 (avg: 0.447)\tLoss: 5.1834 (avg: 5.0790)\tTop1: 3.125 (avg: 2.000)\tTop5: 4.688 (avg: 8.953)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.442 (avg: 0.448)\tLoss: 5.1790 (avg: 5.0839)\tTop1: 3.125 (avg: 1.938)\tTop5: 7.812 (avg: 8.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9878\tTop 1 accuracy: 1.800\tTop 5 accuracy: 6.950\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.444 (avg: 0.439)\tLoss: 4.9650 (avg: 5.0573)\tTop1: 1.562 (avg: 2.062)\tTop5: 6.250 (avg: 8.562)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.440 (avg: 0.443)\tLoss: 5.1930 (avg: 5.0547)\tTop1: 0.000 (avg: 2.000)\tTop5: 9.375 (avg: 8.906)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.444 (avg: 0.446)\tLoss: 5.0160 (avg: 5.0458)\tTop1: 1.562 (avg: 2.021)\tTop5: 9.375 (avg: 9.042)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.446 (avg: 0.447)\tLoss: 5.1512 (avg: 5.0453)\tTop1: 0.000 (avg: 2.109)\tTop5: 7.812 (avg: 8.969)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.439 (avg: 0.448)\tLoss: 5.1426 (avg: 5.0530)\tTop1: 1.562 (avg: 2.025)\tTop5: 1.562 (avg: 8.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1500\tTop 1 accuracy: 1.700\tTop 5 accuracy: 8.950\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.444 (avg: 0.439)\tLoss: 5.1030 (avg: 5.0286)\tTop1: 3.125 (avg: 2.250)\tTop5: 7.812 (avg: 10.562)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.449 (avg: 0.444)\tLoss: 5.0983 (avg: 5.0339)\tTop1: 3.125 (avg: 2.531)\tTop5: 15.625 (avg: 10.312)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.449 (avg: 0.446)\tLoss: 5.0591 (avg: 5.0373)\tTop1: 0.000 (avg: 2.354)\tTop5: 10.938 (avg: 9.667)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.447 (avg: 0.447)\tLoss: 4.7826 (avg: 5.0265)\tTop1: 4.688 (avg: 2.344)\tTop5: 18.750 (avg: 9.828)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.442 (avg: 0.448)\tLoss: 5.0423 (avg: 5.0249)\tTop1: 1.562 (avg: 2.350)\tTop5: 10.938 (avg: 9.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0104\tTop 1 accuracy: 2.050\tTop 5 accuracy: 8.850\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.446 (avg: 0.439)\tLoss: 5.0740 (avg: 5.0382)\tTop1: 1.562 (avg: 1.812)\tTop5: 9.375 (avg: 8.750)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.439 (avg: 0.445)\tLoss: 4.8791 (avg: 5.0062)\tTop1: 9.375 (avg: 2.531)\tTop5: 15.625 (avg: 10.312)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.441 (avg: 0.446)\tLoss: 4.9828 (avg: 5.0054)\tTop1: 6.250 (avg: 2.417)\tTop5: 9.375 (avg: 9.708)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.442 (avg: 0.447)\tLoss: 4.9942 (avg: 4.9979)\tTop1: 3.125 (avg: 2.406)\tTop5: 14.062 (avg: 9.906)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.445 (avg: 0.448)\tLoss: 4.9713 (avg: 4.9958)\tTop1: 0.000 (avg: 2.375)\tTop5: 9.375 (avg: 9.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8906\tTop 1 accuracy: 3.000\tTop 5 accuracy: 9.800\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.444 (avg: 0.438)\tLoss: 4.7815 (avg: 4.9498)\tTop1: 4.688 (avg: 2.500)\tTop5: 15.625 (avg: 11.312)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.444 (avg: 0.444)\tLoss: 4.7314 (avg: 4.9553)\tTop1: 6.250 (avg: 2.531)\tTop5: 14.062 (avg: 10.469)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.442 (avg: 0.446)\tLoss: 5.0449 (avg: 4.9751)\tTop1: 1.562 (avg: 2.354)\tTop5: 12.500 (avg: 10.125)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.442 (avg: 0.446)\tLoss: 4.9190 (avg: 4.9762)\tTop1: 4.688 (avg: 2.656)\tTop5: 10.938 (avg: 10.172)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.444 (avg: 0.447)\tLoss: 4.7189 (avg: 4.9662)\tTop1: 4.688 (avg: 2.663)\tTop5: 9.375 (avg: 10.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6372\tTop 1 accuracy: 3.400\tTop 5 accuracy: 12.450\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.443 (avg: 0.438)\tLoss: 4.8810 (avg: 4.9310)\tTop1: 0.000 (avg: 2.688)\tTop5: 9.375 (avg: 11.125)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.448 (avg: 0.444)\tLoss: 4.9079 (avg: 4.9143)\tTop1: 1.562 (avg: 3.312)\tTop5: 12.500 (avg: 11.156)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.444 (avg: 0.446)\tLoss: 4.8773 (avg: 4.9066)\tTop1: 3.125 (avg: 2.958)\tTop5: 12.500 (avg: 11.125)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.444 (avg: 0.447)\tLoss: 4.8433 (avg: 4.8890)\tTop1: 7.812 (avg: 3.188)\tTop5: 15.625 (avg: 11.547)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.446 (avg: 0.447)\tLoss: 4.9300 (avg: 4.8942)\tTop1: 1.562 (avg: 3.038)\tTop5: 7.812 (avg: 11.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8255\tTop 1 accuracy: 2.900\tTop 5 accuracy: 11.500\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.442 (avg: 0.439)\tLoss: 4.6725 (avg: 4.8333)\tTop1: 3.125 (avg: 3.312)\tTop5: 15.625 (avg: 13.500)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.441 (avg: 0.444)\tLoss: 5.0091 (avg: 4.8138)\tTop1: 4.688 (avg: 3.531)\tTop5: 10.938 (avg: 13.562)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.447 (avg: 0.446)\tLoss: 4.5959 (avg: 4.8155)\tTop1: 7.812 (avg: 3.458)\tTop5: 17.188 (avg: 13.271)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.445 (avg: 0.448)\tLoss: 4.9111 (avg: 4.8134)\tTop1: 1.562 (avg: 3.391)\tTop5: 17.188 (avg: 13.328)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.439 (avg: 0.448)\tLoss: 4.3262 (avg: 4.8198)\tTop1: 3.125 (avg: 3.488)\tTop5: 25.000 (avg: 13.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4434\tTop 1 accuracy: 4.500\tTop 5 accuracy: 15.100\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.445 (avg: 0.439)\tLoss: 4.6148 (avg: 4.7345)\tTop1: 6.250 (avg: 4.688)\tTop5: 12.500 (avg: 15.375)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.442 (avg: 0.444)\tLoss: 5.0334 (avg: 4.7786)\tTop1: 1.562 (avg: 4.562)\tTop5: 7.812 (avg: 14.406)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.441 (avg: 0.446)\tLoss: 4.8306 (avg: 4.7767)\tTop1: 3.125 (avg: 4.458)\tTop5: 14.062 (avg: 14.688)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.450 (avg: 0.447)\tLoss: 4.6329 (avg: 4.7662)\tTop1: 9.375 (avg: 4.453)\tTop5: 17.188 (avg: 14.844)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.444 (avg: 0.448)\tLoss: 4.6667 (avg: 4.7622)\tTop1: 4.688 (avg: 4.375)\tTop5: 20.312 (avg: 15.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5608\tTop 1 accuracy: 4.350\tTop 5 accuracy: 16.050\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.445 (avg: 0.439)\tLoss: 4.7025 (avg: 4.7103)\tTop1: 3.125 (avg: 4.188)\tTop5: 15.625 (avg: 15.938)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.443 (avg: 0.444)\tLoss: 4.7340 (avg: 4.7168)\tTop1: 6.250 (avg: 4.406)\tTop5: 14.062 (avg: 15.844)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.437 (avg: 0.446)\tLoss: 4.7614 (avg: 4.7137)\tTop1: 6.250 (avg: 4.188)\tTop5: 14.062 (avg: 15.458)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.440 (avg: 0.447)\tLoss: 4.9035 (avg: 4.7223)\tTop1: 3.125 (avg: 4.219)\tTop5: 7.812 (avg: 15.484)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.443 (avg: 0.448)\tLoss: 4.6868 (avg: 4.7067)\tTop1: 3.125 (avg: 4.500)\tTop5: 23.438 (avg: 15.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6390\tTop 1 accuracy: 5.100\tTop 5 accuracy: 16.800\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.441 (avg: 0.439)\tLoss: 4.8521 (avg: 4.6787)\tTop1: 4.688 (avg: 4.875)\tTop5: 7.812 (avg: 16.875)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.440 (avg: 0.444)\tLoss: 4.7340 (avg: 4.6762)\tTop1: 4.688 (avg: 4.781)\tTop5: 20.312 (avg: 17.000)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.442 (avg: 0.446)\tLoss: 4.5074 (avg: 4.6841)\tTop1: 4.688 (avg: 4.792)\tTop5: 12.500 (avg: 16.896)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.441 (avg: 0.447)\tLoss: 4.6950 (avg: 4.6823)\tTop1: 4.688 (avg: 4.547)\tTop5: 17.188 (avg: 16.688)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.440 (avg: 0.447)\tLoss: 4.6737 (avg: 4.6632)\tTop1: 1.562 (avg: 4.725)\tTop5: 15.625 (avg: 17.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2862\tTop 1 accuracy: 5.500\tTop 5 accuracy: 17.000\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.440 (avg: 0.439)\tLoss: 4.7463 (avg: 4.6133)\tTop1: 4.688 (avg: 5.250)\tTop5: 15.625 (avg: 18.938)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.440 (avg: 0.444)\tLoss: 4.7070 (avg: 4.6439)\tTop1: 4.688 (avg: 5.312)\tTop5: 23.438 (avg: 18.344)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.441 (avg: 0.446)\tLoss: 4.6089 (avg: 4.6463)\tTop1: 7.812 (avg: 5.208)\tTop5: 21.875 (avg: 17.958)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.447 (avg: 0.447)\tLoss: 4.4968 (avg: 4.6351)\tTop1: 7.812 (avg: 5.359)\tTop5: 21.875 (avg: 18.078)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.441 (avg: 0.447)\tLoss: 4.5097 (avg: 4.6163)\tTop1: 6.250 (avg: 5.475)\tTop5: 23.438 (avg: 18.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5967\tTop 1 accuracy: 5.250\tTop 5 accuracy: 17.100\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.446 (avg: 0.439)\tLoss: 4.8858 (avg: 4.5692)\tTop1: 1.562 (avg: 5.875)\tTop5: 15.625 (avg: 20.125)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.442 (avg: 0.444)\tLoss: 4.1439 (avg: 4.5186)\tTop1: 10.938 (avg: 6.125)\tTop5: 34.375 (avg: 21.188)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.445 (avg: 0.446)\tLoss: 4.7582 (avg: 4.5390)\tTop1: 6.250 (avg: 5.688)\tTop5: 17.188 (avg: 20.271)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.451 (avg: 0.447)\tLoss: 4.4097 (avg: 4.5458)\tTop1: 10.938 (avg: 5.734)\tTop5: 25.000 (avg: 19.828)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.445 (avg: 0.448)\tLoss: 4.6058 (avg: 4.5511)\tTop1: 3.125 (avg: 5.788)\tTop5: 10.938 (avg: 19.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3061\tTop 1 accuracy: 5.450\tTop 5 accuracy: 19.800\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.444 (avg: 0.440)\tLoss: 4.2517 (avg: 4.4020)\tTop1: 9.375 (avg: 6.812)\tTop5: 29.688 (avg: 24.000)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.444 (avg: 0.445)\tLoss: 4.3118 (avg: 4.3491)\tTop1: 9.375 (avg: 8.031)\tTop5: 23.438 (avg: 24.750)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.441 (avg: 0.447)\tLoss: 4.1443 (avg: 4.3358)\tTop1: 1.562 (avg: 8.542)\tTop5: 26.562 (avg: 25.562)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.446 (avg: 0.447)\tLoss: 4.2890 (avg: 4.3121)\tTop1: 12.500 (avg: 8.891)\tTop5: 31.250 (avg: 26.344)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.445 (avg: 0.448)\tLoss: 4.4483 (avg: 4.3048)\tTop1: 7.812 (avg: 8.925)\tTop5: 18.750 (avg: 26.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9668\tTop 1 accuracy: 7.900\tTop 5 accuracy: 22.950\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.443 (avg: 0.439)\tLoss: 4.3388 (avg: 4.2498)\tTop1: 9.375 (avg: 9.250)\tTop5: 25.000 (avg: 27.625)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.443 (avg: 0.445)\tLoss: 4.0435 (avg: 4.2331)\tTop1: 14.062 (avg: 10.281)\tTop5: 29.688 (avg: 28.250)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.444 (avg: 0.447)\tLoss: 4.5469 (avg: 4.2400)\tTop1: 9.375 (avg: 10.271)\tTop5: 25.000 (avg: 28.312)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.441 (avg: 0.447)\tLoss: 4.5308 (avg: 4.2345)\tTop1: 6.250 (avg: 10.156)\tTop5: 26.562 (avg: 28.469)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.441 (avg: 0.448)\tLoss: 4.2906 (avg: 4.2354)\tTop1: 12.500 (avg: 10.113)\tTop5: 34.375 (avg: 28.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0299\tTop 1 accuracy: 8.650\tTop 5 accuracy: 25.050\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.441 (avg: 0.438)\tLoss: 4.5913 (avg: 4.1629)\tTop1: 4.688 (avg: 11.125)\tTop5: 14.062 (avg: 29.625)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.442 (avg: 0.444)\tLoss: 4.3899 (avg: 4.1749)\tTop1: 9.375 (avg: 11.031)\tTop5: 23.438 (avg: 29.750)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.443 (avg: 0.446)\tLoss: 3.9758 (avg: 4.2026)\tTop1: 15.625 (avg: 10.625)\tTop5: 32.812 (avg: 29.688)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.444 (avg: 0.447)\tLoss: 4.1713 (avg: 4.2137)\tTop1: 9.375 (avg: 10.281)\tTop5: 28.125 (avg: 29.453)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.440 (avg: 0.448)\tLoss: 4.3914 (avg: 4.2019)\tTop1: 9.375 (avg: 10.538)\tTop5: 29.688 (avg: 29.650)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9660\tTop 1 accuracy: 8.700\tTop 5 accuracy: 25.300\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.444 (avg: 0.439)\tLoss: 4.3691 (avg: 4.1730)\tTop1: 18.750 (avg: 11.250)\tTop5: 35.938 (avg: 30.312)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.446 (avg: 0.444)\tLoss: 4.5286 (avg: 4.1880)\tTop1: 10.938 (avg: 10.469)\tTop5: 20.312 (avg: 29.031)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.445 (avg: 0.446)\tLoss: 4.0324 (avg: 4.1845)\tTop1: 10.938 (avg: 10.729)\tTop5: 35.938 (avg: 29.333)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.442 (avg: 0.447)\tLoss: 3.8611 (avg: 4.1765)\tTop1: 17.188 (avg: 10.750)\tTop5: 40.625 (avg: 29.672)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.444 (avg: 0.448)\tLoss: 4.0318 (avg: 4.1807)\tTop1: 9.375 (avg: 10.475)\tTop5: 34.375 (avg: 29.563)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9887\tTop 1 accuracy: 8.750\tTop 5 accuracy: 25.300\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.444 (avg: 0.439)\tLoss: 3.9926 (avg: 4.1295)\tTop1: 14.062 (avg: 11.938)\tTop5: 32.812 (avg: 31.688)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.445 (avg: 0.444)\tLoss: 4.2473 (avg: 4.1485)\tTop1: 3.125 (avg: 11.406)\tTop5: 23.438 (avg: 30.312)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.442 (avg: 0.446)\tLoss: 4.2818 (avg: 4.1680)\tTop1: 7.812 (avg: 10.521)\tTop5: 29.688 (avg: 29.708)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.439 (avg: 0.447)\tLoss: 4.0966 (avg: 4.1622)\tTop1: 9.375 (avg: 10.766)\tTop5: 28.125 (avg: 29.859)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.438 (avg: 0.448)\tLoss: 3.8387 (avg: 4.1682)\tTop1: 12.500 (avg: 10.525)\tTop5: 39.062 (avg: 29.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0281\tTop 1 accuracy: 9.050\tTop 5 accuracy: 25.850\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.443 (avg: 0.440)\tLoss: 3.9184 (avg: 4.2196)\tTop1: 12.500 (avg: 11.375)\tTop5: 35.938 (avg: 30.000)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.449 (avg: 0.445)\tLoss: 3.9335 (avg: 4.1455)\tTop1: 12.500 (avg: 11.688)\tTop5: 32.812 (avg: 31.469)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.444 (avg: 0.447)\tLoss: 4.0396 (avg: 4.1505)\tTop1: 10.938 (avg: 11.667)\tTop5: 32.812 (avg: 30.979)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.442 (avg: 0.448)\tLoss: 4.3066 (avg: 4.1539)\tTop1: 12.500 (avg: 11.391)\tTop5: 26.562 (avg: 30.406)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.447 (avg: 0.449)\tLoss: 3.7652 (avg: 4.1413)\tTop1: 18.750 (avg: 11.538)\tTop5: 39.062 (avg: 30.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8765\tTop 1 accuracy: 8.550\tTop 5 accuracy: 25.300\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.439 (avg: 0.440)\tLoss: 4.1120 (avg: 4.0938)\tTop1: 4.688 (avg: 10.375)\tTop5: 31.250 (avg: 31.000)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.442 (avg: 0.446)\tLoss: 4.3354 (avg: 4.1022)\tTop1: 10.938 (avg: 10.469)\tTop5: 26.562 (avg: 31.094)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.450 (avg: 0.449)\tLoss: 4.1693 (avg: 4.1034)\tTop1: 4.688 (avg: 10.917)\tTop5: 23.438 (avg: 30.854)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 4.3096 (avg: 4.1325)\tTop1: 14.062 (avg: 10.562)\tTop5: 26.562 (avg: 30.156)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.447 (avg: 0.451)\tLoss: 4.2123 (avg: 4.1343)\tTop1: 9.375 (avg: 10.675)\tTop5: 26.562 (avg: 30.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0446\tTop 1 accuracy: 8.800\tTop 5 accuracy: 25.100\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.446 (avg: 0.442)\tLoss: 3.8356 (avg: 4.0596)\tTop1: 15.625 (avg: 12.250)\tTop5: 39.062 (avg: 32.438)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.441 (avg: 0.448)\tLoss: 4.5480 (avg: 4.0942)\tTop1: 1.562 (avg: 12.000)\tTop5: 17.188 (avg: 31.719)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.447 (avg: 0.450)\tLoss: 4.0077 (avg: 4.0938)\tTop1: 17.188 (avg: 11.708)\tTop5: 34.375 (avg: 31.958)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.451 (avg: 0.451)\tLoss: 4.3644 (avg: 4.1047)\tTop1: 7.812 (avg: 11.281)\tTop5: 25.000 (avg: 31.234)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 4.3086 (avg: 4.1188)\tTop1: 7.812 (avg: 11.150)\tTop5: 26.562 (avg: 30.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9041\tTop 1 accuracy: 8.950\tTop 5 accuracy: 25.400\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.448 (avg: 0.442)\tLoss: 4.2360 (avg: 4.1225)\tTop1: 9.375 (avg: 11.375)\tTop5: 28.125 (avg: 31.688)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.454 (avg: 0.447)\tLoss: 4.1091 (avg: 4.1188)\tTop1: 15.625 (avg: 11.375)\tTop5: 34.375 (avg: 31.312)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.444 (avg: 0.450)\tLoss: 4.1722 (avg: 4.1104)\tTop1: 15.625 (avg: 11.833)\tTop5: 21.875 (avg: 31.417)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.446 (avg: 0.451)\tLoss: 3.9336 (avg: 4.1137)\tTop1: 12.500 (avg: 11.844)\tTop5: 37.500 (avg: 31.359)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.450 (avg: 0.452)\tLoss: 4.4167 (avg: 4.0992)\tTop1: 3.125 (avg: 11.788)\tTop5: 17.188 (avg: 31.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1132\tTop 1 accuracy: 9.150\tTop 5 accuracy: 26.750\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.438 (avg: 0.443)\tLoss: 4.0642 (avg: 4.0421)\tTop1: 10.938 (avg: 11.812)\tTop5: 29.688 (avg: 33.500)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.447 (avg: 0.447)\tLoss: 3.9946 (avg: 4.0678)\tTop1: 14.062 (avg: 11.531)\tTop5: 32.812 (avg: 32.094)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.448 (avg: 0.448)\tLoss: 3.7882 (avg: 4.0885)\tTop1: 14.062 (avg: 11.292)\tTop5: 34.375 (avg: 31.729)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.441 (avg: 0.449)\tLoss: 4.4254 (avg: 4.0845)\tTop1: 10.938 (avg: 11.453)\tTop5: 23.438 (avg: 32.062)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.445 (avg: 0.449)\tLoss: 4.2326 (avg: 4.0928)\tTop1: 9.375 (avg: 11.500)\tTop5: 29.688 (avg: 31.563)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1029\tTop 1 accuracy: 8.750\tTop 5 accuracy: 26.450\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.443 (avg: 0.440)\tLoss: 4.1714 (avg: 4.0485)\tTop1: 4.688 (avg: 12.625)\tTop5: 31.250 (avg: 33.625)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.439 (avg: 0.446)\tLoss: 4.4384 (avg: 4.0642)\tTop1: 10.938 (avg: 11.688)\tTop5: 25.000 (avg: 32.875)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.443 (avg: 0.447)\tLoss: 3.8520 (avg: 4.0673)\tTop1: 10.938 (avg: 11.771)\tTop5: 43.750 (avg: 32.979)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.447 (avg: 0.448)\tLoss: 4.0331 (avg: 4.0570)\tTop1: 9.375 (avg: 12.031)\tTop5: 35.938 (avg: 32.938)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.440 (avg: 0.449)\tLoss: 4.2091 (avg: 4.0756)\tTop1: 9.375 (avg: 11.775)\tTop5: 32.812 (avg: 32.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0353\tTop 1 accuracy: 8.300\tTop 5 accuracy: 26.000\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.449 (avg: 0.440)\tLoss: 3.9838 (avg: 4.0552)\tTop1: 18.750 (avg: 12.438)\tTop5: 35.938 (avg: 32.875)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.444 (avg: 0.445)\tLoss: 4.1350 (avg: 4.0790)\tTop1: 9.375 (avg: 11.594)\tTop5: 31.250 (avg: 31.625)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.442 (avg: 0.447)\tLoss: 4.1358 (avg: 4.0577)\tTop1: 9.375 (avg: 12.375)\tTop5: 34.375 (avg: 32.688)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.447 (avg: 0.448)\tLoss: 4.0742 (avg: 4.0593)\tTop1: 7.812 (avg: 12.188)\tTop5: 31.250 (avg: 32.312)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.446 (avg: 0.449)\tLoss: 3.9379 (avg: 4.0588)\tTop1: 12.500 (avg: 12.063)\tTop5: 37.500 (avg: 32.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9960\tTop 1 accuracy: 9.950\tTop 5 accuracy: 26.900\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.442 (avg: 0.440)\tLoss: 3.9059 (avg: 4.0407)\tTop1: 14.062 (avg: 13.062)\tTop5: 29.688 (avg: 32.062)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.445 (avg: 0.445)\tLoss: 4.4434 (avg: 4.0612)\tTop1: 12.500 (avg: 12.156)\tTop5: 23.438 (avg: 31.750)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.438 (avg: 0.447)\tLoss: 4.1751 (avg: 4.0621)\tTop1: 10.938 (avg: 12.354)\tTop5: 31.250 (avg: 32.104)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.443 (avg: 0.448)\tLoss: 4.2976 (avg: 4.0633)\tTop1: 4.688 (avg: 11.891)\tTop5: 31.250 (avg: 31.906)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.449 (avg: 0.448)\tLoss: 4.1250 (avg: 4.0500)\tTop1: 10.938 (avg: 12.225)\tTop5: 28.125 (avg: 32.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6756\tTop 1 accuracy: 9.400\tTop 5 accuracy: 26.150\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.447 (avg: 0.440)\tLoss: 4.1455 (avg: 3.9798)\tTop1: 10.938 (avg: 13.375)\tTop5: 28.125 (avg: 34.125)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.443 (avg: 0.445)\tLoss: 4.0254 (avg: 4.0107)\tTop1: 10.938 (avg: 13.062)\tTop5: 32.812 (avg: 33.500)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.441 (avg: 0.447)\tLoss: 3.9920 (avg: 4.0270)\tTop1: 15.625 (avg: 13.104)\tTop5: 34.375 (avg: 33.042)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.447 (avg: 0.448)\tLoss: 4.3168 (avg: 4.0372)\tTop1: 14.062 (avg: 12.594)\tTop5: 29.688 (avg: 33.047)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.443 (avg: 0.448)\tLoss: 4.1339 (avg: 4.0328)\tTop1: 12.500 (avg: 12.638)\tTop5: 34.375 (avg: 32.950)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0664\tTop 1 accuracy: 9.750\tTop 5 accuracy: 26.000\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.445 (avg: 0.439)\tLoss: 4.0619 (avg: 3.9501)\tTop1: 9.375 (avg: 12.625)\tTop5: 35.938 (avg: 36.188)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.445 (avg: 0.445)\tLoss: 4.4222 (avg: 3.9934)\tTop1: 1.562 (avg: 12.812)\tTop5: 20.312 (avg: 34.250)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.447 (avg: 0.447)\tLoss: 4.0752 (avg: 4.0223)\tTop1: 10.938 (avg: 12.417)\tTop5: 35.938 (avg: 33.125)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.445 (avg: 0.448)\tLoss: 4.2413 (avg: 4.0404)\tTop1: 9.375 (avg: 12.297)\tTop5: 23.438 (avg: 32.859)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.445 (avg: 0.448)\tLoss: 3.9155 (avg: 4.0347)\tTop1: 12.500 (avg: 12.263)\tTop5: 39.062 (avg: 32.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1097\tTop 1 accuracy: 10.100\tTop 5 accuracy: 27.550\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.449 (avg: 0.440)\tLoss: 4.0795 (avg: 3.9434)\tTop1: 10.938 (avg: 14.000)\tTop5: 37.500 (avg: 35.188)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.441 (avg: 0.445)\tLoss: 4.1337 (avg: 3.9675)\tTop1: 6.250 (avg: 12.781)\tTop5: 34.375 (avg: 34.562)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.438 (avg: 0.447)\tLoss: 4.0777 (avg: 3.9883)\tTop1: 14.062 (avg: 12.604)\tTop5: 29.688 (avg: 34.292)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.447 (avg: 0.448)\tLoss: 3.7179 (avg: 3.9968)\tTop1: 18.750 (avg: 12.531)\tTop5: 48.438 (avg: 34.344)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.442 (avg: 0.449)\tLoss: 4.1143 (avg: 3.9992)\tTop1: 14.062 (avg: 12.588)\tTop5: 25.000 (avg: 33.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8880\tTop 1 accuracy: 10.550\tTop 5 accuracy: 27.450\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.445 (avg: 0.441)\tLoss: 3.9554 (avg: 3.9565)\tTop1: 14.062 (avg: 13.125)\tTop5: 25.000 (avg: 34.750)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.445 (avg: 0.446)\tLoss: 3.8541 (avg: 3.9879)\tTop1: 18.750 (avg: 12.531)\tTop5: 28.125 (avg: 33.969)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.444 (avg: 0.448)\tLoss: 3.9220 (avg: 3.9830)\tTop1: 15.625 (avg: 12.750)\tTop5: 31.250 (avg: 33.917)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.448 (avg: 0.449)\tLoss: 3.5791 (avg: 3.9860)\tTop1: 25.000 (avg: 12.859)\tTop5: 45.312 (avg: 33.906)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.447 (avg: 0.449)\tLoss: 3.6579 (avg: 3.9863)\tTop1: 23.438 (avg: 12.800)\tTop5: 45.312 (avg: 33.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9349\tTop 1 accuracy: 9.650\tTop 5 accuracy: 27.150\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.441 (avg: 0.440)\tLoss: 4.1055 (avg: 3.9228)\tTop1: 6.250 (avg: 13.188)\tTop5: 32.812 (avg: 34.875)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.446 (avg: 0.446)\tLoss: 4.0441 (avg: 3.9671)\tTop1: 7.812 (avg: 13.031)\tTop5: 23.438 (avg: 33.969)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.445 (avg: 0.447)\tLoss: 4.0668 (avg: 3.9846)\tTop1: 6.250 (avg: 12.750)\tTop5: 28.125 (avg: 34.021)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.439 (avg: 0.448)\tLoss: 3.8631 (avg: 3.9904)\tTop1: 15.625 (avg: 12.625)\tTop5: 34.375 (avg: 33.578)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.446 (avg: 0.449)\tLoss: 3.7700 (avg: 3.9877)\tTop1: 17.188 (avg: 12.638)\tTop5: 35.938 (avg: 33.812)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8494\tTop 1 accuracy: 9.550\tTop 5 accuracy: 27.200\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.434 (avg: 0.439)\tLoss: 4.0999 (avg: 3.9347)\tTop1: 17.188 (avg: 13.812)\tTop5: 34.375 (avg: 35.938)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.447 (avg: 0.444)\tLoss: 3.8802 (avg: 3.9734)\tTop1: 17.188 (avg: 13.281)\tTop5: 35.938 (avg: 34.594)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.446 (avg: 0.446)\tLoss: 3.9313 (avg: 3.9574)\tTop1: 12.500 (avg: 13.125)\tTop5: 35.938 (avg: 34.938)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.447 (avg: 0.448)\tLoss: 3.8287 (avg: 3.9599)\tTop1: 14.062 (avg: 13.203)\tTop5: 40.625 (avg: 35.094)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.443 (avg: 0.448)\tLoss: 4.2032 (avg: 3.9621)\tTop1: 6.250 (avg: 13.200)\tTop5: 18.750 (avg: 34.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1944\tTop 1 accuracy: 9.150\tTop 5 accuracy: 26.350\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.444 (avg: 0.440)\tLoss: 3.7054 (avg: 3.9682)\tTop1: 14.062 (avg: 12.875)\tTop5: 43.750 (avg: 34.812)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.440 (avg: 0.445)\tLoss: 4.0408 (avg: 3.9214)\tTop1: 15.625 (avg: 13.781)\tTop5: 29.688 (avg: 35.375)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.445 (avg: 0.447)\tLoss: 3.7889 (avg: 3.9426)\tTop1: 17.188 (avg: 13.708)\tTop5: 45.312 (avg: 34.958)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.449 (avg: 0.448)\tLoss: 4.0239 (avg: 3.9599)\tTop1: 7.812 (avg: 13.562)\tTop5: 29.688 (avg: 34.266)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.442 (avg: 0.449)\tLoss: 3.9517 (avg: 3.9658)\tTop1: 15.625 (avg: 13.363)\tTop5: 35.938 (avg: 34.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8466\tTop 1 accuracy: 9.900\tTop 5 accuracy: 28.450\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.444 (avg: 0.440)\tLoss: 3.5496 (avg: 3.9150)\tTop1: 18.750 (avg: 14.188)\tTop5: 42.188 (avg: 36.438)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.445 (avg: 0.445)\tLoss: 3.9170 (avg: 3.9465)\tTop1: 17.188 (avg: 13.219)\tTop5: 35.938 (avg: 34.938)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.445 (avg: 0.447)\tLoss: 3.5880 (avg: 3.9326)\tTop1: 21.875 (avg: 13.083)\tTop5: 46.875 (avg: 34.917)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.442 (avg: 0.448)\tLoss: 3.6996 (avg: 3.9349)\tTop1: 18.750 (avg: 13.156)\tTop5: 35.938 (avg: 34.969)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.445 (avg: 0.449)\tLoss: 4.0726 (avg: 3.9438)\tTop1: 6.250 (avg: 13.175)\tTop5: 29.688 (avg: 34.950)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8099\tTop 1 accuracy: 10.750\tTop 5 accuracy: 28.600\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.442 (avg: 0.440)\tLoss: 3.8854 (avg: 3.8666)\tTop1: 7.812 (avg: 13.500)\tTop5: 35.938 (avg: 36.750)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.447 (avg: 0.445)\tLoss: 3.8036 (avg: 3.8761)\tTop1: 7.812 (avg: 13.844)\tTop5: 32.812 (avg: 36.594)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.446 (avg: 0.447)\tLoss: 3.8888 (avg: 3.8879)\tTop1: 9.375 (avg: 13.646)\tTop5: 35.938 (avg: 36.229)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.441 (avg: 0.448)\tLoss: 3.6966 (avg: 3.9096)\tTop1: 23.438 (avg: 13.609)\tTop5: 37.500 (avg: 35.594)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.441 (avg: 0.449)\tLoss: 4.2812 (avg: 3.9198)\tTop1: 10.938 (avg: 13.450)\tTop5: 29.688 (avg: 35.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0368\tTop 1 accuracy: 10.050\tTop 5 accuracy: 27.350\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.443 (avg: 0.440)\tLoss: 4.0029 (avg: 3.8888)\tTop1: 17.188 (avg: 14.375)\tTop5: 35.938 (avg: 35.750)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.443 (avg: 0.445)\tLoss: 3.9749 (avg: 3.9209)\tTop1: 14.062 (avg: 13.094)\tTop5: 37.500 (avg: 34.781)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.443 (avg: 0.447)\tLoss: 3.6852 (avg: 3.9139)\tTop1: 17.188 (avg: 13.521)\tTop5: 40.625 (avg: 35.438)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.451 (avg: 0.448)\tLoss: 4.3426 (avg: 3.9070)\tTop1: 12.500 (avg: 13.453)\tTop5: 26.562 (avg: 35.781)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.445 (avg: 0.448)\tLoss: 3.7886 (avg: 3.9087)\tTop1: 14.062 (avg: 13.638)\tTop5: 35.938 (avg: 35.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0075\tTop 1 accuracy: 10.100\tTop 5 accuracy: 28.200\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.445 (avg: 0.440)\tLoss: 3.6193 (avg: 3.8605)\tTop1: 18.750 (avg: 15.688)\tTop5: 45.312 (avg: 36.125)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.447 (avg: 0.446)\tLoss: 3.6497 (avg: 3.8643)\tTop1: 17.188 (avg: 14.875)\tTop5: 45.312 (avg: 36.219)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.438 (avg: 0.447)\tLoss: 3.9889 (avg: 3.8976)\tTop1: 9.375 (avg: 14.000)\tTop5: 28.125 (avg: 35.438)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.449 (avg: 0.448)\tLoss: 3.7425 (avg: 3.8980)\tTop1: 17.188 (avg: 14.078)\tTop5: 39.062 (avg: 35.641)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.448 (avg: 0.449)\tLoss: 3.9969 (avg: 3.8947)\tTop1: 14.062 (avg: 14.388)\tTop5: 31.250 (avg: 35.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1506\tTop 1 accuracy: 10.500\tTop 5 accuracy: 28.550\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.452 (avg: 0.440)\tLoss: 4.0775 (avg: 3.8361)\tTop1: 10.938 (avg: 14.438)\tTop5: 26.562 (avg: 38.625)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.445 (avg: 0.445)\tLoss: 3.8054 (avg: 3.8696)\tTop1: 12.500 (avg: 14.625)\tTop5: 37.500 (avg: 36.594)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.441 (avg: 0.447)\tLoss: 4.0846 (avg: 3.8816)\tTop1: 9.375 (avg: 14.083)\tTop5: 21.875 (avg: 35.938)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.439 (avg: 0.448)\tLoss: 4.0544 (avg: 3.8786)\tTop1: 10.938 (avg: 13.859)\tTop5: 29.688 (avg: 35.750)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.444 (avg: 0.449)\tLoss: 4.0465 (avg: 3.8788)\tTop1: 14.062 (avg: 13.950)\tTop5: 35.938 (avg: 35.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9586\tTop 1 accuracy: 10.550\tTop 5 accuracy: 29.500\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.439 (avg: 0.440)\tLoss: 4.0490 (avg: 3.8804)\tTop1: 10.938 (avg: 14.312)\tTop5: 29.688 (avg: 36.625)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.444 (avg: 0.445)\tLoss: 3.8538 (avg: 3.8879)\tTop1: 20.312 (avg: 13.781)\tTop5: 40.625 (avg: 36.281)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.445 (avg: 0.447)\tLoss: 3.8150 (avg: 3.8665)\tTop1: 14.062 (avg: 14.021)\tTop5: 35.938 (avg: 36.333)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.440 (avg: 0.448)\tLoss: 3.8216 (avg: 3.8740)\tTop1: 17.188 (avg: 14.234)\tTop5: 37.500 (avg: 36.016)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.443 (avg: 0.449)\tLoss: 4.1265 (avg: 3.8827)\tTop1: 6.250 (avg: 14.188)\tTop5: 25.000 (avg: 35.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8336\tTop 1 accuracy: 10.600\tTop 5 accuracy: 28.800\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.446 (avg: 0.440)\tLoss: 3.3691 (avg: 3.8729)\tTop1: 23.438 (avg: 15.188)\tTop5: 46.875 (avg: 36.062)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.443 (avg: 0.446)\tLoss: 3.9703 (avg: 3.8697)\tTop1: 15.625 (avg: 14.812)\tTop5: 31.250 (avg: 35.500)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.449 (avg: 0.448)\tLoss: 3.9316 (avg: 3.8523)\tTop1: 18.750 (avg: 15.167)\tTop5: 31.250 (avg: 36.354)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.447 (avg: 0.449)\tLoss: 3.7249 (avg: 3.8568)\tTop1: 14.062 (avg: 14.688)\tTop5: 35.938 (avg: 36.328)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.444 (avg: 0.449)\tLoss: 4.0514 (avg: 3.8625)\tTop1: 14.062 (avg: 14.488)\tTop5: 32.812 (avg: 36.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0647\tTop 1 accuracy: 11.000\tTop 5 accuracy: 29.500\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.440 (avg: 0.440)\tLoss: 3.8746 (avg: 3.7196)\tTop1: 14.062 (avg: 16.625)\tTop5: 32.812 (avg: 40.188)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.443 (avg: 0.446)\tLoss: 3.8395 (avg: 3.7956)\tTop1: 18.750 (avg: 15.875)\tTop5: 42.188 (avg: 38.812)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.442 (avg: 0.447)\tLoss: 3.9567 (avg: 3.8401)\tTop1: 17.188 (avg: 14.938)\tTop5: 35.938 (avg: 37.354)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.441 (avg: 0.448)\tLoss: 3.4735 (avg: 3.8428)\tTop1: 17.188 (avg: 14.594)\tTop5: 43.750 (avg: 37.062)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.445 (avg: 0.449)\tLoss: 3.8973 (avg: 3.8515)\tTop1: 7.812 (avg: 14.475)\tTop5: 29.688 (avg: 36.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8179\tTop 1 accuracy: 10.850\tTop 5 accuracy: 29.600\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.445 (avg: 0.439)\tLoss: 3.9250 (avg: 3.8035)\tTop1: 14.062 (avg: 16.875)\tTop5: 31.250 (avg: 38.000)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.446 (avg: 0.445)\tLoss: 3.6667 (avg: 3.8492)\tTop1: 9.375 (avg: 15.562)\tTop5: 37.500 (avg: 37.125)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.442 (avg: 0.447)\tLoss: 3.6734 (avg: 3.8435)\tTop1: 12.500 (avg: 15.021)\tTop5: 31.250 (avg: 37.167)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.444 (avg: 0.448)\tLoss: 3.8861 (avg: 3.8172)\tTop1: 10.938 (avg: 15.422)\tTop5: 43.750 (avg: 37.891)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.444 (avg: 0.449)\tLoss: 3.6492 (avg: 3.8310)\tTop1: 20.312 (avg: 15.050)\tTop5: 39.062 (avg: 37.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8677\tTop 1 accuracy: 11.650\tTop 5 accuracy: 29.900\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.443 (avg: 0.440)\tLoss: 4.0228 (avg: 3.8214)\tTop1: 10.938 (avg: 15.312)\tTop5: 31.250 (avg: 38.000)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.442 (avg: 0.445)\tLoss: 3.9321 (avg: 3.8165)\tTop1: 10.938 (avg: 15.438)\tTop5: 37.500 (avg: 38.188)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.444 (avg: 0.447)\tLoss: 3.4129 (avg: 3.8198)\tTop1: 20.312 (avg: 15.229)\tTop5: 46.875 (avg: 38.562)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.445 (avg: 0.448)\tLoss: 3.9182 (avg: 3.8223)\tTop1: 15.625 (avg: 15.281)\tTop5: 37.500 (avg: 38.156)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.438 (avg: 0.448)\tLoss: 3.5870 (avg: 3.8155)\tTop1: 20.312 (avg: 15.350)\tTop5: 48.438 (avg: 37.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7988\tTop 1 accuracy: 12.000\tTop 5 accuracy: 30.100\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.443 (avg: 0.439)\tLoss: 3.7497 (avg: 3.7244)\tTop1: 18.750 (avg: 16.500)\tTop5: 46.875 (avg: 40.625)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.442 (avg: 0.445)\tLoss: 3.6954 (avg: 3.7325)\tTop1: 17.188 (avg: 16.438)\tTop5: 40.625 (avg: 40.531)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.438 (avg: 0.447)\tLoss: 3.5023 (avg: 3.7114)\tTop1: 17.188 (avg: 17.375)\tTop5: 45.312 (avg: 40.562)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.447 (avg: 0.448)\tLoss: 3.6182 (avg: 3.6971)\tTop1: 21.875 (avg: 17.484)\tTop5: 39.062 (avg: 41.078)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.445 (avg: 0.448)\tLoss: 3.4248 (avg: 3.6879)\tTop1: 21.875 (avg: 17.700)\tTop5: 46.875 (avg: 41.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8400\tTop 1 accuracy: 12.550\tTop 5 accuracy: 31.300\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.450 (avg: 0.440)\tLoss: 3.5277 (avg: 3.6818)\tTop1: 17.188 (avg: 17.062)\tTop5: 35.938 (avg: 40.875)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.442 (avg: 0.445)\tLoss: 3.5643 (avg: 3.6602)\tTop1: 23.438 (avg: 18.375)\tTop5: 46.875 (avg: 41.531)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.443 (avg: 0.447)\tLoss: 3.7173 (avg: 3.6550)\tTop1: 15.625 (avg: 18.292)\tTop5: 39.062 (avg: 41.688)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.449 (avg: 0.448)\tLoss: 3.8975 (avg: 3.6664)\tTop1: 10.938 (avg: 18.156)\tTop5: 35.938 (avg: 41.281)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.444 (avg: 0.449)\tLoss: 3.8628 (avg: 3.6625)\tTop1: 18.750 (avg: 17.988)\tTop5: 34.375 (avg: 41.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7857\tTop 1 accuracy: 12.500\tTop 5 accuracy: 31.650\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.440 (avg: 0.438)\tLoss: 3.9202 (avg: 3.6623)\tTop1: 12.500 (avg: 17.250)\tTop5: 39.062 (avg: 42.938)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.445 (avg: 0.445)\tLoss: 3.4351 (avg: 3.6279)\tTop1: 20.312 (avg: 18.219)\tTop5: 43.750 (avg: 43.219)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.442 (avg: 0.447)\tLoss: 3.4296 (avg: 3.6406)\tTop1: 29.688 (avg: 18.479)\tTop5: 50.000 (avg: 42.833)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.441 (avg: 0.448)\tLoss: 3.7613 (avg: 3.6480)\tTop1: 9.375 (avg: 18.031)\tTop5: 42.188 (avg: 42.438)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.445 (avg: 0.449)\tLoss: 3.7413 (avg: 3.6539)\tTop1: 17.188 (avg: 18.113)\tTop5: 42.188 (avg: 42.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7927\tTop 1 accuracy: 13.100\tTop 5 accuracy: 31.950\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.440 (avg: 0.439)\tLoss: 3.5912 (avg: 3.6153)\tTop1: 17.188 (avg: 18.188)\tTop5: 48.438 (avg: 42.500)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.449 (avg: 0.445)\tLoss: 3.2893 (avg: 3.6429)\tTop1: 31.250 (avg: 17.625)\tTop5: 53.125 (avg: 42.094)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.450 (avg: 0.447)\tLoss: 3.5137 (avg: 3.6238)\tTop1: 20.312 (avg: 18.438)\tTop5: 50.000 (avg: 42.583)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.440 (avg: 0.448)\tLoss: 3.4869 (avg: 3.6500)\tTop1: 20.312 (avg: 18.078)\tTop5: 48.438 (avg: 42.234)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.442 (avg: 0.448)\tLoss: 3.4495 (avg: 3.6526)\tTop1: 18.750 (avg: 18.062)\tTop5: 48.438 (avg: 42.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7988\tTop 1 accuracy: 13.350\tTop 5 accuracy: 32.100\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.440 (avg: 0.440)\tLoss: 3.6916 (avg: 3.6467)\tTop1: 17.188 (avg: 18.062)\tTop5: 45.312 (avg: 41.875)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.445 (avg: 0.446)\tLoss: 3.9262 (avg: 3.6156)\tTop1: 20.312 (avg: 18.969)\tTop5: 35.938 (avg: 42.562)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.443 (avg: 0.448)\tLoss: 3.7483 (avg: 3.6459)\tTop1: 25.000 (avg: 19.229)\tTop5: 37.500 (avg: 42.333)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.445 (avg: 0.448)\tLoss: 3.9594 (avg: 3.6479)\tTop1: 14.062 (avg: 19.000)\tTop5: 37.500 (avg: 42.391)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.446 (avg: 0.449)\tLoss: 3.3395 (avg: 3.6397)\tTop1: 23.438 (avg: 18.800)\tTop5: 46.875 (avg: 42.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7131\tTop 1 accuracy: 13.150\tTop 5 accuracy: 32.050\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.448 (avg: 0.439)\tLoss: 3.8552 (avg: 3.6398)\tTop1: 17.188 (avg: 17.812)\tTop5: 43.750 (avg: 43.000)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.443 (avg: 0.445)\tLoss: 3.6833 (avg: 3.6612)\tTop1: 15.625 (avg: 18.062)\tTop5: 42.188 (avg: 42.250)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.444 (avg: 0.447)\tLoss: 3.5686 (avg: 3.6337)\tTop1: 18.750 (avg: 18.917)\tTop5: 46.875 (avg: 42.167)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.451 (avg: 0.448)\tLoss: 3.4229 (avg: 3.6325)\tTop1: 28.125 (avg: 18.672)\tTop5: 45.312 (avg: 42.078)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.445 (avg: 0.449)\tLoss: 3.6427 (avg: 3.6418)\tTop1: 26.562 (avg: 18.438)\tTop5: 39.062 (avg: 42.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6960\tTop 1 accuracy: 13.150\tTop 5 accuracy: 32.250\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.446 (avg: 0.441)\tLoss: 3.7161 (avg: 3.6587)\tTop1: 18.750 (avg: 19.062)\tTop5: 45.312 (avg: 41.062)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.446 (avg: 0.446)\tLoss: 3.5147 (avg: 3.6526)\tTop1: 15.625 (avg: 18.594)\tTop5: 35.938 (avg: 40.969)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.445 (avg: 0.448)\tLoss: 3.7835 (avg: 3.6397)\tTop1: 18.750 (avg: 18.625)\tTop5: 48.438 (avg: 42.104)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.444 (avg: 0.449)\tLoss: 3.6241 (avg: 3.6382)\tTop1: 21.875 (avg: 18.672)\tTop5: 40.625 (avg: 42.375)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.445 (avg: 0.449)\tLoss: 3.5797 (avg: 3.6373)\tTop1: 20.312 (avg: 18.763)\tTop5: 42.188 (avg: 42.488)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8421\tTop 1 accuracy: 13.050\tTop 5 accuracy: 31.800\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.443 (avg: 0.440)\tLoss: 3.5206 (avg: 3.6321)\tTop1: 20.312 (avg: 19.750)\tTop5: 42.188 (avg: 43.000)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.445 (avg: 0.445)\tLoss: 4.0094 (avg: 3.6259)\tTop1: 17.188 (avg: 19.531)\tTop5: 37.500 (avg: 42.719)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.444 (avg: 0.447)\tLoss: 3.7080 (avg: 3.6027)\tTop1: 17.188 (avg: 19.292)\tTop5: 42.188 (avg: 43.188)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.446 (avg: 0.448)\tLoss: 3.7533 (avg: 3.6175)\tTop1: 18.750 (avg: 18.672)\tTop5: 45.312 (avg: 42.875)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.440 (avg: 0.449)\tLoss: 3.8547 (avg: 3.6316)\tTop1: 14.062 (avg: 18.700)\tTop5: 48.438 (avg: 42.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7454\tTop 1 accuracy: 13.200\tTop 5 accuracy: 32.250\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.443 (avg: 0.440)\tLoss: 3.6578 (avg: 3.6014)\tTop1: 21.875 (avg: 20.188)\tTop5: 45.312 (avg: 43.875)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.437 (avg: 0.445)\tLoss: 3.3168 (avg: 3.6474)\tTop1: 21.875 (avg: 18.969)\tTop5: 59.375 (avg: 42.500)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.448 (avg: 0.447)\tLoss: 3.5562 (avg: 3.6233)\tTop1: 25.000 (avg: 18.875)\tTop5: 43.750 (avg: 43.062)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.447 (avg: 0.448)\tLoss: 3.3939 (avg: 3.6234)\tTop1: 25.000 (avg: 18.844)\tTop5: 40.625 (avg: 43.062)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.440 (avg: 0.449)\tLoss: 3.5331 (avg: 3.6281)\tTop1: 14.062 (avg: 18.988)\tTop5: 50.000 (avg: 42.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8275\tTop 1 accuracy: 13.100\tTop 5 accuracy: 31.650\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.442 (avg: 0.440)\tLoss: 3.3650 (avg: 3.6055)\tTop1: 14.062 (avg: 18.875)\tTop5: 43.750 (avg: 43.938)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.441 (avg: 0.445)\tLoss: 3.5116 (avg: 3.6098)\tTop1: 20.312 (avg: 18.500)\tTop5: 39.062 (avg: 43.188)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.442 (avg: 0.447)\tLoss: 3.6093 (avg: 3.6150)\tTop1: 20.312 (avg: 18.708)\tTop5: 42.188 (avg: 43.479)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.441 (avg: 0.448)\tLoss: 3.6126 (avg: 3.6247)\tTop1: 17.188 (avg: 18.672)\tTop5: 32.812 (avg: 43.125)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.448 (avg: 0.449)\tLoss: 3.6467 (avg: 3.6270)\tTop1: 26.562 (avg: 18.588)\tTop5: 39.062 (avg: 42.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7215\tTop 1 accuracy: 13.350\tTop 5 accuracy: 32.200\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.446 (avg: 0.440)\tLoss: 3.7633 (avg: 3.6166)\tTop1: 10.938 (avg: 20.188)\tTop5: 39.062 (avg: 44.125)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.451 (avg: 0.446)\tLoss: 3.7757 (avg: 3.5927)\tTop1: 15.625 (avg: 19.500)\tTop5: 37.500 (avg: 44.312)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.439 (avg: 0.447)\tLoss: 3.6026 (avg: 3.6085)\tTop1: 20.312 (avg: 19.250)\tTop5: 50.000 (avg: 43.833)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.444 (avg: 0.448)\tLoss: 3.6194 (avg: 3.6221)\tTop1: 25.000 (avg: 19.062)\tTop5: 48.438 (avg: 43.406)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.448 (avg: 0.449)\tLoss: 3.5796 (avg: 3.6246)\tTop1: 18.750 (avg: 18.788)\tTop5: 40.625 (avg: 43.063)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8351\tTop 1 accuracy: 12.900\tTop 5 accuracy: 32.750\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.441 (avg: 0.439)\tLoss: 3.6367 (avg: 3.6280)\tTop1: 18.750 (avg: 19.188)\tTop5: 39.062 (avg: 44.250)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.450 (avg: 0.446)\tLoss: 3.9632 (avg: 3.6351)\tTop1: 14.062 (avg: 19.062)\tTop5: 32.812 (avg: 42.531)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.450 (avg: 0.447)\tLoss: 3.7007 (avg: 3.6189)\tTop1: 20.312 (avg: 18.896)\tTop5: 40.625 (avg: 43.292)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.443 (avg: 0.448)\tLoss: 3.2259 (avg: 3.6224)\tTop1: 25.000 (avg: 18.641)\tTop5: 51.562 (avg: 43.172)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.440 (avg: 0.449)\tLoss: 3.6782 (avg: 3.6176)\tTop1: 14.062 (avg: 18.625)\tTop5: 50.000 (avg: 43.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7671\tTop 1 accuracy: 13.150\tTop 5 accuracy: 32.800\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.443 (avg: 0.443)\tLoss: 3.4260 (avg: 3.5755)\tTop1: 25.000 (avg: 19.312)\tTop5: 53.125 (avg: 43.125)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.444 (avg: 0.449)\tLoss: 3.6212 (avg: 3.6046)\tTop1: 14.062 (avg: 18.594)\tTop5: 40.625 (avg: 42.938)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.452 (avg: 0.450)\tLoss: 3.7660 (avg: 3.6149)\tTop1: 21.875 (avg: 18.333)\tTop5: 45.312 (avg: 43.104)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.451 (avg: 0.451)\tLoss: 3.5742 (avg: 3.6138)\tTop1: 21.875 (avg: 18.859)\tTop5: 48.438 (avg: 43.141)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.446 (avg: 0.452)\tLoss: 3.9277 (avg: 3.6120)\tTop1: 6.250 (avg: 18.750)\tTop5: 26.562 (avg: 43.013)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8727\tTop 1 accuracy: 13.050\tTop 5 accuracy: 32.850\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.450 (avg: 0.443)\tLoss: 3.8785 (avg: 3.6387)\tTop1: 18.750 (avg: 18.562)\tTop5: 45.312 (avg: 41.312)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.443 (avg: 0.448)\tLoss: 4.0063 (avg: 3.6289)\tTop1: 12.500 (avg: 19.125)\tTop5: 28.125 (avg: 42.594)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.447 (avg: 0.450)\tLoss: 3.6383 (avg: 3.6211)\tTop1: 18.750 (avg: 19.146)\tTop5: 42.188 (avg: 43.188)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.450 (avg: 0.451)\tLoss: 3.0571 (avg: 3.6147)\tTop1: 31.250 (avg: 19.625)\tTop5: 53.125 (avg: 43.109)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.446 (avg: 0.452)\tLoss: 3.8956 (avg: 3.6163)\tTop1: 15.625 (avg: 19.125)\tTop5: 34.375 (avg: 42.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9054\tTop 1 accuracy: 12.850\tTop 5 accuracy: 32.300\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.458 (avg: 0.445)\tLoss: 3.2343 (avg: 3.5906)\tTop1: 25.000 (avg: 18.625)\tTop5: 56.250 (avg: 44.562)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.449 (avg: 0.451)\tLoss: 3.6726 (avg: 3.5697)\tTop1: 20.312 (avg: 20.062)\tTop5: 42.188 (avg: 44.562)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.446 (avg: 0.453)\tLoss: 3.8485 (avg: 3.5871)\tTop1: 20.312 (avg: 20.000)\tTop5: 43.750 (avg: 44.146)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.448 (avg: 0.454)\tLoss: 3.4081 (avg: 3.5976)\tTop1: 15.625 (avg: 19.500)\tTop5: 43.750 (avg: 43.672)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.454 (avg: 0.454)\tLoss: 3.7224 (avg: 3.6114)\tTop1: 18.750 (avg: 19.250)\tTop5: 43.750 (avg: 43.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8120\tTop 1 accuracy: 13.150\tTop 5 accuracy: 31.650\n",
            "\n",
            "incr_e = 192: top1 = 13.050000190734863 \t top5 = 32.85000228881836 \t batch time = 0.3207295089960098\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.518 (avg: 0.634)\tLoss: 5.3124 (avg: 5.3052)\tTop1: 0.000 (avg: 0.375)\tTop5: 0.000 (avg: 2.312)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.521 (avg: 0.582)\tLoss: 5.3030 (avg: 5.2984)\tTop1: 0.000 (avg: 0.438)\tTop5: 1.562 (avg: 2.188)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.530 (avg: 0.565)\tLoss: 5.2952 (avg: 5.2950)\tTop1: 3.125 (avg: 0.521)\tTop5: 9.375 (avg: 2.562)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.522 (avg: 0.557)\tLoss: 5.3679 (avg: 5.2957)\tTop1: 0.000 (avg: 0.562)\tTop5: 3.125 (avg: 2.578)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.516 (avg: 0.551)\tLoss: 5.2984 (avg: 5.2961)\tTop1: 1.562 (avg: 0.575)\tTop5: 3.125 (avg: 2.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2967\tTop 1 accuracy: 0.550\tTop 5 accuracy: 2.300\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.523 (avg: 0.517)\tLoss: 5.2542 (avg: 5.2931)\tTop1: 1.562 (avg: 1.000)\tTop5: 4.688 (avg: 3.438)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.519 (avg: 0.523)\tLoss: 5.2951 (avg: 5.2875)\tTop1: 0.000 (avg: 0.750)\tTop5: 3.125 (avg: 3.219)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.523 (avg: 0.526)\tLoss: 5.2900 (avg: 5.2897)\tTop1: 0.000 (avg: 0.646)\tTop5: 1.562 (avg: 2.812)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.528 (avg: 0.527)\tLoss: 5.1926 (avg: 5.2878)\tTop1: 3.125 (avg: 0.688)\tTop5: 6.250 (avg: 2.938)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.523 (avg: 0.528)\tLoss: 5.2948 (avg: 5.2858)\tTop1: 0.000 (avg: 0.738)\tTop5: 1.562 (avg: 3.025)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1289\tTop 1 accuracy: 0.550\tTop 5 accuracy: 2.750\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.524 (avg: 0.515)\tLoss: 5.2979 (avg: 5.2793)\tTop1: 0.000 (avg: 0.688)\tTop5: 4.688 (avg: 3.688)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.522 (avg: 0.522)\tLoss: 5.2818 (avg: 5.2864)\tTop1: 0.000 (avg: 0.750)\tTop5: 4.688 (avg: 3.500)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.518 (avg: 0.524)\tLoss: 5.2809 (avg: 5.2844)\tTop1: 0.000 (avg: 0.771)\tTop5: 1.562 (avg: 3.438)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.516 (avg: 0.525)\tLoss: 5.2577 (avg: 5.2804)\tTop1: 0.000 (avg: 0.766)\tTop5: 3.125 (avg: 3.453)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.522 (avg: 0.526)\tLoss: 5.3121 (avg: 5.2816)\tTop1: 0.000 (avg: 0.763)\tTop5: 0.000 (avg: 3.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1792\tTop 1 accuracy: 0.650\tTop 5 accuracy: 2.950\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.521 (avg: 0.517)\tLoss: 5.3270 (avg: 5.2642)\tTop1: 0.000 (avg: 1.000)\tTop5: 0.000 (avg: 4.562)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.519 (avg: 0.523)\tLoss: 5.2870 (avg: 5.2673)\tTop1: 1.562 (avg: 0.812)\tTop5: 4.688 (avg: 3.938)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.535 (avg: 0.525)\tLoss: 5.2567 (avg: 5.2710)\tTop1: 1.562 (avg: 0.958)\tTop5: 4.688 (avg: 4.229)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.521 (avg: 0.526)\tLoss: 5.2671 (avg: 5.2691)\tTop1: 0.000 (avg: 0.875)\tTop5: 4.688 (avg: 4.141)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.518 (avg: 0.527)\tLoss: 5.2819 (avg: 5.2708)\tTop1: 1.562 (avg: 0.925)\tTop5: 4.688 (avg: 4.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1534\tTop 1 accuracy: 0.650\tTop 5 accuracy: 4.100\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.520 (avg: 0.516)\tLoss: 5.2883 (avg: 5.2626)\tTop1: 1.562 (avg: 0.812)\tTop5: 3.125 (avg: 4.688)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.523 (avg: 0.522)\tLoss: 5.1695 (avg: 5.2606)\tTop1: 0.000 (avg: 0.969)\tTop5: 6.250 (avg: 4.344)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.518 (avg: 0.524)\tLoss: 5.1749 (avg: 5.2658)\tTop1: 3.125 (avg: 0.917)\tTop5: 7.812 (avg: 4.208)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.532 (avg: 0.525)\tLoss: 5.3040 (avg: 5.2670)\tTop1: 0.000 (avg: 0.891)\tTop5: 3.125 (avg: 4.125)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.520 (avg: 0.526)\tLoss: 5.1884 (avg: 5.2654)\tTop1: 0.000 (avg: 0.863)\tTop5: 4.688 (avg: 4.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1522\tTop 1 accuracy: 0.750\tTop 5 accuracy: 4.100\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.520 (avg: 0.516)\tLoss: 5.2458 (avg: 5.2575)\tTop1: 1.562 (avg: 0.938)\tTop5: 7.812 (avg: 5.125)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.532 (avg: 0.523)\tLoss: 5.2558 (avg: 5.2533)\tTop1: 0.000 (avg: 0.875)\tTop5: 3.125 (avg: 4.875)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.523 (avg: 0.525)\tLoss: 5.2734 (avg: 5.2486)\tTop1: 0.000 (avg: 0.896)\tTop5: 1.562 (avg: 4.979)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.519 (avg: 0.526)\tLoss: 5.1916 (avg: 5.2505)\tTop1: 1.562 (avg: 0.891)\tTop5: 6.250 (avg: 4.766)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.515 (avg: 0.527)\tLoss: 5.2115 (avg: 5.2484)\tTop1: 1.562 (avg: 0.988)\tTop5: 6.250 (avg: 4.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2067\tTop 1 accuracy: 1.050\tTop 5 accuracy: 4.650\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.516 (avg: 0.516)\tLoss: 5.2191 (avg: 5.2190)\tTop1: 1.562 (avg: 1.000)\tTop5: 7.812 (avg: 6.188)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.519 (avg: 0.523)\tLoss: 5.2157 (avg: 5.2246)\tTop1: 0.000 (avg: 0.781)\tTop5: 3.125 (avg: 5.375)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.528 (avg: 0.525)\tLoss: 5.1901 (avg: 5.2280)\tTop1: 1.562 (avg: 1.000)\tTop5: 4.688 (avg: 5.542)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.519 (avg: 0.526)\tLoss: 5.1701 (avg: 5.2291)\tTop1: 3.125 (avg: 1.016)\tTop5: 7.812 (avg: 5.266)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.521 (avg: 0.527)\tLoss: 5.1059 (avg: 5.2273)\tTop1: 0.000 (avg: 1.062)\tTop5: 9.375 (avg: 5.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2413\tTop 1 accuracy: 0.950\tTop 5 accuracy: 4.800\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.527 (avg: 0.517)\tLoss: 5.1698 (avg: 5.1987)\tTop1: 4.688 (avg: 1.562)\tTop5: 6.250 (avg: 5.562)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.523 (avg: 0.523)\tLoss: 5.1110 (avg: 5.1956)\tTop1: 0.000 (avg: 1.438)\tTop5: 7.812 (avg: 5.469)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.510 (avg: 0.525)\tLoss: 5.1630 (avg: 5.1958)\tTop1: 4.688 (avg: 1.312)\tTop5: 7.812 (avg: 5.354)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.518 (avg: 0.526)\tLoss: 5.1967 (avg: 5.1948)\tTop1: 1.562 (avg: 1.453)\tTop5: 7.812 (avg: 5.703)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.531 (avg: 0.527)\tLoss: 5.2497 (avg: 5.1986)\tTop1: 6.250 (avg: 1.488)\tTop5: 6.250 (avg: 5.813)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2769\tTop 1 accuracy: 1.250\tTop 5 accuracy: 6.500\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.519 (avg: 0.515)\tLoss: 5.1965 (avg: 5.1810)\tTop1: 0.000 (avg: 1.062)\tTop5: 6.250 (avg: 5.375)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.524 (avg: 0.522)\tLoss: 5.0140 (avg: 5.1724)\tTop1: 6.250 (avg: 1.625)\tTop5: 12.500 (avg: 6.250)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.525 (avg: 0.525)\tLoss: 5.2718 (avg: 5.1661)\tTop1: 1.562 (avg: 1.562)\tTop5: 3.125 (avg: 6.333)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.521 (avg: 0.526)\tLoss: 5.2440 (avg: 5.1651)\tTop1: 1.562 (avg: 1.641)\tTop5: 6.250 (avg: 6.516)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.518 (avg: 0.527)\tLoss: 5.3705 (avg: 5.1658)\tTop1: 0.000 (avg: 1.650)\tTop5: 4.688 (avg: 6.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1870\tTop 1 accuracy: 1.150\tTop 5 accuracy: 6.950\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.522 (avg: 0.518)\tLoss: 5.0714 (avg: 5.1392)\tTop1: 1.562 (avg: 1.312)\tTop5: 6.250 (avg: 7.000)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.512 (avg: 0.524)\tLoss: 5.0405 (avg: 5.1410)\tTop1: 6.250 (avg: 1.844)\tTop5: 7.812 (avg: 7.000)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.519 (avg: 0.526)\tLoss: 5.1453 (avg: 5.1489)\tTop1: 3.125 (avg: 1.792)\tTop5: 9.375 (avg: 6.771)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.533 (avg: 0.527)\tLoss: 5.1694 (avg: 5.1429)\tTop1: 0.000 (avg: 1.812)\tTop5: 6.250 (avg: 6.609)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.533 (avg: 0.528)\tLoss: 5.1817 (avg: 5.1440)\tTop1: 1.562 (avg: 1.738)\tTop5: 4.688 (avg: 6.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0835\tTop 1 accuracy: 2.200\tTop 5 accuracy: 8.500\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.529 (avg: 0.517)\tLoss: 5.1454 (avg: 5.1186)\tTop1: 1.562 (avg: 1.688)\tTop5: 1.562 (avg: 7.375)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.523 (avg: 0.523)\tLoss: 5.1590 (avg: 5.1046)\tTop1: 1.562 (avg: 1.625)\tTop5: 6.250 (avg: 7.312)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.522 (avg: 0.525)\tLoss: 5.1763 (avg: 5.1130)\tTop1: 1.562 (avg: 1.500)\tTop5: 7.812 (avg: 7.458)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.520 (avg: 0.527)\tLoss: 5.1424 (avg: 5.1077)\tTop1: 0.000 (avg: 1.609)\tTop5: 4.688 (avg: 7.500)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.528 (avg: 0.527)\tLoss: 5.1616 (avg: 5.1065)\tTop1: 3.125 (avg: 1.613)\tTop5: 6.250 (avg: 7.563)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9306\tTop 1 accuracy: 1.950\tTop 5 accuracy: 7.000\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.519 (avg: 0.517)\tLoss: 5.1163 (avg: 5.0672)\tTop1: 0.000 (avg: 2.312)\tTop5: 9.375 (avg: 8.750)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.520 (avg: 0.524)\tLoss: 5.0444 (avg: 5.0912)\tTop1: 4.688 (avg: 1.812)\tTop5: 7.812 (avg: 7.406)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.534 (avg: 0.526)\tLoss: 5.1340 (avg: 5.0925)\tTop1: 3.125 (avg: 2.062)\tTop5: 9.375 (avg: 7.729)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.529 (avg: 0.527)\tLoss: 5.0645 (avg: 5.0772)\tTop1: 1.562 (avg: 2.016)\tTop5: 10.938 (avg: 8.125)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.519 (avg: 0.528)\tLoss: 5.0600 (avg: 5.0712)\tTop1: 1.562 (avg: 2.050)\tTop5: 9.375 (avg: 8.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0029\tTop 1 accuracy: 2.500\tTop 5 accuracy: 9.000\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.524 (avg: 0.517)\tLoss: 5.1318 (avg: 4.9966)\tTop1: 0.000 (avg: 3.250)\tTop5: 1.562 (avg: 10.375)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.517 (avg: 0.524)\tLoss: 5.0687 (avg: 5.0135)\tTop1: 1.562 (avg: 2.500)\tTop5: 10.938 (avg: 10.000)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.534 (avg: 0.526)\tLoss: 5.1708 (avg: 5.0162)\tTop1: 3.125 (avg: 2.417)\tTop5: 9.375 (avg: 9.604)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.531 (avg: 0.527)\tLoss: 5.0458 (avg: 5.0278)\tTop1: 1.562 (avg: 2.234)\tTop5: 6.250 (avg: 9.219)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.524 (avg: 0.528)\tLoss: 5.0846 (avg: 5.0288)\tTop1: 0.000 (avg: 2.288)\tTop5: 7.812 (avg: 9.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8511\tTop 1 accuracy: 3.100\tTop 5 accuracy: 9.900\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.523 (avg: 0.518)\tLoss: 4.9713 (avg: 4.9566)\tTop1: 1.562 (avg: 3.062)\tTop5: 9.375 (avg: 10.000)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.532 (avg: 0.525)\tLoss: 5.0123 (avg: 4.9751)\tTop1: 4.688 (avg: 2.750)\tTop5: 12.500 (avg: 9.875)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.530 (avg: 0.527)\tLoss: 4.8407 (avg: 4.9761)\tTop1: 3.125 (avg: 2.458)\tTop5: 10.938 (avg: 9.750)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.520 (avg: 0.528)\tLoss: 4.9459 (avg: 4.9803)\tTop1: 3.125 (avg: 2.531)\tTop5: 15.625 (avg: 10.031)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.522 (avg: 0.529)\tLoss: 4.9974 (avg: 4.9847)\tTop1: 6.250 (avg: 2.675)\tTop5: 7.812 (avg: 10.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6021\tTop 1 accuracy: 2.700\tTop 5 accuracy: 9.950\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.518 (avg: 0.517)\tLoss: 5.0351 (avg: 4.9400)\tTop1: 4.688 (avg: 2.125)\tTop5: 10.938 (avg: 10.875)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.520 (avg: 0.523)\tLoss: 4.9404 (avg: 4.9414)\tTop1: 1.562 (avg: 2.562)\tTop5: 14.062 (avg: 10.938)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.532 (avg: 0.525)\tLoss: 4.9257 (avg: 4.9348)\tTop1: 3.125 (avg: 2.750)\tTop5: 12.500 (avg: 11.146)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.526 (avg: 0.527)\tLoss: 5.0728 (avg: 4.9399)\tTop1: 1.562 (avg: 2.766)\tTop5: 7.812 (avg: 11.062)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.518 (avg: 0.527)\tLoss: 5.0000 (avg: 4.9344)\tTop1: 1.562 (avg: 2.725)\tTop5: 9.375 (avg: 11.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5948\tTop 1 accuracy: 3.050\tTop 5 accuracy: 12.100\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.530 (avg: 0.517)\tLoss: 4.9645 (avg: 4.8999)\tTop1: 1.562 (avg: 2.625)\tTop5: 10.938 (avg: 11.812)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.534 (avg: 0.525)\tLoss: 4.8976 (avg: 4.9184)\tTop1: 1.562 (avg: 2.656)\tTop5: 12.500 (avg: 11.000)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.513 (avg: 0.527)\tLoss: 4.9960 (avg: 4.9104)\tTop1: 3.125 (avg: 2.854)\tTop5: 9.375 (avg: 11.229)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.516 (avg: 0.528)\tLoss: 4.7537 (avg: 4.9031)\tTop1: 4.688 (avg: 2.984)\tTop5: 17.188 (avg: 11.672)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.528 (avg: 0.528)\tLoss: 4.8027 (avg: 4.8978)\tTop1: 1.562 (avg: 2.900)\tTop5: 12.500 (avg: 11.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6801\tTop 1 accuracy: 3.150\tTop 5 accuracy: 12.250\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.520 (avg: 0.516)\tLoss: 4.7458 (avg: 4.8418)\tTop1: 3.125 (avg: 3.125)\tTop5: 14.062 (avg: 13.062)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.525 (avg: 0.523)\tLoss: 4.8234 (avg: 4.8664)\tTop1: 6.250 (avg: 3.125)\tTop5: 14.062 (avg: 12.406)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.527 (avg: 0.525)\tLoss: 4.6856 (avg: 4.8594)\tTop1: 1.562 (avg: 3.458)\tTop5: 10.938 (avg: 12.521)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.514 (avg: 0.526)\tLoss: 4.8982 (avg: 4.8547)\tTop1: 3.125 (avg: 3.594)\tTop5: 10.938 (avg: 12.828)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.517 (avg: 0.527)\tLoss: 4.7475 (avg: 4.8482)\tTop1: 3.125 (avg: 3.538)\tTop5: 9.375 (avg: 12.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3647\tTop 1 accuracy: 4.250\tTop 5 accuracy: 13.000\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.529 (avg: 0.518)\tLoss: 4.7995 (avg: 4.7569)\tTop1: 3.125 (avg: 4.125)\tTop5: 15.625 (avg: 15.500)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.524 (avg: 0.525)\tLoss: 4.9103 (avg: 4.7602)\tTop1: 3.125 (avg: 4.156)\tTop5: 10.938 (avg: 16.125)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.519 (avg: 0.527)\tLoss: 4.9998 (avg: 4.7921)\tTop1: 1.562 (avg: 4.000)\tTop5: 9.375 (avg: 15.333)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.531 (avg: 0.528)\tLoss: 4.9686 (avg: 4.7984)\tTop1: 1.562 (avg: 3.938)\tTop5: 6.250 (avg: 15.172)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.527 (avg: 0.529)\tLoss: 4.7754 (avg: 4.7967)\tTop1: 3.125 (avg: 3.888)\tTop5: 10.938 (avg: 14.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5952\tTop 1 accuracy: 3.750\tTop 5 accuracy: 14.650\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.530 (avg: 0.518)\tLoss: 4.7221 (avg: 4.7837)\tTop1: 0.000 (avg: 3.500)\tTop5: 15.625 (avg: 14.812)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.526 (avg: 0.525)\tLoss: 4.7391 (avg: 4.7370)\tTop1: 9.375 (avg: 4.000)\tTop5: 17.188 (avg: 15.500)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.522 (avg: 0.526)\tLoss: 4.6491 (avg: 4.7422)\tTop1: 4.688 (avg: 3.875)\tTop5: 10.938 (avg: 15.208)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.522 (avg: 0.527)\tLoss: 4.5109 (avg: 4.7226)\tTop1: 6.250 (avg: 4.250)\tTop5: 25.000 (avg: 15.672)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.529 (avg: 0.528)\tLoss: 4.6607 (avg: 4.7215)\tTop1: 6.250 (avg: 4.475)\tTop5: 20.312 (avg: 15.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6489\tTop 1 accuracy: 4.700\tTop 5 accuracy: 15.750\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.528 (avg: 0.517)\tLoss: 4.7157 (avg: 4.6756)\tTop1: 4.688 (avg: 4.688)\tTop5: 10.938 (avg: 16.938)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.523 (avg: 0.524)\tLoss: 4.6071 (avg: 4.6562)\tTop1: 3.125 (avg: 4.844)\tTop5: 14.062 (avg: 17.250)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.536 (avg: 0.527)\tLoss: 4.5651 (avg: 4.6371)\tTop1: 4.688 (avg: 4.979)\tTop5: 18.750 (avg: 17.521)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.524 (avg: 0.528)\tLoss: 4.5642 (avg: 4.6604)\tTop1: 4.688 (avg: 4.969)\tTop5: 12.500 (avg: 17.234)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.519 (avg: 0.529)\tLoss: 4.5833 (avg: 4.6597)\tTop1: 6.250 (avg: 4.850)\tTop5: 17.188 (avg: 17.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1763\tTop 1 accuracy: 5.050\tTop 5 accuracy: 17.750\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.523 (avg: 0.518)\tLoss: 4.7158 (avg: 4.5983)\tTop1: 3.125 (avg: 5.625)\tTop5: 12.500 (avg: 18.188)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.521 (avg: 0.525)\tLoss: 4.4236 (avg: 4.5821)\tTop1: 10.938 (avg: 5.375)\tTop5: 28.125 (avg: 18.906)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.528 (avg: 0.527)\tLoss: 4.7512 (avg: 4.5874)\tTop1: 1.562 (avg: 5.292)\tTop5: 15.625 (avg: 18.833)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.525 (avg: 0.528)\tLoss: 4.6626 (avg: 4.5971)\tTop1: 4.688 (avg: 5.125)\tTop5: 21.875 (avg: 18.641)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.521 (avg: 0.529)\tLoss: 4.4394 (avg: 4.6087)\tTop1: 7.812 (avg: 5.000)\tTop5: 26.562 (avg: 18.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3181\tTop 1 accuracy: 6.000\tTop 5 accuracy: 18.800\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.523 (avg: 0.518)\tLoss: 4.5862 (avg: 4.5411)\tTop1: 7.812 (avg: 6.375)\tTop5: 20.312 (avg: 20.938)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.533 (avg: 0.525)\tLoss: 4.5805 (avg: 4.5520)\tTop1: 4.688 (avg: 5.656)\tTop5: 23.438 (avg: 20.500)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.527 (avg: 0.527)\tLoss: 4.6432 (avg: 4.5536)\tTop1: 6.250 (avg: 5.979)\tTop5: 17.188 (avg: 19.979)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.521 (avg: 0.529)\tLoss: 4.5205 (avg: 4.5536)\tTop1: 3.125 (avg: 5.828)\tTop5: 25.000 (avg: 20.031)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.518 (avg: 0.529)\tLoss: 4.3507 (avg: 4.5641)\tTop1: 9.375 (avg: 5.663)\tTop5: 23.438 (avg: 19.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1923\tTop 1 accuracy: 6.250\tTop 5 accuracy: 19.900\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.520 (avg: 0.518)\tLoss: 4.4506 (avg: 4.4533)\tTop1: 6.250 (avg: 5.938)\tTop5: 23.438 (avg: 22.000)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.528 (avg: 0.525)\tLoss: 4.4109 (avg: 4.5036)\tTop1: 4.688 (avg: 5.750)\tTop5: 18.750 (avg: 20.469)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.535 (avg: 0.527)\tLoss: 4.4200 (avg: 4.4958)\tTop1: 4.688 (avg: 5.917)\tTop5: 18.750 (avg: 20.583)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.522 (avg: 0.528)\tLoss: 4.4923 (avg: 4.4802)\tTop1: 6.250 (avg: 6.094)\tTop5: 25.000 (avg: 21.062)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.521 (avg: 0.529)\tLoss: 4.7417 (avg: 4.4828)\tTop1: 3.125 (avg: 5.988)\tTop5: 15.625 (avg: 20.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3228\tTop 1 accuracy: 5.900\tTop 5 accuracy: 19.850\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.532 (avg: 0.518)\tLoss: 4.4435 (avg: 4.4134)\tTop1: 7.812 (avg: 8.125)\tTop5: 21.875 (avg: 23.938)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.528 (avg: 0.525)\tLoss: 4.4425 (avg: 4.4174)\tTop1: 6.250 (avg: 7.250)\tTop5: 20.312 (avg: 23.781)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.525 (avg: 0.527)\tLoss: 4.2761 (avg: 4.4196)\tTop1: 7.812 (avg: 7.417)\tTop5: 28.125 (avg: 23.271)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.518 (avg: 0.529)\tLoss: 4.4690 (avg: 4.4411)\tTop1: 6.250 (avg: 7.016)\tTop5: 20.312 (avg: 22.391)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.531 (avg: 0.529)\tLoss: 4.3590 (avg: 4.4511)\tTop1: 7.812 (avg: 6.863)\tTop5: 21.875 (avg: 21.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3629\tTop 1 accuracy: 6.500\tTop 5 accuracy: 21.200\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.520 (avg: 0.519)\tLoss: 4.6480 (avg: 4.3892)\tTop1: 9.375 (avg: 8.250)\tTop5: 20.312 (avg: 23.375)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.531 (avg: 0.525)\tLoss: 4.4389 (avg: 4.4153)\tTop1: 6.250 (avg: 7.375)\tTop5: 26.562 (avg: 22.719)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.527 (avg: 0.527)\tLoss: 4.2508 (avg: 4.4040)\tTop1: 10.938 (avg: 7.479)\tTop5: 28.125 (avg: 22.896)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.521 (avg: 0.528)\tLoss: 4.6555 (avg: 4.4137)\tTop1: 3.125 (avg: 7.359)\tTop5: 17.188 (avg: 22.703)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.518 (avg: 0.529)\tLoss: 4.3662 (avg: 4.4222)\tTop1: 4.688 (avg: 7.213)\tTop5: 29.688 (avg: 22.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2809\tTop 1 accuracy: 6.700\tTop 5 accuracy: 20.150\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.523 (avg: 0.519)\tLoss: 4.4658 (avg: 4.3717)\tTop1: 3.125 (avg: 7.875)\tTop5: 17.188 (avg: 23.812)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.520 (avg: 0.526)\tLoss: 4.4281 (avg: 4.3411)\tTop1: 4.688 (avg: 8.094)\tTop5: 20.312 (avg: 24.000)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.524 (avg: 0.528)\tLoss: 4.2963 (avg: 4.3368)\tTop1: 6.250 (avg: 7.917)\tTop5: 21.875 (avg: 23.938)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.534 (avg: 0.530)\tLoss: 4.4486 (avg: 4.3489)\tTop1: 3.125 (avg: 7.688)\tTop5: 18.750 (avg: 23.828)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.528 (avg: 0.530)\tLoss: 4.5412 (avg: 4.3558)\tTop1: 14.062 (avg: 7.813)\tTop5: 26.562 (avg: 23.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9941\tTop 1 accuracy: 7.850\tTop 5 accuracy: 22.850\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.531 (avg: 0.518)\tLoss: 4.1890 (avg: 4.2573)\tTop1: 7.812 (avg: 9.125)\tTop5: 31.250 (avg: 26.812)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.520 (avg: 0.525)\tLoss: 4.1841 (avg: 4.2552)\tTop1: 7.812 (avg: 9.188)\tTop5: 28.125 (avg: 27.375)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.524 (avg: 0.527)\tLoss: 4.5247 (avg: 4.2972)\tTop1: 9.375 (avg: 8.521)\tTop5: 18.750 (avg: 26.083)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.522 (avg: 0.528)\tLoss: 4.4412 (avg: 4.3015)\tTop1: 6.250 (avg: 8.328)\tTop5: 21.875 (avg: 25.766)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.534 (avg: 0.529)\tLoss: 4.4379 (avg: 4.3245)\tTop1: 7.812 (avg: 8.150)\tTop5: 18.750 (avg: 25.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1376\tTop 1 accuracy: 5.400\tTop 5 accuracy: 19.400\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.523 (avg: 0.519)\tLoss: 4.3557 (avg: 4.3115)\tTop1: 6.250 (avg: 8.375)\tTop5: 29.688 (avg: 24.688)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.522 (avg: 0.526)\tLoss: 4.2057 (avg: 4.2700)\tTop1: 10.938 (avg: 9.375)\tTop5: 32.812 (avg: 26.719)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.532 (avg: 0.528)\tLoss: 4.3889 (avg: 4.2879)\tTop1: 7.812 (avg: 8.917)\tTop5: 25.000 (avg: 26.292)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.523 (avg: 0.529)\tLoss: 4.4467 (avg: 4.2830)\tTop1: 6.250 (avg: 8.984)\tTop5: 25.000 (avg: 26.141)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.523 (avg: 0.530)\tLoss: 4.3856 (avg: 4.2894)\tTop1: 7.812 (avg: 8.825)\tTop5: 23.438 (avg: 25.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9707\tTop 1 accuracy: 8.150\tTop 5 accuracy: 23.050\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.523 (avg: 0.519)\tLoss: 4.2005 (avg: 4.1773)\tTop1: 10.938 (avg: 9.500)\tTop5: 28.125 (avg: 28.875)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.525 (avg: 0.526)\tLoss: 3.9010 (avg: 4.2139)\tTop1: 10.938 (avg: 8.594)\tTop5: 34.375 (avg: 27.031)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.521 (avg: 0.528)\tLoss: 3.9688 (avg: 4.2121)\tTop1: 14.062 (avg: 8.812)\tTop5: 32.812 (avg: 27.312)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.522 (avg: 0.529)\tLoss: 4.3187 (avg: 4.2176)\tTop1: 9.375 (avg: 9.062)\tTop5: 31.250 (avg: 27.406)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.523 (avg: 0.530)\tLoss: 4.7449 (avg: 4.2271)\tTop1: 4.688 (avg: 8.938)\tTop5: 21.875 (avg: 27.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5040\tTop 1 accuracy: 8.350\tTop 5 accuracy: 24.400\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.523 (avg: 0.519)\tLoss: 4.1385 (avg: 4.1672)\tTop1: 14.062 (avg: 10.188)\tTop5: 35.938 (avg: 28.750)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.534 (avg: 0.525)\tLoss: 4.2135 (avg: 4.2206)\tTop1: 3.125 (avg: 8.875)\tTop5: 31.250 (avg: 26.906)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.528 (avg: 0.528)\tLoss: 4.4265 (avg: 4.2144)\tTop1: 7.812 (avg: 8.812)\tTop5: 23.438 (avg: 27.271)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.523 (avg: 0.529)\tLoss: 4.0888 (avg: 4.2114)\tTop1: 9.375 (avg: 9.078)\tTop5: 32.812 (avg: 27.281)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.520 (avg: 0.529)\tLoss: 4.3454 (avg: 4.2173)\tTop1: 4.688 (avg: 9.138)\tTop5: 25.000 (avg: 27.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8911\tTop 1 accuracy: 8.850\tTop 5 accuracy: 26.800\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.517 (avg: 0.518)\tLoss: 4.0180 (avg: 4.0369)\tTop1: 9.375 (avg: 11.000)\tTop5: 31.250 (avg: 35.062)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.519 (avg: 0.525)\tLoss: 4.0239 (avg: 3.9895)\tTop1: 7.812 (avg: 12.312)\tTop5: 25.000 (avg: 35.219)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.528 (avg: 0.527)\tLoss: 3.9636 (avg: 3.9635)\tTop1: 10.938 (avg: 12.708)\tTop5: 31.250 (avg: 35.042)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.522 (avg: 0.528)\tLoss: 3.8227 (avg: 3.9311)\tTop1: 18.750 (avg: 13.500)\tTop5: 37.500 (avg: 35.609)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.523 (avg: 0.529)\tLoss: 4.0120 (avg: 3.9164)\tTop1: 15.625 (avg: 13.950)\tTop5: 34.375 (avg: 36.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3509\tTop 1 accuracy: 11.700\tTop 5 accuracy: 30.500\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.535 (avg: 0.520)\tLoss: 3.9687 (avg: 3.8907)\tTop1: 12.500 (avg: 14.188)\tTop5: 32.812 (avg: 36.812)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.524 (avg: 0.526)\tLoss: 3.8364 (avg: 3.8625)\tTop1: 14.062 (avg: 14.344)\tTop5: 39.062 (avg: 36.938)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.526 (avg: 0.528)\tLoss: 3.8932 (avg: 3.8305)\tTop1: 14.062 (avg: 15.375)\tTop5: 35.938 (avg: 38.229)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.521 (avg: 0.529)\tLoss: 4.1239 (avg: 3.8412)\tTop1: 7.812 (avg: 15.234)\tTop5: 20.312 (avg: 38.016)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.534 (avg: 0.530)\tLoss: 3.9179 (avg: 3.8510)\tTop1: 18.750 (avg: 15.038)\tTop5: 34.375 (avg: 37.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3651\tTop 1 accuracy: 10.900\tTop 5 accuracy: 30.050\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.516 (avg: 0.519)\tLoss: 4.1817 (avg: 3.7819)\tTop1: 7.812 (avg: 16.938)\tTop5: 28.125 (avg: 40.562)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.530 (avg: 0.525)\tLoss: 3.9188 (avg: 3.7804)\tTop1: 18.750 (avg: 17.031)\tTop5: 40.625 (avg: 40.125)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.527 (avg: 0.527)\tLoss: 3.5474 (avg: 3.7992)\tTop1: 14.062 (avg: 16.354)\tTop5: 42.188 (avg: 39.208)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.519 (avg: 0.529)\tLoss: 3.9115 (avg: 3.8087)\tTop1: 12.500 (avg: 16.094)\tTop5: 37.500 (avg: 39.031)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.522 (avg: 0.529)\tLoss: 3.9326 (avg: 3.8198)\tTop1: 12.500 (avg: 15.850)\tTop5: 39.062 (avg: 38.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2687\tTop 1 accuracy: 11.200\tTop 5 accuracy: 30.950\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.528 (avg: 0.520)\tLoss: 3.6443 (avg: 3.7903)\tTop1: 21.875 (avg: 14.750)\tTop5: 40.625 (avg: 39.062)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.522 (avg: 0.526)\tLoss: 3.7826 (avg: 3.7726)\tTop1: 15.625 (avg: 15.531)\tTop5: 46.875 (avg: 39.625)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.520 (avg: 0.529)\tLoss: 3.9419 (avg: 3.8031)\tTop1: 23.438 (avg: 15.208)\tTop5: 43.750 (avg: 38.750)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.533 (avg: 0.530)\tLoss: 3.8108 (avg: 3.8067)\tTop1: 14.062 (avg: 15.359)\tTop5: 35.938 (avg: 38.688)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.526 (avg: 0.531)\tLoss: 3.9144 (avg: 3.8026)\tTop1: 12.500 (avg: 15.500)\tTop5: 43.750 (avg: 38.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2067\tTop 1 accuracy: 11.050\tTop 5 accuracy: 31.050\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.534 (avg: 0.519)\tLoss: 3.8659 (avg: 3.7807)\tTop1: 20.312 (avg: 16.125)\tTop5: 39.062 (avg: 40.438)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.527 (avg: 0.525)\tLoss: 3.4859 (avg: 3.8087)\tTop1: 20.312 (avg: 15.719)\tTop5: 48.438 (avg: 39.250)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.521 (avg: 0.528)\tLoss: 3.4277 (avg: 3.7946)\tTop1: 17.188 (avg: 15.854)\tTop5: 50.000 (avg: 39.667)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.527 (avg: 0.529)\tLoss: 3.7670 (avg: 3.7970)\tTop1: 21.875 (avg: 15.812)\tTop5: 40.625 (avg: 39.469)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.523 (avg: 0.529)\tLoss: 3.2843 (avg: 3.7950)\tTop1: 28.125 (avg: 15.725)\tTop5: 57.812 (avg: 39.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2755\tTop 1 accuracy: 11.600\tTop 5 accuracy: 31.000\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.520 (avg: 0.520)\tLoss: 3.9029 (avg: 3.7021)\tTop1: 18.750 (avg: 18.250)\tTop5: 43.750 (avg: 41.938)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.522 (avg: 0.526)\tLoss: 3.7014 (avg: 3.7149)\tTop1: 12.500 (avg: 17.156)\tTop5: 43.750 (avg: 41.094)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.533 (avg: 0.529)\tLoss: 4.0099 (avg: 3.7357)\tTop1: 9.375 (avg: 16.458)\tTop5: 40.625 (avg: 40.604)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.527 (avg: 0.530)\tLoss: 3.7893 (avg: 3.7672)\tTop1: 12.500 (avg: 15.859)\tTop5: 34.375 (avg: 39.484)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.521 (avg: 0.530)\tLoss: 3.8722 (avg: 3.7717)\tTop1: 18.750 (avg: 15.700)\tTop5: 35.938 (avg: 39.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4743\tTop 1 accuracy: 10.800\tTop 5 accuracy: 31.000\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.530 (avg: 0.519)\tLoss: 3.9603 (avg: 3.7310)\tTop1: 9.375 (avg: 17.500)\tTop5: 32.812 (avg: 41.562)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.521 (avg: 0.526)\tLoss: 3.5476 (avg: 3.7439)\tTop1: 23.438 (avg: 17.031)\tTop5: 45.312 (avg: 40.562)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.531 (avg: 0.528)\tLoss: 3.6673 (avg: 3.7444)\tTop1: 15.625 (avg: 16.479)\tTop5: 42.188 (avg: 40.542)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.533 (avg: 0.529)\tLoss: 3.9076 (avg: 3.7485)\tTop1: 20.312 (avg: 16.578)\tTop5: 43.750 (avg: 40.328)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.525 (avg: 0.529)\tLoss: 3.5308 (avg: 3.7577)\tTop1: 17.188 (avg: 16.325)\tTop5: 45.312 (avg: 40.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2126\tTop 1 accuracy: 11.450\tTop 5 accuracy: 31.400\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.511 (avg: 0.520)\tLoss: 3.7117 (avg: 3.7100)\tTop1: 20.312 (avg: 18.125)\tTop5: 48.438 (avg: 41.750)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.535 (avg: 0.527)\tLoss: 3.7587 (avg: 3.7473)\tTop1: 21.875 (avg: 16.719)\tTop5: 37.500 (avg: 40.188)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.527 (avg: 0.529)\tLoss: 4.1140 (avg: 3.7577)\tTop1: 28.125 (avg: 16.542)\tTop5: 40.625 (avg: 39.771)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.525 (avg: 0.530)\tLoss: 3.7710 (avg: 3.7508)\tTop1: 15.625 (avg: 16.188)\tTop5: 35.938 (avg: 39.922)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.526 (avg: 0.531)\tLoss: 3.8944 (avg: 3.7475)\tTop1: 18.750 (avg: 15.975)\tTop5: 35.938 (avg: 40.013)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3704\tTop 1 accuracy: 11.450\tTop 5 accuracy: 31.950\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.523 (avg: 0.519)\tLoss: 3.7122 (avg: 3.6799)\tTop1: 17.188 (avg: 18.875)\tTop5: 48.438 (avg: 42.062)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.520 (avg: 0.526)\tLoss: 4.2456 (avg: 3.7385)\tTop1: 10.938 (avg: 17.062)\tTop5: 31.250 (avg: 40.500)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.533 (avg: 0.528)\tLoss: 4.0926 (avg: 3.7364)\tTop1: 12.500 (avg: 17.458)\tTop5: 37.500 (avg: 41.021)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.522 (avg: 0.529)\tLoss: 3.6008 (avg: 3.7311)\tTop1: 17.188 (avg: 17.234)\tTop5: 43.750 (avg: 40.859)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.528 (avg: 0.529)\tLoss: 3.6085 (avg: 3.7288)\tTop1: 15.625 (avg: 17.025)\tTop5: 42.188 (avg: 40.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4205\tTop 1 accuracy: 11.150\tTop 5 accuracy: 31.450\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.534 (avg: 0.519)\tLoss: 3.9051 (avg: 3.6688)\tTop1: 21.875 (avg: 18.500)\tTop5: 32.812 (avg: 41.562)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.533 (avg: 0.526)\tLoss: 3.8064 (avg: 3.7193)\tTop1: 12.500 (avg: 17.000)\tTop5: 39.062 (avg: 40.719)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.521 (avg: 0.528)\tLoss: 4.0632 (avg: 3.7360)\tTop1: 18.750 (avg: 17.000)\tTop5: 35.938 (avg: 40.146)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.517 (avg: 0.529)\tLoss: 4.0223 (avg: 3.7299)\tTop1: 10.938 (avg: 16.797)\tTop5: 35.938 (avg: 39.828)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.534 (avg: 0.530)\tLoss: 3.5221 (avg: 3.7102)\tTop1: 17.188 (avg: 17.013)\tTop5: 48.438 (avg: 40.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2935\tTop 1 accuracy: 11.450\tTop 5 accuracy: 31.400\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.520 (avg: 0.519)\tLoss: 3.8668 (avg: 3.6413)\tTop1: 9.375 (avg: 19.125)\tTop5: 43.750 (avg: 43.562)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.536 (avg: 0.527)\tLoss: 3.7303 (avg: 3.6905)\tTop1: 17.188 (avg: 17.312)\tTop5: 42.188 (avg: 41.688)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.533 (avg: 0.530)\tLoss: 3.6643 (avg: 3.7013)\tTop1: 23.438 (avg: 16.833)\tTop5: 37.500 (avg: 41.146)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.527 (avg: 0.532)\tLoss: 3.6537 (avg: 3.6986)\tTop1: 20.312 (avg: 16.906)\tTop5: 39.062 (avg: 41.344)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.522 (avg: 0.533)\tLoss: 3.5025 (avg: 3.7048)\tTop1: 23.438 (avg: 16.675)\tTop5: 46.875 (avg: 40.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4071\tTop 1 accuracy: 11.100\tTop 5 accuracy: 31.950\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.536 (avg: 0.526)\tLoss: 3.7824 (avg: 3.6317)\tTop1: 21.875 (avg: 19.125)\tTop5: 37.500 (avg: 42.312)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.527 (avg: 0.532)\tLoss: 3.9233 (avg: 3.6582)\tTop1: 9.375 (avg: 18.531)\tTop5: 31.250 (avg: 42.719)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.525 (avg: 0.534)\tLoss: 3.6253 (avg: 3.6510)\tTop1: 10.938 (avg: 18.333)\tTop5: 42.188 (avg: 42.583)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.540 (avg: 0.535)\tLoss: 3.6903 (avg: 3.6776)\tTop1: 18.750 (avg: 17.938)\tTop5: 45.312 (avg: 41.781)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.537 (avg: 0.536)\tLoss: 3.6735 (avg: 3.6870)\tTop1: 15.625 (avg: 17.463)\tTop5: 42.188 (avg: 41.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4052\tTop 1 accuracy: 11.600\tTop 5 accuracy: 30.900\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.546 (avg: 0.527)\tLoss: 3.4955 (avg: 3.6519)\tTop1: 18.750 (avg: 17.500)\tTop5: 42.188 (avg: 40.688)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.533 (avg: 0.533)\tLoss: 4.0203 (avg: 3.6906)\tTop1: 14.062 (avg: 17.344)\tTop5: 32.812 (avg: 41.094)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.533 (avg: 0.536)\tLoss: 3.5162 (avg: 3.6759)\tTop1: 20.312 (avg: 17.500)\tTop5: 43.750 (avg: 41.104)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.518 (avg: 0.535)\tLoss: 3.5989 (avg: 3.6830)\tTop1: 12.500 (avg: 17.344)\tTop5: 39.062 (avg: 41.047)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.535 (avg: 0.535)\tLoss: 3.3606 (avg: 3.6781)\tTop1: 23.438 (avg: 17.625)\tTop5: 50.000 (avg: 41.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4024\tTop 1 accuracy: 11.250\tTop 5 accuracy: 32.300\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.521 (avg: 0.520)\tLoss: 3.6459 (avg: 3.6563)\tTop1: 21.875 (avg: 17.688)\tTop5: 39.062 (avg: 42.000)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.515 (avg: 0.526)\tLoss: 3.5708 (avg: 3.6373)\tTop1: 14.062 (avg: 17.375)\tTop5: 40.625 (avg: 43.000)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.537 (avg: 0.529)\tLoss: 4.0348 (avg: 3.6499)\tTop1: 3.125 (avg: 17.312)\tTop5: 37.500 (avg: 42.729)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.529 (avg: 0.530)\tLoss: 3.6402 (avg: 3.6671)\tTop1: 18.750 (avg: 17.766)\tTop5: 40.625 (avg: 42.359)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.525 (avg: 0.530)\tLoss: 3.6946 (avg: 3.6670)\tTop1: 10.938 (avg: 17.700)\tTop5: 35.938 (avg: 42.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4059\tTop 1 accuracy: 12.050\tTop 5 accuracy: 32.750\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.529 (avg: 0.519)\tLoss: 3.7926 (avg: 3.6311)\tTop1: 15.625 (avg: 18.500)\tTop5: 35.938 (avg: 42.312)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.521 (avg: 0.525)\tLoss: 4.0239 (avg: 3.6806)\tTop1: 9.375 (avg: 17.562)\tTop5: 28.125 (avg: 41.219)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.520 (avg: 0.527)\tLoss: 3.5885 (avg: 3.6515)\tTop1: 20.312 (avg: 17.896)\tTop5: 45.312 (avg: 41.833)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.532 (avg: 0.528)\tLoss: 3.6807 (avg: 3.6601)\tTop1: 17.188 (avg: 17.672)\tTop5: 48.438 (avg: 41.594)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.522 (avg: 0.529)\tLoss: 3.7041 (avg: 3.6579)\tTop1: 18.750 (avg: 17.788)\tTop5: 43.750 (avg: 41.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.1598\tTop 1 accuracy: 12.350\tTop 5 accuracy: 32.450\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.516 (avg: 0.520)\tLoss: 3.7819 (avg: 3.5676)\tTop1: 17.188 (avg: 19.125)\tTop5: 31.250 (avg: 44.312)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.530 (avg: 0.527)\tLoss: 3.9903 (avg: 3.6201)\tTop1: 14.062 (avg: 18.594)\tTop5: 28.125 (avg: 42.312)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.529 (avg: 0.529)\tLoss: 4.0320 (avg: 3.6263)\tTop1: 10.938 (avg: 18.521)\tTop5: 37.500 (avg: 42.021)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.526 (avg: 0.530)\tLoss: 3.4491 (avg: 3.6327)\tTop1: 25.000 (avg: 18.312)\tTop5: 46.875 (avg: 42.062)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.521 (avg: 0.531)\tLoss: 3.9695 (avg: 3.6373)\tTop1: 12.500 (avg: 18.250)\tTop5: 32.812 (avg: 42.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3476\tTop 1 accuracy: 11.900\tTop 5 accuracy: 32.000\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.517 (avg: 0.519)\tLoss: 3.4703 (avg: 3.5717)\tTop1: 17.188 (avg: 20.000)\tTop5: 42.188 (avg: 44.000)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.512 (avg: 0.526)\tLoss: 3.3618 (avg: 3.5906)\tTop1: 21.875 (avg: 18.531)\tTop5: 56.250 (avg: 43.406)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.534 (avg: 0.528)\tLoss: 3.8062 (avg: 3.6008)\tTop1: 18.750 (avg: 18.271)\tTop5: 42.188 (avg: 43.208)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.527 (avg: 0.529)\tLoss: 3.5606 (avg: 3.6030)\tTop1: 18.750 (avg: 18.219)\tTop5: 50.000 (avg: 43.375)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.521 (avg: 0.530)\tLoss: 3.2889 (avg: 3.6212)\tTop1: 25.000 (avg: 18.075)\tTop5: 45.312 (avg: 42.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3929\tTop 1 accuracy: 12.300\tTop 5 accuracy: 32.450\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.534 (avg: 0.520)\tLoss: 3.7542 (avg: 3.6275)\tTop1: 20.312 (avg: 19.062)\tTop5: 40.625 (avg: 42.500)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.527 (avg: 0.526)\tLoss: 3.6499 (avg: 3.5952)\tTop1: 21.875 (avg: 19.188)\tTop5: 40.625 (avg: 43.469)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.525 (avg: 0.529)\tLoss: 3.6332 (avg: 3.6088)\tTop1: 23.438 (avg: 18.812)\tTop5: 46.875 (avg: 42.979)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.520 (avg: 0.530)\tLoss: 3.5752 (avg: 3.6048)\tTop1: 17.188 (avg: 18.828)\tTop5: 45.312 (avg: 43.375)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.534 (avg: 0.530)\tLoss: 3.5376 (avg: 3.6137)\tTop1: 17.188 (avg: 18.450)\tTop5: 43.750 (avg: 42.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5139\tTop 1 accuracy: 11.800\tTop 5 accuracy: 32.550\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.521 (avg: 0.519)\tLoss: 3.3981 (avg: 3.5446)\tTop1: 15.625 (avg: 20.438)\tTop5: 46.875 (avg: 44.625)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.530 (avg: 0.526)\tLoss: 3.8080 (avg: 3.5547)\tTop1: 17.188 (avg: 19.281)\tTop5: 37.500 (avg: 44.688)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.527 (avg: 0.528)\tLoss: 3.3933 (avg: 3.5492)\tTop1: 20.312 (avg: 19.229)\tTop5: 50.000 (avg: 44.312)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.523 (avg: 0.529)\tLoss: 3.6498 (avg: 3.5793)\tTop1: 14.062 (avg: 18.984)\tTop5: 42.188 (avg: 43.578)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.517 (avg: 0.530)\tLoss: 4.1830 (avg: 3.5945)\tTop1: 17.188 (avg: 18.475)\tTop5: 32.812 (avg: 43.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3896\tTop 1 accuracy: 12.000\tTop 5 accuracy: 32.400\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.537 (avg: 0.520)\tLoss: 3.3441 (avg: 3.5779)\tTop1: 25.000 (avg: 20.375)\tTop5: 46.875 (avg: 43.000)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.524 (avg: 0.526)\tLoss: 3.5528 (avg: 3.5474)\tTop1: 14.062 (avg: 19.469)\tTop5: 40.625 (avg: 43.812)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.524 (avg: 0.528)\tLoss: 3.6720 (avg: 3.5673)\tTop1: 26.562 (avg: 19.396)\tTop5: 39.062 (avg: 43.271)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.526 (avg: 0.530)\tLoss: 3.7428 (avg: 3.5845)\tTop1: 17.188 (avg: 19.047)\tTop5: 40.625 (avg: 42.797)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.525 (avg: 0.530)\tLoss: 3.5412 (avg: 3.5836)\tTop1: 17.188 (avg: 19.150)\tTop5: 45.312 (avg: 42.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3679\tTop 1 accuracy: 12.450\tTop 5 accuracy: 32.700\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.531 (avg: 0.519)\tLoss: 3.6312 (avg: 3.5504)\tTop1: 15.625 (avg: 17.688)\tTop5: 42.188 (avg: 44.125)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.524 (avg: 0.526)\tLoss: 3.2358 (avg: 3.5224)\tTop1: 21.875 (avg: 18.688)\tTop5: 51.562 (avg: 44.625)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.523 (avg: 0.528)\tLoss: 3.9244 (avg: 3.5373)\tTop1: 14.062 (avg: 18.438)\tTop5: 34.375 (avg: 44.521)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.520 (avg: 0.529)\tLoss: 3.7493 (avg: 3.5662)\tTop1: 17.188 (avg: 18.344)\tTop5: 35.938 (avg: 44.000)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.532 (avg: 0.530)\tLoss: 3.3007 (avg: 3.5649)\tTop1: 20.312 (avg: 18.800)\tTop5: 53.125 (avg: 44.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4026\tTop 1 accuracy: 12.450\tTop 5 accuracy: 31.900\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.524 (avg: 0.520)\tLoss: 3.6208 (avg: 3.5777)\tTop1: 18.750 (avg: 19.625)\tTop5: 42.188 (avg: 43.125)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.522 (avg: 0.526)\tLoss: 3.2907 (avg: 3.5590)\tTop1: 17.188 (avg: 19.062)\tTop5: 56.250 (avg: 44.281)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.538 (avg: 0.529)\tLoss: 3.6715 (avg: 3.5526)\tTop1: 17.188 (avg: 18.708)\tTop5: 43.750 (avg: 44.208)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.527 (avg: 0.530)\tLoss: 3.4044 (avg: 3.5597)\tTop1: 28.125 (avg: 19.141)\tTop5: 50.000 (avg: 43.969)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.525 (avg: 0.531)\tLoss: 3.4632 (avg: 3.5545)\tTop1: 20.312 (avg: 19.338)\tTop5: 42.188 (avg: 44.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2277\tTop 1 accuracy: 13.200\tTop 5 accuracy: 32.500\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.532 (avg: 0.519)\tLoss: 3.2955 (avg: 3.5297)\tTop1: 21.875 (avg: 20.750)\tTop5: 45.312 (avg: 44.938)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.521 (avg: 0.526)\tLoss: 3.9238 (avg: 3.5321)\tTop1: 15.625 (avg: 20.000)\tTop5: 34.375 (avg: 45.031)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.521 (avg: 0.528)\tLoss: 3.3218 (avg: 3.5265)\tTop1: 29.688 (avg: 19.958)\tTop5: 53.125 (avg: 45.062)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.535 (avg: 0.529)\tLoss: 3.6276 (avg: 3.5379)\tTop1: 17.188 (avg: 19.750)\tTop5: 40.625 (avg: 44.625)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.526 (avg: 0.530)\tLoss: 3.7573 (avg: 3.5416)\tTop1: 14.062 (avg: 19.713)\tTop5: 34.375 (avg: 44.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3787\tTop 1 accuracy: 12.200\tTop 5 accuracy: 32.200\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.523 (avg: 0.519)\tLoss: 3.2084 (avg: 3.4692)\tTop1: 25.000 (avg: 21.312)\tTop5: 57.812 (avg: 46.250)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.536 (avg: 0.526)\tLoss: 3.5410 (avg: 3.4771)\tTop1: 23.438 (avg: 20.719)\tTop5: 43.750 (avg: 46.312)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.524 (avg: 0.528)\tLoss: 3.6505 (avg: 3.5059)\tTop1: 14.062 (avg: 20.104)\tTop5: 43.750 (avg: 45.750)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.518 (avg: 0.529)\tLoss: 3.4796 (avg: 3.5145)\tTop1: 18.750 (avg: 19.688)\tTop5: 45.312 (avg: 45.609)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.523 (avg: 0.530)\tLoss: 3.3671 (avg: 3.5236)\tTop1: 17.188 (avg: 19.450)\tTop5: 45.312 (avg: 45.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2085\tTop 1 accuracy: 12.700\tTop 5 accuracy: 33.750\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.525 (avg: 0.519)\tLoss: 3.8169 (avg: 3.4687)\tTop1: 12.500 (avg: 21.188)\tTop5: 39.062 (avg: 46.000)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.523 (avg: 0.526)\tLoss: 3.3458 (avg: 3.5017)\tTop1: 23.438 (avg: 20.719)\tTop5: 48.438 (avg: 45.500)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.534 (avg: 0.528)\tLoss: 3.7439 (avg: 3.5263)\tTop1: 18.750 (avg: 20.167)\tTop5: 37.500 (avg: 45.208)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.520 (avg: 0.529)\tLoss: 3.2468 (avg: 3.5166)\tTop1: 25.000 (avg: 20.312)\tTop5: 53.125 (avg: 45.438)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.524 (avg: 0.530)\tLoss: 3.1882 (avg: 3.5169)\tTop1: 28.125 (avg: 20.250)\tTop5: 48.438 (avg: 45.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.1942\tTop 1 accuracy: 12.600\tTop 5 accuracy: 33.450\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.539 (avg: 0.520)\tLoss: 3.6261 (avg: 3.4676)\tTop1: 23.438 (avg: 21.938)\tTop5: 45.312 (avg: 45.562)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.528 (avg: 0.527)\tLoss: 3.1754 (avg: 3.4576)\tTop1: 26.562 (avg: 20.781)\tTop5: 57.812 (avg: 46.688)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.525 (avg: 0.529)\tLoss: 3.1919 (avg: 3.4772)\tTop1: 23.438 (avg: 20.292)\tTop5: 54.688 (avg: 46.312)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.524 (avg: 0.530)\tLoss: 3.6484 (avg: 3.4808)\tTop1: 23.438 (avg: 20.516)\tTop5: 45.312 (avg: 46.000)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.533 (avg: 0.531)\tLoss: 3.4029 (avg: 3.4900)\tTop1: 21.875 (avg: 20.300)\tTop5: 53.125 (avg: 45.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2865\tTop 1 accuracy: 12.900\tTop 5 accuracy: 33.050\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.521 (avg: 0.520)\tLoss: 3.4270 (avg: 3.4984)\tTop1: 21.875 (avg: 21.562)\tTop5: 50.000 (avg: 47.562)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.532 (avg: 0.526)\tLoss: 3.5839 (avg: 3.5044)\tTop1: 17.188 (avg: 20.344)\tTop5: 34.375 (avg: 46.125)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.529 (avg: 0.528)\tLoss: 3.3697 (avg: 3.4787)\tTop1: 15.625 (avg: 20.354)\tTop5: 46.875 (avg: 46.771)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.523 (avg: 0.529)\tLoss: 3.4441 (avg: 3.4707)\tTop1: 23.438 (avg: 20.547)\tTop5: 45.312 (avg: 46.703)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.520 (avg: 0.530)\tLoss: 3.7544 (avg: 3.4826)\tTop1: 14.062 (avg: 20.150)\tTop5: 37.500 (avg: 46.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2202\tTop 1 accuracy: 12.750\tTop 5 accuracy: 33.750\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.529 (avg: 0.520)\tLoss: 3.6842 (avg: 3.4093)\tTop1: 14.062 (avg: 21.000)\tTop5: 37.500 (avg: 47.312)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.521 (avg: 0.527)\tLoss: 3.6861 (avg: 3.3899)\tTop1: 18.750 (avg: 21.094)\tTop5: 39.062 (avg: 47.625)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.519 (avg: 0.529)\tLoss: 3.4036 (avg: 3.4192)\tTop1: 15.625 (avg: 21.125)\tTop5: 48.438 (avg: 47.438)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.528 (avg: 0.530)\tLoss: 3.7412 (avg: 3.4460)\tTop1: 15.625 (avg: 21.141)\tTop5: 35.938 (avg: 47.047)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.527 (avg: 0.530)\tLoss: 3.4629 (avg: 3.4604)\tTop1: 14.062 (avg: 20.663)\tTop5: 46.875 (avg: 46.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3415\tTop 1 accuracy: 12.600\tTop 5 accuracy: 32.550\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.534 (avg: 0.519)\tLoss: 3.3063 (avg: 3.3722)\tTop1: 23.438 (avg: 22.062)\tTop5: 46.875 (avg: 48.750)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.526 (avg: 0.526)\tLoss: 3.1258 (avg: 3.4210)\tTop1: 25.000 (avg: 21.312)\tTop5: 57.812 (avg: 47.156)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.519 (avg: 0.528)\tLoss: 3.6784 (avg: 3.4124)\tTop1: 17.188 (avg: 21.500)\tTop5: 40.625 (avg: 47.938)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.521 (avg: 0.529)\tLoss: 3.6901 (avg: 3.4564)\tTop1: 20.312 (avg: 20.719)\tTop5: 32.812 (avg: 46.359)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.532 (avg: 0.529)\tLoss: 3.8531 (avg: 3.4542)\tTop1: 10.938 (avg: 20.438)\tTop5: 37.500 (avg: 46.313)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.4380\tTop 1 accuracy: 12.350\tTop 5 accuracy: 32.950\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.525 (avg: 0.520)\tLoss: 3.1656 (avg: 3.3777)\tTop1: 28.125 (avg: 22.125)\tTop5: 46.875 (avg: 48.188)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.516 (avg: 0.527)\tLoss: 2.9726 (avg: 3.3767)\tTop1: 26.562 (avg: 21.812)\tTop5: 59.375 (avg: 48.781)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.532 (avg: 0.529)\tLoss: 3.6554 (avg: 3.4172)\tTop1: 17.188 (avg: 21.083)\tTop5: 40.625 (avg: 48.042)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.526 (avg: 0.530)\tLoss: 3.5340 (avg: 3.4234)\tTop1: 17.188 (avg: 21.062)\tTop5: 50.000 (avg: 47.812)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.526 (avg: 0.531)\tLoss: 3.6474 (avg: 3.4348)\tTop1: 14.062 (avg: 20.850)\tTop5: 46.875 (avg: 47.400)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2176\tTop 1 accuracy: 13.800\tTop 5 accuracy: 33.700\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.526 (avg: 0.520)\tLoss: 3.3110 (avg: 3.3295)\tTop1: 23.438 (avg: 22.625)\tTop5: 43.750 (avg: 49.688)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.525 (avg: 0.526)\tLoss: 3.1908 (avg: 3.3127)\tTop1: 20.312 (avg: 23.281)\tTop5: 53.125 (avg: 49.656)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.526 (avg: 0.528)\tLoss: 3.2819 (avg: 3.3139)\tTop1: 29.688 (avg: 23.917)\tTop5: 54.688 (avg: 49.542)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.531 (avg: 0.530)\tLoss: 3.1558 (avg: 3.3028)\tTop1: 32.812 (avg: 24.125)\tTop5: 50.000 (avg: 49.922)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.524 (avg: 0.530)\tLoss: 3.3724 (avg: 3.3068)\tTop1: 20.312 (avg: 23.925)\tTop5: 48.438 (avg: 49.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2810\tTop 1 accuracy: 14.150\tTop 5 accuracy: 34.950\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.526 (avg: 0.520)\tLoss: 3.2634 (avg: 3.2777)\tTop1: 20.312 (avg: 24.500)\tTop5: 50.000 (avg: 51.250)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.537 (avg: 0.527)\tLoss: 3.4515 (avg: 3.2663)\tTop1: 26.562 (avg: 24.875)\tTop5: 48.438 (avg: 51.312)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.529 (avg: 0.529)\tLoss: 3.6266 (avg: 3.2940)\tTop1: 17.188 (avg: 24.396)\tTop5: 45.312 (avg: 51.125)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.527 (avg: 0.530)\tLoss: 3.3166 (avg: 3.2798)\tTop1: 26.562 (avg: 24.594)\tTop5: 51.562 (avg: 50.922)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.524 (avg: 0.531)\tLoss: 3.2414 (avg: 3.2753)\tTop1: 25.000 (avg: 24.563)\tTop5: 54.688 (avg: 50.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2874\tTop 1 accuracy: 14.650\tTop 5 accuracy: 34.800\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.524 (avg: 0.519)\tLoss: 3.2750 (avg: 3.2764)\tTop1: 28.125 (avg: 24.812)\tTop5: 54.688 (avg: 50.750)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.523 (avg: 0.525)\tLoss: 3.0920 (avg: 3.2532)\tTop1: 29.688 (avg: 25.156)\tTop5: 51.562 (avg: 50.812)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.532 (avg: 0.528)\tLoss: 3.4036 (avg: 3.2502)\tTop1: 21.875 (avg: 25.333)\tTop5: 48.438 (avg: 50.938)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.525 (avg: 0.529)\tLoss: 3.2516 (avg: 3.2570)\tTop1: 23.438 (avg: 25.172)\tTop5: 48.438 (avg: 50.703)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.526 (avg: 0.530)\tLoss: 3.3085 (avg: 3.2686)\tTop1: 26.562 (avg: 25.063)\tTop5: 48.438 (avg: 50.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.1779\tTop 1 accuracy: 14.700\tTop 5 accuracy: 35.100\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.533 (avg: 0.520)\tLoss: 3.7654 (avg: 3.2613)\tTop1: 18.750 (avg: 24.812)\tTop5: 39.062 (avg: 51.250)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.523 (avg: 0.527)\tLoss: 3.3309 (avg: 3.2615)\tTop1: 28.125 (avg: 25.094)\tTop5: 45.312 (avg: 50.625)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.525 (avg: 0.529)\tLoss: 2.8979 (avg: 3.2698)\tTop1: 37.500 (avg: 25.167)\tTop5: 57.812 (avg: 50.750)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.523 (avg: 0.530)\tLoss: 3.2194 (avg: 3.2684)\tTop1: 28.125 (avg: 25.188)\tTop5: 48.438 (avg: 50.844)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.529 (avg: 0.530)\tLoss: 3.0720 (avg: 3.2597)\tTop1: 25.000 (avg: 25.000)\tTop5: 59.375 (avg: 51.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3248\tTop 1 accuracy: 14.350\tTop 5 accuracy: 34.450\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.519 (avg: 0.519)\tLoss: 3.1102 (avg: 3.2237)\tTop1: 29.688 (avg: 26.625)\tTop5: 60.938 (avg: 52.250)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.533 (avg: 0.526)\tLoss: 3.2125 (avg: 3.2196)\tTop1: 20.312 (avg: 26.125)\tTop5: 50.000 (avg: 52.188)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.525 (avg: 0.528)\tLoss: 3.4443 (avg: 3.2390)\tTop1: 20.312 (avg: 25.500)\tTop5: 46.875 (avg: 51.396)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.520 (avg: 0.529)\tLoss: 3.3076 (avg: 3.2433)\tTop1: 25.000 (avg: 25.297)\tTop5: 48.438 (avg: 51.312)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.524 (avg: 0.530)\tLoss: 3.3419 (avg: 3.2556)\tTop1: 23.438 (avg: 25.288)\tTop5: 50.000 (avg: 51.013)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2986\tTop 1 accuracy: 14.600\tTop 5 accuracy: 34.700\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.529 (avg: 0.521)\tLoss: 3.4716 (avg: 3.1793)\tTop1: 21.875 (avg: 27.250)\tTop5: 53.125 (avg: 53.125)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.525 (avg: 0.527)\tLoss: 3.4481 (avg: 3.2326)\tTop1: 18.750 (avg: 25.156)\tTop5: 45.312 (avg: 51.688)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.525 (avg: 0.529)\tLoss: 3.2084 (avg: 3.2468)\tTop1: 25.000 (avg: 25.062)\tTop5: 59.375 (avg: 51.167)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.535 (avg: 0.531)\tLoss: 3.5305 (avg: 3.2523)\tTop1: 23.438 (avg: 25.391)\tTop5: 46.875 (avg: 51.172)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.521 (avg: 0.531)\tLoss: 3.1286 (avg: 3.2542)\tTop1: 25.000 (avg: 25.125)\tTop5: 46.875 (avg: 50.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2494\tTop 1 accuracy: 14.450\tTop 5 accuracy: 34.800\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.533 (avg: 0.520)\tLoss: 3.2073 (avg: 3.1488)\tTop1: 25.000 (avg: 27.312)\tTop5: 57.812 (avg: 53.688)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.528 (avg: 0.525)\tLoss: 2.9328 (avg: 3.2208)\tTop1: 32.812 (avg: 25.469)\tTop5: 53.125 (avg: 52.000)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.524 (avg: 0.528)\tLoss: 3.6409 (avg: 3.2355)\tTop1: 12.500 (avg: 25.292)\tTop5: 45.312 (avg: 51.854)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.528 (avg: 0.529)\tLoss: 3.1673 (avg: 3.2474)\tTop1: 29.688 (avg: 25.203)\tTop5: 57.812 (avg: 51.703)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.528 (avg: 0.529)\tLoss: 3.6624 (avg: 3.2489)\tTop1: 18.750 (avg: 25.100)\tTop5: 46.875 (avg: 51.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2659\tTop 1 accuracy: 15.100\tTop 5 accuracy: 34.850\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.519 (avg: 0.521)\tLoss: 3.4359 (avg: 3.1628)\tTop1: 26.562 (avg: 26.812)\tTop5: 42.188 (avg: 53.438)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.522 (avg: 0.527)\tLoss: 2.9041 (avg: 3.1898)\tTop1: 21.875 (avg: 26.156)\tTop5: 57.812 (avg: 51.656)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.534 (avg: 0.529)\tLoss: 2.6703 (avg: 3.2169)\tTop1: 39.062 (avg: 25.667)\tTop5: 64.062 (avg: 51.646)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.525 (avg: 0.530)\tLoss: 3.3683 (avg: 3.2292)\tTop1: 21.875 (avg: 25.547)\tTop5: 51.562 (avg: 51.547)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.522 (avg: 0.531)\tLoss: 3.1152 (avg: 3.2424)\tTop1: 18.750 (avg: 25.250)\tTop5: 59.375 (avg: 51.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2824\tTop 1 accuracy: 14.800\tTop 5 accuracy: 34.850\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.527 (avg: 0.520)\tLoss: 3.3572 (avg: 3.2335)\tTop1: 17.188 (avg: 25.812)\tTop5: 57.812 (avg: 52.500)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.521 (avg: 0.526)\tLoss: 3.1894 (avg: 3.2393)\tTop1: 31.250 (avg: 25.625)\tTop5: 53.125 (avg: 51.844)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.523 (avg: 0.528)\tLoss: 3.3607 (avg: 3.2277)\tTop1: 28.125 (avg: 26.062)\tTop5: 51.562 (avg: 51.792)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.534 (avg: 0.529)\tLoss: 2.9722 (avg: 3.2444)\tTop1: 32.812 (avg: 25.906)\tTop5: 50.000 (avg: 51.375)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.524 (avg: 0.530)\tLoss: 3.1910 (avg: 3.2415)\tTop1: 25.000 (avg: 25.950)\tTop5: 53.125 (avg: 51.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3101\tTop 1 accuracy: 14.850\tTop 5 accuracy: 34.450\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.526 (avg: 0.525)\tLoss: 3.5044 (avg: 3.2156)\tTop1: 21.875 (avg: 27.312)\tTop5: 45.312 (avg: 51.375)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.543 (avg: 0.532)\tLoss: 3.4867 (avg: 3.2297)\tTop1: 18.750 (avg: 25.969)\tTop5: 48.438 (avg: 50.906)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.531 (avg: 0.535)\tLoss: 3.3790 (avg: 3.2236)\tTop1: 26.562 (avg: 26.312)\tTop5: 43.750 (avg: 51.250)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.531 (avg: 0.536)\tLoss: 3.7939 (avg: 3.2366)\tTop1: 14.062 (avg: 25.875)\tTop5: 42.188 (avg: 51.172)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.529 (avg: 0.536)\tLoss: 3.0411 (avg: 3.2399)\tTop1: 17.188 (avg: 25.700)\tTop5: 57.812 (avg: 51.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3175\tTop 1 accuracy: 14.450\tTop 5 accuracy: 34.500\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.526 (avg: 0.524)\tLoss: 2.9020 (avg: 3.2264)\tTop1: 28.125 (avg: 26.688)\tTop5: 56.250 (avg: 51.750)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.534 (avg: 0.530)\tLoss: 3.6217 (avg: 3.2655)\tTop1: 15.625 (avg: 24.938)\tTop5: 43.750 (avg: 50.906)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.539 (avg: 0.533)\tLoss: 3.3574 (avg: 3.2581)\tTop1: 26.562 (avg: 25.229)\tTop5: 56.250 (avg: 51.000)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.534 (avg: 0.534)\tLoss: 3.8197 (avg: 3.2313)\tTop1: 21.875 (avg: 25.469)\tTop5: 53.125 (avg: 51.844)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.529 (avg: 0.535)\tLoss: 3.3289 (avg: 3.2355)\tTop1: 26.562 (avg: 25.413)\tTop5: 50.000 (avg: 51.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3089\tTop 1 accuracy: 15.000\tTop 5 accuracy: 34.950\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.544 (avg: 0.530)\tLoss: 3.4789 (avg: 3.2186)\tTop1: 18.750 (avg: 24.625)\tTop5: 50.000 (avg: 53.312)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.532 (avg: 0.536)\tLoss: 3.4656 (avg: 3.2137)\tTop1: 20.312 (avg: 25.188)\tTop5: 48.438 (avg: 52.188)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.523 (avg: 0.535)\tLoss: 3.3077 (avg: 3.2419)\tTop1: 28.125 (avg: 25.375)\tTop5: 53.125 (avg: 51.833)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.524 (avg: 0.535)\tLoss: 2.9921 (avg: 3.2370)\tTop1: 31.250 (avg: 25.062)\tTop5: 54.688 (avg: 51.281)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.529 (avg: 0.534)\tLoss: 2.8834 (avg: 3.2262)\tTop1: 37.500 (avg: 25.363)\tTop5: 59.375 (avg: 51.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2634\tTop 1 accuracy: 14.950\tTop 5 accuracy: 35.000\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.523 (avg: 0.519)\tLoss: 3.1377 (avg: 3.2020)\tTop1: 29.688 (avg: 27.125)\tTop5: 59.375 (avg: 52.750)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.534 (avg: 0.526)\tLoss: 2.8617 (avg: 3.2033)\tTop1: 34.375 (avg: 27.094)\tTop5: 59.375 (avg: 52.625)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.530 (avg: 0.528)\tLoss: 3.1530 (avg: 3.2097)\tTop1: 18.750 (avg: 26.250)\tTop5: 48.438 (avg: 51.917)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.521 (avg: 0.529)\tLoss: 3.2366 (avg: 3.2131)\tTop1: 25.000 (avg: 26.141)\tTop5: 57.812 (avg: 52.328)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.524 (avg: 0.530)\tLoss: 3.3889 (avg: 3.2258)\tTop1: 20.312 (avg: 25.738)\tTop5: 45.312 (avg: 51.738)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2647\tTop 1 accuracy: 14.750\tTop 5 accuracy: 35.000\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.524 (avg: 0.520)\tLoss: 3.7114 (avg: 3.2562)\tTop1: 25.000 (avg: 25.938)\tTop5: 40.625 (avg: 51.812)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.521 (avg: 0.526)\tLoss: 3.3292 (avg: 3.2195)\tTop1: 28.125 (avg: 26.438)\tTop5: 45.312 (avg: 52.031)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.523 (avg: 0.529)\tLoss: 3.2199 (avg: 3.2329)\tTop1: 23.438 (avg: 26.062)\tTop5: 54.688 (avg: 51.500)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.533 (avg: 0.530)\tLoss: 2.9861 (avg: 3.2324)\tTop1: 29.688 (avg: 25.922)\tTop5: 60.938 (avg: 51.766)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.530 (avg: 0.531)\tLoss: 3.0022 (avg: 3.2266)\tTop1: 26.562 (avg: 25.800)\tTop5: 54.688 (avg: 51.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.2593\tTop 1 accuracy: 14.650\tTop 5 accuracy: 34.850\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.533 (avg: 0.519)\tLoss: 3.2390 (avg: 3.2330)\tTop1: 28.125 (avg: 26.250)\tTop5: 48.438 (avg: 50.812)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.528 (avg: 0.525)\tLoss: 3.0521 (avg: 3.2372)\tTop1: 25.000 (avg: 25.719)\tTop5: 51.562 (avg: 51.156)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.525 (avg: 0.528)\tLoss: 3.1628 (avg: 3.2285)\tTop1: 34.375 (avg: 26.062)\tTop5: 56.250 (avg: 51.583)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.522 (avg: 0.529)\tLoss: 2.9534 (avg: 3.2159)\tTop1: 21.875 (avg: 26.250)\tTop5: 56.250 (avg: 51.984)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.537 (avg: 0.530)\tLoss: 2.8553 (avg: 3.2207)\tTop1: 23.438 (avg: 25.750)\tTop5: 62.500 (avg: 51.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.3331\tTop 1 accuracy: 14.750\tTop 5 accuracy: 34.350\n",
            "\n",
            "incr_e = 256: top1 = 14.700000762939453 \t top5 = 35.10000228881836 \t batch time = 0.3464037775993347\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N91do0fJPEgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38423
        },
        "outputId": "fbfdc66d-97ab-4095-a42a-2af18836c9fb"
      },
      "cell_type": "code",
      "source": [
        "# freq\n",
        "freq_list = [1, 3, 4]\n",
        "freq_top1s = []\n",
        "freq_top5s = []\n",
        "freq_batch_times = []\n",
        "for freq in freq_list:\n",
        "  model = SqueezeNet_MetaParam(version=1.0, freq=freq)\n",
        "  batch_time, top1, top5 = test_model(model)\n",
        "  freq_top1s.append(top1)\n",
        "  freq_top5s.append(top5)\n",
        "  freq_batch_times.append(batch_time)\n",
        "  print(\"freq = {0}: top1 = {1} \\t top5 = {2} \\t batch_time = {3}\\n\".format(freq, top1, top5, batch_time))\n",
        "  \n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.584 (avg: 0.855)\tLoss: 5.2971 (avg: 5.3156)\tTop1: 1.562 (avg: 0.500)\tTop5: 1.562 (avg: 2.312)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.586 (avg: 0.721)\tLoss: 5.2995 (avg: 5.3079)\tTop1: 0.000 (avg: 0.438)\tTop5: 1.562 (avg: 2.312)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.588 (avg: 0.677)\tLoss: 5.2943 (avg: 5.3047)\tTop1: 3.125 (avg: 0.417)\tTop5: 6.250 (avg: 2.354)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.590 (avg: 0.656)\tLoss: 5.2997 (avg: 5.3019)\tTop1: 0.000 (avg: 0.469)\tTop5: 3.125 (avg: 2.469)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.586 (avg: 0.644)\tLoss: 5.2927 (avg: 5.2973)\tTop1: 0.000 (avg: 0.463)\tTop5: 1.562 (avg: 2.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3023\tTop 1 accuracy: 0.500\tTop 5 accuracy: 2.500\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.594 (avg: 0.581)\tLoss: 5.2991 (avg: 5.2702)\tTop1: 0.000 (avg: 0.562)\tTop5: 1.562 (avg: 2.938)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.601 (avg: 0.591)\tLoss: 5.3519 (avg: 5.2691)\tTop1: 0.000 (avg: 0.719)\tTop5: 0.000 (avg: 3.031)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.591 (avg: 0.594)\tLoss: 5.2301 (avg: 5.2680)\tTop1: 0.000 (avg: 0.667)\tTop5: 4.688 (avg: 2.979)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.594 (avg: 0.595)\tLoss: 5.2250 (avg: 5.2657)\tTop1: 3.125 (avg: 0.703)\tTop5: 4.688 (avg: 3.156)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.595 (avg: 0.597)\tLoss: 5.2444 (avg: 5.2647)\tTop1: 0.000 (avg: 0.613)\tTop5: 4.688 (avg: 3.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3482\tTop 1 accuracy: 0.750\tTop 5 accuracy: 3.300\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.589 (avg: 0.584)\tLoss: 5.3161 (avg: 5.2558)\tTop1: 0.000 (avg: 0.875)\tTop5: 0.000 (avg: 4.688)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.598 (avg: 0.591)\tLoss: 5.2728 (avg: 5.2517)\tTop1: 1.562 (avg: 1.000)\tTop5: 1.562 (avg: 4.562)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.590 (avg: 0.593)\tLoss: 5.2258 (avg: 5.2560)\tTop1: 1.562 (avg: 1.083)\tTop5: 3.125 (avg: 4.208)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.587 (avg: 0.594)\tLoss: 5.2972 (avg: 5.2535)\tTop1: 0.000 (avg: 1.000)\tTop5: 0.000 (avg: 4.047)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.595 (avg: 0.595)\tLoss: 5.3012 (avg: 5.2531)\tTop1: 0.000 (avg: 1.013)\tTop5: 3.125 (avg: 4.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3583\tTop 1 accuracy: 0.600\tTop 5 accuracy: 3.650\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.599 (avg: 0.586)\tLoss: 5.2889 (avg: 5.2545)\tTop1: 0.000 (avg: 0.875)\tTop5: 1.562 (avg: 3.562)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.595 (avg: 0.594)\tLoss: 5.1847 (avg: 5.2446)\tTop1: 1.562 (avg: 1.094)\tTop5: 6.250 (avg: 4.406)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.608 (avg: 0.597)\tLoss: 5.2822 (avg: 5.2368)\tTop1: 1.562 (avg: 1.104)\tTop5: 4.688 (avg: 4.646)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.590 (avg: 0.598)\tLoss: 5.2388 (avg: 5.2342)\tTop1: 1.562 (avg: 1.094)\tTop5: 6.250 (avg: 4.750)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.597 (avg: 0.598)\tLoss: 5.2602 (avg: 5.2355)\tTop1: 0.000 (avg: 0.975)\tTop5: 1.562 (avg: 4.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3724\tTop 1 accuracy: 0.650\tTop 5 accuracy: 4.000\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.588 (avg: 0.583)\tLoss: 5.1951 (avg: 5.2253)\tTop1: 0.000 (avg: 1.000)\tTop5: 1.562 (avg: 6.125)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.588 (avg: 0.590)\tLoss: 5.2669 (avg: 5.2409)\tTop1: 0.000 (avg: 0.969)\tTop5: 1.562 (avg: 5.094)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.592 (avg: 0.592)\tLoss: 5.1578 (avg: 5.2430)\tTop1: 0.000 (avg: 1.083)\tTop5: 4.688 (avg: 4.958)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.583 (avg: 0.593)\tLoss: 5.0466 (avg: 5.2399)\tTop1: 1.562 (avg: 1.078)\tTop5: 9.375 (avg: 4.812)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.591 (avg: 0.594)\tLoss: 5.1653 (avg: 5.2345)\tTop1: 0.000 (avg: 1.038)\tTop5: 4.688 (avg: 4.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3407\tTop 1 accuracy: 0.600\tTop 5 accuracy: 4.600\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.587 (avg: 0.586)\tLoss: 5.2711 (avg: 5.2079)\tTop1: 3.125 (avg: 1.250)\tTop5: 4.688 (avg: 5.562)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.588 (avg: 0.593)\tLoss: 5.2391 (avg: 5.2035)\tTop1: 3.125 (avg: 1.125)\tTop5: 6.250 (avg: 5.719)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.595 (avg: 0.595)\tLoss: 5.2045 (avg: 5.1980)\tTop1: 0.000 (avg: 1.208)\tTop5: 3.125 (avg: 5.729)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.603 (avg: 0.596)\tLoss: 5.2438 (avg: 5.2049)\tTop1: 1.562 (avg: 1.172)\tTop5: 6.250 (avg: 5.594)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.590 (avg: 0.597)\tLoss: 5.2277 (avg: 5.2061)\tTop1: 1.562 (avg: 1.188)\tTop5: 9.375 (avg: 5.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3166\tTop 1 accuracy: 1.200\tTop 5 accuracy: 5.000\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.589 (avg: 0.580)\tLoss: 5.2426 (avg: 5.1856)\tTop1: 0.000 (avg: 1.625)\tTop5: 1.562 (avg: 6.562)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.592 (avg: 0.587)\tLoss: 5.2011 (avg: 5.1851)\tTop1: 0.000 (avg: 1.625)\tTop5: 7.812 (avg: 6.781)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.591 (avg: 0.591)\tLoss: 5.2067 (avg: 5.1879)\tTop1: 0.000 (avg: 1.458)\tTop5: 4.688 (avg: 6.312)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.595 (avg: 0.592)\tLoss: 5.1536 (avg: 5.1907)\tTop1: 0.000 (avg: 1.422)\tTop5: 6.250 (avg: 6.344)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.586 (avg: 0.593)\tLoss: 5.2002 (avg: 5.1910)\tTop1: 1.562 (avg: 1.500)\tTop5: 9.375 (avg: 6.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3254\tTop 1 accuracy: 1.000\tTop 5 accuracy: 5.300\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.597 (avg: 0.584)\tLoss: 5.2314 (avg: 5.2050)\tTop1: 1.562 (avg: 0.938)\tTop5: 4.688 (avg: 5.688)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.581 (avg: 0.591)\tLoss: 5.0904 (avg: 5.1853)\tTop1: 3.125 (avg: 1.125)\tTop5: 9.375 (avg: 6.094)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.588 (avg: 0.594)\tLoss: 5.1386 (avg: 5.1775)\tTop1: 1.562 (avg: 1.396)\tTop5: 6.250 (avg: 6.438)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.594 (avg: 0.595)\tLoss: 5.1478 (avg: 5.1776)\tTop1: 1.562 (avg: 1.453)\tTop5: 10.938 (avg: 6.609)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.601 (avg: 0.596)\tLoss: 5.2445 (avg: 5.1752)\tTop1: 0.000 (avg: 1.500)\tTop5: 0.000 (avg: 6.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.4067\tTop 1 accuracy: 1.650\tTop 5 accuracy: 6.050\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.593 (avg: 0.581)\tLoss: 5.2931 (avg: 5.1617)\tTop1: 0.000 (avg: 1.125)\tTop5: 3.125 (avg: 6.938)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.583 (avg: 0.586)\tLoss: 5.2171 (avg: 5.1785)\tTop1: 0.000 (avg: 1.438)\tTop5: 4.688 (avg: 7.094)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.585 (avg: 0.589)\tLoss: 5.0386 (avg: 5.1708)\tTop1: 0.000 (avg: 1.604)\tTop5: 9.375 (avg: 6.979)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.589 (avg: 0.590)\tLoss: 5.2806 (avg: 5.1757)\tTop1: 3.125 (avg: 1.531)\tTop5: 7.812 (avg: 6.891)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.588 (avg: 0.591)\tLoss: 5.1743 (avg: 5.1795)\tTop1: 3.125 (avg: 1.475)\tTop5: 10.938 (avg: 6.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3341\tTop 1 accuracy: 1.300\tTop 5 accuracy: 5.850\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.594 (avg: 0.585)\tLoss: 5.1334 (avg: 5.1735)\tTop1: 3.125 (avg: 1.875)\tTop5: 7.812 (avg: 6.500)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.598 (avg: 0.592)\tLoss: 4.9965 (avg: 5.1513)\tTop1: 1.562 (avg: 1.750)\tTop5: 10.938 (avg: 6.906)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.590 (avg: 0.594)\tLoss: 5.1496 (avg: 5.1537)\tTop1: 1.562 (avg: 1.625)\tTop5: 7.812 (avg: 6.896)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.584 (avg: 0.595)\tLoss: 5.1720 (avg: 5.1531)\tTop1: 1.562 (avg: 1.719)\tTop5: 7.812 (avg: 7.141)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.590 (avg: 0.596)\tLoss: 5.2056 (avg: 5.1613)\tTop1: 3.125 (avg: 1.600)\tTop5: 9.375 (avg: 6.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2204\tTop 1 accuracy: 1.500\tTop 5 accuracy: 6.800\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.593 (avg: 0.579)\tLoss: 5.1565 (avg: 5.1815)\tTop1: 1.562 (avg: 1.688)\tTop5: 6.250 (avg: 7.562)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.590 (avg: 0.588)\tLoss: 5.1872 (avg: 5.1774)\tTop1: 3.125 (avg: 1.406)\tTop5: 6.250 (avg: 6.719)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.588 (avg: 0.590)\tLoss: 5.2566 (avg: 5.1669)\tTop1: 1.562 (avg: 1.479)\tTop5: 10.938 (avg: 6.792)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.588 (avg: 0.591)\tLoss: 5.1857 (avg: 5.1673)\tTop1: 0.000 (avg: 1.547)\tTop5: 9.375 (avg: 6.953)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.589 (avg: 0.592)\tLoss: 5.0801 (avg: 5.1588)\tTop1: 1.562 (avg: 1.538)\tTop5: 6.250 (avg: 7.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2294\tTop 1 accuracy: 2.300\tTop 5 accuracy: 7.300\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.582 (avg: 0.581)\tLoss: 5.3206 (avg: 5.1540)\tTop1: 3.125 (avg: 1.250)\tTop5: 7.812 (avg: 7.438)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.591 (avg: 0.588)\tLoss: 5.0981 (avg: 5.1408)\tTop1: 0.000 (avg: 1.500)\tTop5: 6.250 (avg: 7.562)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.596 (avg: 0.591)\tLoss: 5.2475 (avg: 5.1357)\tTop1: 3.125 (avg: 1.708)\tTop5: 6.250 (avg: 7.792)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.590 (avg: 0.593)\tLoss: 5.0552 (avg: 5.1319)\tTop1: 0.000 (avg: 1.719)\tTop5: 9.375 (avg: 7.953)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.583 (avg: 0.594)\tLoss: 5.1650 (avg: 5.1324)\tTop1: 6.250 (avg: 1.875)\tTop5: 9.375 (avg: 8.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3381\tTop 1 accuracy: 1.500\tTop 5 accuracy: 6.300\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.589 (avg: 0.581)\tLoss: 5.1037 (avg: 5.1444)\tTop1: 3.125 (avg: 1.750)\tTop5: 14.062 (avg: 7.938)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.593 (avg: 0.589)\tLoss: 5.0804 (avg: 5.1195)\tTop1: 3.125 (avg: 1.969)\tTop5: 9.375 (avg: 8.469)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.587 (avg: 0.591)\tLoss: 5.0006 (avg: 5.1269)\tTop1: 1.562 (avg: 1.979)\tTop5: 7.812 (avg: 7.938)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.586 (avg: 0.592)\tLoss: 5.1165 (avg: 5.1228)\tTop1: 3.125 (avg: 2.000)\tTop5: 9.375 (avg: 8.281)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.589 (avg: 0.593)\tLoss: 5.0019 (avg: 5.1251)\tTop1: 3.125 (avg: 2.000)\tTop5: 9.375 (avg: 8.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.4789\tTop 1 accuracy: 1.700\tTop 5 accuracy: 7.150\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.585 (avg: 0.582)\tLoss: 5.0573 (avg: 5.1377)\tTop1: 9.375 (avg: 2.000)\tTop5: 10.938 (avg: 7.812)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.583 (avg: 0.588)\tLoss: 5.1574 (avg: 5.1206)\tTop1: 0.000 (avg: 2.031)\tTop5: 4.688 (avg: 8.625)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.586 (avg: 0.591)\tLoss: 5.0798 (avg: 5.1133)\tTop1: 1.562 (avg: 1.917)\tTop5: 7.812 (avg: 8.458)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.593 (avg: 0.593)\tLoss: 5.1300 (avg: 5.1229)\tTop1: 0.000 (avg: 1.938)\tTop5: 1.562 (avg: 8.328)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.586 (avg: 0.593)\tLoss: 5.0566 (avg: 5.1182)\tTop1: 0.000 (avg: 2.050)\tTop5: 9.375 (avg: 8.625)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3978\tTop 1 accuracy: 1.950\tTop 5 accuracy: 7.600\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.583 (avg: 0.578)\tLoss: 5.0629 (avg: 5.0893)\tTop1: 6.250 (avg: 2.188)\tTop5: 7.812 (avg: 8.750)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.593 (avg: 0.587)\tLoss: 5.1687 (avg: 5.0909)\tTop1: 4.688 (avg: 2.188)\tTop5: 9.375 (avg: 9.031)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.593 (avg: 0.590)\tLoss: 5.2380 (avg: 5.0936)\tTop1: 1.562 (avg: 2.208)\tTop5: 10.938 (avg: 9.104)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.588 (avg: 0.591)\tLoss: 4.9542 (avg: 5.0981)\tTop1: 6.250 (avg: 2.188)\tTop5: 14.062 (avg: 8.969)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.587 (avg: 0.592)\tLoss: 5.0648 (avg: 5.0930)\tTop1: 1.562 (avg: 2.363)\tTop5: 12.500 (avg: 8.988)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3505\tTop 1 accuracy: 1.900\tTop 5 accuracy: 7.600\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.598 (avg: 0.582)\tLoss: 5.1651 (avg: 5.0757)\tTop1: 3.125 (avg: 2.250)\tTop5: 6.250 (avg: 9.250)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.584 (avg: 0.590)\tLoss: 5.1873 (avg: 5.0793)\tTop1: 0.000 (avg: 2.594)\tTop5: 4.688 (avg: 9.688)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.585 (avg: 0.592)\tLoss: 5.0588 (avg: 5.0792)\tTop1: 3.125 (avg: 2.438)\tTop5: 9.375 (avg: 9.542)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.591 (avg: 0.593)\tLoss: 5.0215 (avg: 5.0780)\tTop1: 1.562 (avg: 2.422)\tTop5: 9.375 (avg: 9.266)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.599 (avg: 0.594)\tLoss: 5.0590 (avg: 5.0736)\tTop1: 1.562 (avg: 2.388)\tTop5: 12.500 (avg: 9.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3872\tTop 1 accuracy: 2.000\tTop 5 accuracy: 8.650\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.591 (avg: 0.581)\tLoss: 4.9670 (avg: 5.0481)\tTop1: 4.688 (avg: 2.938)\tTop5: 7.812 (avg: 9.875)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.580 (avg: 0.588)\tLoss: 4.9729 (avg: 5.0559)\tTop1: 1.562 (avg: 2.844)\tTop5: 14.062 (avg: 9.656)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.586 (avg: 0.591)\tLoss: 4.9848 (avg: 5.0508)\tTop1: 4.688 (avg: 2.729)\tTop5: 10.938 (avg: 9.750)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.588 (avg: 0.591)\tLoss: 5.1118 (avg: 5.0616)\tTop1: 1.562 (avg: 2.672)\tTop5: 9.375 (avg: 9.703)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.589 (avg: 0.592)\tLoss: 5.0657 (avg: 5.0720)\tTop1: 3.125 (avg: 2.550)\tTop5: 9.375 (avg: 9.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3170\tTop 1 accuracy: 2.500\tTop 5 accuracy: 8.600\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.592 (avg: 0.582)\tLoss: 5.1580 (avg: 5.0791)\tTop1: 4.688 (avg: 3.125)\tTop5: 7.812 (avg: 9.188)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.596 (avg: 0.590)\tLoss: 5.0744 (avg: 5.0646)\tTop1: 1.562 (avg: 3.062)\tTop5: 14.062 (avg: 9.469)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.586 (avg: 0.592)\tLoss: 5.0677 (avg: 5.0536)\tTop1: 6.250 (avg: 3.188)\tTop5: 10.938 (avg: 9.542)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.587 (avg: 0.594)\tLoss: 5.2811 (avg: 5.0470)\tTop1: 0.000 (avg: 3.031)\tTop5: 4.688 (avg: 9.797)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.590 (avg: 0.595)\tLoss: 4.9639 (avg: 5.0446)\tTop1: 4.688 (avg: 2.950)\tTop5: 17.188 (avg: 9.812)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3932\tTop 1 accuracy: 2.700\tTop 5 accuracy: 9.800\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.593 (avg: 0.580)\tLoss: 4.9335 (avg: 5.0175)\tTop1: 1.562 (avg: 2.750)\tTop5: 15.625 (avg: 10.500)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.594 (avg: 0.588)\tLoss: 5.0994 (avg: 5.0039)\tTop1: 6.250 (avg: 2.844)\tTop5: 10.938 (avg: 10.750)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.589 (avg: 0.590)\tLoss: 5.0340 (avg: 5.0176)\tTop1: 1.562 (avg: 2.812)\tTop5: 7.812 (avg: 10.438)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.588 (avg: 0.592)\tLoss: 4.9772 (avg: 5.0202)\tTop1: 3.125 (avg: 2.625)\tTop5: 7.812 (avg: 10.422)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.590 (avg: 0.593)\tLoss: 4.9501 (avg: 5.0213)\tTop1: 3.125 (avg: 2.750)\tTop5: 12.500 (avg: 10.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.4401\tTop 1 accuracy: 3.050\tTop 5 accuracy: 10.000\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.589 (avg: 0.580)\tLoss: 4.9635 (avg: 4.9838)\tTop1: 3.125 (avg: 2.875)\tTop5: 14.062 (avg: 10.688)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.592 (avg: 0.589)\tLoss: 5.1311 (avg: 5.0007)\tTop1: 0.000 (avg: 3.094)\tTop5: 3.125 (avg: 10.625)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.596 (avg: 0.592)\tLoss: 5.0733 (avg: 4.9886)\tTop1: 1.562 (avg: 2.938)\tTop5: 9.375 (avg: 10.542)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.585 (avg: 0.593)\tLoss: 5.0425 (avg: 4.9865)\tTop1: 1.562 (avg: 2.922)\tTop5: 9.375 (avg: 10.688)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.588 (avg: 0.594)\tLoss: 4.8874 (avg: 4.9943)\tTop1: 1.562 (avg: 2.900)\tTop5: 10.938 (avg: 10.625)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2210\tTop 1 accuracy: 2.600\tTop 5 accuracy: 8.950\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.586 (avg: 0.580)\tLoss: 4.9806 (avg: 4.9343)\tTop1: 0.000 (avg: 2.625)\tTop5: 14.062 (avg: 11.562)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.588 (avg: 0.587)\tLoss: 4.9670 (avg: 4.9651)\tTop1: 6.250 (avg: 2.344)\tTop5: 18.750 (avg: 11.312)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.594 (avg: 0.590)\tLoss: 5.0902 (avg: 4.9682)\tTop1: 6.250 (avg: 2.646)\tTop5: 12.500 (avg: 11.271)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.584 (avg: 0.592)\tLoss: 4.7169 (avg: 4.9796)\tTop1: 4.688 (avg: 2.531)\tTop5: 15.625 (avg: 11.078)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.586 (avg: 0.592)\tLoss: 4.9684 (avg: 4.9825)\tTop1: 4.688 (avg: 2.600)\tTop5: 9.375 (avg: 10.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1205\tTop 1 accuracy: 3.850\tTop 5 accuracy: 11.100\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.591 (avg: 0.583)\tLoss: 4.9003 (avg: 4.9387)\tTop1: 4.688 (avg: 3.375)\tTop5: 15.625 (avg: 12.312)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.587 (avg: 0.591)\tLoss: 4.8895 (avg: 4.9105)\tTop1: 9.375 (avg: 3.219)\tTop5: 14.062 (avg: 12.625)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.593 (avg: 0.593)\tLoss: 4.9014 (avg: 4.9171)\tTop1: 0.000 (avg: 3.271)\tTop5: 9.375 (avg: 12.500)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.600 (avg: 0.595)\tLoss: 4.8078 (avg: 4.9259)\tTop1: 4.688 (avg: 3.234)\tTop5: 9.375 (avg: 12.297)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.589 (avg: 0.595)\tLoss: 4.8157 (avg: 4.9195)\tTop1: 1.562 (avg: 3.200)\tTop5: 14.062 (avg: 12.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9373\tTop 1 accuracy: 3.500\tTop 5 accuracy: 12.300\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.586 (avg: 0.580)\tLoss: 4.7151 (avg: 4.8648)\tTop1: 3.125 (avg: 3.812)\tTop5: 17.188 (avg: 13.375)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.586 (avg: 0.587)\tLoss: 4.6428 (avg: 4.8902)\tTop1: 4.688 (avg: 3.438)\tTop5: 14.062 (avg: 12.750)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.589 (avg: 0.590)\tLoss: 4.7674 (avg: 4.8710)\tTop1: 1.562 (avg: 3.458)\tTop5: 14.062 (avg: 13.333)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.587 (avg: 0.591)\tLoss: 5.0320 (avg: 4.8748)\tTop1: 1.562 (avg: 3.547)\tTop5: 6.250 (avg: 13.281)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.585 (avg: 0.591)\tLoss: 4.9628 (avg: 4.8773)\tTop1: 4.688 (avg: 3.538)\tTop5: 10.938 (avg: 13.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8889\tTop 1 accuracy: 3.650\tTop 5 accuracy: 13.150\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.602 (avg: 0.584)\tLoss: 4.8962 (avg: 4.7838)\tTop1: 1.562 (avg: 3.438)\tTop5: 9.375 (avg: 14.562)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.585 (avg: 0.591)\tLoss: 4.7966 (avg: 4.8049)\tTop1: 6.250 (avg: 3.500)\tTop5: 14.062 (avg: 14.500)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.588 (avg: 0.593)\tLoss: 4.8516 (avg: 4.8205)\tTop1: 6.250 (avg: 3.854)\tTop5: 12.500 (avg: 14.312)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.595 (avg: 0.595)\tLoss: 4.5610 (avg: 4.8212)\tTop1: 9.375 (avg: 3.969)\tTop5: 20.312 (avg: 14.188)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.596 (avg: 0.595)\tLoss: 4.8899 (avg: 4.8333)\tTop1: 3.125 (avg: 3.850)\tTop5: 17.188 (avg: 14.013)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8648\tTop 1 accuracy: 4.550\tTop 5 accuracy: 14.850\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.598 (avg: 0.586)\tLoss: 4.6572 (avg: 4.7665)\tTop1: 3.125 (avg: 4.500)\tTop5: 12.500 (avg: 15.312)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.590 (avg: 0.594)\tLoss: 4.8028 (avg: 4.7852)\tTop1: 1.562 (avg: 4.031)\tTop5: 9.375 (avg: 15.188)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.598 (avg: 0.597)\tLoss: 4.6496 (avg: 4.7668)\tTop1: 4.688 (avg: 4.271)\tTop5: 18.750 (avg: 15.667)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.603 (avg: 0.598)\tLoss: 4.8126 (avg: 4.7688)\tTop1: 3.125 (avg: 4.594)\tTop5: 18.750 (avg: 15.922)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.597 (avg: 0.598)\tLoss: 4.6818 (avg: 4.7796)\tTop1: 3.125 (avg: 4.463)\tTop5: 17.188 (avg: 15.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6895\tTop 1 accuracy: 4.750\tTop 5 accuracy: 16.350\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.607 (avg: 0.590)\tLoss: 4.6772 (avg: 4.6639)\tTop1: 9.375 (avg: 4.500)\tTop5: 23.438 (avg: 17.812)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.601 (avg: 0.598)\tLoss: 4.8166 (avg: 4.7005)\tTop1: 0.000 (avg: 4.562)\tTop5: 14.062 (avg: 16.906)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.595 (avg: 0.600)\tLoss: 4.6594 (avg: 4.7180)\tTop1: 6.250 (avg: 4.771)\tTop5: 15.625 (avg: 16.854)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.599 (avg: 0.601)\tLoss: 4.8539 (avg: 4.7297)\tTop1: 3.125 (avg: 4.547)\tTop5: 12.500 (avg: 16.109)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.605 (avg: 0.602)\tLoss: 4.7928 (avg: 4.7422)\tTop1: 3.125 (avg: 4.438)\tTop5: 15.625 (avg: 15.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8548\tTop 1 accuracy: 5.400\tTop 5 accuracy: 16.650\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.601 (avg: 0.588)\tLoss: 4.8268 (avg: 4.7005)\tTop1: 6.250 (avg: 5.062)\tTop5: 12.500 (avg: 17.125)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.594 (avg: 0.593)\tLoss: 4.7413 (avg: 4.6753)\tTop1: 3.125 (avg: 5.125)\tTop5: 15.625 (avg: 17.344)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.597 (avg: 0.596)\tLoss: 4.7096 (avg: 4.6864)\tTop1: 1.562 (avg: 4.750)\tTop5: 23.438 (avg: 17.271)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.596 (avg: 0.597)\tLoss: 4.6743 (avg: 4.6832)\tTop1: 3.125 (avg: 4.734)\tTop5: 18.750 (avg: 17.125)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.599 (avg: 0.598)\tLoss: 4.5435 (avg: 4.6868)\tTop1: 7.812 (avg: 4.750)\tTop5: 20.312 (avg: 17.312)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4554\tTop 1 accuracy: 5.050\tTop 5 accuracy: 17.450\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.596 (avg: 0.591)\tLoss: 4.6198 (avg: 4.5630)\tTop1: 1.562 (avg: 5.062)\tTop5: 14.062 (avg: 19.625)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.595 (avg: 0.598)\tLoss: 4.4850 (avg: 4.5891)\tTop1: 7.812 (avg: 5.125)\tTop5: 18.750 (avg: 18.219)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.606 (avg: 0.600)\tLoss: 4.5261 (avg: 4.5998)\tTop1: 4.688 (avg: 5.208)\tTop5: 18.750 (avg: 18.167)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.595 (avg: 0.601)\tLoss: 4.7206 (avg: 4.6277)\tTop1: 7.812 (avg: 5.219)\tTop5: 14.062 (avg: 18.125)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.596 (avg: 0.602)\tLoss: 4.7376 (avg: 4.6358)\tTop1: 1.562 (avg: 5.488)\tTop5: 17.188 (avg: 18.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7589\tTop 1 accuracy: 4.950\tTop 5 accuracy: 16.450\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.596 (avg: 0.589)\tLoss: 4.4316 (avg: 4.4850)\tTop1: 4.688 (avg: 6.438)\tTop5: 25.000 (avg: 21.500)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.597 (avg: 0.596)\tLoss: 4.3008 (avg: 4.5550)\tTop1: 10.938 (avg: 6.281)\tTop5: 28.125 (avg: 20.781)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.602 (avg: 0.598)\tLoss: 4.4176 (avg: 4.5660)\tTop1: 4.688 (avg: 5.917)\tTop5: 26.562 (avg: 20.333)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.596 (avg: 0.599)\tLoss: 4.3461 (avg: 4.5705)\tTop1: 3.125 (avg: 5.875)\tTop5: 26.562 (avg: 20.281)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.597 (avg: 0.599)\tLoss: 4.4002 (avg: 4.5738)\tTop1: 6.250 (avg: 6.000)\tTop5: 18.750 (avg: 20.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4619\tTop 1 accuracy: 6.400\tTop 5 accuracy: 20.200\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.595 (avg: 0.590)\tLoss: 4.4061 (avg: 4.4786)\tTop1: 9.375 (avg: 6.312)\tTop5: 23.438 (avg: 22.000)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.595 (avg: 0.597)\tLoss: 4.6228 (avg: 4.4819)\tTop1: 3.125 (avg: 6.406)\tTop5: 23.438 (avg: 21.594)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.603 (avg: 0.600)\tLoss: 4.4295 (avg: 4.5168)\tTop1: 12.500 (avg: 6.375)\tTop5: 26.562 (avg: 21.208)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.605 (avg: 0.601)\tLoss: 4.7770 (avg: 4.5244)\tTop1: 3.125 (avg: 6.156)\tTop5: 20.312 (avg: 20.719)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.593 (avg: 0.601)\tLoss: 4.6805 (avg: 4.5296)\tTop1: 7.812 (avg: 6.125)\tTop5: 17.188 (avg: 20.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2783\tTop 1 accuracy: 6.900\tTop 5 accuracy: 20.500\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.591 (avg: 0.588)\tLoss: 4.3166 (avg: 4.3561)\tTop1: 7.812 (avg: 8.125)\tTop5: 21.875 (avg: 25.438)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.601 (avg: 0.595)\tLoss: 4.1848 (avg: 4.3190)\tTop1: 14.062 (avg: 8.844)\tTop5: 34.375 (avg: 27.312)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.598 (avg: 0.597)\tLoss: 4.4641 (avg: 4.3243)\tTop1: 9.375 (avg: 8.667)\tTop5: 26.562 (avg: 26.854)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.600 (avg: 0.599)\tLoss: 4.4088 (avg: 4.3093)\tTop1: 7.812 (avg: 8.969)\tTop5: 23.438 (avg: 27.438)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.590 (avg: 0.599)\tLoss: 4.2879 (avg: 4.3005)\tTop1: 12.500 (avg: 9.463)\tTop5: 23.438 (avg: 27.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0779\tTop 1 accuracy: 9.150\tTop 5 accuracy: 24.800\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.609 (avg: 0.591)\tLoss: 4.3915 (avg: 4.2119)\tTop1: 9.375 (avg: 10.938)\tTop5: 26.562 (avg: 29.625)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.598 (avg: 0.598)\tLoss: 3.8242 (avg: 4.2099)\tTop1: 10.938 (avg: 11.281)\tTop5: 42.188 (avg: 29.906)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.593 (avg: 0.601)\tLoss: 4.1518 (avg: 4.1989)\tTop1: 6.250 (avg: 11.000)\tTop5: 29.688 (avg: 29.875)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.597 (avg: 0.602)\tLoss: 4.2126 (avg: 4.2238)\tTop1: 6.250 (avg: 10.828)\tTop5: 32.812 (avg: 29.359)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.607 (avg: 0.603)\tLoss: 4.2780 (avg: 4.2251)\tTop1: 7.812 (avg: 10.938)\tTop5: 21.875 (avg: 29.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1210\tTop 1 accuracy: 9.150\tTop 5 accuracy: 24.550\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.598 (avg: 0.588)\tLoss: 4.2427 (avg: 4.2192)\tTop1: 9.375 (avg: 10.562)\tTop5: 31.250 (avg: 30.375)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.595 (avg: 0.595)\tLoss: 3.9350 (avg: 4.2218)\tTop1: 15.625 (avg: 11.281)\tTop5: 39.062 (avg: 30.500)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.595 (avg: 0.597)\tLoss: 4.3702 (avg: 4.2136)\tTop1: 6.250 (avg: 11.292)\tTop5: 17.188 (avg: 30.667)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.595 (avg: 0.599)\tLoss: 3.9041 (avg: 4.2094)\tTop1: 9.375 (avg: 11.094)\tTop5: 37.500 (avg: 30.172)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.602 (avg: 0.599)\tLoss: 4.1322 (avg: 4.2000)\tTop1: 15.625 (avg: 11.150)\tTop5: 35.938 (avg: 30.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1649\tTop 1 accuracy: 9.100\tTop 5 accuracy: 25.400\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.603 (avg: 0.591)\tLoss: 3.7211 (avg: 4.1215)\tTop1: 18.750 (avg: 12.875)\tTop5: 40.625 (avg: 31.562)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.602 (avg: 0.598)\tLoss: 4.5306 (avg: 4.1746)\tTop1: 6.250 (avg: 11.500)\tTop5: 20.312 (avg: 30.844)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.593 (avg: 0.600)\tLoss: 4.2342 (avg: 4.1649)\tTop1: 6.250 (avg: 11.417)\tTop5: 32.812 (avg: 31.125)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.600 (avg: 0.601)\tLoss: 4.2190 (avg: 4.1746)\tTop1: 14.062 (avg: 11.438)\tTop5: 28.125 (avg: 31.031)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.600 (avg: 0.602)\tLoss: 4.3375 (avg: 4.1900)\tTop1: 12.500 (avg: 11.138)\tTop5: 26.562 (avg: 30.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1454\tTop 1 accuracy: 9.750\tTop 5 accuracy: 25.950\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.595 (avg: 0.588)\tLoss: 3.7622 (avg: 4.1487)\tTop1: 17.188 (avg: 11.750)\tTop5: 42.188 (avg: 30.750)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.590 (avg: 0.595)\tLoss: 4.5985 (avg: 4.1527)\tTop1: 7.812 (avg: 11.281)\tTop5: 28.125 (avg: 30.750)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.597 (avg: 0.597)\tLoss: 4.2724 (avg: 4.1680)\tTop1: 9.375 (avg: 11.167)\tTop5: 23.438 (avg: 30.562)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.597 (avg: 0.599)\tLoss: 4.1517 (avg: 4.1694)\tTop1: 14.062 (avg: 11.141)\tTop5: 25.000 (avg: 30.609)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.593 (avg: 0.599)\tLoss: 4.3383 (avg: 4.1680)\tTop1: 9.375 (avg: 11.475)\tTop5: 29.688 (avg: 31.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9700\tTop 1 accuracy: 9.550\tTop 5 accuracy: 26.500\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.603 (avg: 0.593)\tLoss: 4.1264 (avg: 4.1016)\tTop1: 15.625 (avg: 13.500)\tTop5: 40.625 (avg: 34.438)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.605 (avg: 0.601)\tLoss: 4.1369 (avg: 4.1206)\tTop1: 12.500 (avg: 12.188)\tTop5: 26.562 (avg: 32.250)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.611 (avg: 0.603)\tLoss: 4.3402 (avg: 4.1386)\tTop1: 12.500 (avg: 12.104)\tTop5: 28.125 (avg: 31.979)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.592 (avg: 0.605)\tLoss: 4.2153 (avg: 4.1465)\tTop1: 14.062 (avg: 11.906)\tTop5: 29.688 (avg: 31.438)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.599 (avg: 0.606)\tLoss: 4.2184 (avg: 4.1522)\tTop1: 4.688 (avg: 11.925)\tTop5: 34.375 (avg: 31.700)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8922\tTop 1 accuracy: 10.000\tTop 5 accuracy: 26.050\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.599 (avg: 0.591)\tLoss: 4.1087 (avg: 4.1332)\tTop1: 15.625 (avg: 13.125)\tTop5: 34.375 (avg: 32.625)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.600 (avg: 0.599)\tLoss: 3.9349 (avg: 4.1305)\tTop1: 20.312 (avg: 12.281)\tTop5: 32.812 (avg: 31.594)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.599 (avg: 0.601)\tLoss: 4.4958 (avg: 4.1332)\tTop1: 7.812 (avg: 12.188)\tTop5: 20.312 (avg: 31.208)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.593 (avg: 0.601)\tLoss: 4.0099 (avg: 4.1412)\tTop1: 14.062 (avg: 12.078)\tTop5: 39.062 (avg: 31.375)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.592 (avg: 0.602)\tLoss: 4.2275 (avg: 4.1449)\tTop1: 10.938 (avg: 11.850)\tTop5: 25.000 (avg: 31.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9782\tTop 1 accuracy: 9.700\tTop 5 accuracy: 26.150\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.597 (avg: 0.594)\tLoss: 4.1618 (avg: 4.0719)\tTop1: 9.375 (avg: 12.562)\tTop5: 28.125 (avg: 34.000)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.595 (avg: 0.601)\tLoss: 4.4575 (avg: 4.1084)\tTop1: 3.125 (avg: 12.219)\tTop5: 23.438 (avg: 33.812)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.600 (avg: 0.604)\tLoss: 3.8729 (avg: 4.1304)\tTop1: 14.062 (avg: 11.979)\tTop5: 35.938 (avg: 32.417)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.608 (avg: 0.605)\tLoss: 4.1703 (avg: 4.1275)\tTop1: 9.375 (avg: 12.141)\tTop5: 25.000 (avg: 32.156)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.603 (avg: 0.605)\tLoss: 4.4534 (avg: 4.1284)\tTop1: 14.062 (avg: 11.975)\tTop5: 25.000 (avg: 31.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0290\tTop 1 accuracy: 10.100\tTop 5 accuracy: 27.150\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.593 (avg: 0.590)\tLoss: 4.4488 (avg: 4.1217)\tTop1: 4.688 (avg: 11.875)\tTop5: 15.625 (avg: 33.250)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.595 (avg: 0.598)\tLoss: 4.1703 (avg: 4.0959)\tTop1: 9.375 (avg: 12.188)\tTop5: 31.250 (avg: 33.312)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.603 (avg: 0.600)\tLoss: 4.1034 (avg: 4.1023)\tTop1: 10.938 (avg: 12.083)\tTop5: 34.375 (avg: 33.312)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.597 (avg: 0.602)\tLoss: 3.8701 (avg: 4.1136)\tTop1: 15.625 (avg: 12.000)\tTop5: 37.500 (avg: 32.625)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.598 (avg: 0.602)\tLoss: 3.9146 (avg: 4.1147)\tTop1: 15.625 (avg: 12.013)\tTop5: 34.375 (avg: 32.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9614\tTop 1 accuracy: 9.800\tTop 5 accuracy: 26.150\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.612 (avg: 0.592)\tLoss: 4.1393 (avg: 4.1371)\tTop1: 14.062 (avg: 12.812)\tTop5: 31.250 (avg: 31.812)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.594 (avg: 0.599)\tLoss: 4.0208 (avg: 4.0898)\tTop1: 7.812 (avg: 12.531)\tTop5: 26.562 (avg: 32.750)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.594 (avg: 0.601)\tLoss: 4.0283 (avg: 4.0933)\tTop1: 12.500 (avg: 12.500)\tTop5: 31.250 (avg: 32.938)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.599 (avg: 0.601)\tLoss: 4.1974 (avg: 4.1066)\tTop1: 10.938 (avg: 12.453)\tTop5: 25.000 (avg: 33.031)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.606 (avg: 0.602)\tLoss: 4.6764 (avg: 4.1024)\tTop1: 4.688 (avg: 12.288)\tTop5: 17.188 (avg: 32.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9788\tTop 1 accuracy: 10.250\tTop 5 accuracy: 26.200\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.596 (avg: 0.589)\tLoss: 4.0795 (avg: 4.0314)\tTop1: 12.500 (avg: 14.188)\tTop5: 32.812 (avg: 34.438)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.597 (avg: 0.596)\tLoss: 3.8112 (avg: 4.0696)\tTop1: 10.938 (avg: 12.906)\tTop5: 32.812 (avg: 32.812)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.593 (avg: 0.597)\tLoss: 4.1665 (avg: 4.0653)\tTop1: 15.625 (avg: 12.438)\tTop5: 28.125 (avg: 33.021)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.604 (avg: 0.599)\tLoss: 4.4506 (avg: 4.0722)\tTop1: 9.375 (avg: 12.359)\tTop5: 29.688 (avg: 33.250)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.605 (avg: 0.600)\tLoss: 4.3029 (avg: 4.0893)\tTop1: 9.375 (avg: 12.275)\tTop5: 23.438 (avg: 33.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8724\tTop 1 accuracy: 10.300\tTop 5 accuracy: 27.050\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.604 (avg: 0.592)\tLoss: 4.0932 (avg: 4.0322)\tTop1: 15.625 (avg: 14.062)\tTop5: 35.938 (avg: 34.562)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.602 (avg: 0.600)\tLoss: 4.1627 (avg: 4.0320)\tTop1: 7.812 (avg: 13.781)\tTop5: 28.125 (avg: 34.562)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.596 (avg: 0.603)\tLoss: 4.2976 (avg: 4.0724)\tTop1: 9.375 (avg: 12.896)\tTop5: 25.000 (avg: 33.625)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.603 (avg: 0.604)\tLoss: 4.0834 (avg: 4.0758)\tTop1: 18.750 (avg: 12.828)\tTop5: 32.812 (avg: 33.125)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.605 (avg: 0.604)\tLoss: 4.3973 (avg: 4.0774)\tTop1: 7.812 (avg: 12.938)\tTop5: 25.000 (avg: 33.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8451\tTop 1 accuracy: 9.450\tTop 5 accuracy: 26.300\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.602 (avg: 0.590)\tLoss: 4.3457 (avg: 4.0997)\tTop1: 7.812 (avg: 11.375)\tTop5: 32.812 (avg: 32.625)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.599 (avg: 0.597)\tLoss: 3.9966 (avg: 4.0628)\tTop1: 12.500 (avg: 13.344)\tTop5: 35.938 (avg: 34.250)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.596 (avg: 0.599)\tLoss: 3.6612 (avg: 4.0424)\tTop1: 20.312 (avg: 13.396)\tTop5: 37.500 (avg: 34.042)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.597 (avg: 0.600)\tLoss: 4.3539 (avg: 4.0645)\tTop1: 10.938 (avg: 12.922)\tTop5: 28.125 (avg: 33.812)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.601 (avg: 0.601)\tLoss: 4.0136 (avg: 4.0622)\tTop1: 14.062 (avg: 12.750)\tTop5: 34.375 (avg: 33.438)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8545\tTop 1 accuracy: 10.900\tTop 5 accuracy: 27.750\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.600 (avg: 0.593)\tLoss: 3.9333 (avg: 4.0302)\tTop1: 15.625 (avg: 14.000)\tTop5: 32.812 (avg: 35.375)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.604 (avg: 0.600)\tLoss: 4.1280 (avg: 4.0590)\tTop1: 12.500 (avg: 12.938)\tTop5: 32.812 (avg: 34.781)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.611 (avg: 0.603)\tLoss: 3.9603 (avg: 4.0573)\tTop1: 15.625 (avg: 12.896)\tTop5: 42.188 (avg: 34.500)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.594 (avg: 0.604)\tLoss: 4.1439 (avg: 4.0540)\tTop1: 14.062 (avg: 13.047)\tTop5: 32.812 (avg: 34.203)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.597 (avg: 0.604)\tLoss: 4.3888 (avg: 4.0566)\tTop1: 12.500 (avg: 13.025)\tTop5: 29.688 (avg: 34.013)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9252\tTop 1 accuracy: 9.950\tTop 5 accuracy: 27.100\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.599 (avg: 0.589)\tLoss: 4.1367 (avg: 3.9917)\tTop1: 17.188 (avg: 14.375)\tTop5: 45.312 (avg: 35.688)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.600 (avg: 0.597)\tLoss: 4.0883 (avg: 4.0094)\tTop1: 12.500 (avg: 14.219)\tTop5: 32.812 (avg: 34.938)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.597 (avg: 0.599)\tLoss: 3.8724 (avg: 4.0267)\tTop1: 17.188 (avg: 13.646)\tTop5: 34.375 (avg: 34.688)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.600 (avg: 0.600)\tLoss: 3.7671 (avg: 4.0315)\tTop1: 21.875 (avg: 13.547)\tTop5: 35.938 (avg: 34.688)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.594 (avg: 0.600)\tLoss: 3.9613 (avg: 4.0359)\tTop1: 9.375 (avg: 13.150)\tTop5: 29.688 (avg: 34.312)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8198\tTop 1 accuracy: 10.000\tTop 5 accuracy: 28.150\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.587 (avg: 0.584)\tLoss: 3.8945 (avg: 4.0047)\tTop1: 17.188 (avg: 13.375)\tTop5: 31.250 (avg: 33.812)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.592 (avg: 0.591)\tLoss: 4.0667 (avg: 4.0166)\tTop1: 12.500 (avg: 13.500)\tTop5: 45.312 (avg: 34.375)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.593 (avg: 0.593)\tLoss: 3.8371 (avg: 4.0103)\tTop1: 10.938 (avg: 13.625)\tTop5: 39.062 (avg: 34.938)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.598 (avg: 0.595)\tLoss: 3.7153 (avg: 4.0306)\tTop1: 17.188 (avg: 13.625)\tTop5: 45.312 (avg: 34.531)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.583 (avg: 0.595)\tLoss: 4.3056 (avg: 4.0354)\tTop1: 14.062 (avg: 13.425)\tTop5: 32.812 (avg: 34.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0417\tTop 1 accuracy: 9.950\tTop 5 accuracy: 27.200\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.587 (avg: 0.580)\tLoss: 4.2477 (avg: 3.9681)\tTop1: 14.062 (avg: 13.500)\tTop5: 34.375 (avg: 36.250)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.585 (avg: 0.587)\tLoss: 4.3037 (avg: 3.9762)\tTop1: 9.375 (avg: 14.312)\tTop5: 35.938 (avg: 36.375)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.592 (avg: 0.590)\tLoss: 3.9149 (avg: 3.9867)\tTop1: 10.938 (avg: 14.229)\tTop5: 35.938 (avg: 35.438)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.590 (avg: 0.591)\tLoss: 4.0079 (avg: 4.0088)\tTop1: 14.062 (avg: 13.938)\tTop5: 37.500 (avg: 34.766)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.581 (avg: 0.592)\tLoss: 4.2306 (avg: 4.0076)\tTop1: 17.188 (avg: 14.025)\tTop5: 31.250 (avg: 35.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7398\tTop 1 accuracy: 10.200\tTop 5 accuracy: 28.150\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.597 (avg: 0.585)\tLoss: 3.9091 (avg: 3.9326)\tTop1: 10.938 (avg: 15.250)\tTop5: 35.938 (avg: 37.812)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.585 (avg: 0.592)\tLoss: 3.5768 (avg: 3.9825)\tTop1: 15.625 (avg: 14.312)\tTop5: 42.188 (avg: 36.031)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.581 (avg: 0.593)\tLoss: 4.0327 (avg: 3.9908)\tTop1: 10.938 (avg: 14.333)\tTop5: 25.000 (avg: 35.646)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.591 (avg: 0.594)\tLoss: 3.8804 (avg: 3.9911)\tTop1: 20.312 (avg: 14.484)\tTop5: 40.625 (avg: 35.766)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.602 (avg: 0.595)\tLoss: 3.7613 (avg: 3.9982)\tTop1: 20.312 (avg: 14.313)\tTop5: 42.188 (avg: 35.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7205\tTop 1 accuracy: 11.100\tTop 5 accuracy: 27.450\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.587 (avg: 0.579)\tLoss: 4.0248 (avg: 3.9921)\tTop1: 14.062 (avg: 14.312)\tTop5: 34.375 (avg: 35.188)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.583 (avg: 0.585)\tLoss: 3.8073 (avg: 3.9868)\tTop1: 12.500 (avg: 14.156)\tTop5: 43.750 (avg: 35.156)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.585 (avg: 0.587)\tLoss: 4.3776 (avg: 3.9775)\tTop1: 7.812 (avg: 14.271)\tTop5: 23.438 (avg: 35.646)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.590 (avg: 0.589)\tLoss: 4.1415 (avg: 3.9825)\tTop1: 12.500 (avg: 14.078)\tTop5: 37.500 (avg: 35.281)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.590 (avg: 0.590)\tLoss: 3.8384 (avg: 3.9799)\tTop1: 12.500 (avg: 14.100)\tTop5: 39.062 (avg: 35.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6156\tTop 1 accuracy: 10.750\tTop 5 accuracy: 28.550\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.594 (avg: 0.581)\tLoss: 4.1494 (avg: 3.9915)\tTop1: 12.500 (avg: 14.375)\tTop5: 29.688 (avg: 35.625)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.599 (avg: 0.589)\tLoss: 4.2986 (avg: 3.9953)\tTop1: 14.062 (avg: 14.750)\tTop5: 26.562 (avg: 35.469)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.582 (avg: 0.591)\tLoss: 4.3323 (avg: 3.9947)\tTop1: 12.500 (avg: 14.562)\tTop5: 32.812 (avg: 35.917)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.582 (avg: 0.592)\tLoss: 4.0677 (avg: 3.9862)\tTop1: 12.500 (avg: 14.688)\tTop5: 34.375 (avg: 36.234)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.592 (avg: 0.593)\tLoss: 3.9645 (avg: 3.9785)\tTop1: 10.938 (avg: 14.463)\tTop5: 37.500 (avg: 36.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7096\tTop 1 accuracy: 10.550\tTop 5 accuracy: 28.300\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.596 (avg: 0.581)\tLoss: 3.7215 (avg: 3.9402)\tTop1: 17.188 (avg: 13.750)\tTop5: 45.312 (avg: 37.000)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.594 (avg: 0.590)\tLoss: 4.2486 (avg: 3.9272)\tTop1: 6.250 (avg: 14.500)\tTop5: 23.438 (avg: 37.719)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.594 (avg: 0.593)\tLoss: 3.9534 (avg: 3.9465)\tTop1: 14.062 (avg: 14.271)\tTop5: 39.062 (avg: 36.750)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.591 (avg: 0.594)\tLoss: 4.0942 (avg: 3.9634)\tTop1: 18.750 (avg: 14.047)\tTop5: 29.688 (avg: 36.188)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.596 (avg: 0.595)\tLoss: 3.9107 (avg: 3.9580)\tTop1: 10.938 (avg: 14.063)\tTop5: 35.938 (avg: 36.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7709\tTop 1 accuracy: 11.850\tTop 5 accuracy: 29.000\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.585 (avg: 0.584)\tLoss: 4.2265 (avg: 3.8871)\tTop1: 10.938 (avg: 14.812)\tTop5: 28.125 (avg: 37.438)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.591 (avg: 0.592)\tLoss: 3.7802 (avg: 3.9027)\tTop1: 21.875 (avg: 15.219)\tTop5: 40.625 (avg: 37.344)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.605 (avg: 0.595)\tLoss: 3.9993 (avg: 3.9384)\tTop1: 20.312 (avg: 14.979)\tTop5: 34.375 (avg: 36.688)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.594 (avg: 0.596)\tLoss: 3.5225 (avg: 3.9284)\tTop1: 20.312 (avg: 14.969)\tTop5: 45.312 (avg: 36.688)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.584 (avg: 0.597)\tLoss: 3.7911 (avg: 3.9478)\tTop1: 15.625 (avg: 14.625)\tTop5: 40.625 (avg: 36.200)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8351\tTop 1 accuracy: 10.350\tTop 5 accuracy: 28.300\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.583 (avg: 0.583)\tLoss: 4.2724 (avg: 3.9361)\tTop1: 15.625 (avg: 14.125)\tTop5: 35.938 (avg: 36.875)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.595 (avg: 0.591)\tLoss: 3.8481 (avg: 3.9268)\tTop1: 17.188 (avg: 15.469)\tTop5: 40.625 (avg: 37.125)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.592 (avg: 0.592)\tLoss: 3.9808 (avg: 3.9131)\tTop1: 20.312 (avg: 15.417)\tTop5: 42.188 (avg: 37.562)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.589 (avg: 0.594)\tLoss: 3.6533 (avg: 3.9186)\tTop1: 12.500 (avg: 15.000)\tTop5: 48.438 (avg: 37.375)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.582 (avg: 0.594)\tLoss: 4.1310 (avg: 3.9350)\tTop1: 12.500 (avg: 14.550)\tTop5: 34.375 (avg: 36.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8250\tTop 1 accuracy: 10.700\tTop 5 accuracy: 28.750\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.586 (avg: 0.586)\tLoss: 4.2841 (avg: 3.9006)\tTop1: 14.062 (avg: 16.188)\tTop5: 34.375 (avg: 39.812)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.597 (avg: 0.594)\tLoss: 3.8547 (avg: 3.9647)\tTop1: 12.500 (avg: 14.219)\tTop5: 39.062 (avg: 37.469)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.599 (avg: 0.596)\tLoss: 4.2348 (avg: 3.9442)\tTop1: 14.062 (avg: 14.354)\tTop5: 31.250 (avg: 37.312)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.603 (avg: 0.597)\tLoss: 3.8324 (avg: 3.9315)\tTop1: 10.938 (avg: 14.703)\tTop5: 40.625 (avg: 37.422)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.590 (avg: 0.598)\tLoss: 4.0615 (avg: 3.9277)\tTop1: 17.188 (avg: 14.875)\tTop5: 37.500 (avg: 37.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6595\tTop 1 accuracy: 12.100\tTop 5 accuracy: 28.800\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.588 (avg: 0.582)\tLoss: 3.8308 (avg: 3.8537)\tTop1: 23.438 (avg: 16.750)\tTop5: 39.062 (avg: 38.562)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.588 (avg: 0.590)\tLoss: 3.8287 (avg: 3.8629)\tTop1: 12.500 (avg: 15.969)\tTop5: 39.062 (avg: 37.688)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.595 (avg: 0.592)\tLoss: 3.8856 (avg: 3.8540)\tTop1: 20.312 (avg: 16.167)\tTop5: 35.938 (avg: 38.188)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.591 (avg: 0.593)\tLoss: 4.1312 (avg: 3.8770)\tTop1: 12.500 (avg: 16.031)\tTop5: 34.375 (avg: 37.609)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.590 (avg: 0.594)\tLoss: 3.7623 (avg: 3.8912)\tTop1: 15.625 (avg: 15.675)\tTop5: 35.938 (avg: 37.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7576\tTop 1 accuracy: 10.950\tTop 5 accuracy: 29.450\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.601 (avg: 0.585)\tLoss: 3.7332 (avg: 3.8538)\tTop1: 17.188 (avg: 16.938)\tTop5: 39.062 (avg: 39.375)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.590 (avg: 0.593)\tLoss: 3.7841 (avg: 3.8610)\tTop1: 14.062 (avg: 16.219)\tTop5: 45.312 (avg: 39.250)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.592 (avg: 0.595)\tLoss: 3.7676 (avg: 3.8457)\tTop1: 17.188 (avg: 16.396)\tTop5: 39.062 (avg: 39.146)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.599 (avg: 0.597)\tLoss: 4.2425 (avg: 3.8708)\tTop1: 14.062 (avg: 16.359)\tTop5: 31.250 (avg: 38.453)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.605 (avg: 0.598)\tLoss: 3.7776 (avg: 3.8831)\tTop1: 12.500 (avg: 15.888)\tTop5: 35.938 (avg: 37.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5636\tTop 1 accuracy: 10.700\tTop 5 accuracy: 29.250\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.595 (avg: 0.582)\tLoss: 3.8541 (avg: 3.8539)\tTop1: 15.625 (avg: 15.688)\tTop5: 39.062 (avg: 39.375)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.587 (avg: 0.590)\tLoss: 3.6721 (avg: 3.8408)\tTop1: 17.188 (avg: 16.000)\tTop5: 43.750 (avg: 38.844)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.589 (avg: 0.593)\tLoss: 3.7489 (avg: 3.8560)\tTop1: 14.062 (avg: 15.708)\tTop5: 28.125 (avg: 38.500)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.595 (avg: 0.594)\tLoss: 3.8204 (avg: 3.8564)\tTop1: 25.000 (avg: 16.016)\tTop5: 34.375 (avg: 38.703)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.595 (avg: 0.595)\tLoss: 3.8940 (avg: 3.8642)\tTop1: 9.375 (avg: 16.038)\tTop5: 35.938 (avg: 38.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5799\tTop 1 accuracy: 11.850\tTop 5 accuracy: 29.850\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.593 (avg: 0.586)\tLoss: 3.9335 (avg: 3.8637)\tTop1: 20.312 (avg: 15.438)\tTop5: 31.250 (avg: 38.625)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.599 (avg: 0.594)\tLoss: 3.8778 (avg: 3.8677)\tTop1: 15.625 (avg: 15.281)\tTop5: 31.250 (avg: 38.281)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.590 (avg: 0.596)\tLoss: 4.0642 (avg: 3.8751)\tTop1: 18.750 (avg: 15.562)\tTop5: 35.938 (avg: 38.250)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.597 (avg: 0.597)\tLoss: 3.9163 (avg: 3.8560)\tTop1: 12.500 (avg: 15.953)\tTop5: 40.625 (avg: 38.828)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.599 (avg: 0.598)\tLoss: 4.1631 (avg: 3.8645)\tTop1: 15.625 (avg: 15.638)\tTop5: 37.500 (avg: 38.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6370\tTop 1 accuracy: 12.050\tTop 5 accuracy: 29.900\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.591 (avg: 0.583)\tLoss: 3.5185 (avg: 3.7680)\tTop1: 20.312 (avg: 18.562)\tTop5: 45.312 (avg: 39.938)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.587 (avg: 0.589)\tLoss: 4.0324 (avg: 3.8170)\tTop1: 9.375 (avg: 17.312)\tTop5: 37.500 (avg: 39.406)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.593 (avg: 0.592)\tLoss: 3.8283 (avg: 3.8291)\tTop1: 14.062 (avg: 16.958)\tTop5: 39.062 (avg: 39.500)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.591 (avg: 0.593)\tLoss: 4.0546 (avg: 3.8485)\tTop1: 10.938 (avg: 16.703)\tTop5: 34.375 (avg: 39.109)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.596 (avg: 0.594)\tLoss: 3.9987 (avg: 3.8476)\tTop1: 15.625 (avg: 16.625)\tTop5: 32.812 (avg: 39.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9888\tTop 1 accuracy: 10.650\tTop 5 accuracy: 28.850\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.596 (avg: 0.587)\tLoss: 3.5214 (avg: 3.7725)\tTop1: 25.000 (avg: 16.750)\tTop5: 46.875 (avg: 39.250)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.596 (avg: 0.594)\tLoss: 3.9370 (avg: 3.8204)\tTop1: 20.312 (avg: 16.500)\tTop5: 45.312 (avg: 38.906)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.601 (avg: 0.597)\tLoss: 3.9056 (avg: 3.8080)\tTop1: 20.312 (avg: 16.167)\tTop5: 37.500 (avg: 39.333)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.590 (avg: 0.598)\tLoss: 3.6490 (avg: 3.8236)\tTop1: 17.188 (avg: 16.016)\tTop5: 39.062 (avg: 38.859)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.595 (avg: 0.598)\tLoss: 3.7793 (avg: 3.8327)\tTop1: 18.750 (avg: 16.200)\tTop5: 39.062 (avg: 38.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6266\tTop 1 accuracy: 11.750\tTop 5 accuracy: 29.750\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.589 (avg: 0.583)\tLoss: 3.9093 (avg: 3.7427)\tTop1: 18.750 (avg: 19.562)\tTop5: 48.438 (avg: 42.438)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.590 (avg: 0.590)\tLoss: 3.7771 (avg: 3.7280)\tTop1: 18.750 (avg: 19.312)\tTop5: 45.312 (avg: 42.625)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.592 (avg: 0.593)\tLoss: 4.0581 (avg: 3.7273)\tTop1: 9.375 (avg: 18.646)\tTop5: 29.688 (avg: 42.188)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.587 (avg: 0.594)\tLoss: 3.6160 (avg: 3.7130)\tTop1: 17.188 (avg: 18.719)\tTop5: 50.000 (avg: 42.719)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.590 (avg: 0.595)\tLoss: 3.7958 (avg: 3.7154)\tTop1: 18.750 (avg: 18.650)\tTop5: 39.062 (avg: 42.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6254\tTop 1 accuracy: 12.850\tTop 5 accuracy: 30.850\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.587 (avg: 0.582)\tLoss: 3.7820 (avg: 3.6655)\tTop1: 20.312 (avg: 19.062)\tTop5: 40.625 (avg: 43.188)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.585 (avg: 0.589)\tLoss: 3.7208 (avg: 3.6785)\tTop1: 17.188 (avg: 19.125)\tTop5: 42.188 (avg: 43.094)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.589 (avg: 0.591)\tLoss: 3.8391 (avg: 3.7001)\tTop1: 21.875 (avg: 18.896)\tTop5: 37.500 (avg: 42.542)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.598 (avg: 0.592)\tLoss: 3.5309 (avg: 3.6783)\tTop1: 25.000 (avg: 19.078)\tTop5: 46.875 (avg: 43.266)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.582 (avg: 0.593)\tLoss: 3.6611 (avg: 3.6863)\tTop1: 20.312 (avg: 19.288)\tTop5: 39.062 (avg: 43.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5870\tTop 1 accuracy: 12.250\tTop 5 accuracy: 31.250\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.587 (avg: 0.582)\tLoss: 3.3188 (avg: 3.5990)\tTop1: 31.250 (avg: 20.312)\tTop5: 48.438 (avg: 44.875)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.591 (avg: 0.590)\tLoss: 3.7149 (avg: 3.6544)\tTop1: 23.438 (avg: 19.281)\tTop5: 48.438 (avg: 43.969)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.594 (avg: 0.592)\tLoss: 3.8286 (avg: 3.6428)\tTop1: 21.875 (avg: 19.729)\tTop5: 37.500 (avg: 44.271)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.589 (avg: 0.594)\tLoss: 3.6662 (avg: 3.6832)\tTop1: 21.875 (avg: 19.484)\tTop5: 46.875 (avg: 43.609)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.585 (avg: 0.595)\tLoss: 3.6784 (avg: 3.6792)\tTop1: 26.562 (avg: 19.538)\tTop5: 53.125 (avg: 43.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6050\tTop 1 accuracy: 12.650\tTop 5 accuracy: 31.050\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.609 (avg: 0.587)\tLoss: 3.3578 (avg: 3.7007)\tTop1: 18.750 (avg: 19.438)\tTop5: 51.562 (avg: 45.250)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.583 (avg: 0.594)\tLoss: 3.6925 (avg: 3.6655)\tTop1: 20.312 (avg: 20.000)\tTop5: 46.875 (avg: 44.469)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.591 (avg: 0.596)\tLoss: 3.3781 (avg: 3.6488)\tTop1: 17.188 (avg: 19.750)\tTop5: 51.562 (avg: 44.979)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.599 (avg: 0.598)\tLoss: 3.8084 (avg: 3.6741)\tTop1: 20.312 (avg: 19.422)\tTop5: 42.188 (avg: 43.844)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.604 (avg: 0.599)\tLoss: 3.4977 (avg: 3.6704)\tTop1: 25.000 (avg: 19.562)\tTop5: 48.438 (avg: 43.838)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6090\tTop 1 accuracy: 12.700\tTop 5 accuracy: 31.300\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.595 (avg: 0.582)\tLoss: 3.7427 (avg: 3.6925)\tTop1: 20.312 (avg: 19.938)\tTop5: 45.312 (avg: 42.812)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.588 (avg: 0.590)\tLoss: 3.4309 (avg: 3.6848)\tTop1: 26.562 (avg: 19.281)\tTop5: 54.688 (avg: 42.875)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.585 (avg: 0.592)\tLoss: 3.7627 (avg: 3.6655)\tTop1: 25.000 (avg: 19.958)\tTop5: 48.438 (avg: 43.562)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.593 (avg: 0.594)\tLoss: 3.7567 (avg: 3.6704)\tTop1: 25.000 (avg: 19.906)\tTop5: 46.875 (avg: 43.531)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.590 (avg: 0.595)\tLoss: 3.5012 (avg: 3.6659)\tTop1: 17.188 (avg: 19.763)\tTop5: 42.188 (avg: 43.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6533\tTop 1 accuracy: 13.000\tTop 5 accuracy: 31.600\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.595 (avg: 0.586)\tLoss: 3.8727 (avg: 3.6773)\tTop1: 15.625 (avg: 17.438)\tTop5: 37.500 (avg: 43.250)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.595 (avg: 0.594)\tLoss: 3.4566 (avg: 3.6389)\tTop1: 21.875 (avg: 19.219)\tTop5: 45.312 (avg: 44.625)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.590 (avg: 0.595)\tLoss: 3.7618 (avg: 3.6768)\tTop1: 25.000 (avg: 19.729)\tTop5: 50.000 (avg: 44.229)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.587 (avg: 0.597)\tLoss: 3.4544 (avg: 3.6619)\tTop1: 26.562 (avg: 20.188)\tTop5: 45.312 (avg: 43.984)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.598 (avg: 0.598)\tLoss: 3.7338 (avg: 3.6637)\tTop1: 17.188 (avg: 19.963)\tTop5: 45.312 (avg: 43.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6466\tTop 1 accuracy: 13.100\tTop 5 accuracy: 30.600\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.592 (avg: 0.584)\tLoss: 3.5720 (avg: 3.6574)\tTop1: 21.875 (avg: 19.375)\tTop5: 37.500 (avg: 44.312)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.595 (avg: 0.591)\tLoss: 3.6839 (avg: 3.6997)\tTop1: 17.188 (avg: 19.125)\tTop5: 45.312 (avg: 43.531)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.591 (avg: 0.593)\tLoss: 3.9589 (avg: 3.6770)\tTop1: 12.500 (avg: 19.354)\tTop5: 45.312 (avg: 43.938)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.590 (avg: 0.595)\tLoss: 3.5184 (avg: 3.6740)\tTop1: 29.688 (avg: 19.672)\tTop5: 48.438 (avg: 44.141)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.595 (avg: 0.596)\tLoss: 3.6385 (avg: 3.6592)\tTop1: 15.625 (avg: 19.812)\tTop5: 39.062 (avg: 44.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6927\tTop 1 accuracy: 13.200\tTop 5 accuracy: 31.100\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.592 (avg: 0.586)\tLoss: 3.4940 (avg: 3.6321)\tTop1: 29.688 (avg: 19.875)\tTop5: 50.000 (avg: 44.312)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.592 (avg: 0.593)\tLoss: 3.3743 (avg: 3.6037)\tTop1: 28.125 (avg: 20.688)\tTop5: 54.688 (avg: 45.469)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.603 (avg: 0.596)\tLoss: 3.4382 (avg: 3.6301)\tTop1: 21.875 (avg: 20.375)\tTop5: 43.750 (avg: 44.979)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.591 (avg: 0.597)\tLoss: 3.7513 (avg: 3.6549)\tTop1: 17.188 (avg: 20.000)\tTop5: 43.750 (avg: 44.344)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.595 (avg: 0.598)\tLoss: 3.5388 (avg: 3.6554)\tTop1: 23.438 (avg: 19.900)\tTop5: 43.750 (avg: 44.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6995\tTop 1 accuracy: 13.350\tTop 5 accuracy: 31.200\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.588 (avg: 0.583)\tLoss: 3.2843 (avg: 3.7075)\tTop1: 23.438 (avg: 20.625)\tTop5: 51.562 (avg: 44.125)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.586 (avg: 0.590)\tLoss: 3.4889 (avg: 3.6677)\tTop1: 15.625 (avg: 20.219)\tTop5: 46.875 (avg: 44.625)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.592 (avg: 0.593)\tLoss: 3.5931 (avg: 3.6642)\tTop1: 15.625 (avg: 19.750)\tTop5: 32.812 (avg: 44.021)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.590 (avg: 0.594)\tLoss: 3.7006 (avg: 3.6641)\tTop1: 17.188 (avg: 19.469)\tTop5: 42.188 (avg: 43.859)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.584 (avg: 0.595)\tLoss: 3.5378 (avg: 3.6557)\tTop1: 17.188 (avg: 19.675)\tTop5: 45.312 (avg: 44.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.5576\tTop 1 accuracy: 13.050\tTop 5 accuracy: 30.950\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.583 (avg: 0.584)\tLoss: 3.3521 (avg: 3.6711)\tTop1: 31.250 (avg: 19.250)\tTop5: 51.562 (avg: 43.125)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.593 (avg: 0.591)\tLoss: 3.4233 (avg: 3.6662)\tTop1: 21.875 (avg: 20.156)\tTop5: 43.750 (avg: 43.719)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.593 (avg: 0.593)\tLoss: 3.4191 (avg: 3.6511)\tTop1: 17.188 (avg: 19.958)\tTop5: 56.250 (avg: 44.125)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.601 (avg: 0.595)\tLoss: 3.7518 (avg: 3.6356)\tTop1: 20.312 (avg: 20.406)\tTop5: 46.875 (avg: 44.656)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.590 (avg: 0.596)\tLoss: 3.6459 (avg: 3.6490)\tTop1: 18.750 (avg: 20.088)\tTop5: 40.625 (avg: 44.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7052\tTop 1 accuracy: 12.950\tTop 5 accuracy: 30.650\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.596 (avg: 0.583)\tLoss: 3.5737 (avg: 3.6648)\tTop1: 26.562 (avg: 20.000)\tTop5: 53.125 (avg: 45.375)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.591 (avg: 0.591)\tLoss: 3.7522 (avg: 3.6545)\tTop1: 17.188 (avg: 20.719)\tTop5: 40.625 (avg: 44.688)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.591 (avg: 0.593)\tLoss: 3.8378 (avg: 3.6634)\tTop1: 12.500 (avg: 19.875)\tTop5: 25.000 (avg: 44.292)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.590 (avg: 0.595)\tLoss: 3.6356 (avg: 3.6391)\tTop1: 15.625 (avg: 19.859)\tTop5: 43.750 (avg: 44.547)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.587 (avg: 0.595)\tLoss: 3.2465 (avg: 3.6472)\tTop1: 26.562 (avg: 19.875)\tTop5: 53.125 (avg: 44.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6351\tTop 1 accuracy: 13.050\tTop 5 accuracy: 31.150\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.603 (avg: 0.586)\tLoss: 4.0149 (avg: 3.7219)\tTop1: 17.188 (avg: 19.938)\tTop5: 32.812 (avg: 43.375)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.589 (avg: 0.593)\tLoss: 3.5528 (avg: 3.6900)\tTop1: 18.750 (avg: 20.156)\tTop5: 46.875 (avg: 44.000)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.594 (avg: 0.596)\tLoss: 3.1353 (avg: 3.6540)\tTop1: 26.562 (avg: 19.875)\tTop5: 54.688 (avg: 43.750)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.600 (avg: 0.597)\tLoss: 3.8052 (avg: 3.6443)\tTop1: 14.062 (avg: 20.109)\tTop5: 40.625 (avg: 44.234)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.598 (avg: 0.598)\tLoss: 3.2529 (avg: 3.6412)\tTop1: 25.000 (avg: 20.350)\tTop5: 56.250 (avg: 44.275)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6727\tTop 1 accuracy: 13.400\tTop 5 accuracy: 31.000\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.592 (avg: 0.585)\tLoss: 3.6945 (avg: 3.6469)\tTop1: 21.875 (avg: 20.812)\tTop5: 40.625 (avg: 45.062)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.594 (avg: 0.591)\tLoss: 3.5723 (avg: 3.6523)\tTop1: 17.188 (avg: 20.344)\tTop5: 43.750 (avg: 44.188)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.589 (avg: 0.594)\tLoss: 3.6223 (avg: 3.6374)\tTop1: 26.562 (avg: 20.292)\tTop5: 42.188 (avg: 44.312)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.597 (avg: 0.594)\tLoss: 3.5695 (avg: 3.6455)\tTop1: 17.188 (avg: 20.000)\tTop5: 48.438 (avg: 44.344)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.592 (avg: 0.595)\tLoss: 3.7119 (avg: 3.6420)\tTop1: 15.625 (avg: 20.150)\tTop5: 50.000 (avg: 44.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6937\tTop 1 accuracy: 13.250\tTop 5 accuracy: 31.350\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.598 (avg: 0.588)\tLoss: 3.5076 (avg: 3.5726)\tTop1: 29.688 (avg: 21.812)\tTop5: 50.000 (avg: 46.188)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.599 (avg: 0.594)\tLoss: 3.6612 (avg: 3.5772)\tTop1: 20.312 (avg: 21.562)\tTop5: 40.625 (avg: 45.812)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.590 (avg: 0.596)\tLoss: 3.7918 (avg: 3.5876)\tTop1: 20.312 (avg: 21.188)\tTop5: 40.625 (avg: 45.688)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.598 (avg: 0.598)\tLoss: 3.7271 (avg: 3.6164)\tTop1: 10.938 (avg: 20.594)\tTop5: 45.312 (avg: 45.344)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.592 (avg: 0.599)\tLoss: 3.3836 (avg: 3.6330)\tTop1: 18.750 (avg: 19.913)\tTop5: 45.312 (avg: 44.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6730\tTop 1 accuracy: 12.600\tTop 5 accuracy: 31.250\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.589 (avg: 0.582)\tLoss: 3.2200 (avg: 3.6337)\tTop1: 17.188 (avg: 21.125)\tTop5: 57.812 (avg: 45.438)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.594 (avg: 0.589)\tLoss: 3.2827 (avg: 3.6102)\tTop1: 25.000 (avg: 21.219)\tTop5: 45.312 (avg: 45.344)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.585 (avg: 0.591)\tLoss: 3.9936 (avg: 3.6138)\tTop1: 17.188 (avg: 20.833)\tTop5: 39.062 (avg: 44.521)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.587 (avg: 0.593)\tLoss: 3.4001 (avg: 3.6267)\tTop1: 20.312 (avg: 20.453)\tTop5: 59.375 (avg: 44.406)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.592 (avg: 0.593)\tLoss: 4.1625 (avg: 3.6350)\tTop1: 9.375 (avg: 20.175)\tTop5: 37.500 (avg: 44.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.6822\tTop 1 accuracy: 12.900\tTop 5 accuracy: 31.200\n",
            "\n",
            "freq = 1: top1 = 13.000000953674316 \t top5 = 31.60000228881836 \t batch_time = 0.3736392855644226\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.283 (avg: 0.358)\tLoss: 5.3008 (avg: 5.3048)\tTop1: 1.562 (avg: 0.438)\tTop5: 4.688 (avg: 2.625)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.295 (avg: 0.328)\tLoss: 5.2990 (avg: 5.3022)\tTop1: 0.000 (avg: 0.344)\tTop5: 3.125 (avg: 2.344)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.285 (avg: 0.318)\tLoss: 5.2997 (avg: 5.3010)\tTop1: 0.000 (avg: 0.333)\tTop5: 1.562 (avg: 2.354)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.300 (avg: 0.313)\tLoss: 5.3006 (avg: 5.3003)\tTop1: 0.000 (avg: 0.438)\tTop5: 1.562 (avg: 2.203)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.284 (avg: 0.311)\tLoss: 5.2867 (avg: 5.2984)\tTop1: 1.562 (avg: 0.488)\tTop5: 7.812 (avg: 2.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2610\tTop 1 accuracy: 0.350\tTop 5 accuracy: 2.550\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.291 (avg: 0.289)\tLoss: 5.2803 (avg: 5.2813)\tTop1: 0.000 (avg: 0.625)\tTop5: 1.562 (avg: 2.500)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.295 (avg: 0.295)\tLoss: 5.2742 (avg: 5.2787)\tTop1: 0.000 (avg: 0.688)\tTop5: 4.688 (avg: 2.750)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.281 (avg: 0.295)\tLoss: 5.2371 (avg: 5.2770)\tTop1: 0.000 (avg: 0.646)\tTop5: 1.562 (avg: 2.792)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.291 (avg: 0.295)\tLoss: 5.1688 (avg: 5.2742)\tTop1: 1.562 (avg: 0.656)\tTop5: 3.125 (avg: 2.766)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.285 (avg: 0.295)\tLoss: 5.2338 (avg: 5.2697)\tTop1: 1.562 (avg: 0.625)\tTop5: 3.125 (avg: 2.775)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2796\tTop 1 accuracy: 0.650\tTop 5 accuracy: 2.750\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.281 (avg: 0.292)\tLoss: 5.2000 (avg: 5.2459)\tTop1: 0.000 (avg: 0.750)\tTop5: 4.688 (avg: 3.500)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.299 (avg: 0.295)\tLoss: 5.2533 (avg: 5.2471)\tTop1: 0.000 (avg: 0.750)\tTop5: 9.375 (avg: 3.844)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.293 (avg: 0.296)\tLoss: 5.2356 (avg: 5.2442)\tTop1: 1.562 (avg: 0.833)\tTop5: 6.250 (avg: 4.167)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.296 (avg: 0.297)\tLoss: 5.2860 (avg: 5.2507)\tTop1: 1.562 (avg: 0.859)\tTop5: 4.688 (avg: 4.125)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.282 (avg: 0.297)\tLoss: 5.2967 (avg: 5.2497)\tTop1: 1.562 (avg: 0.825)\tTop5: 3.125 (avg: 4.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2732\tTop 1 accuracy: 0.700\tTop 5 accuracy: 3.550\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.294 (avg: 0.289)\tLoss: 5.1222 (avg: 5.2163)\tTop1: 3.125 (avg: 0.750)\tTop5: 9.375 (avg: 5.625)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.294 (avg: 0.293)\tLoss: 5.2576 (avg: 5.2306)\tTop1: 0.000 (avg: 0.688)\tTop5: 3.125 (avg: 5.031)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.282 (avg: 0.294)\tLoss: 5.3214 (avg: 5.2332)\tTop1: 1.562 (avg: 0.708)\tTop5: 3.125 (avg: 4.917)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.292 (avg: 0.295)\tLoss: 5.2243 (avg: 5.2337)\tTop1: 0.000 (avg: 0.719)\tTop5: 3.125 (avg: 4.547)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.288 (avg: 0.295)\tLoss: 5.2754 (avg: 5.2344)\tTop1: 0.000 (avg: 0.713)\tTop5: 0.000 (avg: 4.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3724\tTop 1 accuracy: 0.950\tTop 5 accuracy: 3.600\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.286 (avg: 0.290)\tLoss: 5.2403 (avg: 5.2320)\tTop1: 0.000 (avg: 0.875)\tTop5: 6.250 (avg: 3.938)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.291 (avg: 0.293)\tLoss: 5.2201 (avg: 5.2278)\tTop1: 0.000 (avg: 0.812)\tTop5: 6.250 (avg: 4.688)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.282 (avg: 0.295)\tLoss: 5.1476 (avg: 5.2290)\tTop1: 3.125 (avg: 0.854)\tTop5: 4.688 (avg: 4.458)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.299 (avg: 0.295)\tLoss: 5.2684 (avg: 5.2228)\tTop1: 1.562 (avg: 0.844)\tTop5: 6.250 (avg: 4.719)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.292 (avg: 0.296)\tLoss: 5.1848 (avg: 5.2252)\tTop1: 0.000 (avg: 0.788)\tTop5: 3.125 (avg: 4.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3003\tTop 1 accuracy: 0.650\tTop 5 accuracy: 3.800\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.279 (avg: 0.288)\tLoss: 5.1927 (avg: 5.2237)\tTop1: 0.000 (avg: 1.250)\tTop5: 3.125 (avg: 5.562)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.304 (avg: 0.294)\tLoss: 5.2873 (avg: 5.2182)\tTop1: 1.562 (avg: 1.188)\tTop5: 3.125 (avg: 5.625)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.287 (avg: 0.296)\tLoss: 5.2887 (avg: 5.2229)\tTop1: 3.125 (avg: 1.021)\tTop5: 7.812 (avg: 5.021)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.299 (avg: 0.297)\tLoss: 5.2380 (avg: 5.2254)\tTop1: 0.000 (avg: 0.938)\tTop5: 3.125 (avg: 4.844)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.286 (avg: 0.297)\tLoss: 5.1572 (avg: 5.2251)\tTop1: 3.125 (avg: 1.000)\tTop5: 7.812 (avg: 4.850)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3545\tTop 1 accuracy: 0.850\tTop 5 accuracy: 4.300\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.285 (avg: 0.299)\tLoss: 5.2844 (avg: 5.2170)\tTop1: 0.000 (avg: 0.750)\tTop5: 3.125 (avg: 4.125)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.298 (avg: 0.303)\tLoss: 5.1910 (avg: 5.2219)\tTop1: 1.562 (avg: 1.094)\tTop5: 3.125 (avg: 4.344)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.282 (avg: 0.302)\tLoss: 5.2688 (avg: 5.2207)\tTop1: 0.000 (avg: 1.146)\tTop5: 1.562 (avg: 4.125)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.302 (avg: 0.302)\tLoss: 5.2857 (avg: 5.2147)\tTop1: 0.000 (avg: 1.109)\tTop5: 0.000 (avg: 4.578)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.287 (avg: 0.302)\tLoss: 5.1803 (avg: 5.2130)\tTop1: 0.000 (avg: 1.113)\tTop5: 0.000 (avg: 4.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3216\tTop 1 accuracy: 0.900\tTop 5 accuracy: 4.600\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.289 (avg: 0.292)\tLoss: 5.2178 (avg: 5.2219)\tTop1: 0.000 (avg: 1.125)\tTop5: 3.125 (avg: 5.188)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.300 (avg: 0.296)\tLoss: 5.2214 (avg: 5.2144)\tTop1: 0.000 (avg: 1.125)\tTop5: 7.812 (avg: 4.969)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.285 (avg: 0.298)\tLoss: 5.1843 (avg: 5.2018)\tTop1: 1.562 (avg: 1.167)\tTop5: 3.125 (avg: 5.042)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.302 (avg: 0.299)\tLoss: 5.2544 (avg: 5.2087)\tTop1: 0.000 (avg: 1.172)\tTop5: 4.688 (avg: 5.094)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.296 (avg: 0.299)\tLoss: 5.1983 (avg: 5.2075)\tTop1: 0.000 (avg: 1.125)\tTop5: 0.000 (avg: 4.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3470\tTop 1 accuracy: 1.250\tTop 5 accuracy: 5.150\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.287 (avg: 0.294)\tLoss: 5.2425 (avg: 5.2095)\tTop1: 0.000 (avg: 0.625)\tTop5: 6.250 (avg: 5.000)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.300 (avg: 0.301)\tLoss: 5.2352 (avg: 5.2076)\tTop1: 1.562 (avg: 1.000)\tTop5: 9.375 (avg: 5.250)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.288 (avg: 0.301)\tLoss: 5.2643 (avg: 5.2105)\tTop1: 1.562 (avg: 1.083)\tTop5: 4.688 (avg: 5.229)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.303 (avg: 0.302)\tLoss: 5.1978 (avg: 5.2135)\tTop1: 1.562 (avg: 1.016)\tTop5: 3.125 (avg: 5.094)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.286 (avg: 0.302)\tLoss: 5.2655 (avg: 5.2074)\tTop1: 1.562 (avg: 1.150)\tTop5: 4.688 (avg: 5.075)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3070\tTop 1 accuracy: 1.100\tTop 5 accuracy: 4.250\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.283 (avg: 0.293)\tLoss: 5.1810 (avg: 5.2113)\tTop1: 0.000 (avg: 1.062)\tTop5: 9.375 (avg: 5.375)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.302 (avg: 0.297)\tLoss: 5.1973 (avg: 5.2004)\tTop1: 0.000 (avg: 1.188)\tTop5: 6.250 (avg: 5.406)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.284 (avg: 0.298)\tLoss: 5.2400 (avg: 5.1942)\tTop1: 0.000 (avg: 1.292)\tTop5: 1.562 (avg: 5.708)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.300 (avg: 0.300)\tLoss: 5.0544 (avg: 5.1922)\tTop1: 0.000 (avg: 1.297)\tTop5: 14.062 (avg: 5.750)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.289 (avg: 0.300)\tLoss: 5.1292 (avg: 5.1947)\tTop1: 1.562 (avg: 1.350)\tTop5: 9.375 (avg: 5.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2357\tTop 1 accuracy: 0.850\tTop 5 accuracy: 4.800\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.296 (avg: 0.295)\tLoss: 5.2341 (avg: 5.1737)\tTop1: 0.000 (avg: 1.812)\tTop5: 3.125 (avg: 6.312)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.303 (avg: 0.299)\tLoss: 5.2376 (avg: 5.1839)\tTop1: 0.000 (avg: 1.469)\tTop5: 3.125 (avg: 6.188)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.287 (avg: 0.300)\tLoss: 5.1445 (avg: 5.1845)\tTop1: 0.000 (avg: 1.458)\tTop5: 6.250 (avg: 5.792)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.303 (avg: 0.301)\tLoss: 5.1295 (avg: 5.1813)\tTop1: 1.562 (avg: 1.453)\tTop5: 6.250 (avg: 5.781)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.284 (avg: 0.301)\tLoss: 5.2430 (avg: 5.1840)\tTop1: 0.000 (avg: 1.475)\tTop5: 3.125 (avg: 5.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2483\tTop 1 accuracy: 1.200\tTop 5 accuracy: 5.550\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.296 (avg: 0.294)\tLoss: 5.1817 (avg: 5.1773)\tTop1: 1.562 (avg: 1.625)\tTop5: 6.250 (avg: 6.062)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.295 (avg: 0.298)\tLoss: 5.2154 (avg: 5.1686)\tTop1: 0.000 (avg: 1.750)\tTop5: 3.125 (avg: 6.094)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.285 (avg: 0.299)\tLoss: 5.1632 (avg: 5.1723)\tTop1: 0.000 (avg: 1.646)\tTop5: 3.125 (avg: 5.938)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.302 (avg: 0.299)\tLoss: 5.1577 (avg: 5.1784)\tTop1: 1.562 (avg: 1.703)\tTop5: 4.688 (avg: 5.859)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.284 (avg: 0.300)\tLoss: 5.2276 (avg: 5.1794)\tTop1: 1.562 (avg: 1.713)\tTop5: 1.562 (avg: 5.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2760\tTop 1 accuracy: 1.350\tTop 5 accuracy: 6.150\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.302 (avg: 0.296)\tLoss: 5.2646 (avg: 5.1704)\tTop1: 0.000 (avg: 1.250)\tTop5: 1.562 (avg: 5.750)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.303 (avg: 0.301)\tLoss: 5.1254 (avg: 5.1611)\tTop1: 0.000 (avg: 1.625)\tTop5: 9.375 (avg: 6.250)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.287 (avg: 0.302)\tLoss: 5.1660 (avg: 5.1578)\tTop1: 1.562 (avg: 1.708)\tTop5: 3.125 (avg: 6.458)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.307 (avg: 0.302)\tLoss: 5.2406 (avg: 5.1540)\tTop1: 1.562 (avg: 1.828)\tTop5: 1.562 (avg: 6.734)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.290 (avg: 0.302)\tLoss: 5.2376 (avg: 5.1579)\tTop1: 4.688 (avg: 1.775)\tTop5: 6.250 (avg: 6.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2384\tTop 1 accuracy: 2.050\tTop 5 accuracy: 7.650\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.293 (avg: 0.293)\tLoss: 5.0566 (avg: 5.1281)\tTop1: 0.000 (avg: 1.500)\tTop5: 9.375 (avg: 6.562)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.299 (avg: 0.297)\tLoss: 5.1589 (avg: 5.1346)\tTop1: 1.562 (avg: 1.656)\tTop5: 9.375 (avg: 7.031)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.285 (avg: 0.299)\tLoss: 5.1556 (avg: 5.1379)\tTop1: 0.000 (avg: 1.771)\tTop5: 3.125 (avg: 7.083)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.318 (avg: 0.300)\tLoss: 5.2036 (avg: 5.1383)\tTop1: 1.562 (avg: 1.656)\tTop5: 7.812 (avg: 7.172)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.284 (avg: 0.301)\tLoss: 5.2319 (avg: 5.1433)\tTop1: 0.000 (avg: 1.625)\tTop5: 1.562 (avg: 7.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3242\tTop 1 accuracy: 2.150\tTop 5 accuracy: 7.900\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.289 (avg: 0.295)\tLoss: 5.1492 (avg: 5.1268)\tTop1: 1.562 (avg: 2.000)\tTop5: 1.562 (avg: 7.500)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.300 (avg: 0.298)\tLoss: 5.0667 (avg: 5.1230)\tTop1: 1.562 (avg: 1.906)\tTop5: 7.812 (avg: 7.625)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.289 (avg: 0.301)\tLoss: 5.1503 (avg: 5.1209)\tTop1: 1.562 (avg: 2.042)\tTop5: 9.375 (avg: 7.333)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.303 (avg: 0.302)\tLoss: 5.1051 (avg: 5.1241)\tTop1: 0.000 (avg: 2.000)\tTop5: 3.125 (avg: 7.312)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.283 (avg: 0.303)\tLoss: 5.0991 (avg: 5.1135)\tTop1: 0.000 (avg: 2.025)\tTop5: 10.938 (avg: 7.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2263\tTop 1 accuracy: 1.900\tTop 5 accuracy: 8.100\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.289 (avg: 0.293)\tLoss: 5.2545 (avg: 5.0904)\tTop1: 0.000 (avg: 1.938)\tTop5: 6.250 (avg: 7.250)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.303 (avg: 0.297)\tLoss: 5.0732 (avg: 5.0903)\tTop1: 1.562 (avg: 1.688)\tTop5: 7.812 (avg: 7.562)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.293 (avg: 0.298)\tLoss: 5.1285 (avg: 5.0919)\tTop1: 3.125 (avg: 1.792)\tTop5: 10.938 (avg: 7.792)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.301 (avg: 0.299)\tLoss: 5.0333 (avg: 5.0937)\tTop1: 1.562 (avg: 1.656)\tTop5: 10.938 (avg: 7.688)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.285 (avg: 0.299)\tLoss: 4.9780 (avg: 5.0893)\tTop1: 3.125 (avg: 1.725)\tTop5: 12.500 (avg: 7.950)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0803\tTop 1 accuracy: 2.500\tTop 5 accuracy: 8.650\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.285 (avg: 0.295)\tLoss: 4.8942 (avg: 5.0422)\tTop1: 1.562 (avg: 2.250)\tTop5: 9.375 (avg: 9.812)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.294 (avg: 0.298)\tLoss: 5.0681 (avg: 5.0587)\tTop1: 4.688 (avg: 2.219)\tTop5: 9.375 (avg: 8.781)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.287 (avg: 0.299)\tLoss: 5.0167 (avg: 5.0587)\tTop1: 0.000 (avg: 2.062)\tTop5: 4.688 (avg: 8.729)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.298 (avg: 0.300)\tLoss: 5.0844 (avg: 5.0493)\tTop1: 1.562 (avg: 2.141)\tTop5: 10.938 (avg: 8.922)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.288 (avg: 0.301)\tLoss: 5.0193 (avg: 5.0599)\tTop1: 3.125 (avg: 2.050)\tTop5: 10.938 (avg: 8.600)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9576\tTop 1 accuracy: 1.400\tTop 5 accuracy: 8.350\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.283 (avg: 0.294)\tLoss: 5.0537 (avg: 5.0153)\tTop1: 0.000 (avg: 2.312)\tTop5: 6.250 (avg: 9.000)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.311 (avg: 0.298)\tLoss: 4.8824 (avg: 5.0135)\tTop1: 3.125 (avg: 2.344)\tTop5: 14.062 (avg: 9.562)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.286 (avg: 0.299)\tLoss: 5.0629 (avg: 5.0186)\tTop1: 1.562 (avg: 2.292)\tTop5: 14.062 (avg: 9.750)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.295 (avg: 0.300)\tLoss: 4.9401 (avg: 5.0112)\tTop1: 1.562 (avg: 2.312)\tTop5: 9.375 (avg: 9.500)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.283 (avg: 0.300)\tLoss: 5.0510 (avg: 5.0133)\tTop1: 0.000 (avg: 2.338)\tTop5: 15.625 (avg: 9.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1092\tTop 1 accuracy: 2.350\tTop 5 accuracy: 9.200\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.286 (avg: 0.294)\tLoss: 5.0353 (avg: 4.9814)\tTop1: 0.000 (avg: 2.500)\tTop5: 10.938 (avg: 10.688)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.307 (avg: 0.299)\tLoss: 4.9072 (avg: 4.9757)\tTop1: 6.250 (avg: 2.406)\tTop5: 10.938 (avg: 10.000)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.290 (avg: 0.300)\tLoss: 4.9298 (avg: 4.9781)\tTop1: 1.562 (avg: 2.562)\tTop5: 9.375 (avg: 10.167)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.300 (avg: 0.302)\tLoss: 4.9954 (avg: 4.9595)\tTop1: 4.688 (avg: 2.641)\tTop5: 10.938 (avg: 10.406)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.292 (avg: 0.302)\tLoss: 5.0525 (avg: 4.9605)\tTop1: 3.125 (avg: 2.538)\tTop5: 9.375 (avg: 10.350)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8649\tTop 1 accuracy: 2.750\tTop 5 accuracy: 9.650\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.285 (avg: 0.294)\tLoss: 5.0805 (avg: 4.9428)\tTop1: 0.000 (avg: 2.438)\tTop5: 6.250 (avg: 11.562)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.306 (avg: 0.298)\tLoss: 4.7879 (avg: 4.9553)\tTop1: 3.125 (avg: 2.312)\tTop5: 15.625 (avg: 10.969)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.284 (avg: 0.299)\tLoss: 4.7174 (avg: 4.9484)\tTop1: 1.562 (avg: 2.542)\tTop5: 20.312 (avg: 11.562)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.297 (avg: 0.300)\tLoss: 4.9985 (avg: 4.9357)\tTop1: 1.562 (avg: 2.703)\tTop5: 7.812 (avg: 11.625)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.283 (avg: 0.300)\tLoss: 4.8474 (avg: 4.9338)\tTop1: 1.562 (avg: 2.725)\tTop5: 14.062 (avg: 11.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7377\tTop 1 accuracy: 3.250\tTop 5 accuracy: 11.100\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.295 (avg: 0.296)\tLoss: 4.7651 (avg: 4.8529)\tTop1: 1.562 (avg: 3.062)\tTop5: 9.375 (avg: 13.000)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.306 (avg: 0.300)\tLoss: 5.0729 (avg: 4.8610)\tTop1: 0.000 (avg: 3.469)\tTop5: 3.125 (avg: 13.000)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.286 (avg: 0.301)\tLoss: 4.8343 (avg: 4.8669)\tTop1: 1.562 (avg: 3.458)\tTop5: 7.812 (avg: 13.000)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.300 (avg: 0.302)\tLoss: 4.8686 (avg: 4.8579)\tTop1: 4.688 (avg: 3.344)\tTop5: 12.500 (avg: 13.281)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.290 (avg: 0.302)\tLoss: 4.8804 (avg: 4.8610)\tTop1: 6.250 (avg: 3.513)\tTop5: 12.500 (avg: 13.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7743\tTop 1 accuracy: 3.450\tTop 5 accuracy: 12.650\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.289 (avg: 0.295)\tLoss: 4.7617 (avg: 4.6936)\tTop1: 1.562 (avg: 5.125)\tTop5: 9.375 (avg: 15.438)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.298 (avg: 0.301)\tLoss: 4.8059 (avg: 4.7337)\tTop1: 0.000 (avg: 4.312)\tTop5: 15.625 (avg: 14.781)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.287 (avg: 0.301)\tLoss: 4.7221 (avg: 4.7455)\tTop1: 4.688 (avg: 4.271)\tTop5: 14.062 (avg: 14.646)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.306 (avg: 0.301)\tLoss: 4.7863 (avg: 4.7573)\tTop1: 3.125 (avg: 4.016)\tTop5: 17.188 (avg: 14.656)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.287 (avg: 0.301)\tLoss: 4.6495 (avg: 4.7587)\tTop1: 7.812 (avg: 4.088)\tTop5: 17.188 (avg: 14.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6331\tTop 1 accuracy: 4.300\tTop 5 accuracy: 14.750\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.292 (avg: 0.298)\tLoss: 4.5976 (avg: 4.6571)\tTop1: 9.375 (avg: 4.938)\tTop5: 18.750 (avg: 16.438)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.301 (avg: 0.301)\tLoss: 4.8845 (avg: 4.6929)\tTop1: 3.125 (avg: 4.500)\tTop5: 18.750 (avg: 16.094)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.292 (avg: 0.302)\tLoss: 4.6384 (avg: 4.7081)\tTop1: 4.688 (avg: 4.625)\tTop5: 12.500 (avg: 15.708)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.318 (avg: 0.302)\tLoss: 4.7851 (avg: 4.7098)\tTop1: 1.562 (avg: 4.750)\tTop5: 10.938 (avg: 16.062)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.285 (avg: 0.303)\tLoss: 4.6399 (avg: 4.7042)\tTop1: 3.125 (avg: 4.875)\tTop5: 17.188 (avg: 16.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3425\tTop 1 accuracy: 4.400\tTop 5 accuracy: 16.600\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.283 (avg: 0.294)\tLoss: 4.5483 (avg: 4.6559)\tTop1: 3.125 (avg: 4.125)\tTop5: 20.312 (avg: 15.438)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.297 (avg: 0.297)\tLoss: 4.5182 (avg: 4.6367)\tTop1: 4.688 (avg: 4.375)\tTop5: 12.500 (avg: 16.125)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.285 (avg: 0.299)\tLoss: 4.6440 (avg: 4.6452)\tTop1: 6.250 (avg: 4.896)\tTop5: 17.188 (avg: 16.333)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.297 (avg: 0.300)\tLoss: 4.7641 (avg: 4.6631)\tTop1: 1.562 (avg: 4.766)\tTop5: 12.500 (avg: 16.266)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.283 (avg: 0.300)\tLoss: 4.6513 (avg: 4.6606)\tTop1: 6.250 (avg: 4.850)\tTop5: 20.312 (avg: 16.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7154\tTop 1 accuracy: 5.550\tTop 5 accuracy: 17.800\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.286 (avg: 0.300)\tLoss: 4.4745 (avg: 4.5653)\tTop1: 7.812 (avg: 5.875)\tTop5: 20.312 (avg: 18.938)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.299 (avg: 0.301)\tLoss: 4.2772 (avg: 4.5536)\tTop1: 9.375 (avg: 5.906)\tTop5: 28.125 (avg: 19.125)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.292 (avg: 0.301)\tLoss: 4.4063 (avg: 4.5752)\tTop1: 9.375 (avg: 5.458)\tTop5: 25.000 (avg: 18.500)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.298 (avg: 0.301)\tLoss: 4.7409 (avg: 4.5803)\tTop1: 12.500 (avg: 5.281)\tTop5: 26.562 (avg: 18.547)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.281 (avg: 0.302)\tLoss: 4.6110 (avg: 4.5841)\tTop1: 4.688 (avg: 5.250)\tTop5: 17.188 (avg: 18.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8569\tTop 1 accuracy: 4.500\tTop 5 accuracy: 15.800\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.289 (avg: 0.294)\tLoss: 4.6262 (avg: 4.4994)\tTop1: 1.562 (avg: 6.000)\tTop5: 12.500 (avg: 22.500)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.296 (avg: 0.298)\tLoss: 4.7067 (avg: 4.5457)\tTop1: 3.125 (avg: 5.281)\tTop5: 10.938 (avg: 19.906)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.285 (avg: 0.299)\tLoss: 4.3038 (avg: 4.5451)\tTop1: 10.938 (avg: 5.646)\tTop5: 26.562 (avg: 20.188)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.298 (avg: 0.299)\tLoss: 4.7766 (avg: 4.5400)\tTop1: 3.125 (avg: 5.750)\tTop5: 15.625 (avg: 20.031)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.292 (avg: 0.299)\tLoss: 4.3793 (avg: 4.5444)\tTop1: 6.250 (avg: 5.675)\tTop5: 20.312 (avg: 19.763)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6096\tTop 1 accuracy: 4.200\tTop 5 accuracy: 16.850\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.287 (avg: 0.293)\tLoss: 4.4761 (avg: 4.4581)\tTop1: 7.812 (avg: 7.250)\tTop5: 25.000 (avg: 21.250)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.319 (avg: 0.298)\tLoss: 4.5935 (avg: 4.4735)\tTop1: 3.125 (avg: 7.188)\tTop5: 21.875 (avg: 21.312)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.283 (avg: 0.300)\tLoss: 4.6234 (avg: 4.4919)\tTop1: 3.125 (avg: 6.562)\tTop5: 17.188 (avg: 20.854)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.299 (avg: 0.300)\tLoss: 4.4853 (avg: 4.5009)\tTop1: 3.125 (avg: 6.391)\tTop5: 20.312 (avg: 20.266)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.290 (avg: 0.300)\tLoss: 4.6040 (avg: 4.5033)\tTop1: 4.688 (avg: 6.263)\tTop5: 15.625 (avg: 20.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7163\tTop 1 accuracy: 4.950\tTop 5 accuracy: 18.500\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.285 (avg: 0.293)\tLoss: 4.8355 (avg: 4.4232)\tTop1: 1.562 (avg: 6.688)\tTop5: 9.375 (avg: 22.250)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.306 (avg: 0.296)\tLoss: 4.7224 (avg: 4.4294)\tTop1: 6.250 (avg: 6.750)\tTop5: 18.750 (avg: 22.094)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.284 (avg: 0.298)\tLoss: 4.3372 (avg: 4.4390)\tTop1: 7.812 (avg: 6.208)\tTop5: 21.875 (avg: 21.104)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.299 (avg: 0.299)\tLoss: 4.3750 (avg: 4.4447)\tTop1: 4.688 (avg: 6.469)\tTop5: 26.562 (avg: 21.578)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.283 (avg: 0.299)\tLoss: 4.5612 (avg: 4.4493)\tTop1: 7.812 (avg: 6.525)\tTop5: 26.562 (avg: 21.500)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4482\tTop 1 accuracy: 6.400\tTop 5 accuracy: 20.950\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.296 (avg: 0.294)\tLoss: 4.4503 (avg: 4.3800)\tTop1: 10.938 (avg: 8.812)\tTop5: 20.312 (avg: 23.938)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.297 (avg: 0.297)\tLoss: 4.1682 (avg: 4.3855)\tTop1: 7.812 (avg: 7.812)\tTop5: 37.500 (avg: 24.094)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.283 (avg: 0.298)\tLoss: 4.6132 (avg: 4.3940)\tTop1: 6.250 (avg: 7.417)\tTop5: 26.562 (avg: 23.438)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.295 (avg: 0.299)\tLoss: 4.6991 (avg: 4.3974)\tTop1: 6.250 (avg: 7.328)\tTop5: 23.438 (avg: 23.672)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.295 (avg: 0.300)\tLoss: 4.5765 (avg: 4.4060)\tTop1: 7.812 (avg: 7.225)\tTop5: 21.875 (avg: 23.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7407\tTop 1 accuracy: 5.900\tTop 5 accuracy: 20.000\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.287 (avg: 0.295)\tLoss: 4.0590 (avg: 4.3472)\tTop1: 12.500 (avg: 8.250)\tTop5: 34.375 (avg: 24.438)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.303 (avg: 0.299)\tLoss: 4.3965 (avg: 4.3443)\tTop1: 6.250 (avg: 7.500)\tTop5: 23.438 (avg: 24.406)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.288 (avg: 0.300)\tLoss: 4.3362 (avg: 4.3734)\tTop1: 7.812 (avg: 7.188)\tTop5: 28.125 (avg: 23.646)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.307 (avg: 0.301)\tLoss: 4.2682 (avg: 4.3737)\tTop1: 3.125 (avg: 7.203)\tTop5: 18.750 (avg: 23.594)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.286 (avg: 0.301)\tLoss: 4.8048 (avg: 4.3733)\tTop1: 4.688 (avg: 7.463)\tTop5: 15.625 (avg: 23.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5009\tTop 1 accuracy: 6.700\tTop 5 accuracy: 20.600\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.280 (avg: 0.295)\tLoss: 4.1109 (avg: 4.2456)\tTop1: 10.938 (avg: 8.750)\tTop5: 31.250 (avg: 27.250)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.311 (avg: 0.300)\tLoss: 4.3438 (avg: 4.2144)\tTop1: 4.688 (avg: 8.969)\tTop5: 23.438 (avg: 27.812)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.287 (avg: 0.301)\tLoss: 4.0595 (avg: 4.1757)\tTop1: 10.938 (avg: 9.479)\tTop5: 31.250 (avg: 28.729)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.314 (avg: 0.302)\tLoss: 3.9150 (avg: 4.1474)\tTop1: 17.188 (avg: 10.156)\tTop5: 42.188 (avg: 29.828)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.294 (avg: 0.302)\tLoss: 3.8336 (avg: 4.1327)\tTop1: 14.062 (avg: 10.350)\tTop5: 39.062 (avg: 30.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2404\tTop 1 accuracy: 9.100\tTop 5 accuracy: 26.600\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.288 (avg: 0.296)\tLoss: 4.0922 (avg: 4.0367)\tTop1: 10.938 (avg: 12.688)\tTop5: 28.125 (avg: 32.562)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.298 (avg: 0.299)\tLoss: 4.0879 (avg: 4.0068)\tTop1: 10.938 (avg: 13.312)\tTop5: 37.500 (avg: 33.812)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.297 (avg: 0.300)\tLoss: 3.7665 (avg: 4.0324)\tTop1: 17.188 (avg: 13.021)\tTop5: 40.625 (avg: 33.542)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.306 (avg: 0.301)\tLoss: 3.8035 (avg: 4.0382)\tTop1: 17.188 (avg: 12.812)\tTop5: 40.625 (avg: 33.484)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.286 (avg: 0.301)\tLoss: 4.4320 (avg: 4.0451)\tTop1: 15.625 (avg: 12.763)\tTop5: 32.812 (avg: 33.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1521\tTop 1 accuracy: 9.200\tTop 5 accuracy: 27.750\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.292 (avg: 0.296)\tLoss: 4.1755 (avg: 4.0309)\tTop1: 6.250 (avg: 12.875)\tTop5: 31.250 (avg: 34.562)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.301 (avg: 0.300)\tLoss: 3.8410 (avg: 4.0092)\tTop1: 17.188 (avg: 13.469)\tTop5: 43.750 (avg: 35.531)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.291 (avg: 0.301)\tLoss: 4.0178 (avg: 4.0235)\tTop1: 14.062 (avg: 13.062)\tTop5: 32.812 (avg: 34.312)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.296 (avg: 0.301)\tLoss: 4.0910 (avg: 4.0229)\tTop1: 6.250 (avg: 13.000)\tTop5: 23.438 (avg: 34.250)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.293 (avg: 0.301)\tLoss: 4.1860 (avg: 4.0280)\tTop1: 7.812 (avg: 12.925)\tTop5: 28.125 (avg: 33.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1414\tTop 1 accuracy: 8.700\tTop 5 accuracy: 27.400\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.288 (avg: 0.292)\tLoss: 3.8242 (avg: 3.9783)\tTop1: 18.750 (avg: 13.688)\tTop5: 42.188 (avg: 35.000)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.309 (avg: 0.296)\tLoss: 4.0946 (avg: 4.0102)\tTop1: 10.938 (avg: 12.656)\tTop5: 34.375 (avg: 33.812)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.284 (avg: 0.297)\tLoss: 3.5589 (avg: 3.9913)\tTop1: 18.750 (avg: 13.333)\tTop5: 45.312 (avg: 34.312)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.291 (avg: 0.298)\tLoss: 3.8221 (avg: 3.9944)\tTop1: 18.750 (avg: 13.297)\tTop5: 40.625 (avg: 34.000)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.285 (avg: 0.298)\tLoss: 4.2567 (avg: 4.0057)\tTop1: 18.750 (avg: 13.175)\tTop5: 29.688 (avg: 33.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0383\tTop 1 accuracy: 9.950\tTop 5 accuracy: 27.800\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.281 (avg: 0.293)\tLoss: 3.9593 (avg: 4.0008)\tTop1: 12.500 (avg: 13.000)\tTop5: 34.375 (avg: 34.938)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.305 (avg: 0.297)\tLoss: 4.0501 (avg: 4.0072)\tTop1: 15.625 (avg: 12.938)\tTop5: 32.812 (avg: 33.500)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.293 (avg: 0.298)\tLoss: 3.7569 (avg: 3.9903)\tTop1: 18.750 (avg: 13.646)\tTop5: 35.938 (avg: 34.438)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.297 (avg: 0.299)\tLoss: 4.2947 (avg: 3.9947)\tTop1: 12.500 (avg: 13.406)\tTop5: 34.375 (avg: 34.188)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.281 (avg: 0.300)\tLoss: 4.0065 (avg: 3.9988)\tTop1: 14.062 (avg: 13.288)\tTop5: 39.062 (avg: 34.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1058\tTop 1 accuracy: 9.750\tTop 5 accuracy: 27.850\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.285 (avg: 0.293)\tLoss: 3.9815 (avg: 3.9491)\tTop1: 14.062 (avg: 14.750)\tTop5: 31.250 (avg: 36.000)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.299 (avg: 0.296)\tLoss: 4.1464 (avg: 3.9503)\tTop1: 12.500 (avg: 14.250)\tTop5: 25.000 (avg: 36.188)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.293 (avg: 0.297)\tLoss: 3.8715 (avg: 3.9672)\tTop1: 10.938 (avg: 14.083)\tTop5: 32.812 (avg: 35.271)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.302 (avg: 0.299)\tLoss: 4.0136 (avg: 3.9625)\tTop1: 12.500 (avg: 13.891)\tTop5: 28.125 (avg: 35.453)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.292 (avg: 0.301)\tLoss: 3.8599 (avg: 3.9783)\tTop1: 15.625 (avg: 13.438)\tTop5: 43.750 (avg: 34.812)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0089\tTop 1 accuracy: 9.950\tTop 5 accuracy: 26.950\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.292 (avg: 0.295)\tLoss: 3.9469 (avg: 3.9471)\tTop1: 15.625 (avg: 13.250)\tTop5: 32.812 (avg: 35.562)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.305 (avg: 0.299)\tLoss: 4.0156 (avg: 3.9600)\tTop1: 12.500 (avg: 13.656)\tTop5: 34.375 (avg: 35.219)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.294 (avg: 0.300)\tLoss: 3.6177 (avg: 3.9577)\tTop1: 20.312 (avg: 13.667)\tTop5: 42.188 (avg: 35.417)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.299 (avg: 0.300)\tLoss: 3.9871 (avg: 3.9780)\tTop1: 20.312 (avg: 13.672)\tTop5: 35.938 (avg: 34.953)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.284 (avg: 0.301)\tLoss: 4.0291 (avg: 3.9681)\tTop1: 14.062 (avg: 13.788)\tTop5: 28.125 (avg: 35.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0616\tTop 1 accuracy: 10.200\tTop 5 accuracy: 28.050\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.282 (avg: 0.292)\tLoss: 4.2332 (avg: 3.9726)\tTop1: 14.062 (avg: 14.125)\tTop5: 35.938 (avg: 35.062)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.304 (avg: 0.296)\tLoss: 4.1745 (avg: 3.9783)\tTop1: 17.188 (avg: 13.656)\tTop5: 35.938 (avg: 35.156)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.288 (avg: 0.297)\tLoss: 4.0782 (avg: 3.9663)\tTop1: 12.500 (avg: 14.000)\tTop5: 31.250 (avg: 35.104)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.308 (avg: 0.298)\tLoss: 4.1405 (avg: 3.9566)\tTop1: 9.375 (avg: 14.062)\tTop5: 21.875 (avg: 34.938)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.284 (avg: 0.298)\tLoss: 3.7981 (avg: 3.9546)\tTop1: 4.688 (avg: 13.825)\tTop5: 35.938 (avg: 34.950)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9997\tTop 1 accuracy: 9.800\tTop 5 accuracy: 28.800\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.287 (avg: 0.296)\tLoss: 4.1149 (avg: 3.9434)\tTop1: 10.938 (avg: 14.000)\tTop5: 37.500 (avg: 36.188)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.296 (avg: 0.299)\tLoss: 4.2059 (avg: 3.9414)\tTop1: 9.375 (avg: 14.000)\tTop5: 32.812 (avg: 35.625)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.285 (avg: 0.300)\tLoss: 3.8649 (avg: 3.9553)\tTop1: 10.938 (avg: 13.854)\tTop5: 40.625 (avg: 35.750)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.309 (avg: 0.301)\tLoss: 3.8086 (avg: 3.9554)\tTop1: 23.438 (avg: 13.422)\tTop5: 40.625 (avg: 35.297)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.285 (avg: 0.301)\tLoss: 3.8759 (avg: 3.9386)\tTop1: 23.438 (avg: 14.038)\tTop5: 40.625 (avg: 35.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1415\tTop 1 accuracy: 9.850\tTop 5 accuracy: 27.550\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.284 (avg: 0.294)\tLoss: 3.4983 (avg: 3.8537)\tTop1: 21.875 (avg: 15.750)\tTop5: 46.875 (avg: 37.188)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.300 (avg: 0.297)\tLoss: 4.0820 (avg: 3.9116)\tTop1: 10.938 (avg: 14.719)\tTop5: 29.688 (avg: 36.719)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.287 (avg: 0.298)\tLoss: 4.1822 (avg: 3.9334)\tTop1: 9.375 (avg: 14.458)\tTop5: 28.125 (avg: 35.500)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.306 (avg: 0.299)\tLoss: 3.6886 (avg: 3.9377)\tTop1: 20.312 (avg: 14.188)\tTop5: 45.312 (avg: 35.562)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.282 (avg: 0.299)\tLoss: 4.0643 (avg: 3.9293)\tTop1: 9.375 (avg: 14.363)\tTop5: 35.938 (avg: 35.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0645\tTop 1 accuracy: 10.850\tTop 5 accuracy: 29.800\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.293 (avg: 0.294)\tLoss: 3.7845 (avg: 3.9086)\tTop1: 15.625 (avg: 13.812)\tTop5: 43.750 (avg: 35.938)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.301 (avg: 0.297)\tLoss: 3.9247 (avg: 3.9093)\tTop1: 15.625 (avg: 13.938)\tTop5: 31.250 (avg: 35.406)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.288 (avg: 0.298)\tLoss: 3.8026 (avg: 3.9109)\tTop1: 14.062 (avg: 14.375)\tTop5: 40.625 (avg: 35.896)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.298 (avg: 0.299)\tLoss: 4.0142 (avg: 3.9056)\tTop1: 10.938 (avg: 14.141)\tTop5: 34.375 (avg: 36.281)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.288 (avg: 0.300)\tLoss: 3.9232 (avg: 3.9105)\tTop1: 15.625 (avg: 14.313)\tTop5: 37.500 (avg: 36.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1544\tTop 1 accuracy: 10.800\tTop 5 accuracy: 28.950\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.288 (avg: 0.293)\tLoss: 4.1442 (avg: 3.8885)\tTop1: 10.938 (avg: 14.812)\tTop5: 29.688 (avg: 36.250)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.303 (avg: 0.297)\tLoss: 4.2015 (avg: 3.9027)\tTop1: 10.938 (avg: 14.688)\tTop5: 25.000 (avg: 36.062)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.284 (avg: 0.298)\tLoss: 3.9506 (avg: 3.9067)\tTop1: 17.188 (avg: 14.875)\tTop5: 37.500 (avg: 36.500)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.303 (avg: 0.299)\tLoss: 3.9466 (avg: 3.9071)\tTop1: 23.438 (avg: 14.766)\tTop5: 43.750 (avg: 36.188)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.294 (avg: 0.299)\tLoss: 3.7599 (avg: 3.9156)\tTop1: 17.188 (avg: 14.575)\tTop5: 35.938 (avg: 35.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0281\tTop 1 accuracy: 10.650\tTop 5 accuracy: 28.700\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.288 (avg: 0.297)\tLoss: 3.7593 (avg: 3.8942)\tTop1: 10.938 (avg: 14.000)\tTop5: 39.062 (avg: 35.875)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.322 (avg: 0.302)\tLoss: 4.0303 (avg: 3.8783)\tTop1: 10.938 (avg: 14.344)\tTop5: 35.938 (avg: 36.375)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.285 (avg: 0.303)\tLoss: 4.0248 (avg: 3.8746)\tTop1: 10.938 (avg: 14.500)\tTop5: 28.125 (avg: 36.562)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.300 (avg: 0.303)\tLoss: 3.9540 (avg: 3.8955)\tTop1: 7.812 (avg: 14.188)\tTop5: 32.812 (avg: 36.141)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.283 (avg: 0.302)\tLoss: 3.2256 (avg: 3.8945)\tTop1: 21.875 (avg: 14.550)\tTop5: 50.000 (avg: 36.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0168\tTop 1 accuracy: 10.700\tTop 5 accuracy: 28.050\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.291 (avg: 0.293)\tLoss: 3.8517 (avg: 3.8808)\tTop1: 7.812 (avg: 13.562)\tTop5: 43.750 (avg: 36.188)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.302 (avg: 0.297)\tLoss: 4.1463 (avg: 3.8719)\tTop1: 15.625 (avg: 14.750)\tTop5: 37.500 (avg: 36.812)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.295 (avg: 0.299)\tLoss: 3.9524 (avg: 3.8692)\tTop1: 10.938 (avg: 14.812)\tTop5: 35.938 (avg: 36.542)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.303 (avg: 0.300)\tLoss: 4.1319 (avg: 3.8751)\tTop1: 17.188 (avg: 14.750)\tTop5: 37.500 (avg: 36.672)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.297 (avg: 0.301)\tLoss: 3.5703 (avg: 3.8849)\tTop1: 21.875 (avg: 14.788)\tTop5: 48.438 (avg: 36.663)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0939\tTop 1 accuracy: 10.500\tTop 5 accuracy: 28.450\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.289 (avg: 0.294)\tLoss: 3.9232 (avg: 3.8358)\tTop1: 12.500 (avg: 15.188)\tTop5: 37.500 (avg: 38.312)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.297 (avg: 0.298)\tLoss: 3.8505 (avg: 3.8813)\tTop1: 14.062 (avg: 15.188)\tTop5: 35.938 (avg: 37.219)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.282 (avg: 0.299)\tLoss: 4.0211 (avg: 3.8726)\tTop1: 12.500 (avg: 15.479)\tTop5: 31.250 (avg: 36.938)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.297 (avg: 0.300)\tLoss: 3.8807 (avg: 3.8949)\tTop1: 15.625 (avg: 15.016)\tTop5: 35.938 (avg: 36.234)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.298 (avg: 0.300)\tLoss: 3.7807 (avg: 3.8831)\tTop1: 20.312 (avg: 14.913)\tTop5: 37.500 (avg: 36.538)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1194\tTop 1 accuracy: 10.450\tTop 5 accuracy: 29.550\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.294 (avg: 0.295)\tLoss: 4.2264 (avg: 3.8586)\tTop1: 14.062 (avg: 15.250)\tTop5: 32.812 (avg: 38.250)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.297 (avg: 0.300)\tLoss: 3.8424 (avg: 3.8462)\tTop1: 18.750 (avg: 15.625)\tTop5: 43.750 (avg: 38.812)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.283 (avg: 0.300)\tLoss: 3.7423 (avg: 3.8442)\tTop1: 18.750 (avg: 15.604)\tTop5: 40.625 (avg: 38.604)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.298 (avg: 0.300)\tLoss: 3.7462 (avg: 3.8487)\tTop1: 18.750 (avg: 15.594)\tTop5: 31.250 (avg: 38.047)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.295 (avg: 0.300)\tLoss: 3.5128 (avg: 3.8528)\tTop1: 17.188 (avg: 15.475)\tTop5: 40.625 (avg: 37.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0369\tTop 1 accuracy: 11.100\tTop 5 accuracy: 29.350\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.285 (avg: 0.297)\tLoss: 3.8721 (avg: 3.8529)\tTop1: 15.625 (avg: 15.562)\tTop5: 34.375 (avg: 39.375)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.304 (avg: 0.299)\tLoss: 4.2417 (avg: 3.8487)\tTop1: 12.500 (avg: 15.688)\tTop5: 32.812 (avg: 38.438)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.286 (avg: 0.300)\tLoss: 4.0495 (avg: 3.8576)\tTop1: 20.312 (avg: 15.562)\tTop5: 32.812 (avg: 37.708)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.306 (avg: 0.301)\tLoss: 4.0548 (avg: 3.8457)\tTop1: 23.438 (avg: 15.781)\tTop5: 32.812 (avg: 37.891)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.286 (avg: 0.301)\tLoss: 3.8045 (avg: 3.8466)\tTop1: 15.625 (avg: 15.663)\tTop5: 31.250 (avg: 37.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8684\tTop 1 accuracy: 10.850\tTop 5 accuracy: 29.450\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.285 (avg: 0.294)\tLoss: 3.9485 (avg: 3.8079)\tTop1: 12.500 (avg: 15.875)\tTop5: 34.375 (avg: 37.875)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.299 (avg: 0.298)\tLoss: 3.4252 (avg: 3.8100)\tTop1: 20.312 (avg: 15.844)\tTop5: 46.875 (avg: 38.062)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.290 (avg: 0.299)\tLoss: 3.9896 (avg: 3.8140)\tTop1: 12.500 (avg: 16.375)\tTop5: 29.688 (avg: 38.312)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.296 (avg: 0.300)\tLoss: 3.7721 (avg: 3.8261)\tTop1: 15.625 (avg: 16.000)\tTop5: 34.375 (avg: 37.734)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.293 (avg: 0.300)\tLoss: 4.0426 (avg: 3.8488)\tTop1: 9.375 (avg: 15.750)\tTop5: 32.812 (avg: 37.263)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9716\tTop 1 accuracy: 11.100\tTop 5 accuracy: 30.500\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.286 (avg: 0.295)\tLoss: 3.6443 (avg: 3.7666)\tTop1: 21.875 (avg: 16.812)\tTop5: 50.000 (avg: 39.375)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.313 (avg: 0.298)\tLoss: 3.6735 (avg: 3.7804)\tTop1: 23.438 (avg: 16.625)\tTop5: 48.438 (avg: 39.688)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.293 (avg: 0.300)\tLoss: 4.1836 (avg: 3.8032)\tTop1: 10.938 (avg: 15.854)\tTop5: 37.500 (avg: 38.833)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.308 (avg: 0.301)\tLoss: 3.7306 (avg: 3.8134)\tTop1: 14.062 (avg: 15.766)\tTop5: 42.188 (avg: 38.297)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.290 (avg: 0.302)\tLoss: 3.7214 (avg: 3.8237)\tTop1: 12.500 (avg: 15.500)\tTop5: 39.062 (avg: 38.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0544\tTop 1 accuracy: 11.900\tTop 5 accuracy: 29.450\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.297 (avg: 0.295)\tLoss: 3.8271 (avg: 3.7687)\tTop1: 20.312 (avg: 16.062)\tTop5: 37.500 (avg: 40.250)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.300 (avg: 0.298)\tLoss: 4.0033 (avg: 3.8124)\tTop1: 10.938 (avg: 16.062)\tTop5: 29.688 (avg: 38.781)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.283 (avg: 0.298)\tLoss: 3.5602 (avg: 3.8111)\tTop1: 18.750 (avg: 15.708)\tTop5: 43.750 (avg: 38.500)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.304 (avg: 0.299)\tLoss: 3.4246 (avg: 3.8168)\tTop1: 25.000 (avg: 15.891)\tTop5: 50.000 (avg: 38.359)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.287 (avg: 0.299)\tLoss: 3.6545 (avg: 3.8189)\tTop1: 25.000 (avg: 15.838)\tTop5: 48.438 (avg: 38.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0055\tTop 1 accuracy: 11.450\tTop 5 accuracy: 29.200\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.286 (avg: 0.295)\tLoss: 4.4086 (avg: 3.8054)\tTop1: 7.812 (avg: 15.625)\tTop5: 25.000 (avg: 38.875)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.307 (avg: 0.299)\tLoss: 4.1508 (avg: 3.8061)\tTop1: 10.938 (avg: 15.469)\tTop5: 34.375 (avg: 38.781)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.284 (avg: 0.300)\tLoss: 4.0853 (avg: 3.8171)\tTop1: 9.375 (avg: 15.250)\tTop5: 26.562 (avg: 38.250)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.314 (avg: 0.301)\tLoss: 4.4084 (avg: 3.8140)\tTop1: 10.938 (avg: 15.172)\tTop5: 28.125 (avg: 38.484)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.286 (avg: 0.301)\tLoss: 4.1868 (avg: 3.8178)\tTop1: 9.375 (avg: 15.438)\tTop5: 32.812 (avg: 38.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8364\tTop 1 accuracy: 11.250\tTop 5 accuracy: 30.100\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.291 (avg: 0.294)\tLoss: 3.9342 (avg: 3.7612)\tTop1: 12.500 (avg: 16.938)\tTop5: 34.375 (avg: 40.000)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.294 (avg: 0.297)\tLoss: 3.7215 (avg: 3.7737)\tTop1: 17.188 (avg: 16.531)\tTop5: 46.875 (avg: 39.969)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.294 (avg: 0.299)\tLoss: 3.7980 (avg: 3.7881)\tTop1: 14.062 (avg: 16.208)\tTop5: 40.625 (avg: 39.292)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.308 (avg: 0.301)\tLoss: 3.9461 (avg: 3.7970)\tTop1: 10.938 (avg: 16.172)\tTop5: 37.500 (avg: 38.625)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.286 (avg: 0.301)\tLoss: 3.7543 (avg: 3.7922)\tTop1: 17.188 (avg: 16.363)\tTop5: 32.812 (avg: 38.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0822\tTop 1 accuracy: 11.200\tTop 5 accuracy: 29.400\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.297 (avg: 0.295)\tLoss: 3.8624 (avg: 3.8296)\tTop1: 12.500 (avg: 15.438)\tTop5: 40.625 (avg: 39.750)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.308 (avg: 0.300)\tLoss: 3.6552 (avg: 3.7910)\tTop1: 15.625 (avg: 16.719)\tTop5: 40.625 (avg: 39.625)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.286 (avg: 0.302)\tLoss: 3.6995 (avg: 3.7659)\tTop1: 15.625 (avg: 17.271)\tTop5: 39.062 (avg: 39.729)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.310 (avg: 0.302)\tLoss: 3.9044 (avg: 3.7752)\tTop1: 21.875 (avg: 17.125)\tTop5: 37.500 (avg: 39.469)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.296 (avg: 0.303)\tLoss: 3.9417 (avg: 3.7769)\tTop1: 15.625 (avg: 16.913)\tTop5: 29.688 (avg: 39.312)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8808\tTop 1 accuracy: 11.500\tTop 5 accuracy: 28.500\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.282 (avg: 0.292)\tLoss: 3.6081 (avg: 3.7090)\tTop1: 23.438 (avg: 18.250)\tTop5: 45.312 (avg: 40.188)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.300 (avg: 0.296)\tLoss: 3.8832 (avg: 3.7501)\tTop1: 15.625 (avg: 16.969)\tTop5: 40.625 (avg: 39.656)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.283 (avg: 0.297)\tLoss: 3.8539 (avg: 3.7535)\tTop1: 12.500 (avg: 16.479)\tTop5: 35.938 (avg: 39.583)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.307 (avg: 0.298)\tLoss: 3.8636 (avg: 3.7561)\tTop1: 14.062 (avg: 16.453)\tTop5: 42.188 (avg: 39.625)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.280 (avg: 0.298)\tLoss: 3.9785 (avg: 3.7692)\tTop1: 15.625 (avg: 16.250)\tTop5: 28.125 (avg: 39.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1220\tTop 1 accuracy: 10.550\tTop 5 accuracy: 29.100\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.303 (avg: 0.296)\tLoss: 3.8087 (avg: 3.7047)\tTop1: 17.188 (avg: 17.562)\tTop5: 40.625 (avg: 40.938)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.297 (avg: 0.299)\tLoss: 3.8963 (avg: 3.7418)\tTop1: 18.750 (avg: 17.094)\tTop5: 35.938 (avg: 39.188)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.284 (avg: 0.299)\tLoss: 3.4476 (avg: 3.7438)\tTop1: 18.750 (avg: 16.958)\tTop5: 50.000 (avg: 39.354)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.307 (avg: 0.300)\tLoss: 3.6634 (avg: 3.7477)\tTop1: 14.062 (avg: 16.891)\tTop5: 40.625 (avg: 39.094)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.284 (avg: 0.300)\tLoss: 3.7851 (avg: 3.7599)\tTop1: 17.188 (avg: 16.775)\tTop5: 39.062 (avg: 39.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0658\tTop 1 accuracy: 10.900\tTop 5 accuracy: 29.700\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.283 (avg: 0.295)\tLoss: 4.0042 (avg: 3.7125)\tTop1: 9.375 (avg: 17.625)\tTop5: 37.500 (avg: 40.312)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.296 (avg: 0.297)\tLoss: 3.8402 (avg: 3.7101)\tTop1: 20.312 (avg: 17.875)\tTop5: 35.938 (avg: 39.969)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.286 (avg: 0.298)\tLoss: 4.0535 (avg: 3.7341)\tTop1: 15.625 (avg: 18.021)\tTop5: 37.500 (avg: 40.083)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.302 (avg: 0.299)\tLoss: 3.9187 (avg: 3.7438)\tTop1: 9.375 (avg: 17.703)\tTop5: 31.250 (avg: 40.203)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.295 (avg: 0.299)\tLoss: 3.7932 (avg: 3.7501)\tTop1: 10.938 (avg: 17.363)\tTop5: 48.438 (avg: 40.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8828\tTop 1 accuracy: 12.150\tTop 5 accuracy: 30.000\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.284 (avg: 0.293)\tLoss: 3.8052 (avg: 3.7264)\tTop1: 10.938 (avg: 16.875)\tTop5: 39.062 (avg: 41.562)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.314 (avg: 0.298)\tLoss: 3.9887 (avg: 3.6945)\tTop1: 18.750 (avg: 17.688)\tTop5: 42.188 (avg: 41.531)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.288 (avg: 0.301)\tLoss: 3.9019 (avg: 3.6977)\tTop1: 12.500 (avg: 17.583)\tTop5: 31.250 (avg: 41.583)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.293 (avg: 0.301)\tLoss: 4.0753 (avg: 3.7123)\tTop1: 17.188 (avg: 17.531)\tTop5: 32.812 (avg: 41.156)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.287 (avg: 0.301)\tLoss: 3.4252 (avg: 3.7222)\tTop1: 17.188 (avg: 17.188)\tTop5: 50.000 (avg: 40.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9757\tTop 1 accuracy: 12.050\tTop 5 accuracy: 31.650\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.287 (avg: 0.294)\tLoss: 4.0421 (avg: 3.6824)\tTop1: 9.375 (avg: 18.312)\tTop5: 35.938 (avg: 41.312)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.314 (avg: 0.298)\tLoss: 3.9341 (avg: 3.7028)\tTop1: 12.500 (avg: 17.406)\tTop5: 26.562 (avg: 40.875)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 3.5866 (avg: 3.6855)\tTop1: 28.125 (avg: 17.667)\tTop5: 51.562 (avg: 41.000)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.314 (avg: 0.301)\tLoss: 3.5853 (avg: 3.6991)\tTop1: 23.438 (avg: 17.625)\tTop5: 53.125 (avg: 40.781)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.296 (avg: 0.302)\tLoss: 3.6392 (avg: 3.7147)\tTop1: 15.625 (avg: 17.188)\tTop5: 39.062 (avg: 40.475)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8278\tTop 1 accuracy: 12.100\tTop 5 accuracy: 31.350\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.289 (avg: 0.297)\tLoss: 3.7842 (avg: 3.7121)\tTop1: 12.500 (avg: 17.375)\tTop5: 34.375 (avg: 41.188)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.308 (avg: 0.300)\tLoss: 3.6648 (avg: 3.7116)\tTop1: 15.625 (avg: 17.500)\tTop5: 35.938 (avg: 40.625)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.287 (avg: 0.303)\tLoss: 3.9040 (avg: 3.6916)\tTop1: 14.062 (avg: 17.604)\tTop5: 43.750 (avg: 41.062)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.301 (avg: 0.303)\tLoss: 4.0579 (avg: 3.6996)\tTop1: 14.062 (avg: 17.656)\tTop5: 34.375 (avg: 41.078)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.286 (avg: 0.302)\tLoss: 3.5398 (avg: 3.6992)\tTop1: 25.000 (avg: 17.350)\tTop5: 51.562 (avg: 40.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7678\tTop 1 accuracy: 11.450\tTop 5 accuracy: 30.150\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.284 (avg: 0.294)\tLoss: 3.5504 (avg: 3.6315)\tTop1: 23.438 (avg: 18.562)\tTop5: 45.312 (avg: 43.500)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.301 (avg: 0.298)\tLoss: 3.9023 (avg: 3.6469)\tTop1: 12.500 (avg: 18.000)\tTop5: 37.500 (avg: 42.188)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.290 (avg: 0.298)\tLoss: 3.9255 (avg: 3.6598)\tTop1: 17.188 (avg: 17.688)\tTop5: 43.750 (avg: 41.458)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.299 (avg: 0.299)\tLoss: 3.9212 (avg: 3.6766)\tTop1: 10.938 (avg: 17.281)\tTop5: 34.375 (avg: 41.188)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.294 (avg: 0.300)\tLoss: 3.6642 (avg: 3.6852)\tTop1: 20.312 (avg: 17.312)\tTop5: 46.875 (avg: 41.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8638\tTop 1 accuracy: 11.750\tTop 5 accuracy: 30.900\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.291 (avg: 0.294)\tLoss: 3.3944 (avg: 3.5605)\tTop1: 21.875 (avg: 21.000)\tTop5: 48.438 (avg: 44.812)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.302 (avg: 0.301)\tLoss: 3.3692 (avg: 3.5559)\tTop1: 17.188 (avg: 20.469)\tTop5: 48.438 (avg: 45.812)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.300 (avg: 0.302)\tLoss: 3.5832 (avg: 3.5736)\tTop1: 15.625 (avg: 19.667)\tTop5: 43.750 (avg: 44.979)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.302 (avg: 0.303)\tLoss: 3.5156 (avg: 3.5831)\tTop1: 20.312 (avg: 19.891)\tTop5: 46.875 (avg: 44.281)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.289 (avg: 0.303)\tLoss: 3.4735 (avg: 3.5873)\tTop1: 18.750 (avg: 19.938)\tTop5: 45.312 (avg: 44.313)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7888\tTop 1 accuracy: 12.100\tTop 5 accuracy: 31.000\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.291 (avg: 0.295)\tLoss: 3.6065 (avg: 3.5561)\tTop1: 31.250 (avg: 21.062)\tTop5: 45.312 (avg: 45.375)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.305 (avg: 0.299)\tLoss: 3.7360 (avg: 3.5422)\tTop1: 15.625 (avg: 20.875)\tTop5: 45.312 (avg: 45.719)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.285 (avg: 0.299)\tLoss: 3.3081 (avg: 3.5596)\tTop1: 23.438 (avg: 20.417)\tTop5: 51.562 (avg: 45.000)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.299 (avg: 0.300)\tLoss: 3.3270 (avg: 3.5524)\tTop1: 21.875 (avg: 20.281)\tTop5: 51.562 (avg: 45.031)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.290 (avg: 0.300)\tLoss: 3.6193 (avg: 3.5552)\tTop1: 20.312 (avg: 20.200)\tTop5: 46.875 (avg: 44.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7883\tTop 1 accuracy: 12.650\tTop 5 accuracy: 32.150\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.285 (avg: 0.296)\tLoss: 3.2846 (avg: 3.4816)\tTop1: 23.438 (avg: 22.125)\tTop5: 46.875 (avg: 47.125)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.312 (avg: 0.300)\tLoss: 3.6037 (avg: 3.5172)\tTop1: 17.188 (avg: 21.438)\tTop5: 42.188 (avg: 45.844)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.285 (avg: 0.300)\tLoss: 3.2896 (avg: 3.5112)\tTop1: 26.562 (avg: 20.708)\tTop5: 42.188 (avg: 45.667)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.307 (avg: 0.302)\tLoss: 3.2748 (avg: 3.5350)\tTop1: 18.750 (avg: 20.578)\tTop5: 51.562 (avg: 44.797)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.296 (avg: 0.302)\tLoss: 3.4319 (avg: 3.5502)\tTop1: 21.875 (avg: 20.388)\tTop5: 50.000 (avg: 44.888)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.7502\tTop 1 accuracy: 12.500\tTop 5 accuracy: 32.000\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.284 (avg: 0.294)\tLoss: 3.2905 (avg: 3.5230)\tTop1: 18.750 (avg: 20.500)\tTop5: 39.062 (avg: 45.625)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.315 (avg: 0.298)\tLoss: 3.6907 (avg: 3.5281)\tTop1: 18.750 (avg: 21.344)\tTop5: 37.500 (avg: 45.594)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.284 (avg: 0.301)\tLoss: 3.9157 (avg: 3.5284)\tTop1: 9.375 (avg: 21.146)\tTop5: 35.938 (avg: 45.625)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.300 (avg: 0.301)\tLoss: 3.5402 (avg: 3.5312)\tTop1: 20.312 (avg: 21.000)\tTop5: 46.875 (avg: 45.453)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.292 (avg: 0.302)\tLoss: 3.5608 (avg: 3.5491)\tTop1: 23.438 (avg: 20.688)\tTop5: 57.812 (avg: 45.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8206\tTop 1 accuracy: 12.800\tTop 5 accuracy: 32.250\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.287 (avg: 0.295)\tLoss: 4.2429 (avg: 3.4744)\tTop1: 10.938 (avg: 22.000)\tTop5: 29.688 (avg: 47.125)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.296 (avg: 0.298)\tLoss: 3.5899 (avg: 3.4685)\tTop1: 18.750 (avg: 22.469)\tTop5: 42.188 (avg: 47.594)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.291 (avg: 0.300)\tLoss: 3.3644 (avg: 3.4998)\tTop1: 28.125 (avg: 21.458)\tTop5: 50.000 (avg: 46.021)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.311 (avg: 0.301)\tLoss: 3.9378 (avg: 3.5270)\tTop1: 17.188 (avg: 21.078)\tTop5: 34.375 (avg: 45.250)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.287 (avg: 0.302)\tLoss: 3.8177 (avg: 3.5429)\tTop1: 15.625 (avg: 20.688)\tTop5: 35.938 (avg: 44.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8083\tTop 1 accuracy: 12.950\tTop 5 accuracy: 32.300\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.295 (avg: 0.296)\tLoss: 3.3012 (avg: 3.6057)\tTop1: 25.000 (avg: 20.750)\tTop5: 57.812 (avg: 44.062)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.300 (avg: 0.299)\tLoss: 3.6177 (avg: 3.5751)\tTop1: 21.875 (avg: 19.812)\tTop5: 45.312 (avg: 44.188)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.284 (avg: 0.300)\tLoss: 3.3371 (avg: 3.5671)\tTop1: 21.875 (avg: 20.417)\tTop5: 57.812 (avg: 44.250)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.316 (avg: 0.301)\tLoss: 3.5157 (avg: 3.5472)\tTop1: 23.438 (avg: 20.672)\tTop5: 46.875 (avg: 44.938)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.287 (avg: 0.301)\tLoss: 3.4681 (avg: 3.5441)\tTop1: 10.938 (avg: 20.675)\tTop5: 43.750 (avg: 44.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8904\tTop 1 accuracy: 12.850\tTop 5 accuracy: 32.350\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.292 (avg: 0.294)\tLoss: 3.6979 (avg: 3.5017)\tTop1: 17.188 (avg: 20.438)\tTop5: 43.750 (avg: 45.312)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.306 (avg: 0.299)\tLoss: 3.5171 (avg: 3.5352)\tTop1: 25.000 (avg: 20.875)\tTop5: 43.750 (avg: 45.469)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.291 (avg: 0.299)\tLoss: 3.4886 (avg: 3.5586)\tTop1: 21.875 (avg: 20.667)\tTop5: 43.750 (avg: 45.042)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.305 (avg: 0.300)\tLoss: 3.5455 (avg: 3.5391)\tTop1: 20.312 (avg: 20.688)\tTop5: 43.750 (avg: 45.391)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.288 (avg: 0.300)\tLoss: 3.5472 (avg: 3.5393)\tTop1: 25.000 (avg: 20.875)\tTop5: 48.438 (avg: 45.225)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8160\tTop 1 accuracy: 12.250\tTop 5 accuracy: 32.050\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.283 (avg: 0.290)\tLoss: 3.4780 (avg: 3.5363)\tTop1: 20.312 (avg: 22.000)\tTop5: 45.312 (avg: 45.625)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.310 (avg: 0.295)\tLoss: 3.3599 (avg: 3.5389)\tTop1: 23.438 (avg: 21.844)\tTop5: 53.125 (avg: 45.438)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.282 (avg: 0.296)\tLoss: 3.0958 (avg: 3.5193)\tTop1: 21.875 (avg: 21.458)\tTop5: 53.125 (avg: 45.625)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.290 (avg: 0.296)\tLoss: 3.6026 (avg: 3.5241)\tTop1: 21.875 (avg: 21.016)\tTop5: 51.562 (avg: 45.500)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.281 (avg: 0.296)\tLoss: 3.6260 (avg: 3.5315)\tTop1: 20.312 (avg: 20.900)\tTop5: 35.938 (avg: 45.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8416\tTop 1 accuracy: 12.950\tTop 5 accuracy: 32.200\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.292 (avg: 0.290)\tLoss: 3.7371 (avg: 3.5275)\tTop1: 20.312 (avg: 21.875)\tTop5: 48.438 (avg: 46.312)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.292 (avg: 0.295)\tLoss: 3.4682 (avg: 3.5260)\tTop1: 20.312 (avg: 21.250)\tTop5: 42.188 (avg: 45.906)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.282 (avg: 0.295)\tLoss: 3.5396 (avg: 3.5244)\tTop1: 23.438 (avg: 21.521)\tTop5: 40.625 (avg: 45.729)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.295 (avg: 0.296)\tLoss: 3.3655 (avg: 3.5191)\tTop1: 23.438 (avg: 21.062)\tTop5: 45.312 (avg: 45.484)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.287 (avg: 0.297)\tLoss: 2.9565 (avg: 3.5303)\tTop1: 31.250 (avg: 20.600)\tTop5: 64.062 (avg: 45.000)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8172\tTop 1 accuracy: 12.400\tTop 5 accuracy: 31.700\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.284 (avg: 0.290)\tLoss: 3.4515 (avg: 3.5732)\tTop1: 21.875 (avg: 20.500)\tTop5: 43.750 (avg: 43.438)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.301 (avg: 0.295)\tLoss: 3.4438 (avg: 3.5171)\tTop1: 20.312 (avg: 20.719)\tTop5: 45.312 (avg: 44.125)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.281 (avg: 0.296)\tLoss: 3.6764 (avg: 3.5268)\tTop1: 18.750 (avg: 20.812)\tTop5: 40.625 (avg: 44.875)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.295 (avg: 0.297)\tLoss: 3.3213 (avg: 3.5256)\tTop1: 21.875 (avg: 20.797)\tTop5: 51.562 (avg: 45.094)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.283 (avg: 0.297)\tLoss: 3.3395 (avg: 3.5300)\tTop1: 17.188 (avg: 20.763)\tTop5: 48.438 (avg: 45.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8274\tTop 1 accuracy: 13.350\tTop 5 accuracy: 32.450\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.283 (avg: 0.294)\tLoss: 3.2864 (avg: 3.4769)\tTop1: 28.125 (avg: 20.750)\tTop5: 46.875 (avg: 46.625)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.294 (avg: 0.296)\tLoss: 3.6589 (avg: 3.5193)\tTop1: 15.625 (avg: 20.906)\tTop5: 35.938 (avg: 45.781)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.282 (avg: 0.296)\tLoss: 3.8200 (avg: 3.5145)\tTop1: 15.625 (avg: 20.896)\tTop5: 35.938 (avg: 45.896)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.314 (avg: 0.298)\tLoss: 3.2122 (avg: 3.5111)\tTop1: 29.688 (avg: 20.797)\tTop5: 51.562 (avg: 45.781)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.282 (avg: 0.298)\tLoss: 3.2629 (avg: 3.5229)\tTop1: 26.562 (avg: 20.838)\tTop5: 50.000 (avg: 45.388)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8260\tTop 1 accuracy: 12.900\tTop 5 accuracy: 32.000\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.284 (avg: 0.290)\tLoss: 3.7323 (avg: 3.4872)\tTop1: 14.062 (avg: 22.062)\tTop5: 40.625 (avg: 46.125)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.300 (avg: 0.293)\tLoss: 3.4635 (avg: 3.4910)\tTop1: 18.750 (avg: 22.000)\tTop5: 51.562 (avg: 46.281)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.283 (avg: 0.296)\tLoss: 3.4294 (avg: 3.4986)\tTop1: 15.625 (avg: 21.812)\tTop5: 51.562 (avg: 46.000)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.293 (avg: 0.296)\tLoss: 3.6745 (avg: 3.5174)\tTop1: 7.812 (avg: 21.219)\tTop5: 39.062 (avg: 45.703)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.281 (avg: 0.296)\tLoss: 3.6073 (avg: 3.5199)\tTop1: 17.188 (avg: 21.063)\tTop5: 42.188 (avg: 45.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8281\tTop 1 accuracy: 12.950\tTop 5 accuracy: 32.600\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.285 (avg: 0.292)\tLoss: 3.5184 (avg: 3.5727)\tTop1: 29.688 (avg: 20.562)\tTop5: 54.688 (avg: 45.125)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.302 (avg: 0.297)\tLoss: 3.9503 (avg: 3.5492)\tTop1: 14.062 (avg: 20.625)\tTop5: 35.938 (avg: 45.406)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.285 (avg: 0.297)\tLoss: 3.2995 (avg: 3.5615)\tTop1: 28.125 (avg: 20.333)\tTop5: 53.125 (avg: 44.896)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.299 (avg: 0.297)\tLoss: 3.3262 (avg: 3.5417)\tTop1: 20.312 (avg: 20.578)\tTop5: 51.562 (avg: 44.953)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.284 (avg: 0.297)\tLoss: 3.3203 (avg: 3.5238)\tTop1: 25.000 (avg: 20.888)\tTop5: 42.188 (avg: 45.300)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8136\tTop 1 accuracy: 12.950\tTop 5 accuracy: 32.400\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.284 (avg: 0.288)\tLoss: 3.6189 (avg: 3.4993)\tTop1: 17.188 (avg: 20.500)\tTop5: 46.875 (avg: 46.125)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.298 (avg: 0.293)\tLoss: 3.2331 (avg: 3.5051)\tTop1: 23.438 (avg: 20.719)\tTop5: 50.000 (avg: 46.219)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.289 (avg: 0.294)\tLoss: 3.6969 (avg: 3.5062)\tTop1: 21.875 (avg: 20.729)\tTop5: 46.875 (avg: 45.938)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.297 (avg: 0.295)\tLoss: 3.4526 (avg: 3.5121)\tTop1: 21.875 (avg: 20.844)\tTop5: 46.875 (avg: 46.047)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.286 (avg: 0.297)\tLoss: 3.7213 (avg: 3.5145)\tTop1: 18.750 (avg: 20.875)\tTop5: 37.500 (avg: 45.788)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8797\tTop 1 accuracy: 12.650\tTop 5 accuracy: 32.050\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.285 (avg: 0.295)\tLoss: 3.5246 (avg: 3.4981)\tTop1: 14.062 (avg: 20.000)\tTop5: 45.312 (avg: 46.688)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.306 (avg: 0.299)\tLoss: 3.4676 (avg: 3.4754)\tTop1: 21.875 (avg: 21.188)\tTop5: 48.438 (avg: 46.375)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.295 (avg: 0.301)\tLoss: 3.2824 (avg: 3.4866)\tTop1: 25.000 (avg: 21.104)\tTop5: 51.562 (avg: 46.208)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.298 (avg: 0.302)\tLoss: 3.4398 (avg: 3.5034)\tTop1: 28.125 (avg: 21.344)\tTop5: 37.500 (avg: 45.969)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.289 (avg: 0.302)\tLoss: 3.4388 (avg: 3.5119)\tTop1: 26.562 (avg: 21.350)\tTop5: 51.562 (avg: 45.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8447\tTop 1 accuracy: 13.100\tTop 5 accuracy: 32.750\n",
            "\n",
            "freq = 3: top1 = 13.100000381469727 \t top5 = 32.75 \t batch_time = 0.26953237503767014\n",
            "\n",
            "Training...\n",
            "Epoch: 0[25/125]\tTime used: 0.275 (avg: 0.306)\tLoss: 5.3023 (avg: 5.3049)\tTop1: 0.000 (avg: 0.375)\tTop5: 0.000 (avg: 1.688)\t\n",
            "Epoch: 0[50/125]\tTime used: 0.294 (avg: 0.299)\tLoss: 5.2983 (avg: 5.3020)\tTop1: 0.000 (avg: 0.344)\tTop5: 1.562 (avg: 1.781)\t\n",
            "Epoch: 0[75/125]\tTime used: 0.278 (avg: 0.297)\tLoss: 5.2985 (avg: 5.3009)\tTop1: 1.562 (avg: 0.396)\tTop5: 4.688 (avg: 1.875)\t\n",
            "Epoch: 0[100/125]\tTime used: 0.304 (avg: 0.295)\tLoss: 5.2990 (avg: 5.3003)\tTop1: 0.000 (avg: 0.422)\tTop5: 0.000 (avg: 1.797)\t\n",
            "Epoch: 0[125/125]\tTime used: 0.287 (avg: 0.295)\tLoss: 5.2971 (avg: 5.3000)\tTop1: 1.562 (avg: 0.400)\tTop5: 6.250 (avg: 1.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2983\tTop 1 accuracy: 0.400\tTop 5 accuracy: 1.800\n",
            "\n",
            "Training...\n",
            "Epoch: 1[25/125]\tTime used: 0.280 (avg: 0.286)\tLoss: 5.2970 (avg: 5.2981)\tTop1: 0.000 (avg: 0.625)\tTop5: 4.688 (avg: 2.375)\t\n",
            "Epoch: 1[50/125]\tTime used: 0.300 (avg: 0.292)\tLoss: 5.2986 (avg: 5.2980)\tTop1: 1.562 (avg: 0.625)\tTop5: 1.562 (avg: 2.469)\t\n",
            "Epoch: 1[75/125]\tTime used: 0.275 (avg: 0.293)\tLoss: 5.2996 (avg: 5.2979)\tTop1: 0.000 (avg: 0.708)\tTop5: 0.000 (avg: 2.562)\t\n",
            "Epoch: 1[100/125]\tTime used: 0.301 (avg: 0.293)\tLoss: 5.2986 (avg: 5.2980)\tTop1: 0.000 (avg: 0.609)\tTop5: 4.688 (avg: 2.406)\t\n",
            "Epoch: 1[125/125]\tTime used: 0.283 (avg: 0.293)\tLoss: 5.2979 (avg: 5.2979)\tTop1: 0.000 (avg: 0.588)\tTop5: 0.000 (avg: 2.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2938\tTop 1 accuracy: 0.450\tTop 5 accuracy: 1.900\n",
            "\n",
            "Training...\n",
            "Epoch: 2[25/125]\tTime used: 0.274 (avg: 0.286)\tLoss: 5.2846 (avg: 5.2948)\tTop1: 1.562 (avg: 0.625)\tTop5: 3.125 (avg: 2.125)\t\n",
            "Epoch: 2[50/125]\tTime used: 0.294 (avg: 0.289)\tLoss: 5.2967 (avg: 5.2909)\tTop1: 0.000 (avg: 0.500)\tTop5: 1.562 (avg: 2.344)\t\n",
            "Epoch: 2[75/125]\tTime used: 0.275 (avg: 0.289)\tLoss: 5.3243 (avg: 5.2897)\tTop1: 1.562 (avg: 0.542)\tTop5: 3.125 (avg: 2.479)\t\n",
            "Epoch: 2[100/125]\tTime used: 0.294 (avg: 0.290)\tLoss: 5.2634 (avg: 5.2873)\tTop1: 0.000 (avg: 0.562)\tTop5: 3.125 (avg: 2.656)\t\n",
            "Epoch: 2[125/125]\tTime used: 0.275 (avg: 0.290)\tLoss: 5.1521 (avg: 5.2798)\tTop1: 0.000 (avg: 0.562)\tTop5: 12.500 (avg: 2.938)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3219\tTop 1 accuracy: 0.600\tTop 5 accuracy: 3.400\n",
            "\n",
            "Training...\n",
            "Epoch: 3[25/125]\tTime used: 0.274 (avg: 0.282)\tLoss: 5.2306 (avg: 5.2477)\tTop1: 1.562 (avg: 0.625)\tTop5: 4.688 (avg: 3.750)\t\n",
            "Epoch: 3[50/125]\tTime used: 0.287 (avg: 0.286)\tLoss: 5.3089 (avg: 5.2465)\tTop1: 0.000 (avg: 1.062)\tTop5: 0.000 (avg: 3.750)\t\n",
            "Epoch: 3[75/125]\tTime used: 0.277 (avg: 0.287)\tLoss: 5.3641 (avg: 5.2483)\tTop1: 0.000 (avg: 0.938)\tTop5: 1.562 (avg: 3.979)\t\n",
            "Epoch: 3[100/125]\tTime used: 0.303 (avg: 0.289)\tLoss: 5.2016 (avg: 5.2513)\tTop1: 0.000 (avg: 0.859)\tTop5: 6.250 (avg: 3.875)\t\n",
            "Epoch: 3[125/125]\tTime used: 0.283 (avg: 0.290)\tLoss: 5.2144 (avg: 5.2528)\tTop1: 1.562 (avg: 0.888)\tTop5: 4.688 (avg: 3.975)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.4632\tTop 1 accuracy: 0.650\tTop 5 accuracy: 3.250\n",
            "\n",
            "Training...\n",
            "Epoch: 4[25/125]\tTime used: 0.276 (avg: 0.290)\tLoss: 5.1909 (avg: 5.2167)\tTop1: 1.562 (avg: 0.938)\tTop5: 4.688 (avg: 3.812)\t\n",
            "Epoch: 4[50/125]\tTime used: 0.291 (avg: 0.292)\tLoss: 5.2952 (avg: 5.2355)\tTop1: 0.000 (avg: 0.812)\tTop5: 6.250 (avg: 3.812)\t\n",
            "Epoch: 4[75/125]\tTime used: 0.273 (avg: 0.292)\tLoss: 5.2625 (avg: 5.2357)\tTop1: 1.562 (avg: 0.812)\tTop5: 3.125 (avg: 3.896)\t\n",
            "Epoch: 4[100/125]\tTime used: 0.294 (avg: 0.292)\tLoss: 5.2168 (avg: 5.2345)\tTop1: 1.562 (avg: 0.812)\tTop5: 6.250 (avg: 3.828)\t\n",
            "Epoch: 4[125/125]\tTime used: 0.281 (avg: 0.292)\tLoss: 5.1555 (avg: 5.2323)\tTop1: 1.562 (avg: 0.913)\tTop5: 7.812 (avg: 4.138)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3750\tTop 1 accuracy: 0.500\tTop 5 accuracy: 3.450\n",
            "\n",
            "Training...\n",
            "Epoch: 5[25/125]\tTime used: 0.280 (avg: 0.290)\tLoss: 5.2242 (avg: 5.2167)\tTop1: 0.000 (avg: 0.938)\tTop5: 4.688 (avg: 4.938)\t\n",
            "Epoch: 5[50/125]\tTime used: 0.292 (avg: 0.291)\tLoss: 5.2877 (avg: 5.2248)\tTop1: 1.562 (avg: 0.969)\tTop5: 3.125 (avg: 4.219)\t\n",
            "Epoch: 5[75/125]\tTime used: 0.275 (avg: 0.291)\tLoss: 5.2375 (avg: 5.2265)\tTop1: 0.000 (avg: 0.979)\tTop5: 6.250 (avg: 4.396)\t\n",
            "Epoch: 5[100/125]\tTime used: 0.290 (avg: 0.291)\tLoss: 5.1560 (avg: 5.2290)\tTop1: 1.562 (avg: 1.016)\tTop5: 7.812 (avg: 4.375)\t\n",
            "Epoch: 5[125/125]\tTime used: 0.276 (avg: 0.290)\tLoss: 5.0378 (avg: 5.2260)\tTop1: 4.688 (avg: 1.025)\tTop5: 9.375 (avg: 4.525)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.3478\tTop 1 accuracy: 0.500\tTop 5 accuracy: 3.800\n",
            "\n",
            "Training...\n",
            "Epoch: 6[25/125]\tTime used: 0.273 (avg: 0.283)\tLoss: 5.1521 (avg: 5.2182)\tTop1: 3.125 (avg: 0.875)\tTop5: 7.812 (avg: 4.500)\t\n",
            "Epoch: 6[50/125]\tTime used: 0.292 (avg: 0.287)\tLoss: 5.2324 (avg: 5.2198)\tTop1: 1.562 (avg: 1.000)\tTop5: 3.125 (avg: 4.156)\t\n",
            "Epoch: 6[75/125]\tTime used: 0.272 (avg: 0.288)\tLoss: 5.1737 (avg: 5.2168)\tTop1: 0.000 (avg: 1.083)\tTop5: 4.688 (avg: 4.417)\t\n",
            "Epoch: 6[100/125]\tTime used: 0.289 (avg: 0.289)\tLoss: 5.2880 (avg: 5.2187)\tTop1: 0.000 (avg: 1.094)\tTop5: 3.125 (avg: 4.484)\t\n",
            "Epoch: 6[125/125]\tTime used: 0.277 (avg: 0.289)\tLoss: 5.1834 (avg: 5.2152)\tTop1: 1.562 (avg: 1.062)\tTop5: 9.375 (avg: 4.562)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2977\tTop 1 accuracy: 0.650\tTop 5 accuracy: 3.900\n",
            "\n",
            "Training...\n",
            "Epoch: 7[25/125]\tTime used: 0.283 (avg: 0.285)\tLoss: 5.2642 (avg: 5.2156)\tTop1: 1.562 (avg: 1.062)\tTop5: 3.125 (avg: 4.812)\t\n",
            "Epoch: 7[50/125]\tTime used: 0.294 (avg: 0.287)\tLoss: 5.1586 (avg: 5.2085)\tTop1: 3.125 (avg: 1.156)\tTop5: 4.688 (avg: 5.156)\t\n",
            "Epoch: 7[75/125]\tTime used: 0.283 (avg: 0.287)\tLoss: 5.3131 (avg: 5.2096)\tTop1: 0.000 (avg: 1.000)\tTop5: 1.562 (avg: 5.062)\t\n",
            "Epoch: 7[100/125]\tTime used: 0.297 (avg: 0.288)\tLoss: 5.1247 (avg: 5.2122)\tTop1: 3.125 (avg: 1.031)\tTop5: 7.812 (avg: 5.000)\t\n",
            "Epoch: 7[125/125]\tTime used: 0.283 (avg: 0.289)\tLoss: 5.2553 (avg: 5.2136)\tTop1: 1.562 (avg: 1.013)\tTop5: 1.562 (avg: 5.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2363\tTop 1 accuracy: 1.100\tTop 5 accuracy: 4.400\n",
            "\n",
            "Training...\n",
            "Epoch: 8[25/125]\tTime used: 0.278 (avg: 0.285)\tLoss: 5.1948 (avg: 5.2056)\tTop1: 1.562 (avg: 1.562)\tTop5: 6.250 (avg: 5.312)\t\n",
            "Epoch: 8[50/125]\tTime used: 0.283 (avg: 0.288)\tLoss: 5.2162 (avg: 5.2127)\tTop1: 0.000 (avg: 1.188)\tTop5: 6.250 (avg: 5.031)\t\n",
            "Epoch: 8[75/125]\tTime used: 0.277 (avg: 0.289)\tLoss: 5.2329 (avg: 5.2126)\tTop1: 1.562 (avg: 1.125)\tTop5: 7.812 (avg: 4.896)\t\n",
            "Epoch: 8[100/125]\tTime used: 0.289 (avg: 0.290)\tLoss: 5.0828 (avg: 5.2103)\tTop1: 1.562 (avg: 1.141)\tTop5: 7.812 (avg: 5.109)\t\n",
            "Epoch: 8[125/125]\tTime used: 0.277 (avg: 0.290)\tLoss: 5.0825 (avg: 5.2071)\tTop1: 0.000 (avg: 1.088)\tTop5: 7.812 (avg: 5.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2595\tTop 1 accuracy: 1.100\tTop 5 accuracy: 4.800\n",
            "\n",
            "Training...\n",
            "Epoch: 9[25/125]\tTime used: 0.286 (avg: 0.288)\tLoss: 5.2102 (avg: 5.2051)\tTop1: 1.562 (avg: 1.188)\tTop5: 6.250 (avg: 5.188)\t\n",
            "Epoch: 9[50/125]\tTime used: 0.301 (avg: 0.294)\tLoss: 5.2095 (avg: 5.2028)\tTop1: 4.688 (avg: 1.250)\tTop5: 14.062 (avg: 5.375)\t\n",
            "Epoch: 9[75/125]\tTime used: 0.280 (avg: 0.296)\tLoss: 5.1018 (avg: 5.1953)\tTop1: 0.000 (avg: 1.312)\tTop5: 6.250 (avg: 5.146)\t\n",
            "Epoch: 9[100/125]\tTime used: 0.298 (avg: 0.297)\tLoss: 5.0929 (avg: 5.1959)\tTop1: 3.125 (avg: 1.250)\tTop5: 9.375 (avg: 5.297)\t\n",
            "Epoch: 9[125/125]\tTime used: 0.285 (avg: 0.297)\tLoss: 5.1885 (avg: 5.1940)\tTop1: 0.000 (avg: 1.200)\tTop5: 6.250 (avg: 5.413)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2623\tTop 1 accuracy: 1.250\tTop 5 accuracy: 5.050\n",
            "\n",
            "Training...\n",
            "Epoch: 10[25/125]\tTime used: 0.286 (avg: 0.293)\tLoss: 5.1880 (avg: 5.1976)\tTop1: 1.562 (avg: 0.812)\tTop5: 7.812 (avg: 5.250)\t\n",
            "Epoch: 10[50/125]\tTime used: 0.298 (avg: 0.297)\tLoss: 5.1070 (avg: 5.1939)\tTop1: 4.688 (avg: 0.938)\tTop5: 9.375 (avg: 5.219)\t\n",
            "Epoch: 10[75/125]\tTime used: 0.294 (avg: 0.297)\tLoss: 5.2870 (avg: 5.2058)\tTop1: 3.125 (avg: 0.979)\tTop5: 4.688 (avg: 5.167)\t\n",
            "Epoch: 10[100/125]\tTime used: 0.293 (avg: 0.297)\tLoss: 5.1493 (avg: 5.1983)\tTop1: 3.125 (avg: 0.906)\tTop5: 6.250 (avg: 5.312)\t\n",
            "Epoch: 10[125/125]\tTime used: 0.282 (avg: 0.298)\tLoss: 5.2475 (avg: 5.1924)\tTop1: 0.000 (avg: 1.025)\tTop5: 1.562 (avg: 5.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1971\tTop 1 accuracy: 1.250\tTop 5 accuracy: 4.400\n",
            "\n",
            "Training...\n",
            "Epoch: 11[25/125]\tTime used: 0.284 (avg: 0.291)\tLoss: 5.1313 (avg: 5.1748)\tTop1: 3.125 (avg: 1.562)\tTop5: 7.812 (avg: 6.688)\t\n",
            "Epoch: 11[50/125]\tTime used: 0.287 (avg: 0.294)\tLoss: 5.2649 (avg: 5.1823)\tTop1: 0.000 (avg: 1.219)\tTop5: 3.125 (avg: 6.094)\t\n",
            "Epoch: 11[75/125]\tTime used: 0.275 (avg: 0.293)\tLoss: 5.2600 (avg: 5.1782)\tTop1: 0.000 (avg: 1.104)\tTop5: 1.562 (avg: 5.979)\t\n",
            "Epoch: 11[100/125]\tTime used: 0.287 (avg: 0.292)\tLoss: 5.1642 (avg: 5.1833)\tTop1: 0.000 (avg: 1.203)\tTop5: 4.688 (avg: 5.766)\t\n",
            "Epoch: 11[125/125]\tTime used: 0.270 (avg: 0.291)\tLoss: 5.2285 (avg: 5.1843)\tTop1: 0.000 (avg: 1.225)\tTop5: 1.562 (avg: 5.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1249\tTop 1 accuracy: 1.000\tTop 5 accuracy: 5.450\n",
            "\n",
            "Training...\n",
            "Epoch: 12[25/125]\tTime used: 0.274 (avg: 0.283)\tLoss: 5.3008 (avg: 5.2175)\tTop1: 0.000 (avg: 1.375)\tTop5: 1.562 (avg: 5.688)\t\n",
            "Epoch: 12[50/125]\tTime used: 0.302 (avg: 0.286)\tLoss: 5.1793 (avg: 5.2025)\tTop1: 0.000 (avg: 1.156)\tTop5: 4.688 (avg: 5.500)\t\n",
            "Epoch: 12[75/125]\tTime used: 0.275 (avg: 0.289)\tLoss: 5.1775 (avg: 5.1935)\tTop1: 0.000 (avg: 1.292)\tTop5: 4.688 (avg: 5.646)\t\n",
            "Epoch: 12[100/125]\tTime used: 0.291 (avg: 0.289)\tLoss: 5.1452 (avg: 5.1875)\tTop1: 1.562 (avg: 1.328)\tTop5: 7.812 (avg: 5.875)\t\n",
            "Epoch: 12[125/125]\tTime used: 0.281 (avg: 0.289)\tLoss: 5.2465 (avg: 5.1889)\tTop1: 0.000 (avg: 1.400)\tTop5: 3.125 (avg: 5.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1264\tTop 1 accuracy: 1.200\tTop 5 accuracy: 4.450\n",
            "\n",
            "Training...\n",
            "Epoch: 13[25/125]\tTime used: 0.290 (avg: 0.286)\tLoss: 5.1140 (avg: 5.1701)\tTop1: 0.000 (avg: 1.375)\tTop5: 9.375 (avg: 7.062)\t\n",
            "Epoch: 13[50/125]\tTime used: 0.301 (avg: 0.293)\tLoss: 5.1412 (avg: 5.1658)\tTop1: 1.562 (avg: 1.344)\tTop5: 7.812 (avg: 6.594)\t\n",
            "Epoch: 13[75/125]\tTime used: 0.276 (avg: 0.293)\tLoss: 5.1777 (avg: 5.1675)\tTop1: 0.000 (avg: 1.312)\tTop5: 3.125 (avg: 6.458)\t\n",
            "Epoch: 13[100/125]\tTime used: 0.289 (avg: 0.292)\tLoss: 5.0967 (avg: 5.1722)\tTop1: 0.000 (avg: 1.188)\tTop5: 6.250 (avg: 6.281)\t\n",
            "Epoch: 13[125/125]\tTime used: 0.275 (avg: 0.291)\tLoss: 5.1506 (avg: 5.1759)\tTop1: 1.562 (avg: 1.200)\tTop5: 4.688 (avg: 6.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2728\tTop 1 accuracy: 1.100\tTop 5 accuracy: 4.750\n",
            "\n",
            "Training...\n",
            "Epoch: 14[25/125]\tTime used: 0.287 (avg: 0.288)\tLoss: 5.2081 (avg: 5.1654)\tTop1: 0.000 (avg: 1.938)\tTop5: 3.125 (avg: 6.188)\t\n",
            "Epoch: 14[50/125]\tTime used: 0.306 (avg: 0.294)\tLoss: 5.2708 (avg: 5.1616)\tTop1: 0.000 (avg: 1.875)\tTop5: 3.125 (avg: 6.656)\t\n",
            "Epoch: 14[75/125]\tTime used: 0.284 (avg: 0.294)\tLoss: 5.2252 (avg: 5.1678)\tTop1: 0.000 (avg: 1.771)\tTop5: 3.125 (avg: 6.500)\t\n",
            "Epoch: 14[100/125]\tTime used: 0.290 (avg: 0.294)\tLoss: 5.1851 (avg: 5.1680)\tTop1: 0.000 (avg: 1.562)\tTop5: 6.250 (avg: 6.312)\t\n",
            "Epoch: 14[125/125]\tTime used: 0.281 (avg: 0.293)\tLoss: 5.1510 (avg: 5.1660)\tTop1: 0.000 (avg: 1.525)\tTop5: 6.250 (avg: 6.425)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1184\tTop 1 accuracy: 1.600\tTop 5 accuracy: 6.450\n",
            "\n",
            "Training...\n",
            "Epoch: 15[25/125]\tTime used: 0.282 (avg: 0.291)\tLoss: 5.1822 (avg: 5.1325)\tTop1: 3.125 (avg: 1.688)\tTop5: 3.125 (avg: 7.312)\t\n",
            "Epoch: 15[50/125]\tTime used: 0.308 (avg: 0.294)\tLoss: 5.1596 (avg: 5.1628)\tTop1: 0.000 (avg: 1.594)\tTop5: 6.250 (avg: 6.812)\t\n",
            "Epoch: 15[75/125]\tTime used: 0.275 (avg: 0.295)\tLoss: 5.1161 (avg: 5.1645)\tTop1: 1.562 (avg: 1.500)\tTop5: 7.812 (avg: 6.438)\t\n",
            "Epoch: 15[100/125]\tTime used: 0.297 (avg: 0.295)\tLoss: 5.1569 (avg: 5.1669)\tTop1: 3.125 (avg: 1.484)\tTop5: 6.250 (avg: 6.203)\t\n",
            "Epoch: 15[125/125]\tTime used: 0.274 (avg: 0.295)\tLoss: 5.1919 (avg: 5.1701)\tTop1: 1.562 (avg: 1.388)\tTop5: 1.562 (avg: 5.963)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0967\tTop 1 accuracy: 1.450\tTop 5 accuracy: 5.600\n",
            "\n",
            "Training...\n",
            "Epoch: 16[25/125]\tTime used: 0.283 (avg: 0.294)\tLoss: 5.1079 (avg: 5.1517)\tTop1: 1.562 (avg: 1.688)\tTop5: 7.812 (avg: 6.375)\t\n",
            "Epoch: 16[50/125]\tTime used: 0.296 (avg: 0.296)\tLoss: 4.9958 (avg: 5.1480)\tTop1: 1.562 (avg: 1.656)\tTop5: 15.625 (avg: 6.656)\t\n",
            "Epoch: 16[75/125]\tTime used: 0.283 (avg: 0.296)\tLoss: 5.1011 (avg: 5.1586)\tTop1: 1.562 (avg: 1.542)\tTop5: 7.812 (avg: 6.146)\t\n",
            "Epoch: 16[100/125]\tTime used: 0.304 (avg: 0.297)\tLoss: 5.1959 (avg: 5.1564)\tTop1: 3.125 (avg: 1.562)\tTop5: 7.812 (avg: 6.297)\t\n",
            "Epoch: 16[125/125]\tTime used: 0.293 (avg: 0.297)\tLoss: 5.0576 (avg: 5.1552)\tTop1: 3.125 (avg: 1.550)\tTop5: 10.938 (avg: 6.450)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9739\tTop 1 accuracy: 1.900\tTop 5 accuracy: 6.200\n",
            "\n",
            "Training...\n",
            "Epoch: 17[25/125]\tTime used: 0.272 (avg: 0.282)\tLoss: 5.1797 (avg: 5.1704)\tTop1: 1.562 (avg: 1.188)\tTop5: 3.125 (avg: 6.688)\t\n",
            "Epoch: 17[50/125]\tTime used: 0.304 (avg: 0.289)\tLoss: 5.1642 (avg: 5.1639)\tTop1: 1.562 (avg: 1.344)\tTop5: 7.812 (avg: 6.375)\t\n",
            "Epoch: 17[75/125]\tTime used: 0.277 (avg: 0.290)\tLoss: 5.0186 (avg: 5.1534)\tTop1: 1.562 (avg: 1.396)\tTop5: 6.250 (avg: 6.396)\t\n",
            "Epoch: 17[100/125]\tTime used: 0.299 (avg: 0.292)\tLoss: 5.1382 (avg: 5.1506)\tTop1: 0.000 (avg: 1.484)\tTop5: 6.250 (avg: 6.719)\t\n",
            "Epoch: 17[125/125]\tTime used: 0.284 (avg: 0.293)\tLoss: 5.1461 (avg: 5.1485)\tTop1: 1.562 (avg: 1.425)\tTop5: 4.688 (avg: 6.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0662\tTop 1 accuracy: 1.200\tTop 5 accuracy: 6.700\n",
            "\n",
            "Training...\n",
            "Epoch: 18[25/125]\tTime used: 0.281 (avg: 0.293)\tLoss: 5.1017 (avg: 5.1054)\tTop1: 4.688 (avg: 1.938)\tTop5: 9.375 (avg: 8.312)\t\n",
            "Epoch: 18[50/125]\tTime used: 0.298 (avg: 0.297)\tLoss: 5.0691 (avg: 5.1200)\tTop1: 0.000 (avg: 1.750)\tTop5: 7.812 (avg: 7.844)\t\n",
            "Epoch: 18[75/125]\tTime used: 0.296 (avg: 0.298)\tLoss: 5.1811 (avg: 5.1223)\tTop1: 0.000 (avg: 1.667)\tTop5: 6.250 (avg: 7.792)\t\n",
            "Epoch: 18[100/125]\tTime used: 0.297 (avg: 0.298)\tLoss: 5.2510 (avg: 5.1236)\tTop1: 3.125 (avg: 1.750)\tTop5: 6.250 (avg: 7.625)\t\n",
            "Epoch: 18[125/125]\tTime used: 0.285 (avg: 0.298)\tLoss: 5.1796 (avg: 5.1262)\tTop1: 0.000 (avg: 1.700)\tTop5: 1.562 (avg: 7.463)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.0870\tTop 1 accuracy: 1.400\tTop 5 accuracy: 6.850\n",
            "\n",
            "Training...\n",
            "Epoch: 19[25/125]\tTime used: 0.281 (avg: 0.291)\tLoss: 4.9793 (avg: 5.1043)\tTop1: 1.562 (avg: 1.625)\tTop5: 9.375 (avg: 8.812)\t\n",
            "Epoch: 19[50/125]\tTime used: 0.300 (avg: 0.295)\tLoss: 5.1395 (avg: 5.1259)\tTop1: 3.125 (avg: 1.531)\tTop5: 6.250 (avg: 8.031)\t\n",
            "Epoch: 19[75/125]\tTime used: 0.282 (avg: 0.296)\tLoss: 5.0368 (avg: 5.1233)\tTop1: 1.562 (avg: 1.750)\tTop5: 7.812 (avg: 7.812)\t\n",
            "Epoch: 19[100/125]\tTime used: 0.300 (avg: 0.296)\tLoss: 5.1082 (avg: 5.1250)\tTop1: 0.000 (avg: 1.562)\tTop5: 6.250 (avg: 7.625)\t\n",
            "Epoch: 19[125/125]\tTime used: 0.293 (avg: 0.297)\tLoss: 5.1751 (avg: 5.1199)\tTop1: 1.562 (avg: 1.700)\tTop5: 4.688 (avg: 7.925)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.5245\tTop 1 accuracy: 1.700\tTop 5 accuracy: 7.400\n",
            "\n",
            "Training...\n",
            "Epoch: 20[25/125]\tTime used: 0.283 (avg: 0.292)\tLoss: 5.0725 (avg: 5.1039)\tTop1: 0.000 (avg: 2.062)\tTop5: 9.375 (avg: 8.188)\t\n",
            "Epoch: 20[50/125]\tTime used: 0.306 (avg: 0.296)\tLoss: 5.2172 (avg: 5.1191)\tTop1: 1.562 (avg: 2.000)\tTop5: 6.250 (avg: 8.219)\t\n",
            "Epoch: 20[75/125]\tTime used: 0.286 (avg: 0.294)\tLoss: 5.0745 (avg: 5.1114)\tTop1: 0.000 (avg: 2.000)\tTop5: 10.938 (avg: 8.167)\t\n",
            "Epoch: 20[100/125]\tTime used: 0.299 (avg: 0.295)\tLoss: 5.1668 (avg: 5.1085)\tTop1: 1.562 (avg: 2.000)\tTop5: 7.812 (avg: 8.172)\t\n",
            "Epoch: 20[125/125]\tTime used: 0.273 (avg: 0.294)\tLoss: 5.0219 (avg: 5.1047)\tTop1: 0.000 (avg: 1.963)\tTop5: 9.375 (avg: 8.175)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.4535\tTop 1 accuracy: 2.250\tTop 5 accuracy: 8.450\n",
            "\n",
            "Training...\n",
            "Epoch: 21[25/125]\tTime used: 0.289 (avg: 0.293)\tLoss: 5.0347 (avg: 5.0860)\tTop1: 1.562 (avg: 2.312)\tTop5: 7.812 (avg: 9.375)\t\n",
            "Epoch: 21[50/125]\tTime used: 0.300 (avg: 0.296)\tLoss: 5.0875 (avg: 5.0944)\tTop1: 1.562 (avg: 2.094)\tTop5: 4.688 (avg: 9.000)\t\n",
            "Epoch: 21[75/125]\tTime used: 0.274 (avg: 0.294)\tLoss: 5.1458 (avg: 5.0969)\tTop1: 0.000 (avg: 2.021)\tTop5: 9.375 (avg: 8.729)\t\n",
            "Epoch: 21[100/125]\tTime used: 0.297 (avg: 0.295)\tLoss: 5.1267 (avg: 5.0928)\tTop1: 3.125 (avg: 2.031)\tTop5: 9.375 (avg: 8.891)\t\n",
            "Epoch: 21[125/125]\tTime used: 0.291 (avg: 0.296)\tLoss: 5.2021 (avg: 5.0923)\tTop1: 0.000 (avg: 2.062)\tTop5: 6.250 (avg: 9.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.5319\tTop 1 accuracy: 1.850\tTop 5 accuracy: 8.300\n",
            "\n",
            "Training...\n",
            "Epoch: 22[25/125]\tTime used: 0.279 (avg: 0.290)\tLoss: 5.2499 (avg: 5.0768)\tTop1: 1.562 (avg: 2.000)\tTop5: 6.250 (avg: 8.750)\t\n",
            "Epoch: 22[50/125]\tTime used: 0.303 (avg: 0.293)\tLoss: 5.0163 (avg: 5.0827)\tTop1: 3.125 (avg: 2.406)\tTop5: 12.500 (avg: 8.594)\t\n",
            "Epoch: 22[75/125]\tTime used: 0.281 (avg: 0.296)\tLoss: 5.0418 (avg: 5.0718)\tTop1: 0.000 (avg: 2.521)\tTop5: 9.375 (avg: 8.792)\t\n",
            "Epoch: 22[100/125]\tTime used: 0.299 (avg: 0.297)\tLoss: 5.0788 (avg: 5.0708)\tTop1: 3.125 (avg: 2.391)\tTop5: 10.938 (avg: 9.172)\t\n",
            "Epoch: 22[125/125]\tTime used: 0.290 (avg: 0.297)\tLoss: 5.0589 (avg: 5.0690)\tTop1: 1.562 (avg: 2.350)\tTop5: 4.688 (avg: 9.188)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.2246\tTop 1 accuracy: 2.750\tTop 5 accuracy: 9.750\n",
            "\n",
            "Training...\n",
            "Epoch: 23[25/125]\tTime used: 0.282 (avg: 0.286)\tLoss: 4.9684 (avg: 5.0348)\tTop1: 4.688 (avg: 3.250)\tTop5: 9.375 (avg: 9.688)\t\n",
            "Epoch: 23[50/125]\tTime used: 0.300 (avg: 0.292)\tLoss: 5.1594 (avg: 5.0476)\tTop1: 0.000 (avg: 2.844)\tTop5: 6.250 (avg: 9.344)\t\n",
            "Epoch: 23[75/125]\tTime used: 0.282 (avg: 0.294)\tLoss: 5.1799 (avg: 5.0467)\tTop1: 1.562 (avg: 2.833)\tTop5: 4.688 (avg: 9.542)\t\n",
            "Epoch: 23[100/125]\tTime used: 0.288 (avg: 0.293)\tLoss: 5.0457 (avg: 5.0454)\tTop1: 3.125 (avg: 2.844)\tTop5: 10.938 (avg: 10.000)\t\n",
            "Epoch: 23[125/125]\tTime used: 0.272 (avg: 0.291)\tLoss: 5.0874 (avg: 5.0444)\tTop1: 3.125 (avg: 2.850)\tTop5: 7.812 (avg: 10.013)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8762\tTop 1 accuracy: 2.950\tTop 5 accuracy: 9.300\n",
            "\n",
            "Training...\n",
            "Epoch: 24[25/125]\tTime used: 0.285 (avg: 0.288)\tLoss: 5.0315 (avg: 5.0274)\tTop1: 1.562 (avg: 3.062)\tTop5: 7.812 (avg: 10.312)\t\n",
            "Epoch: 24[50/125]\tTime used: 0.291 (avg: 0.293)\tLoss: 5.0077 (avg: 5.0089)\tTop1: 3.125 (avg: 2.688)\tTop5: 12.500 (avg: 10.500)\t\n",
            "Epoch: 24[75/125]\tTime used: 0.283 (avg: 0.294)\tLoss: 5.0774 (avg: 5.0130)\tTop1: 4.688 (avg: 2.812)\tTop5: 7.812 (avg: 10.542)\t\n",
            "Epoch: 24[100/125]\tTime used: 0.298 (avg: 0.295)\tLoss: 4.8536 (avg: 5.0160)\tTop1: 4.688 (avg: 2.859)\tTop5: 17.188 (avg: 10.641)\t\n",
            "Epoch: 24[125/125]\tTime used: 0.290 (avg: 0.296)\tLoss: 5.0253 (avg: 5.0187)\tTop1: 3.125 (avg: 2.938)\tTop5: 17.188 (avg: 10.813)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 5.1123\tTop 1 accuracy: 2.350\tTop 5 accuracy: 9.650\n",
            "\n",
            "Training...\n",
            "Epoch: 25[25/125]\tTime used: 0.285 (avg: 0.291)\tLoss: 5.0280 (avg: 4.9654)\tTop1: 4.688 (avg: 3.562)\tTop5: 9.375 (avg: 11.625)\t\n",
            "Epoch: 25[50/125]\tTime used: 0.305 (avg: 0.296)\tLoss: 5.0151 (avg: 4.9891)\tTop1: 0.000 (avg: 3.250)\tTop5: 7.812 (avg: 11.219)\t\n",
            "Epoch: 25[75/125]\tTime used: 0.291 (avg: 0.297)\tLoss: 4.8425 (avg: 4.9886)\tTop1: 6.250 (avg: 3.104)\tTop5: 18.750 (avg: 11.333)\t\n",
            "Epoch: 25[100/125]\tTime used: 0.304 (avg: 0.298)\tLoss: 5.0265 (avg: 4.9858)\tTop1: 3.125 (avg: 3.141)\tTop5: 10.938 (avg: 11.250)\t\n",
            "Epoch: 25[125/125]\tTime used: 0.284 (avg: 0.297)\tLoss: 4.9719 (avg: 4.9877)\tTop1: 1.562 (avg: 3.100)\tTop5: 7.812 (avg: 11.088)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7317\tTop 1 accuracy: 3.150\tTop 5 accuracy: 9.500\n",
            "\n",
            "Training...\n",
            "Epoch: 26[25/125]\tTime used: 0.279 (avg: 0.288)\tLoss: 4.9414 (avg: 4.9313)\tTop1: 3.125 (avg: 3.750)\tTop5: 10.938 (avg: 12.625)\t\n",
            "Epoch: 26[50/125]\tTime used: 0.302 (avg: 0.291)\tLoss: 4.8370 (avg: 4.9612)\tTop1: 3.125 (avg: 3.281)\tTop5: 14.062 (avg: 12.094)\t\n",
            "Epoch: 26[75/125]\tTime used: 0.284 (avg: 0.293)\tLoss: 5.0529 (avg: 4.9599)\tTop1: 1.562 (avg: 3.333)\tTop5: 10.938 (avg: 11.771)\t\n",
            "Epoch: 26[100/125]\tTime used: 0.296 (avg: 0.294)\tLoss: 5.0989 (avg: 4.9611)\tTop1: 1.562 (avg: 3.344)\tTop5: 14.062 (avg: 11.984)\t\n",
            "Epoch: 26[125/125]\tTime used: 0.285 (avg: 0.295)\tLoss: 5.0872 (avg: 4.9653)\tTop1: 6.250 (avg: 3.300)\tTop5: 10.938 (avg: 11.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9154\tTop 1 accuracy: 3.000\tTop 5 accuracy: 10.150\n",
            "\n",
            "Training...\n",
            "Epoch: 27[25/125]\tTime used: 0.280 (avg: 0.282)\tLoss: 4.9708 (avg: 4.9059)\tTop1: 3.125 (avg: 3.562)\tTop5: 10.938 (avg: 13.125)\t\n",
            "Epoch: 27[50/125]\tTime used: 0.294 (avg: 0.286)\tLoss: 4.7580 (avg: 4.9308)\tTop1: 3.125 (avg: 3.469)\tTop5: 12.500 (avg: 12.969)\t\n",
            "Epoch: 27[75/125]\tTime used: 0.286 (avg: 0.287)\tLoss: 4.7751 (avg: 4.9237)\tTop1: 3.125 (avg: 3.396)\tTop5: 12.500 (avg: 12.771)\t\n",
            "Epoch: 27[100/125]\tTime used: 0.299 (avg: 0.289)\tLoss: 4.7773 (avg: 4.9236)\tTop1: 6.250 (avg: 3.500)\tTop5: 15.625 (avg: 12.688)\t\n",
            "Epoch: 27[125/125]\tTime used: 0.280 (avg: 0.290)\tLoss: 5.0770 (avg: 4.9244)\tTop1: 3.125 (avg: 3.500)\tTop5: 14.062 (avg: 12.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.9319\tTop 1 accuracy: 3.550\tTop 5 accuracy: 11.450\n",
            "\n",
            "Training...\n",
            "Epoch: 28[25/125]\tTime used: 0.278 (avg: 0.290)\tLoss: 4.8808 (avg: 4.8793)\tTop1: 4.688 (avg: 3.125)\tTop5: 10.938 (avg: 13.562)\t\n",
            "Epoch: 28[50/125]\tTime used: 0.293 (avg: 0.290)\tLoss: 4.9622 (avg: 4.9021)\tTop1: 1.562 (avg: 3.219)\tTop5: 12.500 (avg: 13.281)\t\n",
            "Epoch: 28[75/125]\tTime used: 0.292 (avg: 0.293)\tLoss: 4.9276 (avg: 4.9069)\tTop1: 3.125 (avg: 3.375)\tTop5: 9.375 (avg: 12.896)\t\n",
            "Epoch: 28[100/125]\tTime used: 0.297 (avg: 0.295)\tLoss: 4.9645 (avg: 4.8972)\tTop1: 6.250 (avg: 3.422)\tTop5: 9.375 (avg: 13.047)\t\n",
            "Epoch: 28[125/125]\tTime used: 0.282 (avg: 0.296)\tLoss: 4.8361 (avg: 4.8922)\tTop1: 9.375 (avg: 3.563)\tTop5: 17.188 (avg: 13.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.8481\tTop 1 accuracy: 3.150\tTop 5 accuracy: 11.950\n",
            "\n",
            "Training...\n",
            "Epoch: 29[25/125]\tTime used: 0.285 (avg: 0.294)\tLoss: 4.8523 (avg: 4.8549)\tTop1: 3.125 (avg: 3.625)\tTop5: 9.375 (avg: 13.938)\t\n",
            "Epoch: 29[50/125]\tTime used: 0.294 (avg: 0.298)\tLoss: 4.7384 (avg: 4.8488)\tTop1: 4.688 (avg: 3.656)\tTop5: 26.562 (avg: 14.750)\t\n",
            "Epoch: 29[75/125]\tTime used: 0.282 (avg: 0.298)\tLoss: 4.8952 (avg: 4.8531)\tTop1: 3.125 (avg: 3.562)\tTop5: 12.500 (avg: 14.583)\t\n",
            "Epoch: 29[100/125]\tTime used: 0.293 (avg: 0.298)\tLoss: 4.6779 (avg: 4.8495)\tTop1: 3.125 (avg: 3.703)\tTop5: 14.062 (avg: 14.562)\t\n",
            "Epoch: 29[125/125]\tTime used: 0.298 (avg: 0.298)\tLoss: 4.7415 (avg: 4.8426)\tTop1: 3.125 (avg: 3.788)\tTop5: 14.062 (avg: 14.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.7290\tTop 1 accuracy: 3.500\tTop 5 accuracy: 13.300\n",
            "\n",
            "Training...\n",
            "Epoch: 30[25/125]\tTime used: 0.283 (avg: 0.293)\tLoss: 4.6917 (avg: 4.7402)\tTop1: 6.250 (avg: 4.812)\tTop5: 25.000 (avg: 17.375)\t\n",
            "Epoch: 30[50/125]\tTime used: 0.309 (avg: 0.297)\tLoss: 4.6304 (avg: 4.6994)\tTop1: 6.250 (avg: 5.000)\tTop5: 18.750 (avg: 17.781)\t\n",
            "Epoch: 30[75/125]\tTime used: 0.287 (avg: 0.298)\tLoss: 4.6677 (avg: 4.6691)\tTop1: 7.812 (avg: 5.562)\tTop5: 21.875 (avg: 18.938)\t\n",
            "Epoch: 30[100/125]\tTime used: 0.301 (avg: 0.299)\tLoss: 4.8153 (avg: 4.6590)\tTop1: 3.125 (avg: 5.562)\tTop5: 18.750 (avg: 19.094)\t\n",
            "Epoch: 30[125/125]\tTime used: 0.286 (avg: 0.299)\tLoss: 4.7832 (avg: 4.6582)\tTop1: 3.125 (avg: 5.488)\tTop5: 15.625 (avg: 19.038)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5344\tTop 1 accuracy: 4.200\tTop 5 accuracy: 15.850\n",
            "\n",
            "Training...\n",
            "Epoch: 31[25/125]\tTime used: 0.291 (avg: 0.294)\tLoss: 4.6025 (avg: 4.5619)\tTop1: 6.250 (avg: 6.750)\tTop5: 18.750 (avg: 22.125)\t\n",
            "Epoch: 31[50/125]\tTime used: 0.299 (avg: 0.297)\tLoss: 4.8890 (avg: 4.5791)\tTop1: 7.812 (avg: 6.625)\tTop5: 15.625 (avg: 21.875)\t\n",
            "Epoch: 31[75/125]\tTime used: 0.298 (avg: 0.298)\tLoss: 4.5201 (avg: 4.5962)\tTop1: 6.250 (avg: 6.583)\tTop5: 21.875 (avg: 21.250)\t\n",
            "Epoch: 31[100/125]\tTime used: 0.301 (avg: 0.298)\tLoss: 4.4887 (avg: 4.5915)\tTop1: 10.938 (avg: 6.781)\tTop5: 23.438 (avg: 21.000)\t\n",
            "Epoch: 31[125/125]\tTime used: 0.286 (avg: 0.298)\tLoss: 4.9238 (avg: 4.5921)\tTop1: 1.562 (avg: 6.613)\tTop5: 12.500 (avg: 20.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.6476\tTop 1 accuracy: 5.000\tTop 5 accuracy: 15.850\n",
            "\n",
            "Training...\n",
            "Epoch: 32[25/125]\tTime used: 0.291 (avg: 0.296)\tLoss: 4.7824 (avg: 4.6199)\tTop1: 1.562 (avg: 5.938)\tTop5: 15.625 (avg: 19.625)\t\n",
            "Epoch: 32[50/125]\tTime used: 0.303 (avg: 0.299)\tLoss: 4.4175 (avg: 4.5943)\tTop1: 6.250 (avg: 6.375)\tTop5: 25.000 (avg: 20.469)\t\n",
            "Epoch: 32[75/125]\tTime used: 0.286 (avg: 0.300)\tLoss: 4.5687 (avg: 4.5758)\tTop1: 6.250 (avg: 6.667)\tTop5: 23.438 (avg: 20.729)\t\n",
            "Epoch: 32[100/125]\tTime used: 0.314 (avg: 0.300)\tLoss: 4.2448 (avg: 4.5692)\tTop1: 9.375 (avg: 6.656)\tTop5: 29.688 (avg: 20.859)\t\n",
            "Epoch: 32[125/125]\tTime used: 0.286 (avg: 0.300)\tLoss: 4.5372 (avg: 4.5669)\tTop1: 6.250 (avg: 6.563)\tTop5: 26.562 (avg: 20.900)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.5094\tTop 1 accuracy: 5.200\tTop 5 accuracy: 15.750\n",
            "\n",
            "Training...\n",
            "Epoch: 33[25/125]\tTime used: 0.280 (avg: 0.291)\tLoss: 4.6388 (avg: 4.4736)\tTop1: 7.812 (avg: 8.250)\tTop5: 18.750 (avg: 22.625)\t\n",
            "Epoch: 33[50/125]\tTime used: 0.307 (avg: 0.293)\tLoss: 4.6014 (avg: 4.4912)\tTop1: 7.812 (avg: 7.875)\tTop5: 18.750 (avg: 22.344)\t\n",
            "Epoch: 33[75/125]\tTime used: 0.284 (avg: 0.295)\tLoss: 4.5344 (avg: 4.5141)\tTop1: 7.812 (avg: 7.229)\tTop5: 18.750 (avg: 21.646)\t\n",
            "Epoch: 33[100/125]\tTime used: 0.298 (avg: 0.296)\tLoss: 4.4138 (avg: 4.5175)\tTop1: 4.688 (avg: 7.000)\tTop5: 28.125 (avg: 21.734)\t\n",
            "Epoch: 33[125/125]\tTime used: 0.278 (avg: 0.297)\tLoss: 4.7035 (avg: 4.5235)\tTop1: 6.250 (avg: 6.763)\tTop5: 21.875 (avg: 21.675)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4078\tTop 1 accuracy: 5.300\tTop 5 accuracy: 17.350\n",
            "\n",
            "Training...\n",
            "Epoch: 34[25/125]\tTime used: 0.287 (avg: 0.294)\tLoss: 4.4886 (avg: 4.5026)\tTop1: 3.125 (avg: 7.125)\tTop5: 18.750 (avg: 21.562)\t\n",
            "Epoch: 34[50/125]\tTime used: 0.294 (avg: 0.295)\tLoss: 4.3818 (avg: 4.4884)\tTop1: 10.938 (avg: 7.094)\tTop5: 26.562 (avg: 22.500)\t\n",
            "Epoch: 34[75/125]\tTime used: 0.285 (avg: 0.295)\tLoss: 4.4635 (avg: 4.4923)\tTop1: 6.250 (avg: 6.958)\tTop5: 21.875 (avg: 22.458)\t\n",
            "Epoch: 34[100/125]\tTime used: 0.300 (avg: 0.295)\tLoss: 4.3264 (avg: 4.4994)\tTop1: 6.250 (avg: 6.781)\tTop5: 25.000 (avg: 21.953)\t\n",
            "Epoch: 34[125/125]\tTime used: 0.295 (avg: 0.296)\tLoss: 4.2707 (avg: 4.4912)\tTop1: 12.500 (avg: 7.150)\tTop5: 32.812 (avg: 22.313)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4194\tTop 1 accuracy: 5.400\tTop 5 accuracy: 18.550\n",
            "\n",
            "Training...\n",
            "Epoch: 35[25/125]\tTime used: 0.288 (avg: 0.288)\tLoss: 4.5091 (avg: 4.4697)\tTop1: 6.250 (avg: 6.625)\tTop5: 23.438 (avg: 22.750)\t\n",
            "Epoch: 35[50/125]\tTime used: 0.304 (avg: 0.294)\tLoss: 4.4113 (avg: 4.4509)\tTop1: 6.250 (avg: 6.875)\tTop5: 25.000 (avg: 22.688)\t\n",
            "Epoch: 35[75/125]\tTime used: 0.292 (avg: 0.296)\tLoss: 4.3519 (avg: 4.4681)\tTop1: 6.250 (avg: 6.979)\tTop5: 15.625 (avg: 22.438)\t\n",
            "Epoch: 35[100/125]\tTime used: 0.295 (avg: 0.296)\tLoss: 4.5954 (avg: 4.4676)\tTop1: 6.250 (avg: 7.281)\tTop5: 17.188 (avg: 22.141)\t\n",
            "Epoch: 35[125/125]\tTime used: 0.280 (avg: 0.297)\tLoss: 4.4489 (avg: 4.4626)\tTop1: 6.250 (avg: 7.213)\tTop5: 25.000 (avg: 22.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4945\tTop 1 accuracy: 6.150\tTop 5 accuracy: 18.500\n",
            "\n",
            "Training...\n",
            "Epoch: 36[25/125]\tTime used: 0.293 (avg: 0.291)\tLoss: 4.3717 (avg: 4.3669)\tTop1: 6.250 (avg: 8.562)\tTop5: 31.250 (avg: 26.500)\t\n",
            "Epoch: 36[50/125]\tTime used: 0.301 (avg: 0.296)\tLoss: 4.5626 (avg: 4.3987)\tTop1: 3.125 (avg: 8.000)\tTop5: 17.188 (avg: 24.375)\t\n",
            "Epoch: 36[75/125]\tTime used: 0.288 (avg: 0.297)\tLoss: 4.5364 (avg: 4.4181)\tTop1: 3.125 (avg: 7.500)\tTop5: 18.750 (avg: 23.604)\t\n",
            "Epoch: 36[100/125]\tTime used: 0.302 (avg: 0.299)\tLoss: 4.3661 (avg: 4.4288)\tTop1: 6.250 (avg: 7.156)\tTop5: 25.000 (avg: 23.078)\t\n",
            "Epoch: 36[125/125]\tTime used: 0.295 (avg: 0.299)\tLoss: 4.4940 (avg: 4.4278)\tTop1: 6.250 (avg: 7.225)\tTop5: 18.750 (avg: 23.063)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4020\tTop 1 accuracy: 6.150\tTop 5 accuracy: 18.400\n",
            "\n",
            "Training...\n",
            "Epoch: 37[25/125]\tTime used: 0.283 (avg: 0.293)\tLoss: 4.2835 (avg: 4.3922)\tTop1: 9.375 (avg: 8.875)\tTop5: 25.000 (avg: 23.812)\t\n",
            "Epoch: 37[50/125]\tTime used: 0.308 (avg: 0.297)\tLoss: 4.5271 (avg: 4.3986)\tTop1: 9.375 (avg: 8.438)\tTop5: 25.000 (avg: 23.531)\t\n",
            "Epoch: 37[75/125]\tTime used: 0.281 (avg: 0.298)\tLoss: 4.5718 (avg: 4.4148)\tTop1: 10.938 (avg: 8.042)\tTop5: 28.125 (avg: 23.167)\t\n",
            "Epoch: 37[100/125]\tTime used: 0.302 (avg: 0.298)\tLoss: 4.2742 (avg: 4.4193)\tTop1: 10.938 (avg: 8.094)\tTop5: 26.562 (avg: 23.109)\t\n",
            "Epoch: 37[125/125]\tTime used: 0.301 (avg: 0.299)\tLoss: 4.4517 (avg: 4.4208)\tTop1: 4.688 (avg: 8.062)\tTop5: 28.125 (avg: 23.250)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3195\tTop 1 accuracy: 5.650\tTop 5 accuracy: 20.100\n",
            "\n",
            "Training...\n",
            "Epoch: 38[25/125]\tTime used: 0.286 (avg: 0.293)\tLoss: 4.3450 (avg: 4.3475)\tTop1: 7.812 (avg: 8.250)\tTop5: 25.000 (avg: 26.625)\t\n",
            "Epoch: 38[50/125]\tTime used: 0.306 (avg: 0.298)\tLoss: 4.3492 (avg: 4.3655)\tTop1: 9.375 (avg: 7.906)\tTop5: 26.562 (avg: 25.500)\t\n",
            "Epoch: 38[75/125]\tTime used: 0.300 (avg: 0.299)\tLoss: 4.4733 (avg: 4.3918)\tTop1: 12.500 (avg: 7.688)\tTop5: 20.312 (avg: 24.125)\t\n",
            "Epoch: 38[100/125]\tTime used: 0.295 (avg: 0.299)\tLoss: 4.2623 (avg: 4.3875)\tTop1: 6.250 (avg: 7.766)\tTop5: 25.000 (avg: 24.109)\t\n",
            "Epoch: 38[125/125]\tTime used: 0.285 (avg: 0.299)\tLoss: 4.4794 (avg: 4.3899)\tTop1: 3.125 (avg: 7.775)\tTop5: 15.625 (avg: 24.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3738\tTop 1 accuracy: 6.700\tTop 5 accuracy: 20.200\n",
            "\n",
            "Training...\n",
            "Epoch: 39[25/125]\tTime used: 0.280 (avg: 0.293)\tLoss: 4.3969 (avg: 4.3360)\tTop1: 9.375 (avg: 9.250)\tTop5: 28.125 (avg: 26.188)\t\n",
            "Epoch: 39[50/125]\tTime used: 0.295 (avg: 0.295)\tLoss: 4.2827 (avg: 4.3476)\tTop1: 7.812 (avg: 8.750)\tTop5: 31.250 (avg: 26.438)\t\n",
            "Epoch: 39[75/125]\tTime used: 0.283 (avg: 0.296)\tLoss: 4.0924 (avg: 4.3429)\tTop1: 14.062 (avg: 8.708)\tTop5: 32.812 (avg: 26.146)\t\n",
            "Epoch: 39[100/125]\tTime used: 0.313 (avg: 0.297)\tLoss: 4.0136 (avg: 4.3476)\tTop1: 10.938 (avg: 8.641)\tTop5: 32.812 (avg: 25.641)\t\n",
            "Epoch: 39[125/125]\tTime used: 0.286 (avg: 0.298)\tLoss: 4.5892 (avg: 4.3577)\tTop1: 12.500 (avg: 8.538)\tTop5: 20.312 (avg: 25.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3850\tTop 1 accuracy: 6.700\tTop 5 accuracy: 20.450\n",
            "\n",
            "Training...\n",
            "Epoch: 40[25/125]\tTime used: 0.292 (avg: 0.293)\tLoss: 4.4632 (avg: 4.3051)\tTop1: 4.688 (avg: 7.812)\tTop5: 20.312 (avg: 26.688)\t\n",
            "Epoch: 40[50/125]\tTime used: 0.297 (avg: 0.297)\tLoss: 4.7222 (avg: 4.3239)\tTop1: 6.250 (avg: 8.219)\tTop5: 23.438 (avg: 26.281)\t\n",
            "Epoch: 40[75/125]\tTime used: 0.277 (avg: 0.297)\tLoss: 4.2635 (avg: 4.3317)\tTop1: 10.938 (avg: 8.479)\tTop5: 32.812 (avg: 25.938)\t\n",
            "Epoch: 40[100/125]\tTime used: 0.299 (avg: 0.297)\tLoss: 4.1325 (avg: 4.3318)\tTop1: 7.812 (avg: 8.375)\tTop5: 29.688 (avg: 25.750)\t\n",
            "Epoch: 40[125/125]\tTime used: 0.293 (avg: 0.297)\tLoss: 3.8948 (avg: 4.3379)\tTop1: 10.938 (avg: 8.163)\tTop5: 31.250 (avg: 25.375)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1990\tTop 1 accuracy: 7.050\tTop 5 accuracy: 21.600\n",
            "\n",
            "Training...\n",
            "Epoch: 41[25/125]\tTime used: 0.285 (avg: 0.294)\tLoss: 4.2918 (avg: 4.2723)\tTop1: 10.938 (avg: 8.188)\tTop5: 31.250 (avg: 26.250)\t\n",
            "Epoch: 41[50/125]\tTime used: 0.298 (avg: 0.298)\tLoss: 4.5155 (avg: 4.3019)\tTop1: 6.250 (avg: 8.094)\tTop5: 14.062 (avg: 24.781)\t\n",
            "Epoch: 41[75/125]\tTime used: 0.283 (avg: 0.299)\tLoss: 4.1534 (avg: 4.2974)\tTop1: 14.062 (avg: 8.625)\tTop5: 34.375 (avg: 25.875)\t\n",
            "Epoch: 41[100/125]\tTime used: 0.296 (avg: 0.298)\tLoss: 4.3502 (avg: 4.2996)\tTop1: 12.500 (avg: 8.516)\tTop5: 28.125 (avg: 25.891)\t\n",
            "Epoch: 41[125/125]\tTime used: 0.277 (avg: 0.297)\tLoss: 4.2030 (avg: 4.2878)\tTop1: 12.500 (avg: 8.613)\tTop5: 37.500 (avg: 26.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3932\tTop 1 accuracy: 6.550\tTop 5 accuracy: 19.950\n",
            "\n",
            "Training...\n",
            "Epoch: 42[25/125]\tTime used: 0.292 (avg: 0.292)\tLoss: 4.3940 (avg: 4.2442)\tTop1: 10.938 (avg: 10.188)\tTop5: 25.000 (avg: 27.250)\t\n",
            "Epoch: 42[50/125]\tTime used: 0.293 (avg: 0.295)\tLoss: 4.3562 (avg: 4.2511)\tTop1: 1.562 (avg: 10.062)\tTop5: 23.438 (avg: 27.312)\t\n",
            "Epoch: 42[75/125]\tTime used: 0.285 (avg: 0.297)\tLoss: 4.4529 (avg: 4.2797)\tTop1: 7.812 (avg: 9.521)\tTop5: 23.438 (avg: 26.417)\t\n",
            "Epoch: 42[100/125]\tTime used: 0.305 (avg: 0.297)\tLoss: 4.4480 (avg: 4.2808)\tTop1: 7.812 (avg: 9.422)\tTop5: 18.750 (avg: 26.719)\t\n",
            "Epoch: 42[125/125]\tTime used: 0.278 (avg: 0.297)\tLoss: 4.1856 (avg: 4.2795)\tTop1: 9.375 (avg: 9.400)\tTop5: 31.250 (avg: 27.113)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2225\tTop 1 accuracy: 7.600\tTop 5 accuracy: 22.050\n",
            "\n",
            "Training...\n",
            "Epoch: 43[25/125]\tTime used: 0.267 (avg: 0.275)\tLoss: 4.4741 (avg: 4.2691)\tTop1: 4.688 (avg: 8.938)\tTop5: 15.625 (avg: 25.375)\t\n",
            "Epoch: 43[50/125]\tTime used: 0.279 (avg: 0.278)\tLoss: 4.2497 (avg: 4.2715)\tTop1: 6.250 (avg: 8.812)\tTop5: 23.438 (avg: 25.469)\t\n",
            "Epoch: 43[75/125]\tTime used: 0.268 (avg: 0.278)\tLoss: 4.4019 (avg: 4.2692)\tTop1: 7.812 (avg: 8.688)\tTop5: 21.875 (avg: 25.979)\t\n",
            "Epoch: 43[100/125]\tTime used: 0.283 (avg: 0.279)\tLoss: 4.5202 (avg: 4.2679)\tTop1: 6.250 (avg: 8.891)\tTop5: 25.000 (avg: 26.516)\t\n",
            "Epoch: 43[125/125]\tTime used: 0.275 (avg: 0.282)\tLoss: 4.5370 (avg: 4.2637)\tTop1: 4.688 (avg: 9.000)\tTop5: 20.312 (avg: 26.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3164\tTop 1 accuracy: 7.050\tTop 5 accuracy: 21.250\n",
            "\n",
            "Training...\n",
            "Epoch: 44[25/125]\tTime used: 0.277 (avg: 0.286)\tLoss: 4.2555 (avg: 4.1840)\tTop1: 12.500 (avg: 9.625)\tTop5: 31.250 (avg: 28.562)\t\n",
            "Epoch: 44[50/125]\tTime used: 0.289 (avg: 0.289)\tLoss: 4.3978 (avg: 4.2423)\tTop1: 10.938 (avg: 8.844)\tTop5: 25.000 (avg: 27.000)\t\n",
            "Epoch: 44[75/125]\tTime used: 0.280 (avg: 0.291)\tLoss: 4.2540 (avg: 4.2504)\tTop1: 12.500 (avg: 9.271)\tTop5: 26.562 (avg: 26.938)\t\n",
            "Epoch: 44[100/125]\tTime used: 0.299 (avg: 0.292)\tLoss: 4.4251 (avg: 4.2472)\tTop1: 4.688 (avg: 9.141)\tTop5: 21.875 (avg: 27.203)\t\n",
            "Epoch: 44[125/125]\tTime used: 0.277 (avg: 0.292)\tLoss: 4.2008 (avg: 4.2373)\tTop1: 14.062 (avg: 9.225)\tTop5: 31.250 (avg: 27.588)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3752\tTop 1 accuracy: 7.550\tTop 5 accuracy: 23.700\n",
            "\n",
            "Training...\n",
            "Epoch: 45[25/125]\tTime used: 0.283 (avg: 0.287)\tLoss: 4.1234 (avg: 4.2365)\tTop1: 9.375 (avg: 9.000)\tTop5: 26.562 (avg: 28.062)\t\n",
            "Epoch: 45[50/125]\tTime used: 0.290 (avg: 0.290)\tLoss: 4.4635 (avg: 4.2399)\tTop1: 6.250 (avg: 9.312)\tTop5: 31.250 (avg: 27.750)\t\n",
            "Epoch: 45[75/125]\tTime used: 0.287 (avg: 0.291)\tLoss: 4.0842 (avg: 4.2538)\tTop1: 14.062 (avg: 9.354)\tTop5: 29.688 (avg: 27.250)\t\n",
            "Epoch: 45[100/125]\tTime used: 0.294 (avg: 0.292)\tLoss: 4.0923 (avg: 4.2328)\tTop1: 15.625 (avg: 9.500)\tTop5: 32.812 (avg: 27.641)\t\n",
            "Epoch: 45[125/125]\tTime used: 0.291 (avg: 0.292)\tLoss: 4.2816 (avg: 4.2349)\tTop1: 6.250 (avg: 9.688)\tTop5: 21.875 (avg: 27.550)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3030\tTop 1 accuracy: 7.300\tTop 5 accuracy: 23.300\n",
            "\n",
            "Training...\n",
            "Epoch: 46[25/125]\tTime used: 0.283 (avg: 0.287)\tLoss: 3.9351 (avg: 4.1715)\tTop1: 10.938 (avg: 10.750)\tTop5: 34.375 (avg: 30.125)\t\n",
            "Epoch: 46[50/125]\tTime used: 0.290 (avg: 0.290)\tLoss: 4.1489 (avg: 4.2010)\tTop1: 12.500 (avg: 10.344)\tTop5: 26.562 (avg: 29.250)\t\n",
            "Epoch: 46[75/125]\tTime used: 0.279 (avg: 0.291)\tLoss: 4.0499 (avg: 4.1895)\tTop1: 10.938 (avg: 10.438)\tTop5: 37.500 (avg: 29.500)\t\n",
            "Epoch: 46[100/125]\tTime used: 0.292 (avg: 0.292)\tLoss: 4.2623 (avg: 4.1924)\tTop1: 14.062 (avg: 10.375)\tTop5: 29.688 (avg: 29.172)\t\n",
            "Epoch: 46[125/125]\tTime used: 0.276 (avg: 0.292)\tLoss: 4.1092 (avg: 4.1891)\tTop1: 7.812 (avg: 10.200)\tTop5: 25.000 (avg: 29.163)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2183\tTop 1 accuracy: 8.450\tTop 5 accuracy: 23.650\n",
            "\n",
            "Training...\n",
            "Epoch: 47[25/125]\tTime used: 0.281 (avg: 0.287)\tLoss: 4.2081 (avg: 4.1278)\tTop1: 3.125 (avg: 10.250)\tTop5: 26.562 (avg: 30.188)\t\n",
            "Epoch: 47[50/125]\tTime used: 0.290 (avg: 0.288)\tLoss: 4.3594 (avg: 4.1385)\tTop1: 9.375 (avg: 10.281)\tTop5: 25.000 (avg: 30.656)\t\n",
            "Epoch: 47[75/125]\tTime used: 0.280 (avg: 0.289)\tLoss: 3.7710 (avg: 4.1416)\tTop1: 17.188 (avg: 10.292)\tTop5: 37.500 (avg: 30.104)\t\n",
            "Epoch: 47[100/125]\tTime used: 0.293 (avg: 0.291)\tLoss: 4.2600 (avg: 4.1708)\tTop1: 7.812 (avg: 10.172)\tTop5: 20.312 (avg: 29.469)\t\n",
            "Epoch: 47[125/125]\tTime used: 0.277 (avg: 0.291)\tLoss: 4.0723 (avg: 4.1838)\tTop1: 6.250 (avg: 10.075)\tTop5: 32.812 (avg: 29.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4088\tTop 1 accuracy: 8.000\tTop 5 accuracy: 23.050\n",
            "\n",
            "Training...\n",
            "Epoch: 48[25/125]\tTime used: 0.279 (avg: 0.286)\tLoss: 4.1073 (avg: 4.1415)\tTop1: 9.375 (avg: 10.625)\tTop5: 26.562 (avg: 31.500)\t\n",
            "Epoch: 48[50/125]\tTime used: 0.290 (avg: 0.289)\tLoss: 4.0962 (avg: 4.1450)\tTop1: 9.375 (avg: 10.188)\tTop5: 37.500 (avg: 30.625)\t\n",
            "Epoch: 48[75/125]\tTime used: 0.277 (avg: 0.290)\tLoss: 4.3263 (avg: 4.1322)\tTop1: 10.938 (avg: 10.688)\tTop5: 25.000 (avg: 30.500)\t\n",
            "Epoch: 48[100/125]\tTime used: 0.291 (avg: 0.290)\tLoss: 4.2682 (avg: 4.1477)\tTop1: 14.062 (avg: 10.875)\tTop5: 34.375 (avg: 30.297)\t\n",
            "Epoch: 48[125/125]\tTime used: 0.281 (avg: 0.290)\tLoss: 4.4024 (avg: 4.1469)\tTop1: 7.812 (avg: 10.875)\tTop5: 25.000 (avg: 30.238)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3035\tTop 1 accuracy: 8.550\tTop 5 accuracy: 24.850\n",
            "\n",
            "Training...\n",
            "Epoch: 49[25/125]\tTime used: 0.278 (avg: 0.286)\tLoss: 4.3169 (avg: 4.0739)\tTop1: 14.062 (avg: 12.438)\tTop5: 31.250 (avg: 32.062)\t\n",
            "Epoch: 49[50/125]\tTime used: 0.297 (avg: 0.290)\tLoss: 4.4285 (avg: 4.0974)\tTop1: 9.375 (avg: 11.875)\tTop5: 29.688 (avg: 31.500)\t\n",
            "Epoch: 49[75/125]\tTime used: 0.279 (avg: 0.291)\tLoss: 4.1426 (avg: 4.1211)\tTop1: 9.375 (avg: 11.104)\tTop5: 29.688 (avg: 30.542)\t\n",
            "Epoch: 49[100/125]\tTime used: 0.296 (avg: 0.292)\tLoss: 4.1474 (avg: 4.1399)\tTop1: 6.250 (avg: 10.719)\tTop5: 25.000 (avg: 29.734)\t\n",
            "Epoch: 49[125/125]\tTime used: 0.279 (avg: 0.293)\tLoss: 4.1795 (avg: 4.1354)\tTop1: 7.812 (avg: 10.650)\tTop5: 29.688 (avg: 29.750)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1682\tTop 1 accuracy: 8.700\tTop 5 accuracy: 24.400\n",
            "\n",
            "Training...\n",
            "Epoch: 50[25/125]\tTime used: 0.288 (avg: 0.288)\tLoss: 4.3864 (avg: 4.1075)\tTop1: 6.250 (avg: 11.312)\tTop5: 21.875 (avg: 30.125)\t\n",
            "Epoch: 50[50/125]\tTime used: 0.295 (avg: 0.292)\tLoss: 4.0977 (avg: 4.1270)\tTop1: 7.812 (avg: 10.312)\tTop5: 26.562 (avg: 29.656)\t\n",
            "Epoch: 50[75/125]\tTime used: 0.276 (avg: 0.293)\tLoss: 4.0507 (avg: 4.1240)\tTop1: 12.500 (avg: 10.729)\tTop5: 31.250 (avg: 30.167)\t\n",
            "Epoch: 50[100/125]\tTime used: 0.289 (avg: 0.291)\tLoss: 4.0826 (avg: 4.1205)\tTop1: 7.812 (avg: 11.016)\tTop5: 31.250 (avg: 30.484)\t\n",
            "Epoch: 50[125/125]\tTime used: 0.270 (avg: 0.290)\tLoss: 4.3016 (avg: 4.1331)\tTop1: 12.500 (avg: 10.788)\tTop5: 23.438 (avg: 30.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2870\tTop 1 accuracy: 7.550\tTop 5 accuracy: 22.850\n",
            "\n",
            "Training...\n",
            "Epoch: 51[25/125]\tTime used: 0.276 (avg: 0.274)\tLoss: 4.1119 (avg: 4.0914)\tTop1: 10.938 (avg: 11.375)\tTop5: 31.250 (avg: 30.375)\t\n",
            "Epoch: 51[50/125]\tTime used: 0.282 (avg: 0.279)\tLoss: 4.1020 (avg: 4.1152)\tTop1: 17.188 (avg: 11.438)\tTop5: 34.375 (avg: 30.188)\t\n",
            "Epoch: 51[75/125]\tTime used: 0.272 (avg: 0.280)\tLoss: 3.7344 (avg: 4.1057)\tTop1: 18.750 (avg: 11.875)\tTop5: 37.500 (avg: 30.479)\t\n",
            "Epoch: 51[100/125]\tTime used: 0.279 (avg: 0.281)\tLoss: 4.2486 (avg: 4.1159)\tTop1: 10.938 (avg: 11.344)\tTop5: 23.438 (avg: 30.156)\t\n",
            "Epoch: 51[125/125]\tTime used: 0.264 (avg: 0.281)\tLoss: 4.0369 (avg: 4.1144)\tTop1: 17.188 (avg: 11.413)\tTop5: 37.500 (avg: 30.513)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2704\tTop 1 accuracy: 8.300\tTop 5 accuracy: 24.850\n",
            "\n",
            "Training...\n",
            "Epoch: 52[25/125]\tTime used: 0.270 (avg: 0.274)\tLoss: 4.0610 (avg: 4.0737)\tTop1: 14.062 (avg: 11.938)\tTop5: 32.812 (avg: 32.938)\t\n",
            "Epoch: 52[50/125]\tTime used: 0.290 (avg: 0.278)\tLoss: 4.1116 (avg: 4.1062)\tTop1: 7.812 (avg: 11.312)\tTop5: 29.688 (avg: 31.156)\t\n",
            "Epoch: 52[75/125]\tTime used: 0.273 (avg: 0.279)\tLoss: 4.1175 (avg: 4.1136)\tTop1: 15.625 (avg: 11.292)\tTop5: 35.938 (avg: 30.792)\t\n",
            "Epoch: 52[100/125]\tTime used: 0.280 (avg: 0.280)\tLoss: 4.1633 (avg: 4.0934)\tTop1: 12.500 (avg: 11.984)\tTop5: 28.125 (avg: 30.938)\t\n",
            "Epoch: 52[125/125]\tTime used: 0.269 (avg: 0.280)\tLoss: 4.1276 (avg: 4.1050)\tTop1: 6.250 (avg: 11.775)\tTop5: 28.125 (avg: 30.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.4400\tTop 1 accuracy: 7.750\tTop 5 accuracy: 25.100\n",
            "\n",
            "Training...\n",
            "Epoch: 53[25/125]\tTime used: 0.272 (avg: 0.276)\tLoss: 3.9258 (avg: 4.0329)\tTop1: 17.188 (avg: 12.188)\tTop5: 35.938 (avg: 32.375)\t\n",
            "Epoch: 53[50/125]\tTime used: 0.288 (avg: 0.278)\tLoss: 3.7566 (avg: 4.0268)\tTop1: 17.188 (avg: 12.500)\tTop5: 43.750 (avg: 32.188)\t\n",
            "Epoch: 53[75/125]\tTime used: 0.271 (avg: 0.280)\tLoss: 3.9696 (avg: 4.0273)\tTop1: 9.375 (avg: 12.417)\tTop5: 37.500 (avg: 32.333)\t\n",
            "Epoch: 53[100/125]\tTime used: 0.280 (avg: 0.280)\tLoss: 4.0017 (avg: 4.0506)\tTop1: 14.062 (avg: 12.188)\tTop5: 34.375 (avg: 32.172)\t\n",
            "Epoch: 53[125/125]\tTime used: 0.265 (avg: 0.280)\tLoss: 4.0404 (avg: 4.0617)\tTop1: 4.688 (avg: 12.000)\tTop5: 26.562 (avg: 31.688)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1156\tTop 1 accuracy: 9.000\tTop 5 accuracy: 26.050\n",
            "\n",
            "Training...\n",
            "Epoch: 54[25/125]\tTime used: 0.272 (avg: 0.276)\tLoss: 4.2413 (avg: 4.0455)\tTop1: 14.062 (avg: 13.062)\tTop5: 28.125 (avg: 31.688)\t\n",
            "Epoch: 54[50/125]\tTime used: 0.275 (avg: 0.280)\tLoss: 3.9248 (avg: 4.0379)\tTop1: 10.938 (avg: 11.938)\tTop5: 35.938 (avg: 32.875)\t\n",
            "Epoch: 54[75/125]\tTime used: 0.270 (avg: 0.280)\tLoss: 3.8867 (avg: 4.0379)\tTop1: 20.312 (avg: 12.083)\tTop5: 37.500 (avg: 32.750)\t\n",
            "Epoch: 54[100/125]\tTime used: 0.286 (avg: 0.281)\tLoss: 4.4161 (avg: 4.0623)\tTop1: 9.375 (avg: 11.594)\tTop5: 29.688 (avg: 32.094)\t\n",
            "Epoch: 54[125/125]\tTime used: 0.264 (avg: 0.281)\tLoss: 4.4012 (avg: 4.0659)\tTop1: 10.938 (avg: 11.750)\tTop5: 29.688 (avg: 32.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.2241\tTop 1 accuracy: 8.950\tTop 5 accuracy: 26.250\n",
            "\n",
            "Training...\n",
            "Epoch: 55[25/125]\tTime used: 0.274 (avg: 0.274)\tLoss: 3.9322 (avg: 4.0274)\tTop1: 17.188 (avg: 11.875)\tTop5: 31.250 (avg: 32.562)\t\n",
            "Epoch: 55[50/125]\tTime used: 0.278 (avg: 0.277)\tLoss: 4.2096 (avg: 4.0464)\tTop1: 9.375 (avg: 11.594)\tTop5: 32.812 (avg: 33.250)\t\n",
            "Epoch: 55[75/125]\tTime used: 0.267 (avg: 0.278)\tLoss: 4.1742 (avg: 4.0360)\tTop1: 9.375 (avg: 12.021)\tTop5: 29.688 (avg: 33.271)\t\n",
            "Epoch: 55[100/125]\tTime used: 0.287 (avg: 0.280)\tLoss: 3.9680 (avg: 4.0446)\tTop1: 9.375 (avg: 11.938)\tTop5: 35.938 (avg: 33.125)\t\n",
            "Epoch: 55[125/125]\tTime used: 0.276 (avg: 0.281)\tLoss: 3.9392 (avg: 4.0420)\tTop1: 9.375 (avg: 11.988)\tTop5: 32.812 (avg: 33.363)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0837\tTop 1 accuracy: 9.900\tTop 5 accuracy: 26.700\n",
            "\n",
            "Training...\n",
            "Epoch: 56[25/125]\tTime used: 0.264 (avg: 0.274)\tLoss: 4.0244 (avg: 4.0344)\tTop1: 6.250 (avg: 13.000)\tTop5: 34.375 (avg: 33.375)\t\n",
            "Epoch: 56[50/125]\tTime used: 0.284 (avg: 0.278)\tLoss: 3.8156 (avg: 4.0074)\tTop1: 17.188 (avg: 13.438)\tTop5: 43.750 (avg: 33.406)\t\n",
            "Epoch: 56[75/125]\tTime used: 0.270 (avg: 0.280)\tLoss: 3.7896 (avg: 4.0143)\tTop1: 10.938 (avg: 13.438)\tTop5: 46.875 (avg: 33.521)\t\n",
            "Epoch: 56[100/125]\tTime used: 0.278 (avg: 0.281)\tLoss: 3.9586 (avg: 4.0223)\tTop1: 7.812 (avg: 12.906)\tTop5: 35.938 (avg: 33.188)\t\n",
            "Epoch: 56[125/125]\tTime used: 0.266 (avg: 0.281)\tLoss: 3.9381 (avg: 4.0304)\tTop1: 12.500 (avg: 12.713)\tTop5: 31.250 (avg: 33.100)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.1935\tTop 1 accuracy: 9.100\tTop 5 accuracy: 25.600\n",
            "\n",
            "Training...\n",
            "Epoch: 57[25/125]\tTime used: 0.263 (avg: 0.275)\tLoss: 4.0308 (avg: 3.9487)\tTop1: 15.625 (avg: 13.000)\tTop5: 31.250 (avg: 35.625)\t\n",
            "Epoch: 57[50/125]\tTime used: 0.279 (avg: 0.280)\tLoss: 3.9112 (avg: 3.9782)\tTop1: 17.188 (avg: 12.469)\tTop5: 31.250 (avg: 34.500)\t\n",
            "Epoch: 57[75/125]\tTime used: 0.281 (avg: 0.282)\tLoss: 3.9989 (avg: 3.9997)\tTop1: 6.250 (avg: 12.208)\tTop5: 34.375 (avg: 33.729)\t\n",
            "Epoch: 57[100/125]\tTime used: 0.291 (avg: 0.284)\tLoss: 3.8683 (avg: 4.0080)\tTop1: 14.062 (avg: 12.062)\tTop5: 35.938 (avg: 33.625)\t\n",
            "Epoch: 57[125/125]\tTime used: 0.279 (avg: 0.284)\tLoss: 3.8913 (avg: 4.0132)\tTop1: 12.500 (avg: 12.063)\tTop5: 35.938 (avg: 33.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3364\tTop 1 accuracy: 10.900\tTop 5 accuracy: 27.750\n",
            "\n",
            "Training...\n",
            "Epoch: 58[25/125]\tTime used: 0.264 (avg: 0.276)\tLoss: 3.9523 (avg: 3.9699)\tTop1: 12.500 (avg: 13.625)\tTop5: 35.938 (avg: 33.875)\t\n",
            "Epoch: 58[50/125]\tTime used: 0.276 (avg: 0.278)\tLoss: 4.0149 (avg: 3.9878)\tTop1: 7.812 (avg: 12.688)\tTop5: 28.125 (avg: 33.625)\t\n",
            "Epoch: 58[75/125]\tTime used: 0.267 (avg: 0.279)\tLoss: 4.0303 (avg: 3.9828)\tTop1: 9.375 (avg: 12.896)\tTop5: 26.562 (avg: 33.896)\t\n",
            "Epoch: 58[100/125]\tTime used: 0.278 (avg: 0.280)\tLoss: 3.8361 (avg: 3.9867)\tTop1: 7.812 (avg: 12.984)\tTop5: 37.500 (avg: 33.781)\t\n",
            "Epoch: 58[125/125]\tTime used: 0.267 (avg: 0.280)\tLoss: 3.7467 (avg: 3.9972)\tTop1: 21.875 (avg: 12.800)\tTop5: 46.875 (avg: 33.613)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.8591\tTop 1 accuracy: 10.300\tTop 5 accuracy: 27.500\n",
            "\n",
            "Training...\n",
            "Epoch: 59[25/125]\tTime used: 0.261 (avg: 0.271)\tLoss: 3.8978 (avg: 3.9997)\tTop1: 15.625 (avg: 13.125)\tTop5: 37.500 (avg: 34.688)\t\n",
            "Epoch: 59[50/125]\tTime used: 0.274 (avg: 0.275)\tLoss: 3.8330 (avg: 3.9893)\tTop1: 18.750 (avg: 13.375)\tTop5: 34.375 (avg: 34.594)\t\n",
            "Epoch: 59[75/125]\tTime used: 0.264 (avg: 0.277)\tLoss: 3.9807 (avg: 3.9763)\tTop1: 14.062 (avg: 13.229)\tTop5: 37.500 (avg: 34.667)\t\n",
            "Epoch: 59[100/125]\tTime used: 0.275 (avg: 0.278)\tLoss: 3.8770 (avg: 3.9629)\tTop1: 23.438 (avg: 13.406)\tTop5: 42.188 (avg: 34.875)\t\n",
            "Epoch: 59[125/125]\tTime used: 0.262 (avg: 0.278)\tLoss: 4.0699 (avg: 3.9734)\tTop1: 12.500 (avg: 13.200)\tTop5: 31.250 (avg: 34.913)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.3915\tTop 1 accuracy: 8.000\tTop 5 accuracy: 25.300\n",
            "\n",
            "Training...\n",
            "Epoch: 60[25/125]\tTime used: 0.272 (avg: 0.273)\tLoss: 3.7141 (avg: 3.8034)\tTop1: 17.188 (avg: 14.375)\tTop5: 35.938 (avg: 38.312)\t\n",
            "Epoch: 60[50/125]\tTime used: 0.279 (avg: 0.277)\tLoss: 3.7846 (avg: 3.8370)\tTop1: 15.625 (avg: 14.281)\tTop5: 40.625 (avg: 38.188)\t\n",
            "Epoch: 60[75/125]\tTime used: 0.266 (avg: 0.277)\tLoss: 3.6489 (avg: 3.8516)\tTop1: 20.312 (avg: 14.938)\tTop5: 42.188 (avg: 37.438)\t\n",
            "Epoch: 60[100/125]\tTime used: 0.287 (avg: 0.278)\tLoss: 4.0587 (avg: 3.8521)\tTop1: 10.938 (avg: 15.031)\tTop5: 32.812 (avg: 37.250)\t\n",
            "Epoch: 60[125/125]\tTime used: 0.264 (avg: 0.278)\tLoss: 3.6432 (avg: 3.8401)\tTop1: 23.438 (avg: 15.350)\tTop5: 48.438 (avg: 37.713)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0606\tTop 1 accuracy: 10.850\tTop 5 accuracy: 28.800\n",
            "\n",
            "Training...\n",
            "Epoch: 61[25/125]\tTime used: 0.278 (avg: 0.276)\tLoss: 3.9423 (avg: 3.8091)\tTop1: 21.875 (avg: 16.000)\tTop5: 32.812 (avg: 38.312)\t\n",
            "Epoch: 61[50/125]\tTime used: 0.278 (avg: 0.281)\tLoss: 3.7221 (avg: 3.8176)\tTop1: 21.875 (avg: 15.531)\tTop5: 39.062 (avg: 38.031)\t\n",
            "Epoch: 61[75/125]\tTime used: 0.269 (avg: 0.280)\tLoss: 3.7576 (avg: 3.7995)\tTop1: 20.312 (avg: 16.583)\tTop5: 35.938 (avg: 38.708)\t\n",
            "Epoch: 61[100/125]\tTime used: 0.285 (avg: 0.280)\tLoss: 3.5749 (avg: 3.7905)\tTop1: 28.125 (avg: 16.453)\tTop5: 45.312 (avg: 38.922)\t\n",
            "Epoch: 61[125/125]\tTime used: 0.266 (avg: 0.280)\tLoss: 3.8134 (avg: 3.7967)\tTop1: 18.750 (avg: 16.500)\tTop5: 35.938 (avg: 38.875)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0241\tTop 1 accuracy: 10.500\tTop 5 accuracy: 30.150\n",
            "\n",
            "Training...\n",
            "Epoch: 62[25/125]\tTime used: 0.277 (avg: 0.275)\tLoss: 3.7065 (avg: 3.7874)\tTop1: 15.625 (avg: 17.000)\tTop5: 35.938 (avg: 39.812)\t\n",
            "Epoch: 62[50/125]\tTime used: 0.278 (avg: 0.278)\tLoss: 3.5463 (avg: 3.7813)\tTop1: 23.438 (avg: 17.625)\tTop5: 42.188 (avg: 39.250)\t\n",
            "Epoch: 62[75/125]\tTime used: 0.270 (avg: 0.279)\tLoss: 3.8318 (avg: 3.7683)\tTop1: 12.500 (avg: 17.521)\tTop5: 28.125 (avg: 39.896)\t\n",
            "Epoch: 62[100/125]\tTime used: 0.288 (avg: 0.280)\tLoss: 3.7765 (avg: 3.7742)\tTop1: 18.750 (avg: 16.984)\tTop5: 34.375 (avg: 39.703)\t\n",
            "Epoch: 62[125/125]\tTime used: 0.274 (avg: 0.281)\tLoss: 3.4641 (avg: 3.7806)\tTop1: 18.750 (avg: 16.963)\tTop5: 51.562 (avg: 39.825)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0017\tTop 1 accuracy: 10.550\tTop 5 accuracy: 29.350\n",
            "\n",
            "Training...\n",
            "Epoch: 63[25/125]\tTime used: 0.273 (avg: 0.276)\tLoss: 3.7904 (avg: 3.8100)\tTop1: 14.062 (avg: 17.188)\tTop5: 34.375 (avg: 39.688)\t\n",
            "Epoch: 63[50/125]\tTime used: 0.285 (avg: 0.279)\tLoss: 4.2136 (avg: 3.7620)\tTop1: 15.625 (avg: 16.875)\tTop5: 31.250 (avg: 39.938)\t\n",
            "Epoch: 63[75/125]\tTime used: 0.271 (avg: 0.279)\tLoss: 3.6911 (avg: 3.7683)\tTop1: 15.625 (avg: 16.875)\tTop5: 35.938 (avg: 40.062)\t\n",
            "Epoch: 63[100/125]\tTime used: 0.279 (avg: 0.280)\tLoss: 3.8052 (avg: 3.7810)\tTop1: 14.062 (avg: 16.703)\tTop5: 28.125 (avg: 39.578)\t\n",
            "Epoch: 63[125/125]\tTime used: 0.275 (avg: 0.280)\tLoss: 3.4154 (avg: 3.7732)\tTop1: 20.312 (avg: 16.838)\tTop5: 53.125 (avg: 40.125)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9217\tTop 1 accuracy: 11.350\tTop 5 accuracy: 29.800\n",
            "\n",
            "Training...\n",
            "Epoch: 64[25/125]\tTime used: 0.263 (avg: 0.272)\tLoss: 3.6482 (avg: 3.7274)\tTop1: 20.312 (avg: 17.875)\tTop5: 37.500 (avg: 40.750)\t\n",
            "Epoch: 64[50/125]\tTime used: 0.278 (avg: 0.277)\tLoss: 4.0245 (avg: 3.7499)\tTop1: 12.500 (avg: 17.281)\tTop5: 31.250 (avg: 40.156)\t\n",
            "Epoch: 64[75/125]\tTime used: 0.267 (avg: 0.278)\tLoss: 3.4457 (avg: 3.7335)\tTop1: 21.875 (avg: 17.208)\tTop5: 51.562 (avg: 40.729)\t\n",
            "Epoch: 64[100/125]\tTime used: 0.278 (avg: 0.279)\tLoss: 4.0551 (avg: 3.7477)\tTop1: 14.062 (avg: 17.250)\tTop5: 29.688 (avg: 40.125)\t\n",
            "Epoch: 64[125/125]\tTime used: 0.277 (avg: 0.279)\tLoss: 4.0414 (avg: 3.7692)\tTop1: 14.062 (avg: 16.875)\tTop5: 40.625 (avg: 39.575)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0475\tTop 1 accuracy: 11.050\tTop 5 accuracy: 30.050\n",
            "\n",
            "Training...\n",
            "Epoch: 65[25/125]\tTime used: 0.269 (avg: 0.274)\tLoss: 3.6229 (avg: 3.7502)\tTop1: 18.750 (avg: 17.625)\tTop5: 42.188 (avg: 41.188)\t\n",
            "Epoch: 65[50/125]\tTime used: 0.276 (avg: 0.277)\tLoss: 3.8743 (avg: 3.7444)\tTop1: 15.625 (avg: 17.469)\tTop5: 34.375 (avg: 40.906)\t\n",
            "Epoch: 65[75/125]\tTime used: 0.264 (avg: 0.278)\tLoss: 3.6458 (avg: 3.7509)\tTop1: 10.938 (avg: 17.396)\tTop5: 43.750 (avg: 40.021)\t\n",
            "Epoch: 65[100/125]\tTime used: 0.278 (avg: 0.279)\tLoss: 3.4695 (avg: 3.7676)\tTop1: 17.188 (avg: 16.875)\tTop5: 43.750 (avg: 39.953)\t\n",
            "Epoch: 65[125/125]\tTime used: 0.282 (avg: 0.279)\tLoss: 3.8559 (avg: 3.7749)\tTop1: 9.375 (avg: 16.812)\tTop5: 34.375 (avg: 39.725)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0433\tTop 1 accuracy: 10.950\tTop 5 accuracy: 30.250\n",
            "\n",
            "Training...\n",
            "Epoch: 66[25/125]\tTime used: 0.266 (avg: 0.273)\tLoss: 3.6957 (avg: 3.7159)\tTop1: 20.312 (avg: 17.625)\tTop5: 51.562 (avg: 41.188)\t\n",
            "Epoch: 66[50/125]\tTime used: 0.279 (avg: 0.277)\tLoss: 3.3807 (avg: 3.7412)\tTop1: 18.750 (avg: 17.250)\tTop5: 53.125 (avg: 40.094)\t\n",
            "Epoch: 66[75/125]\tTime used: 0.268 (avg: 0.278)\tLoss: 3.8124 (avg: 3.7559)\tTop1: 15.625 (avg: 16.938)\tTop5: 39.062 (avg: 40.333)\t\n",
            "Epoch: 66[100/125]\tTime used: 0.276 (avg: 0.279)\tLoss: 3.9739 (avg: 3.7737)\tTop1: 12.500 (avg: 16.609)\tTop5: 37.500 (avg: 39.906)\t\n",
            "Epoch: 66[125/125]\tTime used: 0.274 (avg: 0.279)\tLoss: 3.9801 (avg: 3.7686)\tTop1: 14.062 (avg: 16.825)\tTop5: 29.688 (avg: 40.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0598\tTop 1 accuracy: 11.100\tTop 5 accuracy: 30.550\n",
            "\n",
            "Training...\n",
            "Epoch: 67[25/125]\tTime used: 0.275 (avg: 0.283)\tLoss: 3.6902 (avg: 3.7162)\tTop1: 26.562 (avg: 18.250)\tTop5: 48.438 (avg: 41.125)\t\n",
            "Epoch: 67[50/125]\tTime used: 0.278 (avg: 0.282)\tLoss: 4.0640 (avg: 3.7423)\tTop1: 15.625 (avg: 17.469)\tTop5: 35.938 (avg: 40.688)\t\n",
            "Epoch: 67[75/125]\tTime used: 0.265 (avg: 0.282)\tLoss: 3.8178 (avg: 3.7691)\tTop1: 17.188 (avg: 16.938)\tTop5: 42.188 (avg: 39.479)\t\n",
            "Epoch: 67[100/125]\tTime used: 0.276 (avg: 0.281)\tLoss: 3.8915 (avg: 3.7668)\tTop1: 18.750 (avg: 16.984)\tTop5: 31.250 (avg: 39.703)\t\n",
            "Epoch: 67[125/125]\tTime used: 0.265 (avg: 0.281)\tLoss: 3.8220 (avg: 3.7641)\tTop1: 18.750 (avg: 17.100)\tTop5: 37.500 (avg: 39.800)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9893\tTop 1 accuracy: 11.100\tTop 5 accuracy: 29.950\n",
            "\n",
            "Training...\n",
            "Epoch: 68[25/125]\tTime used: 0.270 (avg: 0.276)\tLoss: 3.3113 (avg: 3.7929)\tTop1: 28.125 (avg: 16.375)\tTop5: 56.250 (avg: 39.375)\t\n",
            "Epoch: 68[50/125]\tTime used: 0.285 (avg: 0.281)\tLoss: 3.6015 (avg: 3.7747)\tTop1: 17.188 (avg: 16.500)\tTop5: 43.750 (avg: 39.969)\t\n",
            "Epoch: 68[75/125]\tTime used: 0.273 (avg: 0.281)\tLoss: 4.1286 (avg: 3.7820)\tTop1: 12.500 (avg: 16.583)\tTop5: 39.062 (avg: 39.812)\t\n",
            "Epoch: 68[100/125]\tTime used: 0.275 (avg: 0.281)\tLoss: 3.7334 (avg: 3.7815)\tTop1: 15.625 (avg: 16.719)\tTop5: 42.188 (avg: 39.797)\t\n",
            "Epoch: 68[125/125]\tTime used: 0.269 (avg: 0.281)\tLoss: 3.8836 (avg: 3.7631)\tTop1: 12.500 (avg: 17.038)\tTop5: 31.250 (avg: 40.150)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0576\tTop 1 accuracy: 11.800\tTop 5 accuracy: 30.150\n",
            "\n",
            "Training...\n",
            "Epoch: 69[25/125]\tTime used: 0.267 (avg: 0.276)\tLoss: 3.8596 (avg: 3.7364)\tTop1: 15.625 (avg: 17.625)\tTop5: 34.375 (avg: 39.438)\t\n",
            "Epoch: 69[50/125]\tTime used: 0.284 (avg: 0.279)\tLoss: 3.8344 (avg: 3.7342)\tTop1: 21.875 (avg: 17.250)\tTop5: 42.188 (avg: 40.188)\t\n",
            "Epoch: 69[75/125]\tTime used: 0.277 (avg: 0.280)\tLoss: 3.8763 (avg: 3.7422)\tTop1: 17.188 (avg: 17.208)\tTop5: 34.375 (avg: 40.521)\t\n",
            "Epoch: 69[100/125]\tTime used: 0.281 (avg: 0.280)\tLoss: 3.8207 (avg: 3.7520)\tTop1: 18.750 (avg: 17.234)\tTop5: 37.500 (avg: 40.156)\t\n",
            "Epoch: 69[125/125]\tTime used: 0.268 (avg: 0.280)\tLoss: 3.4418 (avg: 3.7541)\tTop1: 20.312 (avg: 17.163)\tTop5: 50.000 (avg: 40.050)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0857\tTop 1 accuracy: 10.900\tTop 5 accuracy: 29.800\n",
            "\n",
            "Training...\n",
            "Epoch: 70[25/125]\tTime used: 0.265 (avg: 0.277)\tLoss: 3.9902 (avg: 3.7379)\tTop1: 17.188 (avg: 17.625)\tTop5: 35.938 (avg: 40.875)\t\n",
            "Epoch: 70[50/125]\tTime used: 0.274 (avg: 0.278)\tLoss: 3.7202 (avg: 3.7635)\tTop1: 15.625 (avg: 16.969)\tTop5: 39.062 (avg: 40.062)\t\n",
            "Epoch: 70[75/125]\tTime used: 0.265 (avg: 0.278)\tLoss: 3.8156 (avg: 3.7480)\tTop1: 15.625 (avg: 17.333)\tTop5: 37.500 (avg: 40.292)\t\n",
            "Epoch: 70[100/125]\tTime used: 0.286 (avg: 0.279)\tLoss: 3.7625 (avg: 3.7552)\tTop1: 12.500 (avg: 17.203)\tTop5: 37.500 (avg: 40.094)\t\n",
            "Epoch: 70[125/125]\tTime used: 0.266 (avg: 0.279)\tLoss: 3.8290 (avg: 3.7565)\tTop1: 10.938 (avg: 17.300)\tTop5: 34.375 (avg: 40.213)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 3.9990\tTop 1 accuracy: 11.200\tTop 5 accuracy: 30.350\n",
            "\n",
            "Training...\n",
            "Epoch: 71[25/125]\tTime used: 0.264 (avg: 0.271)\tLoss: 3.8478 (avg: 3.7126)\tTop1: 15.625 (avg: 17.500)\tTop5: 37.500 (avg: 41.688)\t\n",
            "Epoch: 71[50/125]\tTime used: 0.277 (avg: 0.275)\tLoss: 3.5019 (avg: 3.7678)\tTop1: 25.000 (avg: 17.062)\tTop5: 53.125 (avg: 39.781)\t\n",
            "Epoch: 71[75/125]\tTime used: 0.278 (avg: 0.277)\tLoss: 3.5026 (avg: 3.7472)\tTop1: 20.312 (avg: 17.104)\tTop5: 42.188 (avg: 40.771)\t\n",
            "Epoch: 71[100/125]\tTime used: 0.279 (avg: 0.278)\tLoss: 3.6837 (avg: 3.7420)\tTop1: 15.625 (avg: 17.094)\tTop5: 46.875 (avg: 40.422)\t\n",
            "Epoch: 71[125/125]\tTime used: 0.264 (avg: 0.278)\tLoss: 3.8565 (avg: 3.7472)\tTop1: 15.625 (avg: 17.025)\tTop5: 35.938 (avg: 40.338)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0254\tTop 1 accuracy: 11.000\tTop 5 accuracy: 30.300\n",
            "\n",
            "Training...\n",
            "Epoch: 72[25/125]\tTime used: 0.272 (avg: 0.273)\tLoss: 3.5572 (avg: 3.7416)\tTop1: 14.062 (avg: 16.750)\tTop5: 45.312 (avg: 39.250)\t\n",
            "Epoch: 72[50/125]\tTime used: 0.277 (avg: 0.277)\tLoss: 3.8745 (avg: 3.7368)\tTop1: 17.188 (avg: 17.094)\tTop5: 32.812 (avg: 39.562)\t\n",
            "Epoch: 72[75/125]\tTime used: 0.272 (avg: 0.277)\tLoss: 3.6558 (avg: 3.7349)\tTop1: 17.188 (avg: 17.250)\tTop5: 43.750 (avg: 39.583)\t\n",
            "Epoch: 72[100/125]\tTime used: 0.284 (avg: 0.278)\tLoss: 3.8516 (avg: 3.7392)\tTop1: 15.625 (avg: 16.891)\tTop5: 32.812 (avg: 39.594)\t\n",
            "Epoch: 72[125/125]\tTime used: 0.273 (avg: 0.278)\tLoss: 3.4649 (avg: 3.7456)\tTop1: 20.312 (avg: 17.000)\tTop5: 53.125 (avg: 39.863)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0569\tTop 1 accuracy: 11.100\tTop 5 accuracy: 30.650\n",
            "\n",
            "Training...\n",
            "Epoch: 73[25/125]\tTime used: 0.269 (avg: 0.274)\tLoss: 3.7710 (avg: 3.7262)\tTop1: 15.625 (avg: 18.188)\tTop5: 48.438 (avg: 40.438)\t\n",
            "Epoch: 73[50/125]\tTime used: 0.283 (avg: 0.278)\tLoss: 3.6649 (avg: 3.7141)\tTop1: 20.312 (avg: 17.500)\tTop5: 46.875 (avg: 40.500)\t\n",
            "Epoch: 73[75/125]\tTime used: 0.277 (avg: 0.278)\tLoss: 3.5492 (avg: 3.7134)\tTop1: 20.312 (avg: 17.625)\tTop5: 45.312 (avg: 40.583)\t\n",
            "Epoch: 73[100/125]\tTime used: 0.277 (avg: 0.279)\tLoss: 3.9420 (avg: 3.7239)\tTop1: 12.500 (avg: 17.609)\tTop5: 29.688 (avg: 40.641)\t\n",
            "Epoch: 73[125/125]\tTime used: 0.270 (avg: 0.279)\tLoss: 3.5531 (avg: 3.7350)\tTop1: 21.875 (avg: 17.413)\tTop5: 46.875 (avg: 40.638)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0917\tTop 1 accuracy: 10.750\tTop 5 accuracy: 30.500\n",
            "\n",
            "Training...\n",
            "Epoch: 74[25/125]\tTime used: 0.267 (avg: 0.273)\tLoss: 3.9378 (avg: 3.7576)\tTop1: 18.750 (avg: 17.375)\tTop5: 32.812 (avg: 39.625)\t\n",
            "Epoch: 74[50/125]\tTime used: 0.283 (avg: 0.276)\tLoss: 3.8360 (avg: 3.7563)\tTop1: 14.062 (avg: 17.531)\tTop5: 34.375 (avg: 40.375)\t\n",
            "Epoch: 74[75/125]\tTime used: 0.268 (avg: 0.277)\tLoss: 3.7775 (avg: 3.7348)\tTop1: 20.312 (avg: 18.312)\tTop5: 35.938 (avg: 40.917)\t\n",
            "Epoch: 74[100/125]\tTime used: 0.274 (avg: 0.278)\tLoss: 3.7096 (avg: 3.7367)\tTop1: 15.625 (avg: 17.969)\tTop5: 43.750 (avg: 40.609)\t\n",
            "Epoch: 74[125/125]\tTime used: 0.264 (avg: 0.278)\tLoss: 3.9169 (avg: 3.7388)\tTop1: 20.312 (avg: 17.863)\tTop5: 31.250 (avg: 40.288)\t\n",
            "\n",
            "Validating...\n",
            "Loss: 4.0906\tTop 1 accuracy: 11.250\tTop 5 accuracy: 30.050\n",
            "\n",
            "freq = 4: top1 = 11.100000381469727 \t top5 = 30.650001525878906 \t batch_time = 0.25249379873275757\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U-YZm6fODZ5x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Downsampling"
      ]
    },
    {
      "metadata": {
        "id": "v8BW3MiEDYnp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "late_model = SqueezeNet_Late_Pooling(version=1.0)\n",
        "batch_time, top1, top5 = test_model(late_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PXfmbzWrDdZF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "very_early_model = SqueezeNet_Very_Early_Pooling(version=1.0)\n",
        "batch_time, top1, top5 = test_model(very_early_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aQCh2_XZGnLv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "semi_early_model = SqueezeNet_Semi_Early_Pooling(version=1.0)\n",
        "batch_time, top1, top5 = test_model(semi_early_model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}